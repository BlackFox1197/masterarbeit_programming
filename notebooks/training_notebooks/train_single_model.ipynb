{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 12:09:05.439421: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 12:09:05.891247: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-11 12:09:05.891303: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-11 12:09:05.891307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_model_conv import SSConvModel3Sec\n",
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import  SmallDimRed\n",
    "from network_models.soundsream_models_and_utils.ss_complex_conv_net import SSComplexConvModel3Sec\n",
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 12\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/\"\n",
    "#models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/3_5_sec_dimred/Nr1/\"\n",
    "trials_per_model_type = 2\n",
    "epochs = 1000\n",
    "save_highest_acc_min_acc = 0.5\n",
    "save_model_every = 50\n",
    "lr = 1e-4\n",
    "lr_quotient = 2\n",
    "gc.collect()\n",
    "#data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncs_betterSS_12_1_relwrap_music_tess.pkl\", device=\"cuda\")\n",
    "data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks_clip/content/datasets/mfcc/mfcc_dataset_3_5_sec.pkl\", device=device)\n",
    "#data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks_clip/content/datasets/soundstream_encoded/allEncodings_noInducednoStimuli_3_5_sec_v12_1_basic.pkl\", device=device)\n",
    "\n",
    "\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.2, seed=100)\n",
    "testDs, valDs = train_val_dataset(testDs, val_split=0.5, seed=100)\n",
    "torch.manual_seed(33333)\n",
    "#model = SSComplexConvModel3Sec().to(device)\n",
    "model = SmallDimRed(x_size=110).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_trainer_gen_models import SSGenModelTrainer\n",
    "\n",
    "trainer = SSGenModelTrainer(lr=lr, num_epochs=epochs, model=model, train_dataset=trainDS,\n",
    "                            eval_dataset=valDs,\n",
    "                            device=device, labelList=data_set.encoded_dataset.label_list,\n",
    "                            batch_size=batch_size,\n",
    "                            save_model_every=save_model_every,\n",
    "                            save_highest_acc_min_acc=save_highest_acc_min_acc,\n",
    "                            model_path = models_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.887752  [ 1200/ 4873]\n",
      "loss: 2.056283  [ 2400/ 4873]\n",
      "loss: 1.917265  [ 3600/ 4873]\n",
      "loss: 1.942188  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.177     0.292     0.400    105\n",
      " disgust     0.177     0.000     0.000    109\n",
      "    fear     0.177     0.109     0.062    80\n",
      "   happy     0.177     0.145     0.753    81\n",
      " neutral     0.177     0.000     0.000    84\n",
      "     sad     0.177     0.000     0.000    87\n",
      "surprise     0.177     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.177     0.078     0.174    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.7%, Avg loss: 1.921421 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.901522  [ 1200/ 4873]\n",
      "loss: 1.901947  [ 2400/ 4873]\n",
      "loss: 1.935531  [ 3600/ 4873]\n",
      "loss: 1.946076  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.148     0.295     0.419    105\n",
      " disgust     0.148     0.000     0.000    109\n",
      "    fear     0.148     0.054     0.075    80\n",
      "   happy     0.148     0.115     0.494    81\n",
      " neutral     0.148     0.000     0.000    84\n",
      "     sad     0.148     0.000     0.000    87\n",
      "surprise     0.148     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.148     0.066     0.141    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 14.8%, Avg loss: 1.893584 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.903742  [ 1200/ 4873]\n",
      "loss: 1.904604  [ 2400/ 4873]\n",
      "loss: 1.943089  [ 3600/ 4873]\n",
      "loss: 1.829348  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.226     0.274     0.714    105\n",
      " disgust     0.226     0.000     0.000    109\n",
      "    fear     0.226     0.118     0.075    80\n",
      "   happy     0.226     0.067     0.086    81\n",
      " neutral     0.226     0.000     0.000    84\n",
      "     sad     0.226     0.276     0.575    87\n",
      "surprise     0.226     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.226     0.105     0.207    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 22.6%, Avg loss: 1.880902 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.929885  [ 1200/ 4873]\n",
      "loss: 1.826489  [ 2400/ 4873]\n",
      "loss: 1.943212  [ 3600/ 4873]\n",
      "loss: 1.980884  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.225     0.315     0.486    105\n",
      " disgust     0.225     0.000     0.000    109\n",
      "    fear     0.225     0.096     0.138    80\n",
      "   happy     0.225     0.169     0.556    81\n",
      " neutral     0.225     0.000     0.000    84\n",
      "     sad     0.225     0.455     0.345    87\n",
      "surprise     0.225     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.225     0.148     0.218    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 22.5%, Avg loss: 1.880440 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.956694  [ 1200/ 4873]\n",
      "loss: 1.943047  [ 2400/ 4873]\n",
      "loss: 1.897441  [ 3600/ 4873]\n",
      "loss: 1.817960  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.266     0.371     0.505    105\n",
      " disgust     0.266     0.000     0.000    109\n",
      "    fear     0.266     0.113     0.113    80\n",
      "   happy     0.266     0.265     0.531    81\n",
      " neutral     0.266     0.000     0.000    84\n",
      "     sad     0.266     0.253     0.655    87\n",
      "surprise     0.266     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.266     0.143     0.258    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 26.6%, Avg loss: 1.843311 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.764854  [ 1200/ 4873]\n",
      "loss: 1.886837  [ 2400/ 4873]\n",
      "loss: 1.849350  [ 3600/ 4873]\n",
      "loss: 1.899765  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.290     0.364     0.524    105\n",
      " disgust     0.290     0.000     0.000    109\n",
      "    fear     0.290     0.172     0.275    80\n",
      "   happy     0.290     0.313     0.580    81\n",
      " neutral     0.290     0.000     0.000    84\n",
      "     sad     0.290     0.293     0.609    87\n",
      "surprise     0.290     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.290     0.163     0.284    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 29.0%, Avg loss: 1.827296 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.706218  [ 1200/ 4873]\n",
      "loss: 1.858471  [ 2400/ 4873]\n",
      "loss: 1.783155  [ 3600/ 4873]\n",
      "loss: 1.847243  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.256     0.363     0.590    105\n",
      " disgust     0.256     0.000     0.000    109\n",
      "    fear     0.256     0.108     0.163    80\n",
      "   happy     0.256     0.377     0.247    81\n",
      " neutral     0.256     0.000     0.000    84\n",
      "     sad     0.256     0.230     0.701    87\n",
      "surprise     0.256     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.256     0.154     0.243    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 25.6%, Avg loss: 1.828048 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.885041  [ 1200/ 4873]\n",
      "loss: 1.856867  [ 2400/ 4873]\n",
      "loss: 1.935679  [ 3600/ 4873]\n",
      "loss: 1.740690  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.266     0.314     0.619    105\n",
      " disgust     0.266     0.000     0.000    109\n",
      "    fear     0.266     0.146     0.275    80\n",
      "   happy     0.266     0.389     0.259    81\n",
      " neutral     0.266     0.000     0.000    84\n",
      "     sad     0.266     0.274     0.621    87\n",
      "surprise     0.266     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.266     0.160     0.253    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 26.6%, Avg loss: 1.810506 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.763777  [ 1200/ 4873]\n",
      "loss: 1.728021  [ 2400/ 4873]\n",
      "loss: 1.626241  [ 3600/ 4873]\n",
      "loss: 1.852886  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.270     0.417     0.429    105\n",
      " disgust     0.270     0.000     0.000    109\n",
      "    fear     0.270     0.135     0.250    80\n",
      "   happy     0.270     0.319     0.531    81\n",
      " neutral     0.270     0.000     0.000    84\n",
      "     sad     0.270     0.265     0.655    87\n",
      "surprise     0.270     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.270     0.162     0.266    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 27.0%, Avg loss: 1.786848 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.858274  [ 1200/ 4873]\n",
      "loss: 1.832144  [ 2400/ 4873]\n",
      "loss: 1.646816  [ 3600/ 4873]\n",
      "loss: 1.715627  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.279     0.377     0.381    105\n",
      " disgust     0.279     0.238     0.046    109\n",
      "    fear     0.279     0.168     0.375    80\n",
      "   happy     0.279     0.386     0.481    81\n",
      " neutral     0.279     0.000     0.000    84\n",
      "     sad     0.279     0.276     0.644    87\n",
      "surprise     0.279     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.279     0.206     0.275    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 27.9%, Avg loss: 1.781521 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.792064  [ 1200/ 4873]\n",
      "loss: 2.067652  [ 2400/ 4873]\n",
      "loss: 1.650370  [ 3600/ 4873]\n",
      "loss: 1.799451  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.287     0.345     0.467    105\n",
      " disgust     0.287     0.216     0.101    109\n",
      "    fear     0.287     0.144     0.275    80\n",
      "   happy     0.287     0.430     0.494    81\n",
      " neutral     0.287     0.000     0.000    84\n",
      "     sad     0.287     0.310     0.609    87\n",
      "surprise     0.287     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.287     0.206     0.278    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 1.763461 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.736130  [ 1200/ 4873]\n",
      "loss: 1.810460  [ 2400/ 4873]\n",
      "loss: 1.669619  [ 3600/ 4873]\n",
      "loss: 1.812148  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.262     0.310     0.457    105\n",
      " disgust     0.262     0.083     0.037    109\n",
      "    fear     0.262     0.133     0.237    80\n",
      "   happy     0.262     0.824     0.346    81\n",
      " neutral     0.262     0.000     0.000    84\n",
      "     sad     0.262     0.265     0.701    87\n",
      "surprise     0.262     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.262     0.231     0.254    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 1.763985 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.821157  [ 1200/ 4873]\n",
      "loss: 1.716613  [ 2400/ 4873]\n",
      "loss: 1.648608  [ 3600/ 4873]\n",
      "loss: 1.754702  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.293     0.293     0.438    105\n",
      " disgust     0.293     0.303     0.339    109\n",
      "    fear     0.293     0.200     0.275    80\n",
      "   happy     0.293     0.537     0.531    81\n",
      " neutral     0.293     0.000     0.000    84\n",
      "     sad     0.293     0.220     0.356    87\n",
      "surprise     0.293     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.293     0.222     0.277    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 29.3%, Avg loss: 1.735472 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.691531  [ 1200/ 4873]\n",
      "loss: 1.816168  [ 2400/ 4873]\n",
      "loss: 1.880774  [ 3600/ 4873]\n",
      "loss: 1.801636  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.320     0.309     0.448    105\n",
      " disgust     0.320     0.378     0.651    109\n",
      "    fear     0.320     0.209     0.175    80\n",
      "   happy     0.320     0.585     0.469    81\n",
      " neutral     0.320     0.000     0.000    84\n",
      "     sad     0.320     0.183     0.276    87\n",
      "surprise     0.320     0.143     0.016    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.320     0.258     0.291    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 32.0%, Avg loss: 1.755979 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.877939  [ 1200/ 4873]\n",
      "loss: 1.779417  [ 2400/ 4873]\n",
      "loss: 1.831412  [ 3600/ 4873]\n",
      "loss: 2.020381  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.300     0.288     0.486    105\n",
      " disgust     0.300     0.385     0.431    109\n",
      "    fear     0.300     0.134     0.188    80\n",
      "   happy     0.300     0.507     0.457    81\n",
      " neutral     0.300     0.000     0.000    84\n",
      "     sad     0.300     0.255     0.276    87\n",
      "surprise     0.300     0.281     0.141    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.300     0.264     0.283    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 30.0%, Avg loss: 1.727034 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.789797  [ 1200/ 4873]\n",
      "loss: 1.765586  [ 2400/ 4873]\n",
      "loss: 1.703213  [ 3600/ 4873]\n",
      "loss: 1.648399  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.282     0.289     0.438    105\n",
      " disgust     0.282     0.248     0.312    109\n",
      "    fear     0.282     0.180     0.138    80\n",
      "   happy     0.282     0.588     0.494    81\n",
      " neutral     0.282     0.000     0.000    84\n",
      "     sad     0.282     0.201     0.333    87\n",
      "surprise     0.282     0.293     0.188    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.282     0.257     0.272    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 28.2%, Avg loss: 1.715254 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.101015  [ 1200/ 4873]\n",
      "loss: 1.650714  [ 2400/ 4873]\n",
      "loss: 1.611809  [ 3600/ 4873]\n",
      "loss: 1.645737  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.302     0.278     0.448    105\n",
      " disgust     0.302     0.308     0.339    109\n",
      "    fear     0.302     0.213     0.125    80\n",
      "   happy     0.302     0.600     0.556    81\n",
      " neutral     0.302     0.000     0.000    84\n",
      "     sad     0.302     0.226     0.402    87\n",
      "surprise     0.302     0.227     0.156    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.302     0.265     0.289    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 30.2%, Avg loss: 1.696172 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.818588  [ 1200/ 4873]\n",
      "loss: 1.800657  [ 2400/ 4873]\n",
      "loss: 1.622272  [ 3600/ 4873]\n",
      "loss: 1.827133  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.298     0.275     0.419    105\n",
      " disgust     0.298     0.169     0.119    109\n",
      "    fear     0.298     0.192     0.175    80\n",
      "   happy     0.298     0.592     0.556    81\n",
      " neutral     0.298     0.000     0.000    84\n",
      "     sad     0.298     0.319     0.529    87\n",
      "surprise     0.298     0.250     0.312    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.298     0.257     0.301    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 29.8%, Avg loss: 1.686783 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.578674  [ 1200/ 4873]\n",
      "loss: 1.517993  [ 2400/ 4873]\n",
      "loss: 1.513692  [ 3600/ 4873]\n",
      "loss: 1.753480  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.330     0.329     0.438    105\n",
      " disgust     0.330     0.224     0.138    109\n",
      "    fear     0.330     0.216     0.100    80\n",
      "   happy     0.330     0.538     0.519    81\n",
      " neutral     0.330     0.000     0.000    84\n",
      "     sad     0.330     0.275     0.609    87\n",
      "surprise     0.330     0.389     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.330     0.282     0.340    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.0%, Avg loss: 1.683109 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.602638  [ 1200/ 4873]\n",
      "loss: 1.888273  [ 2400/ 4873]\n",
      "loss: 1.509963  [ 3600/ 4873]\n",
      "loss: 1.451342  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.334     0.292     0.429    105\n",
      " disgust     0.334     0.202     0.174    109\n",
      "    fear     0.334     0.273     0.150    80\n",
      "   happy     0.334     0.597     0.568    81\n",
      " neutral     0.334     0.000     0.000    84\n",
      "     sad     0.334     0.325     0.609    87\n",
      "surprise     0.334     0.372     0.453    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.334     0.294     0.340    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.4%, Avg loss: 1.679062 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.452769  [ 1200/ 4873]\n",
      "loss: 1.720052  [ 2400/ 4873]\n",
      "loss: 1.373572  [ 3600/ 4873]\n",
      "loss: 1.677375  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.331     0.315     0.381    105\n",
      " disgust     0.331     0.181     0.119    109\n",
      "    fear     0.331     0.375     0.113    80\n",
      "   happy     0.331     0.452     0.580    81\n",
      " neutral     0.331     0.000     0.000    84\n",
      "     sad     0.331     0.283     0.667    87\n",
      "surprise     0.331     0.449     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.331     0.293     0.344    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 1.681368 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.922297  [ 1200/ 4873]\n",
      "loss: 1.722794  [ 2400/ 4873]\n",
      "loss: 1.822214  [ 3600/ 4873]\n",
      "loss: 1.724566  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.320     0.304     0.457    105\n",
      " disgust     0.320     0.222     0.110    109\n",
      "    fear     0.320     0.244     0.125    80\n",
      "   happy     0.320     0.450     0.605    81\n",
      " neutral     0.320     0.000     0.000    84\n",
      "     sad     0.320     0.321     0.621    87\n",
      "surprise     0.320     0.275     0.344    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.320     0.259     0.323    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 32.0%, Avg loss: 1.672877 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.645779  [ 1200/ 4873]\n",
      "loss: 1.439733  [ 2400/ 4873]\n",
      "loss: 1.769117  [ 3600/ 4873]\n",
      "loss: 1.835059  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.338     0.319     0.343    105\n",
      " disgust     0.338     0.189     0.128    109\n",
      "    fear     0.338     0.300     0.113    80\n",
      "   happy     0.338     0.475     0.580    81\n",
      " neutral     0.338     0.000     0.000    84\n",
      "     sad     0.338     0.282     0.655    87\n",
      "surprise     0.338     0.467     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.338     0.290     0.356    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.8%, Avg loss: 1.665271 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.489524  [ 1200/ 4873]\n",
      "loss: 1.901494  [ 2400/ 4873]\n",
      "loss: 1.644137  [ 3600/ 4873]\n",
      "loss: 1.636545  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.325     0.314     0.419    105\n",
      " disgust     0.325     0.214     0.110    109\n",
      "    fear     0.325     0.222     0.100    80\n",
      "   happy     0.325     0.541     0.568    81\n",
      " neutral     0.325     0.000     0.000    84\n",
      "     sad     0.325     0.283     0.586    87\n",
      "surprise     0.325     0.327     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.325     0.272     0.337    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 32.5%, Avg loss: 1.654093 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.711592  [ 1200/ 4873]\n",
      "loss: 1.451539  [ 2400/ 4873]\n",
      "loss: 1.530508  [ 3600/ 4873]\n",
      "loss: 1.969581  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.333     0.338     0.429    105\n",
      " disgust     0.333     0.217     0.138    109\n",
      "    fear     0.333     0.350     0.087    80\n",
      "   happy     0.333     0.439     0.580    81\n",
      " neutral     0.333     0.000     0.000    84\n",
      "     sad     0.333     0.313     0.483    87\n",
      "surprise     0.333     0.320     0.734    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.333     0.283     0.350    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.3%, Avg loss: 1.652279 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.939134  [ 1200/ 4873]\n",
      "loss: 1.467914  [ 2400/ 4873]\n",
      "loss: 1.675308  [ 3600/ 4873]\n",
      "loss: 1.553426  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.338     0.311     0.448    105\n",
      " disgust     0.338     0.265     0.119    109\n",
      "    fear     0.338     0.188     0.113    80\n",
      "   happy     0.338     0.479     0.568    81\n",
      " neutral     0.338     0.000     0.000    84\n",
      "     sad     0.338     0.351     0.598    87\n",
      "surprise     0.338     0.331     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.338     0.275     0.351    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.8%, Avg loss: 1.642534 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.518280  [ 1200/ 4873]\n",
      "loss: 1.703492  [ 2400/ 4873]\n",
      "loss: 1.811747  [ 3600/ 4873]\n",
      "loss: 1.741834  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.336     0.309     0.410    105\n",
      " disgust     0.336     0.167     0.046    109\n",
      "    fear     0.336     0.257     0.113    80\n",
      "   happy     0.336     0.500     0.568    81\n",
      " neutral     0.336     0.000     0.000    84\n",
      "     sad     0.336     0.314     0.632    87\n",
      "surprise     0.336     0.338     0.734    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.336     0.269     0.357    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 1.630343 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.456762  [ 1200/ 4873]\n",
      "loss: 1.302081  [ 2400/ 4873]\n",
      "loss: 1.586341  [ 3600/ 4873]\n",
      "loss: 1.790130  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.331     0.351     0.371    105\n",
      " disgust     0.331     0.159     0.064    109\n",
      "    fear     0.331     0.294     0.125    80\n",
      "   happy     0.331     0.453     0.593    81\n",
      " neutral     0.331     0.000     0.000    84\n",
      "     sad     0.331     0.289     0.632    87\n",
      "surprise     0.331     0.344     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.331     0.270     0.351    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 1.641446 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.634097  [ 1200/ 4873]\n",
      "loss: 1.539481  [ 2400/ 4873]\n",
      "loss: 1.534164  [ 3600/ 4873]\n",
      "loss: 1.655091  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.336     0.365     0.333    105\n",
      " disgust     0.336     0.197     0.110    109\n",
      "    fear     0.336     0.303     0.125    80\n",
      "   happy     0.336     0.489     0.568    81\n",
      " neutral     0.336     0.000     0.000    84\n",
      "     sad     0.336     0.288     0.701    87\n",
      "surprise     0.336     0.360     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.336     0.286     0.354    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 1.648568 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.572965  [ 1200/ 4873]\n",
      "loss: 1.690289  [ 2400/ 4873]\n",
      "loss: 1.356577  [ 3600/ 4873]\n",
      "loss: 1.714524  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.331     0.323     0.381    105\n",
      " disgust     0.331     0.220     0.083    109\n",
      "    fear     0.331     0.196     0.113    80\n",
      "   happy     0.331     0.562     0.556    81\n",
      " neutral     0.331     0.000     0.000    84\n",
      "     sad     0.331     0.267     0.667    87\n",
      "surprise     0.331     0.402     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.331     0.281     0.348    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 1.635039 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.795803  [ 1200/ 4873]\n",
      "loss: 1.813670  [ 2400/ 4873]\n",
      "loss: 1.591270  [ 3600/ 4873]\n",
      "loss: 1.708296  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.351     0.325     0.371    105\n",
      " disgust     0.351     0.271     0.147    109\n",
      "    fear     0.351     0.258     0.100    80\n",
      "   happy     0.351     0.517     0.556    81\n",
      " neutral     0.351     0.333     0.012    84\n",
      "     sad     0.351     0.301     0.575    87\n",
      "surprise     0.351     0.382     0.859    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.351     0.341     0.374    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 1.622285 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.707757  [ 1200/ 4873]\n",
      "loss: 1.647260  [ 2400/ 4873]\n",
      "loss: 1.591501  [ 3600/ 4873]\n",
      "loss: 1.552725  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.315     0.356     0.400    105\n",
      " disgust     0.315     0.097     0.028    109\n",
      "    fear     0.315     0.176     0.150    80\n",
      "   happy     0.315     0.569     0.506    81\n",
      " neutral     0.315     0.444     0.048    84\n",
      "     sad     0.315     0.287     0.552    87\n",
      "surprise     0.315     0.290     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.315     0.317     0.334    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 31.5%, Avg loss: 1.633447 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.609057  [ 1200/ 4873]\n",
      "loss: 1.547167  [ 2400/ 4873]\n",
      "loss: 1.875144  [ 3600/ 4873]\n",
      "loss: 1.665337  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.336     0.291     0.305    105\n",
      " disgust     0.336     0.214     0.083    109\n",
      "    fear     0.336     0.156     0.062    80\n",
      "   happy     0.336     0.412     0.605    81\n",
      " neutral     0.336     0.286     0.024    84\n",
      "     sad     0.336     0.322     0.678    87\n",
      "surprise     0.336     0.419     0.766    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.336     0.300     0.360    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 1.627584 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.508188  [ 1200/ 4873]\n",
      "loss: 1.558614  [ 2400/ 4873]\n",
      "loss: 1.394253  [ 3600/ 4873]\n",
      "loss: 1.409362  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.334     0.369     0.362    105\n",
      " disgust     0.334     0.143     0.037    109\n",
      "    fear     0.334     0.208     0.062    80\n",
      "   happy     0.334     0.364     0.593    81\n",
      " neutral     0.334     0.826     0.226    84\n",
      "     sad     0.334     0.322     0.529    87\n",
      "surprise     0.334     0.280     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.334     0.359     0.357    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.4%, Avg loss: 1.632066 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.605161  [ 1200/ 4873]\n",
      "loss: 1.518864  [ 2400/ 4873]\n",
      "loss: 1.663028  [ 3600/ 4873]\n",
      "loss: 1.412073  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.370     0.373     0.362    105\n",
      " disgust     0.370     0.222     0.073    109\n",
      "    fear     0.370     0.256     0.138    80\n",
      "   happy     0.370     0.539     0.593    81\n",
      " neutral     0.370     0.680     0.202    84\n",
      "     sad     0.370     0.310     0.609    87\n",
      "surprise     0.370     0.354     0.797    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.370     0.391     0.396    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 1.601224 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.421289  [ 1200/ 4873]\n",
      "loss: 1.597599  [ 2400/ 4873]\n",
      "loss: 1.756167  [ 3600/ 4873]\n",
      "loss: 1.441886  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.392     0.474     0.343    105\n",
      " disgust     0.392     0.267     0.037    109\n",
      "    fear     0.392     0.243     0.113    80\n",
      "   happy     0.392     0.552     0.593    81\n",
      " neutral     0.392     0.881     0.440    84\n",
      "     sad     0.392     0.270     0.667    87\n",
      "surprise     0.392     0.341     0.734    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.392     0.432     0.418    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.2%, Avg loss: 1.628615 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.247218  [ 1200/ 4873]\n",
      "loss: 1.386360  [ 2400/ 4873]\n",
      "loss: 2.067111  [ 3600/ 4873]\n",
      "loss: 1.489334  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.392     0.500     0.400    105\n",
      " disgust     0.392     0.182     0.037    109\n",
      "    fear     0.392     0.204     0.138    80\n",
      "   happy     0.392     0.630     0.568    81\n",
      " neutral     0.392     0.722     0.464    84\n",
      "     sad     0.392     0.283     0.644    87\n",
      "surprise     0.392     0.328     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.392     0.407     0.413    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.2%, Avg loss: 1.606192 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.453397  [ 1200/ 4873]\n",
      "loss: 1.431596  [ 2400/ 4873]\n",
      "loss: 1.337083  [ 3600/ 4873]\n",
      "loss: 1.647272  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.389     0.507     0.352    105\n",
      " disgust     0.389     0.250     0.037    109\n",
      "    fear     0.389     0.213     0.125    80\n",
      "   happy     0.389     0.490     0.580    81\n",
      " neutral     0.389     0.741     0.512    84\n",
      "     sad     0.389     0.295     0.644    87\n",
      "surprise     0.389     0.308     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.389     0.400     0.411    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 38.9%, Avg loss: 1.599005 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.489640  [ 1200/ 4873]\n",
      "loss: 1.210389  [ 2400/ 4873]\n",
      "loss: 1.522241  [ 3600/ 4873]\n",
      "loss: 1.301696  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.397     0.462     0.410    105\n",
      " disgust     0.397     0.421     0.073    109\n",
      "    fear     0.397     0.204     0.138    80\n",
      "   happy     0.397     0.652     0.531    81\n",
      " neutral     0.397     0.860     0.512    84\n",
      "     sad     0.397     0.271     0.598    87\n",
      "surprise     0.397     0.309     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.397     0.454     0.417    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.595759 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.965867  [ 1200/ 4873]\n",
      "loss: 1.655483  [ 2400/ 4873]\n",
      "loss: 1.462855  [ 3600/ 4873]\n",
      "loss: 1.679691  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.415     0.474     0.352    105\n",
      " disgust     0.415     0.231     0.028    109\n",
      "    fear     0.415     0.273     0.113    80\n",
      "   happy     0.415     0.614     0.531    81\n",
      " neutral     0.415     0.634     0.619    84\n",
      "     sad     0.415     0.306     0.655    87\n",
      "surprise     0.415     0.351     0.812    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.415     0.412     0.444    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 1.589817 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.216825  [ 1200/ 4873]\n",
      "loss: 1.430923  [ 2400/ 4873]\n",
      "loss: 1.812699  [ 3600/ 4873]\n",
      "loss: 1.530438  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.403     0.514     0.352    105\n",
      " disgust     0.403     0.200     0.018    109\n",
      "    fear     0.403     0.231     0.113    80\n",
      "   happy     0.403     0.392     0.580    81\n",
      " neutral     0.403     0.789     0.536    84\n",
      "     sad     0.403     0.316     0.678    87\n",
      "surprise     0.403     0.376     0.734    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.403     0.402     0.430    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 1.582144 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.234032  [ 1200/ 4873]\n",
      "loss: 1.451003  [ 2400/ 4873]\n",
      "loss: 1.286191  [ 3600/ 4873]\n",
      "loss: 1.742687  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.395     0.506     0.371    105\n",
      " disgust     0.395     0.250     0.009    109\n",
      "    fear     0.395     0.208     0.138    80\n",
      "   happy     0.395     0.431     0.580    81\n",
      " neutral     0.395     0.865     0.536    84\n",
      "     sad     0.395     0.281     0.713    87\n",
      "surprise     0.395     0.383     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.395     0.418     0.416    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.589446 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.464454  [ 1200/ 4873]\n",
      "loss: 1.660599  [ 2400/ 4873]\n",
      "loss: 1.320122  [ 3600/ 4873]\n",
      "loss: 1.681792  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.395     0.484     0.295    105\n",
      " disgust     0.395     0.333     0.009    109\n",
      "    fear     0.395     0.244     0.125    80\n",
      "   happy     0.395     0.426     0.642    81\n",
      " neutral     0.395     0.818     0.536    84\n",
      "     sad     0.395     0.266     0.736    87\n",
      "surprise     0.395     0.452     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.395     0.432     0.419    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.591160 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.652833  [ 1200/ 4873]\n",
      "loss: 1.512764  [ 2400/ 4873]\n",
      "loss: 1.677049  [ 3600/ 4873]\n",
      "loss: 1.420323  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.397     0.487     0.352    105\n",
      " disgust     0.397     0.400     0.018    109\n",
      "    fear     0.397     0.238     0.125    80\n",
      "   happy     0.397     0.461     0.580    81\n",
      " neutral     0.397     0.742     0.548    84\n",
      "     sad     0.397     0.282     0.655    87\n",
      "surprise     0.397     0.355     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.397     0.424     0.422    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.578522 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.632571  [ 1200/ 4873]\n",
      "loss: 1.484493  [ 2400/ 4873]\n",
      "loss: 1.406774  [ 3600/ 4873]\n",
      "loss: 1.291690  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.375     0.507     0.352    105\n",
      " disgust     0.375     0.200     0.009    109\n",
      "    fear     0.375     0.176     0.113    80\n",
      "   happy     0.375     0.389     0.630    81\n",
      " neutral     0.375     0.662     0.536    84\n",
      "     sad     0.375     0.270     0.575    87\n",
      "surprise     0.375     0.371     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.375     0.368     0.397    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 1.584170 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.574699  [ 1200/ 4873]\n",
      "loss: 1.618396  [ 2400/ 4873]\n",
      "loss: 1.127392  [ 3600/ 4873]\n",
      "loss: 1.431641  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.390     0.474     0.352    105\n",
      " disgust     0.390     0.250     0.009    109\n",
      "    fear     0.390     0.191     0.113    80\n",
      "   happy     0.390     0.382     0.642    81\n",
      " neutral     0.390     0.714     0.536    84\n",
      "     sad     0.390     0.295     0.621    87\n",
      "surprise     0.390     0.404     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.390     0.387     0.414    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 1.575644 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.446722  [ 1200/ 4873]\n",
      "loss: 1.661559  [ 2400/ 4873]\n",
      "loss: 1.274217  [ 3600/ 4873]\n",
      "loss: 1.551402  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.413     0.481     0.352    105\n",
      " disgust     0.413     0.308     0.037    109\n",
      "    fear     0.413     0.238     0.125    80\n",
      "   happy     0.413     0.475     0.593    81\n",
      " neutral     0.413     0.636     0.583    84\n",
      "     sad     0.413     0.307     0.632    87\n",
      "surprise     0.413     0.405     0.766    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.413     0.407     0.441    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 1.557565 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.599307  [ 1200/ 4873]\n",
      "loss: 1.843858  [ 2400/ 4873]\n",
      "loss: 1.616437  [ 3600/ 4873]\n",
      "loss: 1.541164  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.395     0.514     0.362    105\n",
      " disgust     0.395     0.200     0.009    109\n",
      "    fear     0.395     0.286     0.150    80\n",
      "   happy     0.395     0.374     0.642    81\n",
      " neutral     0.395     0.821     0.548    84\n",
      "     sad     0.395     0.260     0.586    87\n",
      "surprise     0.395     0.418     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.395     0.410     0.420    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.563149 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.309803  [ 1200/ 4873]\n",
      "loss: 1.463204  [ 2400/ 4873]\n",
      "loss: 1.534572  [ 3600/ 4873]\n",
      "loss: 1.348341  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.398     0.494     0.362    105\n",
      " disgust     0.398     0.357     0.046    109\n",
      "    fear     0.398     0.239     0.138    80\n",
      "   happy     0.398     0.412     0.605    81\n",
      " neutral     0.398     0.870     0.560    84\n",
      "     sad     0.398     0.251     0.621    87\n",
      "surprise     0.398     0.459     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.398     0.440     0.420    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 1.566507 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.473239  [ 1200/ 4873]\n",
      "loss: 1.479019  [ 2400/ 4873]\n",
      "loss: 1.389672  [ 3600/ 4873]\n",
      "loss: 1.736065  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.397     0.494     0.381    105\n",
      " disgust     0.397     0.250     0.018    109\n",
      "    fear     0.397     0.224     0.138    80\n",
      "   happy     0.397     0.365     0.667    81\n",
      " neutral     0.397     0.635     0.560    84\n",
      "     sad     0.397     0.307     0.540    87\n",
      "surprise     0.397     0.423     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.397     0.385     0.421    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.576198 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.342127  [ 1200/ 4873]\n",
      "loss: 1.117196  [ 2400/ 4873]\n",
      "loss: 1.436975  [ 3600/ 4873]\n",
      "loss: 1.796127  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.395     0.524     0.314    105\n",
      " disgust     0.395     0.625     0.046    109\n",
      "    fear     0.395     0.220     0.138    80\n",
      "   happy     0.395     0.393     0.654    81\n",
      " neutral     0.395     0.750     0.571    84\n",
      "     sad     0.395     0.269     0.621    87\n",
      "surprise     0.395     0.416     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.395     0.457     0.417    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.558357 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.271672  [ 1200/ 4873]\n",
      "loss: 1.557396  [ 2400/ 4873]\n",
      "loss: 1.636988  [ 3600/ 4873]\n",
      "loss: 1.546551  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.408     0.553     0.400    105\n",
      " disgust     0.408     0.100     0.009    109\n",
      "    fear     0.408     0.211     0.188    80\n",
      "   happy     0.408     0.464     0.630    81\n",
      " neutral     0.408     0.640     0.571    84\n",
      "     sad     0.408     0.287     0.529    87\n",
      "surprise     0.408     0.426     0.719    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.408     0.383     0.435    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.545533 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 1.512914  [ 1200/ 4873]\n",
      "loss: 1.246217  [ 2400/ 4873]\n",
      "loss: 1.493547  [ 3600/ 4873]\n",
      "loss: 1.418955  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.403     0.534     0.371    105\n",
      " disgust     0.403     0.333     0.018    109\n",
      "    fear     0.403     0.227     0.125    80\n",
      "   happy     0.403     0.324     0.704    81\n",
      " neutral     0.403     0.694     0.595    84\n",
      "     sad     0.403     0.313     0.540    87\n",
      "surprise     0.403     0.461     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.403     0.412     0.428    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 1.530276 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.184096  [ 1200/ 4873]\n",
      "loss: 1.439811  [ 2400/ 4873]\n",
      "loss: 1.610657  [ 3600/ 4873]\n",
      "loss: 1.120418  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.397     0.500     0.324    105\n",
      " disgust     0.397     0.250     0.028    109\n",
      "    fear     0.397     0.222     0.175    80\n",
      "   happy     0.397     0.410     0.679    81\n",
      " neutral     0.397     0.833     0.536    84\n",
      "     sad     0.397     0.263     0.621    87\n",
      "surprise     0.397     0.500     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.397     0.426     0.420    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.547069 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 1.291863  [ 1200/ 4873]\n",
      "loss: 1.748443  [ 2400/ 4873]\n",
      "loss: 1.282697  [ 3600/ 4873]\n",
      "loss: 1.148212  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.408     0.519     0.400    105\n",
      " disgust     0.408     0.188     0.028    109\n",
      "    fear     0.408     0.229     0.200    80\n",
      "   happy     0.408     0.480     0.580    81\n",
      " neutral     0.408     0.649     0.571    84\n",
      "     sad     0.408     0.296     0.540    87\n",
      "surprise     0.408     0.411     0.719    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.408     0.396     0.434    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.526665 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.217182  [ 1200/ 4873]\n",
      "loss: 1.790894  [ 2400/ 4873]\n",
      "loss: 1.447383  [ 3600/ 4873]\n",
      "loss: 1.474168  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.398     0.538     0.400    105\n",
      " disgust     0.398     0.167     0.009    109\n",
      "    fear     0.398     0.169     0.163    80\n",
      "   happy     0.398     0.481     0.617    81\n",
      " neutral     0.398     0.590     0.583    84\n",
      "     sad     0.398     0.291     0.586    87\n",
      "surprise     0.398     0.425     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.398     0.380     0.420    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 1.550800 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 1.192218  [ 1200/ 4873]\n",
      "loss: 1.157421  [ 2400/ 4873]\n",
      "loss: 1.279362  [ 3600/ 4873]\n",
      "loss: 1.209758  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.403     0.522     0.343    105\n",
      " disgust     0.403     0.053     0.009    109\n",
      "    fear     0.403     0.186     0.163    80\n",
      "   happy     0.403     0.528     0.580    81\n",
      " neutral     0.403     0.817     0.583    84\n",
      "     sad     0.403     0.267     0.644    87\n",
      "surprise     0.403     0.473     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.403     0.406     0.430    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 1.522163 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.618075  [ 1200/ 4873]\n",
      "loss: 1.027495  [ 2400/ 4873]\n",
      "loss: 1.471744  [ 3600/ 4873]\n",
      "loss: 1.235364  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.395     0.521     0.362    105\n",
      " disgust     0.395     0.217     0.046    109\n",
      "    fear     0.395     0.253     0.250    80\n",
      "   happy     0.395     0.459     0.617    81\n",
      " neutral     0.395     0.836     0.548    84\n",
      "     sad     0.395     0.256     0.575    87\n",
      "surprise     0.395     0.421     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.395     0.423     0.414    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.521587 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 1.466521  [ 1200/ 4873]\n",
      "loss: 1.150487  [ 2400/ 4873]\n",
      "loss: 1.360865  [ 3600/ 4873]\n",
      "loss: 1.833583  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.413     0.560     0.400    105\n",
      " disgust     0.413     0.235     0.037    109\n",
      "    fear     0.413     0.286     0.200    80\n",
      "   happy     0.413     0.361     0.593    81\n",
      " neutral     0.413     0.671     0.583    84\n",
      "     sad     0.413     0.316     0.563    87\n",
      "surprise     0.413     0.436     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.413     0.409     0.438    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 1.505074 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 1.520475  [ 1200/ 4873]\n",
      "loss: 1.181945  [ 2400/ 4873]\n",
      "loss: 1.242850  [ 3600/ 4873]\n",
      "loss: 1.430064  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.418     0.532     0.400    105\n",
      " disgust     0.418     0.312     0.046    109\n",
      "    fear     0.418     0.277     0.225    80\n",
      "   happy     0.418     0.357     0.679    81\n",
      " neutral     0.418     0.703     0.619    84\n",
      "     sad     0.418     0.323     0.471    87\n",
      "surprise     0.418     0.442     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.418     0.421     0.442    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.8%, Avg loss: 1.519723 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.129659  [ 1200/ 4873]\n",
      "loss: 1.361117  [ 2400/ 4873]\n",
      "loss: 1.287265  [ 3600/ 4873]\n",
      "loss: 1.303249  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.413     0.488     0.390    105\n",
      " disgust     0.413     0.238     0.046    109\n",
      "    fear     0.413     0.259     0.175    80\n",
      "   happy     0.413     0.455     0.630    81\n",
      " neutral     0.413     0.634     0.619    84\n",
      "     sad     0.413     0.296     0.552    87\n",
      "surprise     0.413     0.432     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.413     0.400     0.436    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 1.494826 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 1.102600  [ 1200/ 4873]\n",
      "loss: 1.298670  [ 2400/ 4873]\n",
      "loss: 1.035527  [ 3600/ 4873]\n",
      "loss: 1.371801  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.436     0.573     0.410    105\n",
      " disgust     0.436     0.357     0.092    109\n",
      "    fear     0.436     0.261     0.287    80\n",
      "   happy     0.436     0.480     0.580    81\n",
      " neutral     0.436     0.810     0.560    84\n",
      "     sad     0.436     0.310     0.598    87\n",
      "surprise     0.436     0.463     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.436     0.465     0.459    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.488099 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.164849  [ 1200/ 4873]\n",
      "loss: 1.270045  [ 2400/ 4873]\n",
      "loss: 0.974203  [ 3600/ 4873]\n",
      "loss: 1.067883  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.431     0.500     0.429    105\n",
      " disgust     0.431     0.304     0.064    109\n",
      "    fear     0.431     0.309     0.263    80\n",
      "   happy     0.431     0.465     0.580    81\n",
      " neutral     0.431     0.675     0.667    84\n",
      "     sad     0.431     0.294     0.540    87\n",
      "surprise     0.431     0.471     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.431     0.431     0.452    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 1.498793 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 1.224232  [ 1200/ 4873]\n",
      "loss: 1.245583  [ 2400/ 4873]\n",
      "loss: 1.721293  [ 3600/ 4873]\n",
      "loss: 1.210947  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.415     0.438     0.400    105\n",
      " disgust     0.415     0.387     0.110    109\n",
      "    fear     0.415     0.219     0.287    80\n",
      "   happy     0.415     0.522     0.580    81\n",
      " neutral     0.415     0.766     0.583    84\n",
      "     sad     0.415     0.329     0.552    87\n",
      "surprise     0.415     0.410     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.415     0.439     0.430    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 1.534552 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.311167  [ 1200/ 4873]\n",
      "loss: 1.534501  [ 2400/ 4873]\n",
      "loss: 1.356652  [ 3600/ 4873]\n",
      "loss: 1.212386  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.418     0.532     0.400    105\n",
      " disgust     0.418     0.192     0.046    109\n",
      "    fear     0.418     0.271     0.200    80\n",
      "   happy     0.418     0.402     0.605    81\n",
      " neutral     0.418     0.750     0.607    84\n",
      "     sad     0.418     0.289     0.552    87\n",
      "surprise     0.418     0.489     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.418     0.418     0.442    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.8%, Avg loss: 1.484092 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 1.788392  [ 1200/ 4873]\n",
      "loss: 1.206758  [ 2400/ 4873]\n",
      "loss: 1.498465  [ 3600/ 4873]\n",
      "loss: 1.512984  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.400     0.565     0.333    105\n",
      " disgust     0.400     0.182     0.018    109\n",
      "    fear     0.400     0.227     0.125    80\n",
      "   happy     0.400     0.345     0.605    81\n",
      " neutral     0.400     0.683     0.667    84\n",
      "     sad     0.400     0.281     0.621    87\n",
      "surprise     0.400     0.494     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.400     0.397     0.423    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 1.508573 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 1.635715  [ 1200/ 4873]\n",
      "loss: 1.270144  [ 2400/ 4873]\n",
      "loss: 1.359005  [ 3600/ 4873]\n",
      "loss: 1.490170  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.448     0.506     0.419    105\n",
      " disgust     0.448     0.429     0.083    109\n",
      "    fear     0.448     0.349     0.362    80\n",
      "   happy     0.448     0.595     0.580    81\n",
      " neutral     0.448     0.605     0.619    84\n",
      "     sad     0.448     0.301     0.494    87\n",
      "surprise     0.448     0.441     0.766    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.448     0.461     0.475    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.520017 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.487541  [ 1200/ 4873]\n",
      "loss: 1.291757  [ 2400/ 4873]\n",
      "loss: 1.337024  [ 3600/ 4873]\n",
      "loss: 1.686146  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.444     0.603     0.390    105\n",
      " disgust     0.444     0.364     0.110    109\n",
      "    fear     0.444     0.455     0.375    80\n",
      "   happy     0.444     0.364     0.630    81\n",
      " neutral     0.444     0.718     0.607    84\n",
      "     sad     0.444     0.325     0.471    87\n",
      "surprise     0.444     0.425     0.703    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.444     0.465     0.470    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.477143 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 1.196901  [ 1200/ 4873]\n",
      "loss: 1.845290  [ 2400/ 4873]\n",
      "loss: 1.348565  [ 3600/ 4873]\n",
      "loss: 1.403903  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.448     0.600     0.429    105\n",
      " disgust     0.448     0.222     0.055    109\n",
      "    fear     0.448     0.430     0.463    80\n",
      "   happy     0.448     0.460     0.642    81\n",
      " neutral     0.448     0.690     0.583    84\n",
      "     sad     0.448     0.289     0.529    87\n",
      "surprise     0.448     0.481     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.448     0.453     0.471    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.489251 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 1.111786  [ 1200/ 4873]\n",
      "loss: 1.363141  [ 2400/ 4873]\n",
      "loss: 1.058139  [ 3600/ 4873]\n",
      "loss: 1.634012  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.451     0.600     0.429    105\n",
      " disgust     0.451     0.357     0.046    109\n",
      "    fear     0.451     0.490     0.312    80\n",
      "   happy     0.451     0.432     0.630    81\n",
      " neutral     0.451     0.644     0.690    84\n",
      "     sad     0.451     0.295     0.529    87\n",
      "surprise     0.451     0.425     0.703    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.451     0.463     0.477    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.468208 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 1.171824  [ 1200/ 4873]\n",
      "loss: 1.205354  [ 2400/ 4873]\n",
      "loss: 1.136830  [ 3600/ 4873]\n",
      "loss: 1.189711  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.431     0.577     0.390    105\n",
      " disgust     0.431     0.231     0.055    109\n",
      "    fear     0.431     0.468     0.275    80\n",
      "   happy     0.431     0.381     0.630    81\n",
      " neutral     0.431     0.684     0.619    84\n",
      "     sad     0.431     0.278     0.563    87\n",
      "surprise     0.431     0.525     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.431     0.449     0.456    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 1.493265 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 1.634079  [ 1200/ 4873]\n",
      "loss: 0.865249  [ 2400/ 4873]\n",
      "loss: 1.254777  [ 3600/ 4873]\n",
      "loss: 1.119376  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.449     0.627     0.400    105\n",
      " disgust     0.449     0.217     0.046    109\n",
      "    fear     0.449     0.533     0.400    80\n",
      "   happy     0.449     0.411     0.630    81\n",
      " neutral     0.449     0.766     0.583    84\n",
      "     sad     0.449     0.289     0.632    87\n",
      "surprise     0.449     0.488     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.449     0.476     0.474    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 1.484956 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.936065  [ 1200/ 4873]\n",
      "loss: 1.208289  [ 2400/ 4873]\n",
      "loss: 1.647522  [ 3600/ 4873]\n",
      "loss: 1.220839  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.448     0.583     0.400    105\n",
      " disgust     0.448     0.167     0.037    109\n",
      "    fear     0.448     0.500     0.463    80\n",
      "   happy     0.448     0.385     0.642    81\n",
      " neutral     0.448     0.794     0.595    84\n",
      "     sad     0.448     0.286     0.575    87\n",
      "surprise     0.448     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.448     0.469     0.472    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.466436 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 1.873375  [ 1200/ 4873]\n",
      "loss: 1.266584  [ 2400/ 4873]\n",
      "loss: 1.179066  [ 3600/ 4873]\n",
      "loss: 1.287301  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.451     0.500     0.467    105\n",
      " disgust     0.451     0.400     0.110    109\n",
      "    fear     0.451     0.459     0.212    80\n",
      "   happy     0.451     0.414     0.654    81\n",
      " neutral     0.451     0.644     0.690    84\n",
      "     sad     0.451     0.319     0.494    87\n",
      "surprise     0.451     0.467     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.451     0.458     0.471    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.458313 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 1.464241  [ 1200/ 4873]\n",
      "loss: 0.970834  [ 2400/ 4873]\n",
      "loss: 1.628541  [ 3600/ 4873]\n",
      "loss: 1.244939  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.470     0.540     0.448    105\n",
      " disgust     0.470     0.395     0.138    109\n",
      "    fear     0.470     0.472     0.312    80\n",
      "   happy     0.470     0.500     0.605    81\n",
      " neutral     0.470     0.679     0.679    84\n",
      "     sad     0.470     0.319     0.517    87\n",
      "surprise     0.470     0.450     0.766    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.470     0.479     0.495    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.472050 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.178613  [ 1200/ 4873]\n",
      "loss: 1.401834  [ 2400/ 4873]\n",
      "loss: 1.131817  [ 3600/ 4873]\n",
      "loss: 1.125672  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.428     0.661     0.352    105\n",
      " disgust     0.428     0.222     0.018    109\n",
      "    fear     0.428     0.490     0.312    80\n",
      "   happy     0.428     0.308     0.753    81\n",
      " neutral     0.428     0.697     0.631    84\n",
      "     sad     0.428     0.291     0.529    87\n",
      "surprise     0.428     0.597     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.428     0.467     0.453    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 1.496915 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.974512  [ 1200/ 4873]\n",
      "loss: 0.988541  [ 2400/ 4873]\n",
      "loss: 1.279190  [ 3600/ 4873]\n",
      "loss: 1.062692  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.457     0.580     0.448    105\n",
      " disgust     0.457     0.250     0.101    109\n",
      "    fear     0.457     0.510     0.325    80\n",
      "   happy     0.457     0.490     0.605    81\n",
      " neutral     0.457     0.785     0.607    84\n",
      "     sad     0.457     0.293     0.586    87\n",
      "surprise     0.457     0.463     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.457     0.482     0.480    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 1.459535 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 1.381474  [ 1200/ 4873]\n",
      "loss: 1.247801  [ 2400/ 4873]\n",
      "loss: 1.197485  [ 3600/ 4873]\n",
      "loss: 1.042961  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.439     0.539     0.457    105\n",
      " disgust     0.439     0.222     0.037    109\n",
      "    fear     0.439     0.341     0.175    80\n",
      "   happy     0.439     0.490     0.630    81\n",
      " neutral     0.439     0.545     0.726    84\n",
      "     sad     0.439     0.297     0.494    87\n",
      "surprise     0.439     0.465     0.734    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.439     0.414     0.465    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 1.483223 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.193972  [ 1200/ 4873]\n",
      "loss: 1.359514  [ 2400/ 4873]\n",
      "loss: 1.409412  [ 3600/ 4873]\n",
      "loss: 0.912969  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.448     0.562     0.476    105\n",
      " disgust     0.448     0.333     0.110    109\n",
      "    fear     0.448     0.388     0.412    80\n",
      "   happy     0.448     0.399     0.679    81\n",
      " neutral     0.448     0.735     0.595    84\n",
      "     sad     0.448     0.302     0.402    87\n",
      "surprise     0.448     0.487     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.448     0.458     0.467    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.454166 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 1.166705  [ 1200/ 4873]\n",
      "loss: 1.409422  [ 2400/ 4873]\n",
      "loss: 1.126536  [ 3600/ 4873]\n",
      "loss: 1.238331  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.456     0.595     0.448    105\n",
      " disgust     0.456     0.302     0.147    109\n",
      "    fear     0.456     0.361     0.325    80\n",
      "   happy     0.456     0.475     0.580    81\n",
      " neutral     0.456     0.828     0.571    84\n",
      "     sad     0.456     0.311     0.598    87\n",
      "surprise     0.456     0.512     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.456     0.483     0.475    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 1.458743 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.091069  [ 1200/ 4873]\n",
      "loss: 0.865164  [ 2400/ 4873]\n",
      "loss: 1.341023  [ 3600/ 4873]\n",
      "loss: 1.327082  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.464     0.516     0.457    105\n",
      " disgust     0.464     0.441     0.138    109\n",
      "    fear     0.464     0.409     0.338    80\n",
      "   happy     0.464     0.505     0.630    81\n",
      " neutral     0.464     0.628     0.702    84\n",
      "     sad     0.464     0.336     0.448    87\n",
      "surprise     0.464     0.415     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.464     0.464     0.486    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.483412 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.994216  [ 1200/ 4873]\n",
      "loss: 0.910983  [ 2400/ 4873]\n",
      "loss: 1.193292  [ 3600/ 4873]\n",
      "loss: 1.781744  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.452     0.495     0.457    105\n",
      " disgust     0.452     0.304     0.064    109\n",
      "    fear     0.452     0.403     0.388    80\n",
      "   happy     0.452     0.433     0.679    81\n",
      " neutral     0.452     0.776     0.619    84\n",
      "     sad     0.452     0.313     0.471    87\n",
      "surprise     0.452     0.477     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.452     0.457     0.476    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 1.471388 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.979741  [ 1200/ 4873]\n",
      "loss: 1.339575  [ 2400/ 4873]\n",
      "loss: 0.930350  [ 3600/ 4873]\n",
      "loss: 1.121880  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.430     0.522     0.448    105\n",
      " disgust     0.430     0.400     0.128    109\n",
      "    fear     0.430     0.293     0.212    80\n",
      "   happy     0.430     0.425     0.556    81\n",
      " neutral     0.430     0.606     0.714    84\n",
      "     sad     0.430     0.296     0.391    87\n",
      "surprise     0.430     0.421     0.703    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.430     0.423     0.450    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 1.479199 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 1.016958  [ 1200/ 4873]\n",
      "loss: 1.508272  [ 2400/ 4873]\n",
      "loss: 1.025429  [ 3600/ 4873]\n",
      "loss: 1.322387  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.454     0.585     0.457    105\n",
      " disgust     0.454     0.238     0.046    109\n",
      "    fear     0.454     0.398     0.412    80\n",
      "   happy     0.454     0.388     0.667    81\n",
      " neutral     0.454     0.663     0.679    84\n",
      "     sad     0.454     0.318     0.483    87\n",
      "surprise     0.454     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.454     0.451     0.477    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.460639 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 1.019878  [ 1200/ 4873]\n",
      "loss: 1.189792  [ 2400/ 4873]\n",
      "loss: 1.335015  [ 3600/ 4873]\n",
      "loss: 1.072604  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.449     0.495     0.457    105\n",
      " disgust     0.449     0.250     0.055    109\n",
      "    fear     0.449     0.338     0.312    80\n",
      "   happy     0.449     0.546     0.654    81\n",
      " neutral     0.449     0.617     0.690    84\n",
      "     sad     0.449     0.294     0.402    87\n",
      "surprise     0.449     0.467     0.766    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.449     0.430     0.477    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 1.475514 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.970561  [ 1200/ 4873]\n",
      "loss: 1.257186  [ 2400/ 4873]\n",
      "loss: 1.018812  [ 3600/ 4873]\n",
      "loss: 1.034730  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.439     0.489     0.429    105\n",
      " disgust     0.439     0.467     0.064    109\n",
      "    fear     0.439     0.369     0.512    80\n",
      "   happy     0.439     0.368     0.691    81\n",
      " neutral     0.439     0.810     0.607    84\n",
      "     sad     0.439     0.303     0.414    87\n",
      "surprise     0.439     0.552     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.439     0.480     0.460    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 1.473861 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.107014  [ 1200/ 4873]\n",
      "loss: 1.521851  [ 2400/ 4873]\n",
      "loss: 0.993611  [ 3600/ 4873]\n",
      "loss: 1.270940  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.449     0.592     0.400    105\n",
      " disgust     0.449     0.167     0.037    109\n",
      "    fear     0.449     0.419     0.487    80\n",
      "   happy     0.449     0.426     0.642    81\n",
      " neutral     0.449     0.810     0.560    84\n",
      "     sad     0.449     0.296     0.575    87\n",
      "surprise     0.449     0.548     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.449     0.465     0.475    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 1.479042 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 1.358128  [ 1200/ 4873]\n",
      "loss: 1.343225  [ 2400/ 4873]\n",
      "loss: 1.056983  [ 3600/ 4873]\n",
      "loss: 1.322512  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.459     0.505     0.457    105\n",
      " disgust     0.459     0.375     0.083    109\n",
      "    fear     0.459     0.365     0.525    80\n",
      "   happy     0.459     0.625     0.556    81\n",
      " neutral     0.459     0.712     0.619    84\n",
      "     sad     0.459     0.310     0.460    87\n",
      "surprise     0.459     0.431     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.459     0.475     0.484    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 1.485452 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 1.149673  [ 1200/ 4873]\n",
      "loss: 1.006894  [ 2400/ 4873]\n",
      "loss: 1.354215  [ 3600/ 4873]\n",
      "loss: 1.638066  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.454     0.554     0.390    105\n",
      " disgust     0.454     0.385     0.046    109\n",
      "    fear     0.454     0.365     0.475    80\n",
      "   happy     0.454     0.404     0.679    81\n",
      " neutral     0.454     0.792     0.679    84\n",
      "     sad     0.454     0.316     0.552    87\n",
      "surprise     0.454     0.559     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.454     0.482     0.477    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.473978 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 1.037146  [ 1200/ 4873]\n",
      "loss: 1.517137  [ 2400/ 4873]\n",
      "loss: 1.123701  [ 3600/ 4873]\n",
      "loss: 1.174023  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.470     0.475     0.457    105\n",
      " disgust     0.470     0.349     0.138    109\n",
      "    fear     0.470     0.376     0.550    80\n",
      "   happy     0.470     0.565     0.593    81\n",
      " neutral     0.470     0.714     0.655    84\n",
      "     sad     0.470     0.354     0.402    87\n",
      "surprise     0.470     0.477     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.470     0.473     0.493    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.482638 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.900909  [ 1200/ 4873]\n",
      "loss: 0.944629  [ 2400/ 4873]\n",
      "loss: 1.426056  [ 3600/ 4873]\n",
      "loss: 0.896910  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.475     0.535     0.438    105\n",
      " disgust     0.475     0.240     0.055    109\n",
      "    fear     0.475     0.448     0.588    80\n",
      "   happy     0.475     0.466     0.679    81\n",
      " neutral     0.475     0.714     0.655    84\n",
      "     sad     0.475     0.345     0.448    87\n",
      "surprise     0.475     0.488     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.475     0.462     0.503    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.452891 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 1.025244  [ 1200/ 4873]\n",
      "loss: 1.259178  [ 2400/ 4873]\n",
      "loss: 0.855475  [ 3600/ 4873]\n",
      "loss: 1.220605  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.467     0.600     0.429    105\n",
      " disgust     0.467     0.474     0.083    109\n",
      "    fear     0.467     0.425     0.463    80\n",
      "   happy     0.467     0.397     0.716    81\n",
      " neutral     0.467     0.663     0.679    84\n",
      "     sad     0.467     0.342     0.471    87\n",
      "surprise     0.467     0.494     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.467     0.485     0.490    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.479502 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.916561  [ 1200/ 4873]\n",
      "loss: 1.405739  [ 2400/ 4873]\n",
      "loss: 1.096199  [ 3600/ 4873]\n",
      "loss: 1.049773  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.443     0.608     0.429    105\n",
      " disgust     0.443     0.300     0.055    109\n",
      "    fear     0.443     0.411     0.487    80\n",
      "   happy     0.443     0.377     0.642    81\n",
      " neutral     0.443     0.860     0.583    84\n",
      "     sad     0.443     0.287     0.529    87\n",
      "surprise     0.443     0.500     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.443     0.478     0.463    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.465165 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 1.006035  [ 1200/ 4873]\n",
      "loss: 1.375724  [ 2400/ 4873]\n",
      "loss: 1.153027  [ 3600/ 4873]\n",
      "loss: 1.202037  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.474     0.511     0.448    105\n",
      " disgust     0.474     0.389     0.128    109\n",
      "    fear     0.474     0.430     0.425    80\n",
      "   happy     0.474     0.453     0.654    81\n",
      " neutral     0.474     0.705     0.655    84\n",
      "     sad     0.474     0.352     0.437    87\n",
      "surprise     0.474     0.480     0.750    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.474     0.474     0.500    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.457319 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 1.501260  [ 1200/ 4873]\n",
      "loss: 1.148510  [ 2400/ 4873]\n",
      "loss: 1.225962  [ 3600/ 4873]\n",
      "loss: 0.983772  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.477     0.588     0.448    105\n",
      " disgust     0.477     0.333     0.101    109\n",
      "    fear     0.477     0.391     0.562    80\n",
      "   happy     0.477     0.495     0.654    81\n",
      " neutral     0.477     0.771     0.643    84\n",
      "     sad     0.477     0.326     0.483    87\n",
      "surprise     0.477     0.513     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.477     0.488     0.500    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.452080 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 1.251488  [ 1200/ 4873]\n",
      "loss: 0.817148  [ 2400/ 4873]\n",
      "loss: 0.932460  [ 3600/ 4873]\n",
      "loss: 1.081107  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.472     0.542     0.495    105\n",
      " disgust     0.472     0.292     0.064    109\n",
      "    fear     0.472     0.358     0.537    80\n",
      "   happy     0.472     0.500     0.654    81\n",
      " neutral     0.472     0.761     0.643    84\n",
      "     sad     0.472     0.353     0.483    87\n",
      "surprise     0.472     0.500     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.472     0.472     0.494    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.458789 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.787315  [ 1200/ 4873]\n",
      "loss: 1.208083  [ 2400/ 4873]\n",
      "loss: 1.074955  [ 3600/ 4873]\n",
      "loss: 0.822659  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.467     0.600     0.371    105\n",
      " disgust     0.467     0.250     0.092    109\n",
      "    fear     0.467     0.432     0.438    80\n",
      "   happy     0.467     0.471     0.605    81\n",
      " neutral     0.467     0.763     0.690    84\n",
      "     sad     0.467     0.311     0.529    87\n",
      "surprise     0.467     0.500     0.750    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.467     0.475     0.496    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.520933 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.900670  [ 1200/ 4873]\n",
      "loss: 1.105804  [ 2400/ 4873]\n",
      "loss: 1.456956  [ 3600/ 4873]\n",
      "loss: 1.027414  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.443     0.610     0.476    105\n",
      " disgust     0.443     0.370     0.092    109\n",
      "    fear     0.443     0.351     0.412    80\n",
      "   happy     0.443     0.354     0.704    81\n",
      " neutral     0.443     0.685     0.595    84\n",
      "     sad     0.443     0.308     0.425    87\n",
      "surprise     0.443     0.623     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.443     0.472     0.460    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.458060 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 1.455970  [ 1200/ 4873]\n",
      "loss: 1.238848  [ 2400/ 4873]\n",
      "loss: 1.377975  [ 3600/ 4873]\n",
      "loss: 0.810053  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.472     0.632     0.457    105\n",
      " disgust     0.472     0.205     0.073    109\n",
      "    fear     0.472     0.419     0.487    80\n",
      "   happy     0.472     0.564     0.654    81\n",
      " neutral     0.472     0.659     0.690    84\n",
      "     sad     0.472     0.301     0.471    87\n",
      "surprise     0.472     0.488     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.472     0.467     0.496    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.484903 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.753608  [ 1200/ 4873]\n",
      "loss: 0.910739  [ 2400/ 4873]\n",
      "loss: 1.127672  [ 3600/ 4873]\n",
      "loss: 1.259030  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.479     0.593     0.457    105\n",
      " disgust     0.479     0.314     0.101    109\n",
      "    fear     0.479     0.431     0.550    80\n",
      "   happy     0.479     0.514     0.667    81\n",
      " neutral     0.479     0.733     0.655    84\n",
      "     sad     0.479     0.298     0.425    87\n",
      "surprise     0.479     0.489     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.479     0.482     0.504    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 1.460067 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 1.237610  [ 1200/ 4873]\n",
      "loss: 1.503869  [ 2400/ 4873]\n",
      "loss: 1.214514  [ 3600/ 4873]\n",
      "loss: 0.974597  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.529     0.514    105\n",
      " disgust     0.489     0.447     0.156    109\n",
      "    fear     0.489     0.392     0.500    80\n",
      "   happy     0.489     0.554     0.630    81\n",
      " neutral     0.489     0.722     0.619    84\n",
      "     sad     0.489     0.328     0.460    87\n",
      "surprise     0.489     0.537     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.501     0.509    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.459875 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.795759  [ 1200/ 4873]\n",
      "loss: 0.788459  [ 2400/ 4873]\n",
      "loss: 1.309612  [ 3600/ 4873]\n",
      "loss: 1.556781  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.469     0.592     0.400    105\n",
      " disgust     0.469     0.419     0.119    109\n",
      "    fear     0.469     0.367     0.550    80\n",
      "   happy     0.469     0.413     0.704    81\n",
      " neutral     0.469     0.775     0.655    84\n",
      "     sad     0.469     0.324     0.402    87\n",
      "surprise     0.469     0.563     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.469     0.493     0.494    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.454789 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.715287  [ 1200/ 4873]\n",
      "loss: 0.937309  [ 2400/ 4873]\n",
      "loss: 0.938460  [ 3600/ 4873]\n",
      "loss: 1.182055  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.475     0.571     0.457    105\n",
      " disgust     0.475     0.391     0.165    109\n",
      "    fear     0.475     0.415     0.487    80\n",
      "   happy     0.475     0.474     0.679    81\n",
      " neutral     0.475     0.683     0.667    84\n",
      "     sad     0.475     0.337     0.333    87\n",
      "surprise     0.475     0.441     0.703    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.475     0.473     0.499    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.471217 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.892887  [ 1200/ 4873]\n",
      "loss: 1.070622  [ 2400/ 4873]\n",
      "loss: 1.324226  [ 3600/ 4873]\n",
      "loss: 1.278789  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.462     0.635     0.448    105\n",
      " disgust     0.462     0.368     0.064    109\n",
      "    fear     0.462     0.426     0.500    80\n",
      "   happy     0.462     0.370     0.741    81\n",
      " neutral     0.462     0.716     0.631    84\n",
      "     sad     0.462     0.325     0.460    87\n",
      "surprise     0.462     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.462     0.484     0.484    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.468829 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 1.275574  [ 1200/ 4873]\n",
      "loss: 0.769475  [ 2400/ 4873]\n",
      "loss: 0.773807  [ 3600/ 4873]\n",
      "loss: 0.944956  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.464     0.623     0.410    105\n",
      " disgust     0.464     0.385     0.138    109\n",
      "    fear     0.464     0.358     0.537    80\n",
      "   happy     0.464     0.470     0.679    81\n",
      " neutral     0.464     0.640     0.655    84\n",
      "     sad     0.464     0.344     0.368    87\n",
      "surprise     0.464     0.465     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.464     0.469     0.487    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.480724 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 1.130308  [ 1200/ 4873]\n",
      "loss: 1.072341  [ 2400/ 4873]\n",
      "loss: 0.626420  [ 3600/ 4873]\n",
      "loss: 1.193545  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.487     0.667     0.495    105\n",
      " disgust     0.487     0.500     0.156    109\n",
      "    fear     0.487     0.435     0.500    80\n",
      "   happy     0.487     0.425     0.704    81\n",
      " neutral     0.487     0.679     0.679    84\n",
      "     sad     0.487     0.330     0.368    87\n",
      "surprise     0.487     0.462     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.487     0.500     0.508    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 1.467460 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 1.462179  [ 1200/ 4873]\n",
      "loss: 1.788186  [ 2400/ 4873]\n",
      "loss: 1.276673  [ 3600/ 4873]\n",
      "loss: 0.793364  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.469     0.606     0.381    105\n",
      " disgust     0.469     0.306     0.138    109\n",
      "    fear     0.469     0.396     0.525    80\n",
      "   happy     0.469     0.527     0.593    81\n",
      " neutral     0.469     0.765     0.619    84\n",
      "     sad     0.469     0.317     0.448    87\n",
      "surprise     0.469     0.467     0.781    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.469     0.484     0.498    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.498989 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 1.095948  [ 1200/ 4873]\n",
      "loss: 0.839687  [ 2400/ 4873]\n",
      "loss: 0.578816  [ 3600/ 4873]\n",
      "loss: 1.452200  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.477     0.652     0.410    105\n",
      " disgust     0.477     0.296     0.073    109\n",
      "    fear     0.477     0.409     0.588    80\n",
      "   happy     0.477     0.520     0.654    81\n",
      " neutral     0.477     0.791     0.631    84\n",
      "     sad     0.477     0.307     0.529    87\n",
      "surprise     0.477     0.494     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.477     0.495     0.504    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.551282 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 1.326046  [ 1200/ 4873]\n",
      "loss: 1.395724  [ 2400/ 4873]\n",
      "loss: 1.052387  [ 3600/ 4873]\n",
      "loss: 1.013360  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.495     0.646     0.486    105\n",
      " disgust     0.495     0.319     0.202    109\n",
      "    fear     0.495     0.455     0.438    80\n",
      "   happy     0.495     0.536     0.642    81\n",
      " neutral     0.495     0.722     0.679    84\n",
      "     sad     0.495     0.325     0.460    87\n",
      "surprise     0.495     0.523     0.703    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.495     0.504     0.515    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 1.463819 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 1.142889  [ 1200/ 4873]\n",
      "loss: 0.648690  [ 2400/ 4873]\n",
      "loss: 0.919803  [ 3600/ 4873]\n",
      "loss: 1.199148  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.451     0.645     0.381    105\n",
      " disgust     0.451     0.348     0.147    109\n",
      "    fear     0.451     0.374     0.575    80\n",
      "   happy     0.451     0.421     0.630    81\n",
      " neutral     0.451     0.754     0.583    84\n",
      "     sad     0.451     0.319     0.414    87\n",
      "surprise     0.451     0.463     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.451     0.475     0.473    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.517559 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.921837  [ 1200/ 4873]\n",
      "loss: 0.963296  [ 2400/ 4873]\n",
      "loss: 0.565251  [ 3600/ 4873]\n",
      "loss: 0.896986  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.475     0.614     0.410    105\n",
      " disgust     0.475     0.308     0.110    109\n",
      "    fear     0.475     0.385     0.588    80\n",
      "   happy     0.475     0.487     0.679    81\n",
      " neutral     0.475     0.675     0.667    84\n",
      "     sad     0.475     0.366     0.425    87\n",
      "surprise     0.475     0.488     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.475     0.475     0.500    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.533999 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 1.276504  [ 1200/ 4873]\n",
      "loss: 0.927020  [ 2400/ 4873]\n",
      "loss: 0.807032  [ 3600/ 4873]\n",
      "loss: 0.941971  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.623     0.457    105\n",
      " disgust     0.489     0.389     0.128    109\n",
      "    fear     0.489     0.386     0.613    80\n",
      "   happy     0.489     0.538     0.704    81\n",
      " neutral     0.489     0.705     0.655    84\n",
      "     sad     0.489     0.327     0.391    87\n",
      "surprise     0.489     0.500     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.495     0.513    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.479923 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 1.166149  [ 1200/ 4873]\n",
      "loss: 0.834538  [ 2400/ 4873]\n",
      "loss: 0.879845  [ 3600/ 4873]\n",
      "loss: 1.285543  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.472     0.600     0.429    105\n",
      " disgust     0.472     0.395     0.138    109\n",
      "    fear     0.472     0.370     0.500    80\n",
      "   happy     0.472     0.495     0.617    81\n",
      " neutral     0.472     0.696     0.655    84\n",
      "     sad     0.472     0.321     0.494    87\n",
      "surprise     0.472     0.533     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.472     0.487     0.494    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.472249 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 1.367310  [ 1200/ 4873]\n",
      "loss: 1.122060  [ 2400/ 4873]\n",
      "loss: 1.350197  [ 3600/ 4873]\n",
      "loss: 0.911523  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.472     0.633     0.476    105\n",
      " disgust     0.472     0.341     0.128    109\n",
      "    fear     0.472     0.416     0.525    80\n",
      "   happy     0.472     0.433     0.642    81\n",
      " neutral     0.472     0.726     0.631    84\n",
      "     sad     0.472     0.317     0.437    87\n",
      "surprise     0.472     0.513     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.472     0.483     0.493    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.481697 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.947334  [ 1200/ 4873]\n",
      "loss: 0.756697  [ 2400/ 4873]\n",
      "loss: 1.450036  [ 3600/ 4873]\n",
      "loss: 0.937784  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.469     0.633     0.476    105\n",
      " disgust     0.469     0.303     0.092    109\n",
      "    fear     0.469     0.380     0.613    80\n",
      "   happy     0.469     0.528     0.580    81\n",
      " neutral     0.469     0.740     0.643    84\n",
      "     sad     0.469     0.287     0.425    87\n",
      "surprise     0.469     0.500     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.469     0.481     0.491    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.509089 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 1.484792  [ 1200/ 4873]\n",
      "loss: 1.453650  [ 2400/ 4873]\n",
      "loss: 1.158963  [ 3600/ 4873]\n",
      "loss: 1.512062  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.452     0.621     0.390    105\n",
      " disgust     0.452     0.294     0.092    109\n",
      "    fear     0.452     0.386     0.487    80\n",
      "   happy     0.452     0.401     0.704    81\n",
      " neutral     0.452     0.722     0.679    84\n",
      "     sad     0.452     0.317     0.437    87\n",
      "surprise     0.452     0.500     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.452     0.463     0.474    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 1.507616 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.899910  [ 1200/ 4873]\n",
      "loss: 0.696161  [ 2400/ 4873]\n",
      "loss: 1.086008  [ 3600/ 4873]\n",
      "loss: 0.924877  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.469     0.577     0.429    105\n",
      " disgust     0.469     0.368     0.128    109\n",
      "    fear     0.469     0.329     0.575    80\n",
      "   happy     0.469     0.529     0.679    81\n",
      " neutral     0.469     0.684     0.619    84\n",
      "     sad     0.469     0.362     0.437    87\n",
      "surprise     0.469     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.469     0.482     0.490    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.515946 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.889786  [ 1200/ 4873]\n",
      "loss: 0.999314  [ 2400/ 4873]\n",
      "loss: 1.185122  [ 3600/ 4873]\n",
      "loss: 0.704217  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.730     0.514    105\n",
      " disgust     0.489     0.341     0.138    109\n",
      "    fear     0.489     0.374     0.575    80\n",
      "   happy     0.489     0.486     0.667    81\n",
      " neutral     0.489     0.820     0.595    84\n",
      "     sad     0.489     0.324     0.402    87\n",
      "surprise     0.489     0.494     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.510     0.511    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.460483 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.947702  [ 1200/ 4873]\n",
      "loss: 0.961660  [ 2400/ 4873]\n",
      "loss: 0.830839  [ 3600/ 4873]\n",
      "loss: 0.961069  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.667     0.457    105\n",
      " disgust     0.489     0.500     0.147    109\n",
      "    fear     0.489     0.368     0.575    80\n",
      "   happy     0.489     0.448     0.691    81\n",
      " neutral     0.489     0.768     0.631    84\n",
      "     sad     0.489     0.333     0.414    87\n",
      "surprise     0.489     0.544     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.518     0.512    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.475439 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 1.023827  [ 1200/ 4873]\n",
      "loss: 0.716361  [ 2400/ 4873]\n",
      "loss: 0.757409  [ 3600/ 4873]\n",
      "loss: 0.891516  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.475     0.650     0.495    105\n",
      " disgust     0.475     0.296     0.147    109\n",
      "    fear     0.475     0.344     0.537    80\n",
      "   happy     0.475     0.557     0.605    81\n",
      " neutral     0.475     0.810     0.607    84\n",
      "     sad     0.475     0.321     0.483    87\n",
      "surprise     0.475     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.475     0.502     0.493    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.497011 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 1.180143  [ 1200/ 4873]\n",
      "loss: 0.985782  [ 2400/ 4873]\n",
      "loss: 0.821395  [ 3600/ 4873]\n",
      "loss: 0.785891  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.480     0.667     0.438    105\n",
      " disgust     0.480     0.327     0.156    109\n",
      "    fear     0.480     0.392     0.500    80\n",
      "   happy     0.480     0.482     0.667    81\n",
      " neutral     0.480     0.855     0.631    84\n",
      "     sad     0.480     0.303     0.494    87\n",
      "surprise     0.480     0.563     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.480     0.513     0.502    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.499175 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 1.652928  [ 1200/ 4873]\n",
      "loss: 0.956189  [ 2400/ 4873]\n",
      "loss: 1.604758  [ 3600/ 4873]\n",
      "loss: 1.202810  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.627     0.495    105\n",
      " disgust     0.489     0.436     0.156    109\n",
      "    fear     0.489     0.413     0.537    80\n",
      "   happy     0.489     0.419     0.704    81\n",
      " neutral     0.489     0.760     0.679    84\n",
      "     sad     0.489     0.355     0.437    87\n",
      "surprise     0.489     0.515     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.504     0.506    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.506494 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 1.052039  [ 1200/ 4873]\n",
      "loss: 0.667920  [ 2400/ 4873]\n",
      "loss: 1.194833  [ 3600/ 4873]\n",
      "loss: 0.956329  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.477     0.657     0.438    105\n",
      " disgust     0.477     0.300     0.083    109\n",
      "    fear     0.477     0.400     0.550    80\n",
      "   happy     0.477     0.455     0.691    81\n",
      " neutral     0.477     0.757     0.667    84\n",
      "     sad     0.477     0.323     0.471    87\n",
      "surprise     0.477     0.513     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.477     0.486     0.501    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.540936 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.944988  [ 1200/ 4873]\n",
      "loss: 0.780045  [ 2400/ 4873]\n",
      "loss: 0.804534  [ 3600/ 4873]\n",
      "loss: 1.243059  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.502     0.675     0.495    105\n",
      " disgust     0.502     0.500     0.156    109\n",
      "    fear     0.502     0.363     0.562    80\n",
      "   happy     0.502     0.509     0.667    81\n",
      " neutral     0.502     0.714     0.655    84\n",
      "     sad     0.502     0.336     0.425    87\n",
      "surprise     0.502     0.561     0.719    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.502     0.523     0.526    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 1.504995 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep123_acc_50.md \n",
      "\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep123_acc_50\"!  new accuracy: 50.2\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.736728  [ 1200/ 4873]\n",
      "loss: 0.726467  [ 2400/ 4873]\n",
      "loss: 0.978240  [ 3600/ 4873]\n",
      "loss: 0.651459  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.477     0.556     0.476    105\n",
      " disgust     0.477     0.442     0.174    109\n",
      "    fear     0.477     0.344     0.525    80\n",
      "   happy     0.477     0.581     0.617    81\n",
      " neutral     0.477     0.684     0.643    84\n",
      "     sad     0.477     0.327     0.368    87\n",
      "surprise     0.477     0.478     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.477     0.487     0.499    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.556882 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 2.105672  [ 1200/ 4873]\n",
      "loss: 0.747242  [ 2400/ 4873]\n",
      "loss: 0.877234  [ 3600/ 4873]\n",
      "loss: 1.089770  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.475     0.667     0.476    105\n",
      " disgust     0.475     0.468     0.202    109\n",
      "    fear     0.475     0.396     0.500    80\n",
      "   happy     0.475     0.453     0.593    81\n",
      " neutral     0.475     0.618     0.655    84\n",
      "     sad     0.475     0.356     0.368    87\n",
      "surprise     0.475     0.422     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.475     0.483     0.495    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.507768 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.737564  [ 1200/ 4873]\n",
      "loss: 1.277183  [ 2400/ 4873]\n",
      "loss: 1.083291  [ 3600/ 4873]\n",
      "loss: 0.584293  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.482     0.593     0.457    105\n",
      " disgust     0.482     0.438     0.193    109\n",
      "    fear     0.482     0.364     0.500    80\n",
      "   happy     0.482     0.495     0.654    81\n",
      " neutral     0.482     0.730     0.643    84\n",
      "     sad     0.482     0.349     0.425    87\n",
      "surprise     0.482     0.488     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.482     0.494     0.502    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.519028 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 1.281018  [ 1200/ 4873]\n",
      "loss: 1.208245  [ 2400/ 4873]\n",
      "loss: 0.911010  [ 3600/ 4873]\n",
      "loss: 0.860098  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.477     0.696     0.457    105\n",
      " disgust     0.477     0.383     0.165    109\n",
      "    fear     0.477     0.381     0.537    80\n",
      "   happy     0.477     0.455     0.679    81\n",
      " neutral     0.477     0.705     0.655    84\n",
      "     sad     0.477     0.323     0.356    87\n",
      "surprise     0.477     0.477     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.477     0.488     0.499    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.501814 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 1.629109  [ 1200/ 4873]\n",
      "loss: 0.916153  [ 2400/ 4873]\n",
      "loss: 0.658261  [ 3600/ 4873]\n",
      "loss: 0.526818  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.474     0.620     0.419    105\n",
      " disgust     0.474     0.353     0.165    109\n",
      "    fear     0.474     0.362     0.525    80\n",
      "   happy     0.474     0.460     0.704    81\n",
      " neutral     0.474     0.701     0.643    84\n",
      "     sad     0.474     0.351     0.379    87\n",
      "surprise     0.474     0.532     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.474     0.483     0.497    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.501100 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.996768  [ 1200/ 4873]\n",
      "loss: 0.708468  [ 2400/ 4873]\n",
      "loss: 0.913716  [ 3600/ 4873]\n",
      "loss: 1.411607  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.470     0.592     0.429    105\n",
      " disgust     0.470     0.415     0.156    109\n",
      "    fear     0.470     0.350     0.525    80\n",
      "   happy     0.470     0.509     0.704    81\n",
      " neutral     0.470     0.730     0.643    84\n",
      "     sad     0.470     0.319     0.333    87\n",
      "surprise     0.470     0.448     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.470     0.480     0.494    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.508547 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 1.208708  [ 1200/ 4873]\n",
      "loss: 1.020331  [ 2400/ 4873]\n",
      "loss: 1.265869  [ 3600/ 4873]\n",
      "loss: 0.763657  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.467     0.657     0.438    105\n",
      " disgust     0.467     0.500     0.119    109\n",
      "    fear     0.467     0.394     0.512    80\n",
      "   happy     0.467     0.353     0.728    81\n",
      " neutral     0.467     0.707     0.631    84\n",
      "     sad     0.467     0.347     0.379    87\n",
      "surprise     0.467     0.548     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.467     0.501     0.491    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.521021 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 1.145599  [ 1200/ 4873]\n",
      "loss: 0.872642  [ 2400/ 4873]\n",
      "loss: 0.833062  [ 3600/ 4873]\n",
      "loss: 1.575240  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.472     0.681     0.448    105\n",
      " disgust     0.472     0.400     0.147    109\n",
      "    fear     0.472     0.372     0.525    80\n",
      "   happy     0.472     0.454     0.667    81\n",
      " neutral     0.472     0.659     0.667    84\n",
      "     sad     0.472     0.333     0.368    87\n",
      "surprise     0.472     0.466     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.472     0.481     0.494    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.545207 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.915740  [ 1200/ 4873]\n",
      "loss: 0.911874  [ 2400/ 4873]\n",
      "loss: 0.556750  [ 3600/ 4873]\n",
      "loss: 1.284753  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.474     0.658     0.476    105\n",
      " disgust     0.474     0.429     0.165    109\n",
      "    fear     0.474     0.371     0.450    80\n",
      "   happy     0.474     0.405     0.654    81\n",
      " neutral     0.474     0.621     0.702    84\n",
      "     sad     0.474     0.354     0.322    87\n",
      "surprise     0.474     0.500     0.703    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.474     0.477     0.496    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.512058 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.941089  [ 1200/ 4873]\n",
      "loss: 0.879291  [ 2400/ 4873]\n",
      "loss: 0.739317  [ 3600/ 4873]\n",
      "loss: 0.625504  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.477     0.671     0.486    105\n",
      " disgust     0.477     0.429     0.138    109\n",
      "    fear     0.477     0.394     0.463    80\n",
      "   happy     0.477     0.384     0.691    81\n",
      " neutral     0.477     0.682     0.714    84\n",
      "     sad     0.477     0.317     0.368    87\n",
      "surprise     0.477     0.571     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.477     0.492     0.498    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.501881 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 1.791333  [ 1200/ 4873]\n",
      "loss: 1.044925  [ 2400/ 4873]\n",
      "loss: 1.075923  [ 3600/ 4873]\n",
      "loss: 0.682833  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.597     0.410    105\n",
      " disgust     0.489     0.426     0.211    109\n",
      "    fear     0.489     0.348     0.588    80\n",
      "   happy     0.489     0.510     0.654    81\n",
      " neutral     0.489     0.768     0.631    84\n",
      "     sad     0.489     0.342     0.448    87\n",
      "surprise     0.489     0.645     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.519     0.510    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.553915 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.750954  [ 1200/ 4873]\n",
      "loss: 0.691548  [ 2400/ 4873]\n",
      "loss: 0.951904  [ 3600/ 4873]\n",
      "loss: 0.640627  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.451     0.671     0.448    105\n",
      " disgust     0.451     0.400     0.128    109\n",
      "    fear     0.451     0.300     0.450    80\n",
      "   happy     0.451     0.385     0.704    81\n",
      " neutral     0.451     0.688     0.631    84\n",
      "     sad     0.451     0.333     0.391    87\n",
      "surprise     0.451     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.451     0.481     0.469    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.503845 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.962608  [ 1200/ 4873]\n",
      "loss: 1.200338  [ 2400/ 4873]\n",
      "loss: 1.311801  [ 3600/ 4873]\n",
      "loss: 1.725795  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.495     0.587     0.514    105\n",
      " disgust     0.495     0.477     0.193    109\n",
      "    fear     0.495     0.372     0.600    80\n",
      "   happy     0.495     0.495     0.630    81\n",
      " neutral     0.495     0.747     0.667    84\n",
      "     sad     0.495     0.340     0.368    87\n",
      "surprise     0.495     0.548     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.495     0.510     0.514    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 1.539583 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 1.061117  [ 1200/ 4873]\n",
      "loss: 0.705927  [ 2400/ 4873]\n",
      "loss: 0.912485  [ 3600/ 4873]\n",
      "loss: 0.818296  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.503     0.734     0.552    105\n",
      " disgust     0.503     0.409     0.165    109\n",
      "    fear     0.503     0.382     0.525    80\n",
      "   happy     0.503     0.483     0.691    81\n",
      " neutral     0.503     0.659     0.690    84\n",
      "     sad     0.503     0.345     0.448    87\n",
      "surprise     0.503     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.503     0.516     0.519    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 1.507213 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep137_acc_50.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep123_acc_50\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep137_acc_50\"! Old accuracy: 50.2, new accuracy: 50.3\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.495577  [ 1200/ 4873]\n",
      "loss: 0.878346  [ 2400/ 4873]\n",
      "loss: 0.748960  [ 3600/ 4873]\n",
      "loss: 0.583774  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.493     0.641     0.476    105\n",
      " disgust     0.493     0.488     0.193    109\n",
      "    fear     0.493     0.364     0.588    80\n",
      "   happy     0.493     0.515     0.654    81\n",
      " neutral     0.493     0.750     0.643    84\n",
      "     sad     0.493     0.348     0.460    87\n",
      "surprise     0.493     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.493     0.517     0.511    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 1.531285 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.806491  [ 1200/ 4873]\n",
      "loss: 0.863523  [ 2400/ 4873]\n",
      "loss: 1.104337  [ 3600/ 4873]\n",
      "loss: 0.852034  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.733     0.419    105\n",
      " disgust     0.489     0.477     0.193    109\n",
      "    fear     0.489     0.414     0.575    80\n",
      "   happy     0.489     0.431     0.728    81\n",
      " neutral     0.489     0.688     0.655    84\n",
      "     sad     0.489     0.349     0.437    87\n",
      "surprise     0.489     0.507     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.514     0.508    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.575312 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.658393  [ 1200/ 4873]\n",
      "loss: 0.636456  [ 2400/ 4873]\n",
      "loss: 1.008610  [ 3600/ 4873]\n",
      "loss: 0.942625  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.484     0.735     0.581    105\n",
      " disgust     0.484     0.431     0.202    109\n",
      "    fear     0.484     0.354     0.425    80\n",
      "   happy     0.484     0.429     0.593    81\n",
      " neutral     0.484     0.630     0.690    84\n",
      "     sad     0.484     0.330     0.368    87\n",
      "surprise     0.484     0.506     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.484     0.488     0.498    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 1.522414 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.950342  [ 1200/ 4873]\n",
      "loss: 0.996667  [ 2400/ 4873]\n",
      "loss: 1.607354  [ 3600/ 4873]\n",
      "loss: 0.791029  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.479     0.759     0.419    105\n",
      " disgust     0.479     0.400     0.165    109\n",
      "    fear     0.479     0.410     0.537    80\n",
      "   happy     0.479     0.415     0.691    81\n",
      " neutral     0.479     0.667     0.619    84\n",
      "     sad     0.479     0.333     0.414    87\n",
      "surprise     0.479     0.531     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.479     0.502     0.503    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 1.583380 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 1.035895  [ 1200/ 4873]\n",
      "loss: 0.814288  [ 2400/ 4873]\n",
      "loss: 0.872593  [ 3600/ 4873]\n",
      "loss: 0.920098  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.457     0.750     0.457    105\n",
      " disgust     0.457     0.260     0.119    109\n",
      "    fear     0.457     0.417     0.438    80\n",
      "   happy     0.457     0.393     0.654    81\n",
      " neutral     0.457     0.684     0.619    84\n",
      "     sad     0.457     0.292     0.402    87\n",
      "surprise     0.457     0.531     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.457     0.475     0.480    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 1.554703 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.670745  [ 1200/ 4873]\n",
      "loss: 0.778543  [ 2400/ 4873]\n",
      "loss: 0.618385  [ 3600/ 4873]\n",
      "loss: 0.998727  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.487     0.654     0.486    105\n",
      " disgust     0.487     0.485     0.147    109\n",
      "    fear     0.487     0.381     0.537    80\n",
      "   happy     0.487     0.472     0.630    81\n",
      " neutral     0.487     0.705     0.655    84\n",
      "     sad     0.487     0.345     0.471    87\n",
      "surprise     0.487     0.494     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.487     0.505     0.507    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 1.586004 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.774396  [ 1200/ 4873]\n",
      "loss: 0.908980  [ 2400/ 4873]\n",
      "loss: 0.654907  [ 3600/ 4873]\n",
      "loss: 0.552254  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.650     0.495    105\n",
      " disgust     0.489     0.500     0.229    109\n",
      "    fear     0.489     0.352     0.537    80\n",
      "   happy     0.489     0.451     0.630    81\n",
      " neutral     0.489     0.654     0.631    84\n",
      "     sad     0.489     0.395     0.345    87\n",
      "surprise     0.489     0.500     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.500     0.508    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.594919 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.611609  [ 1200/ 4873]\n",
      "loss: 0.885316  [ 2400/ 4873]\n",
      "loss: 0.850900  [ 3600/ 4873]\n",
      "loss: 0.853698  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.474     0.648     0.438    105\n",
      " disgust     0.474     0.490     0.220    109\n",
      "    fear     0.474     0.341     0.550    80\n",
      "   happy     0.474     0.466     0.667    81\n",
      " neutral     0.474     0.693     0.619    84\n",
      "     sad     0.474     0.344     0.356    87\n",
      "surprise     0.474     0.475     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.474     0.494     0.492    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.590734 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 1.492147  [ 1200/ 4873]\n",
      "loss: 0.910425  [ 2400/ 4873]\n",
      "loss: 1.317681  [ 3600/ 4873]\n",
      "loss: 0.528801  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.505     0.705     0.524    105\n",
      " disgust     0.505     0.558     0.220    109\n",
      "    fear     0.505     0.366     0.512    80\n",
      "   happy     0.505     0.430     0.642    81\n",
      " neutral     0.505     0.718     0.667    84\n",
      "     sad     0.505     0.381     0.425    87\n",
      "surprise     0.505     0.531     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.505     0.527     0.523    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.537250 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep146_acc_50.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep137_acc_50\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep146_acc_50\"! Old accuracy: 50.3, new accuracy: 50.5\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.823065  [ 1200/ 4873]\n",
      "loss: 0.894745  [ 2400/ 4873]\n",
      "loss: 1.031982  [ 3600/ 4873]\n",
      "loss: 0.764573  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.464     0.719     0.438    105\n",
      " disgust     0.464     0.463     0.174    109\n",
      "    fear     0.464     0.347     0.537    80\n",
      "   happy     0.464     0.382     0.716    81\n",
      " neutral     0.464     0.667     0.643    84\n",
      "     sad     0.464     0.326     0.333    87\n",
      "surprise     0.464     0.576     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.464     0.497     0.482    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.558377 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 1.605708  [ 1200/ 4873]\n",
      "loss: 1.024030  [ 2400/ 4873]\n",
      "loss: 1.270611  [ 3600/ 4873]\n",
      "loss: 0.452712  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.482     0.645     0.467    105\n",
      " disgust     0.482     0.440     0.202    109\n",
      "    fear     0.482     0.348     0.500    80\n",
      "   happy     0.482     0.462     0.667    81\n",
      " neutral     0.482     0.691     0.667    84\n",
      "     sad     0.482     0.339     0.460    87\n",
      "surprise     0.482     0.623     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.482     0.507     0.497    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.520402 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.722879  [ 1200/ 4873]\n",
      "loss: 0.807681  [ 2400/ 4873]\n",
      "loss: 0.785322  [ 3600/ 4873]\n",
      "loss: 0.570712  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.475     0.651     0.514    105\n",
      " disgust     0.475     0.533     0.220    109\n",
      "    fear     0.475     0.419     0.450    80\n",
      "   happy     0.475     0.407     0.617    81\n",
      " neutral     0.475     0.576     0.679    84\n",
      "     sad     0.475     0.338     0.287    87\n",
      "surprise     0.475     0.440     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.475     0.480     0.494    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.595250 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.902992  [ 1200/ 4873]\n",
      "loss: 0.928912  [ 2400/ 4873]\n",
      "loss: 0.889482  [ 3600/ 4873]\n",
      "loss: 0.997267  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.469     0.662     0.429    105\n",
      " disgust     0.469     0.345     0.183    109\n",
      "    fear     0.469     0.373     0.512    80\n",
      "   happy     0.469     0.415     0.691    81\n",
      " neutral     0.469     0.722     0.619    84\n",
      "     sad     0.469     0.340     0.391    87\n",
      "surprise     0.469     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.469     0.489     0.489    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.573016 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.713367  [ 1200/ 4873]\n",
      "loss: 0.737523  [ 2400/ 4873]\n",
      "loss: 1.340769  [ 3600/ 4873]\n",
      "loss: 0.575145  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.469     0.575     0.438    105\n",
      " disgust     0.469     0.468     0.202    109\n",
      "    fear     0.469     0.390     0.487    80\n",
      "   happy     0.469     0.442     0.654    81\n",
      " neutral     0.469     0.571     0.667    84\n",
      "     sad     0.469     0.378     0.322    87\n",
      "surprise     0.469     0.462     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.469     0.469     0.490    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.616180 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.891170  [ 1200/ 4873]\n",
      "loss: 0.883192  [ 2400/ 4873]\n",
      "loss: 0.891910  [ 3600/ 4873]\n",
      "loss: 0.996701  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.480     0.614     0.486    105\n",
      " disgust     0.480     0.423     0.202    109\n",
      "    fear     0.480     0.360     0.562    80\n",
      "   happy     0.480     0.510     0.605    81\n",
      " neutral     0.480     0.737     0.667    84\n",
      "     sad     0.480     0.344     0.379    87\n",
      "surprise     0.480     0.451     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.480     0.491     0.497    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.577612 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 1.176156  [ 1200/ 4873]\n",
      "loss: 0.467136  [ 2400/ 4873]\n",
      "loss: 0.754810  [ 3600/ 4873]\n",
      "loss: 1.464548  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.467     0.716     0.457    105\n",
      " disgust     0.467     0.439     0.165    109\n",
      "    fear     0.467     0.360     0.500    80\n",
      "   happy     0.467     0.407     0.679    81\n",
      " neutral     0.467     0.701     0.643    84\n",
      "     sad     0.467     0.298     0.414    87\n",
      "surprise     0.467     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.467     0.501     0.484    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 1.586937 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.698789  [ 1200/ 4873]\n",
      "loss: 0.615704  [ 2400/ 4873]\n",
      "loss: 0.656720  [ 3600/ 4873]\n",
      "loss: 0.909967  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.485     0.667     0.514    105\n",
      " disgust     0.485     0.559     0.174    109\n",
      "    fear     0.485     0.346     0.562    80\n",
      "   happy     0.485     0.387     0.679    81\n",
      " neutral     0.485     0.740     0.643    84\n",
      "     sad     0.485     0.340     0.379    87\n",
      "surprise     0.485     0.679     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.485     0.531     0.502    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.574200 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.707032  [ 1200/ 4873]\n",
      "loss: 1.057737  [ 2400/ 4873]\n",
      "loss: 0.777120  [ 3600/ 4873]\n",
      "loss: 1.548788  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.625     0.476    105\n",
      " disgust     0.489     0.457     0.147    109\n",
      "    fear     0.489     0.364     0.588    80\n",
      "   happy     0.489     0.475     0.691    81\n",
      " neutral     0.489     0.761     0.643    84\n",
      "     sad     0.489     0.345     0.437    87\n",
      "surprise     0.489     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.489     0.511     0.509    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.571156 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.960610  [ 1200/ 4873]\n",
      "loss: 0.651451  [ 2400/ 4873]\n",
      "loss: 0.626762  [ 3600/ 4873]\n",
      "loss: 0.603244  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.484     0.653     0.467    105\n",
      " disgust     0.484     0.422     0.248    109\n",
      "    fear     0.484     0.371     0.487    80\n",
      "   happy     0.484     0.421     0.630    81\n",
      " neutral     0.484     0.700     0.667    84\n",
      "     sad     0.484     0.347     0.379    87\n",
      "surprise     0.484     0.571     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.484     0.498     0.500    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 1.554333 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.558336  [ 1200/ 4873]\n",
      "loss: 0.965559  [ 2400/ 4873]\n",
      "loss: 0.742184  [ 3600/ 4873]\n",
      "loss: 1.033118  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.495     0.684     0.495    105\n",
      " disgust     0.495     0.407     0.202    109\n",
      "    fear     0.495     0.396     0.500    80\n",
      "   happy     0.495     0.510     0.654    81\n",
      " neutral     0.495     0.679     0.679    84\n",
      "     sad     0.495     0.327     0.425    87\n",
      "surprise     0.495     0.526     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.495     0.504     0.514    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 1.630483 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.560119  [ 1200/ 4873]\n",
      "loss: 0.540591  [ 2400/ 4873]\n",
      "loss: 0.622826  [ 3600/ 4873]\n",
      "loss: 0.285983  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.484     0.617     0.476    105\n",
      " disgust     0.484     0.435     0.248    109\n",
      "    fear     0.484     0.333     0.562    80\n",
      "   happy     0.484     0.514     0.691    81\n",
      " neutral     0.484     0.700     0.667    84\n",
      "     sad     0.484     0.372     0.333    87\n",
      "surprise     0.484     0.492     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.484     0.495     0.497    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 1.610237 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.964931  [ 1200/ 4873]\n",
      "loss: 0.520247  [ 2400/ 4873]\n",
      "loss: 0.729869  [ 3600/ 4873]\n",
      "loss: 0.705092  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.497     0.688     0.524    105\n",
      " disgust     0.497     0.424     0.229    109\n",
      "    fear     0.497     0.364     0.537    80\n",
      "   happy     0.497     0.462     0.667    81\n",
      " neutral     0.497     0.825     0.619    84\n",
      "     sad     0.497     0.349     0.425    87\n",
      "surprise     0.497     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.497     0.523     0.511    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 1.553015 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.549498  [ 1200/ 4873]\n",
      "loss: 0.516528  [ 2400/ 4873]\n",
      "loss: 0.704688  [ 3600/ 4873]\n",
      "loss: 0.682779  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.495     0.586     0.486    105\n",
      " disgust     0.495     0.500     0.257    109\n",
      "    fear     0.495     0.316     0.537    80\n",
      "   happy     0.495     0.520     0.642    81\n",
      " neutral     0.495     0.716     0.690    84\n",
      "     sad     0.495     0.396     0.437    87\n",
      "surprise     0.495     0.593     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.495     0.518     0.507    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 1.616609 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.724506  [ 1200/ 4873]\n",
      "loss: 0.801840  [ 2400/ 4873]\n",
      "loss: 0.520447  [ 3600/ 4873]\n",
      "loss: 0.500689  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.472     0.654     0.486    105\n",
      " disgust     0.472     0.449     0.202    109\n",
      "    fear     0.472     0.385     0.438    80\n",
      "   happy     0.472     0.395     0.630    81\n",
      " neutral     0.472     0.712     0.619    84\n",
      "     sad     0.472     0.343     0.425    87\n",
      "surprise     0.472     0.488     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.472     0.489     0.489    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.601148 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.790204  [ 1200/ 4873]\n",
      "loss: 0.483836  [ 2400/ 4873]\n",
      "loss: 1.094182  [ 3600/ 4873]\n",
      "loss: 0.864610  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.505     0.707     0.505    105\n",
      " disgust     0.505     0.435     0.183    109\n",
      "    fear     0.505     0.349     0.562    80\n",
      "   happy     0.505     0.524     0.679    81\n",
      " neutral     0.505     0.747     0.667    84\n",
      "     sad     0.505     0.349     0.437    87\n",
      "surprise     0.505     0.577     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.505     0.527     0.525    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.599912 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.816040  [ 1200/ 4873]\n",
      "loss: 0.789828  [ 2400/ 4873]\n",
      "loss: 0.995817  [ 3600/ 4873]\n",
      "loss: 0.924733  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.487     0.697     0.505    105\n",
      " disgust     0.487     0.455     0.229    109\n",
      "    fear     0.487     0.417     0.438    80\n",
      "   happy     0.487     0.419     0.667    81\n",
      " neutral     0.487     0.626     0.679    84\n",
      "     sad     0.487     0.301     0.322    87\n",
      "surprise     0.487     0.549     0.703    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.487     0.495     0.506    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 1.650405 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.804374  [ 1200/ 4873]\n",
      "loss: 0.568670  [ 2400/ 4873]\n",
      "loss: 0.790591  [ 3600/ 4873]\n",
      "loss: 0.508229  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.653     0.590    105\n",
      " disgust     0.533     0.609     0.385    109\n",
      "    fear     0.533     0.361     0.537    80\n",
      "   happy     0.533     0.505     0.593    81\n",
      " neutral     0.533     0.688     0.655    84\n",
      "     sad     0.533     0.479     0.391    87\n",
      "surprise     0.533     0.506     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.543     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.590268 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep164_acc_53.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep146_acc_50\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep164_acc_53\"! Old accuracy: 50.5, new accuracy: 53.3\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.723647  [ 1200/ 4873]\n",
      "loss: 0.749774  [ 2400/ 4873]\n",
      "loss: 0.804858  [ 3600/ 4873]\n",
      "loss: 0.912418  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.497     0.679     0.524    105\n",
      " disgust     0.497     0.476     0.275    109\n",
      "    fear     0.497     0.324     0.562    80\n",
      "   happy     0.497     0.473     0.654    81\n",
      " neutral     0.497     0.803     0.631    84\n",
      "     sad     0.497     0.349     0.333    87\n",
      "surprise     0.497     0.576     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.497     0.526     0.511    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 1.541742 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.729040  [ 1200/ 4873]\n",
      "loss: 0.895817  [ 2400/ 4873]\n",
      "loss: 0.663562  [ 3600/ 4873]\n",
      "loss: 0.440525  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.492     0.688     0.419    105\n",
      " disgust     0.492     0.622     0.257    109\n",
      "    fear     0.492     0.379     0.487    80\n",
      "   happy     0.492     0.404     0.778    81\n",
      " neutral     0.492     0.621     0.643    84\n",
      "     sad     0.492     0.416     0.368    87\n",
      "surprise     0.492     0.513     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.492     0.520     0.511    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.577221 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 1.374818  [ 1200/ 4873]\n",
      "loss: 0.900264  [ 2400/ 4873]\n",
      "loss: 0.698207  [ 3600/ 4873]\n",
      "loss: 0.543996  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.484     0.703     0.495    105\n",
      " disgust     0.484     0.429     0.193    109\n",
      "    fear     0.484     0.382     0.487    80\n",
      "   happy     0.484     0.391     0.642    81\n",
      " neutral     0.484     0.691     0.667    84\n",
      "     sad     0.484     0.343     0.402    87\n",
      "surprise     0.484     0.580     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.484     0.503     0.502    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 1.603876 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.309668  [ 1200/ 4873]\n",
      "loss: 0.906092  [ 2400/ 4873]\n",
      "loss: 0.709971  [ 3600/ 4873]\n",
      "loss: 0.534971  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.511     0.658     0.476    105\n",
      " disgust     0.511     0.569     0.339    109\n",
      "    fear     0.511     0.346     0.562    80\n",
      "   happy     0.511     0.500     0.630    81\n",
      " neutral     0.511     0.670     0.702    84\n",
      "     sad     0.511     0.423     0.345    87\n",
      "surprise     0.511     0.513     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.511     0.526     0.526    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 1.629858 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.771001  [ 1200/ 4873]\n",
      "loss: 0.948877  [ 2400/ 4873]\n",
      "loss: 0.676046  [ 3600/ 4873]\n",
      "loss: 1.430102  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.498     0.679     0.505    105\n",
      " disgust     0.498     0.463     0.174    109\n",
      "    fear     0.498     0.396     0.550    80\n",
      "   happy     0.498     0.453     0.654    81\n",
      " neutral     0.498     0.695     0.679    84\n",
      "     sad     0.498     0.364     0.460    87\n",
      "surprise     0.498     0.535     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.498     0.512     0.516    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 1.628031 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.995991  [ 1200/ 4873]\n",
      "loss: 0.836177  [ 2400/ 4873]\n",
      "loss: 0.954907  [ 3600/ 4873]\n",
      "loss: 0.755302  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.477     0.734     0.448    105\n",
      " disgust     0.477     0.449     0.202    109\n",
      "    fear     0.477     0.363     0.562    80\n",
      "   happy     0.477     0.403     0.642    81\n",
      " neutral     0.477     0.736     0.631    84\n",
      "     sad     0.477     0.346     0.425    87\n",
      "surprise     0.477     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.477     0.510     0.494    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.625189 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.570324  [ 1200/ 4873]\n",
      "loss: 0.918184  [ 2400/ 4873]\n",
      "loss: 1.060960  [ 3600/ 4873]\n",
      "loss: 0.927430  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.500     0.662     0.505    105\n",
      " disgust     0.500     0.490     0.220    109\n",
      "    fear     0.500     0.377     0.500    80\n",
      "   happy     0.500     0.472     0.617    81\n",
      " neutral     0.500     0.711     0.643    84\n",
      "     sad     0.500     0.354     0.460    87\n",
      "surprise     0.500     0.550     0.688    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.500     0.517     0.519    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.624763 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.677931  [ 1200/ 4873]\n",
      "loss: 0.651558  [ 2400/ 4873]\n",
      "loss: 1.121071  [ 3600/ 4873]\n",
      "loss: 0.606783  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.482     0.667     0.495    105\n",
      " disgust     0.482     0.477     0.193    109\n",
      "    fear     0.482     0.328     0.550    80\n",
      "   happy     0.482     0.424     0.654    81\n",
      " neutral     0.482     0.746     0.631    84\n",
      "     sad     0.482     0.349     0.437    87\n",
      "surprise     0.482     0.673     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.482     0.524     0.497    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.620072 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.888466  [ 1200/ 4873]\n",
      "loss: 0.668809  [ 2400/ 4873]\n",
      "loss: 0.885479  [ 3600/ 4873]\n",
      "loss: 0.589390  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.498     0.557     0.514    105\n",
      " disgust     0.498     0.484     0.275    109\n",
      "    fear     0.498     0.354     0.500    80\n",
      "   happy     0.498     0.545     0.593    81\n",
      " neutral     0.498     0.692     0.643    84\n",
      "     sad     0.498     0.355     0.437    87\n",
      "surprise     0.498     0.615     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.498     0.515     0.512    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 1.731408 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 1.252767  [ 1200/ 4873]\n",
      "loss: 0.429542  [ 2400/ 4873]\n",
      "loss: 0.865616  [ 3600/ 4873]\n",
      "loss: 0.519239  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.516     0.674     0.590    105\n",
      " disgust     0.516     0.484     0.284    109\n",
      "    fear     0.516     0.395     0.562    80\n",
      "   happy     0.516     0.490     0.617    81\n",
      " neutral     0.516     0.730     0.643    84\n",
      "     sad     0.516     0.380     0.402    87\n",
      "surprise     0.516     0.528     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.516     0.526     0.528    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.639054 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.561507  [ 1200/ 4873]\n",
      "loss: 1.004360  [ 2400/ 4873]\n",
      "loss: 0.624194  [ 3600/ 4873]\n",
      "loss: 1.006843  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.505     0.641     0.476    105\n",
      " disgust     0.505     0.529     0.330    109\n",
      "    fear     0.505     0.382     0.525    80\n",
      "   happy     0.505     0.407     0.679    81\n",
      " neutral     0.505     0.675     0.619    84\n",
      "     sad     0.505     0.422     0.402    87\n",
      "surprise     0.505     0.644     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.505     0.529     0.518    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.627914 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.593588  [ 1200/ 4873]\n",
      "loss: 0.500975  [ 2400/ 4873]\n",
      "loss: 0.664516  [ 3600/ 4873]\n",
      "loss: 0.640951  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.490     0.614     0.486    105\n",
      " disgust     0.490     0.548     0.211    109\n",
      "    fear     0.490     0.347     0.537    80\n",
      "   happy     0.490     0.482     0.679    81\n",
      " neutral     0.490     0.712     0.619    84\n",
      "     sad     0.490     0.362     0.437    87\n",
      "surprise     0.490     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.490     0.515     0.507    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.628599 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.784315  [ 1200/ 4873]\n",
      "loss: 1.131304  [ 2400/ 4873]\n",
      "loss: 0.596783  [ 3600/ 4873]\n",
      "loss: 0.473916  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.690     0.571    105\n",
      " disgust     0.541     0.530     0.321    109\n",
      "    fear     0.541     0.357     0.575    80\n",
      "   happy     0.541     0.600     0.630    81\n",
      " neutral     0.541     0.734     0.690    84\n",
      "     sad     0.541     0.440     0.425    87\n",
      "surprise     0.541     0.537     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.556     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.626554 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep177_acc_54.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep164_acc_53\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep177_acc_54\"! Old accuracy: 53.3, new accuracy: 54.1\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 1.006485  [ 1200/ 4873]\n",
      "loss: 0.577809  [ 2400/ 4873]\n",
      "loss: 0.617984  [ 3600/ 4873]\n",
      "loss: 0.754061  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.507     0.701     0.514    105\n",
      " disgust     0.507     0.435     0.275    109\n",
      "    fear     0.507     0.421     0.562    80\n",
      "   happy     0.507     0.447     0.630    81\n",
      " neutral     0.507     0.688     0.631    84\n",
      "     sad     0.507     0.388     0.437    87\n",
      "surprise     0.507     0.559     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.507     0.520     0.520    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.659976 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.601755  [ 1200/ 4873]\n",
      "loss: 0.540924  [ 2400/ 4873]\n",
      "loss: 0.944419  [ 3600/ 4873]\n",
      "loss: 0.829958  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.503     0.773     0.486    105\n",
      " disgust     0.503     0.508     0.284    109\n",
      "    fear     0.503     0.368     0.575    80\n",
      "   happy     0.503     0.414     0.679    81\n",
      " neutral     0.503     0.737     0.667    84\n",
      "     sad     0.503     0.362     0.391    87\n",
      "surprise     0.503     0.618     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.503     0.540     0.516    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 1.627445 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.532046  [ 1200/ 4873]\n",
      "loss: 1.020930  [ 2400/ 4873]\n",
      "loss: 0.726163  [ 3600/ 4873]\n",
      "loss: 0.548972  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.484     0.636     0.400    105\n",
      " disgust     0.484     0.413     0.239    109\n",
      "    fear     0.484     0.398     0.562    80\n",
      "   happy     0.484     0.456     0.642    81\n",
      " neutral     0.484     0.750     0.607    84\n",
      "     sad     0.484     0.344     0.483    87\n",
      "surprise     0.484     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.484     0.511     0.502    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 1.777438 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.563752  [ 1200/ 4873]\n",
      "loss: 0.622790  [ 2400/ 4873]\n",
      "loss: 0.465844  [ 3600/ 4873]\n",
      "loss: 0.615964  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.508     0.646     0.505    105\n",
      " disgust     0.508     0.533     0.294    109\n",
      "    fear     0.508     0.371     0.575    80\n",
      "   happy     0.508     0.510     0.642    81\n",
      " neutral     0.508     0.626     0.679    84\n",
      "     sad     0.508     0.395     0.345    87\n",
      "surprise     0.508     0.533     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.508     0.516     0.523    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.668144 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.357129  [ 1200/ 4873]\n",
      "loss: 0.646730  [ 2400/ 4873]\n",
      "loss: 0.452668  [ 3600/ 4873]\n",
      "loss: 0.461449  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.516     0.675     0.514    105\n",
      " disgust     0.516     0.396     0.349    109\n",
      "    fear     0.516     0.356     0.525    80\n",
      "   happy     0.516     0.614     0.630    81\n",
      " neutral     0.516     0.700     0.667    84\n",
      "     sad     0.516     0.409     0.414    87\n",
      "surprise     0.516     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.516     0.534     0.527    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.661726 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.490894  [ 1200/ 4873]\n",
      "loss: 0.768256  [ 2400/ 4873]\n",
      "loss: 0.370751  [ 3600/ 4873]\n",
      "loss: 0.818556  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.500     0.684     0.495    105\n",
      " disgust     0.500     0.536     0.275    109\n",
      "    fear     0.500     0.357     0.575    80\n",
      "   happy     0.500     0.411     0.630    81\n",
      " neutral     0.500     0.688     0.655    84\n",
      "     sad     0.500     0.412     0.379    87\n",
      "surprise     0.500     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.500     0.525     0.515    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.639779 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.698933  [ 1200/ 4873]\n",
      "loss: 0.775034  [ 2400/ 4873]\n",
      "loss: 0.533263  [ 3600/ 4873]\n",
      "loss: 0.992337  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.505     0.679     0.524    105\n",
      " disgust     0.505     0.474     0.339    109\n",
      "    fear     0.505     0.350     0.512    80\n",
      "   happy     0.505     0.486     0.630    81\n",
      " neutral     0.505     0.722     0.679    84\n",
      "     sad     0.505     0.416     0.368    87\n",
      "surprise     0.505     0.479     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.505     0.515     0.514    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.649358 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.839569  [ 1200/ 4873]\n",
      "loss: 0.522566  [ 2400/ 4873]\n",
      "loss: 0.479688  [ 3600/ 4873]\n",
      "loss: 0.922766  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.667     0.590    105\n",
      " disgust     0.531     0.619     0.358    109\n",
      "    fear     0.531     0.368     0.525    80\n",
      "   happy     0.531     0.505     0.654    81\n",
      " neutral     0.531     0.663     0.655    84\n",
      "     sad     0.531     0.458     0.379    87\n",
      "surprise     0.531     0.500     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.540     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.688129 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.546999  [ 1200/ 4873]\n",
      "loss: 0.833789  [ 2400/ 4873]\n",
      "loss: 0.507259  [ 3600/ 4873]\n",
      "loss: 0.712453  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.493     0.658     0.476    105\n",
      " disgust     0.493     0.444     0.294    109\n",
      "    fear     0.493     0.381     0.500    80\n",
      "   happy     0.493     0.431     0.654    81\n",
      " neutral     0.493     0.667     0.667    84\n",
      "     sad     0.493     0.398     0.379    87\n",
      "surprise     0.493     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.493     0.504     0.507    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 1.668860 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.543863  [ 1200/ 4873]\n",
      "loss: 0.720445  [ 2400/ 4873]\n",
      "loss: 0.505644  [ 3600/ 4873]\n",
      "loss: 0.634301  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.704     0.543    105\n",
      " disgust     0.531     0.456     0.376    109\n",
      "    fear     0.531     0.410     0.512    80\n",
      "   happy     0.531     0.565     0.593    81\n",
      " neutral     0.531     0.652     0.690    84\n",
      "     sad     0.531     0.437     0.437    87\n",
      "surprise     0.531     0.526     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.535     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.674392 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.592499  [ 1200/ 4873]\n",
      "loss: 0.979540  [ 2400/ 4873]\n",
      "loss: 0.817253  [ 3600/ 4873]\n",
      "loss: 0.581826  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.518     0.639     0.438    105\n",
      " disgust     0.518     0.515     0.477    109\n",
      "    fear     0.518     0.345     0.500    80\n",
      "   happy     0.518     0.495     0.654    81\n",
      " neutral     0.518     0.640     0.679    84\n",
      "     sad     0.518     0.508     0.379    87\n",
      "surprise     0.518     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.518     0.532     0.525    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.727593 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.505907  [ 1200/ 4873]\n",
      "loss: 0.888988  [ 2400/ 4873]\n",
      "loss: 0.528406  [ 3600/ 4873]\n",
      "loss: 0.601646  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.510     0.704     0.476    105\n",
      " disgust     0.510     0.528     0.349    109\n",
      "    fear     0.510     0.447     0.525    80\n",
      "   happy     0.510     0.481     0.630    81\n",
      " neutral     0.510     0.594     0.679    84\n",
      "     sad     0.510     0.398     0.402    87\n",
      "surprise     0.510     0.458     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.510     0.516     0.522    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.741454 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.601372  [ 1200/ 4873]\n",
      "loss: 0.308075  [ 2400/ 4873]\n",
      "loss: 0.449004  [ 3600/ 4873]\n",
      "loss: 0.537859  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.498     0.688     0.505    105\n",
      " disgust     0.498     0.625     0.275    109\n",
      "    fear     0.498     0.451     0.463    80\n",
      "   happy     0.498     0.343     0.704    81\n",
      " neutral     0.498     0.625     0.655    84\n",
      "     sad     0.498     0.395     0.391    87\n",
      "surprise     0.498     0.603     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.498     0.533     0.512    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 1.656359 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.748836  [ 1200/ 4873]\n",
      "loss: 0.544867  [ 2400/ 4873]\n",
      "loss: 1.109632  [ 3600/ 4873]\n",
      "loss: 0.590359  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.526     0.712     0.495    105\n",
      " disgust     0.526     0.505     0.422    109\n",
      "    fear     0.526     0.398     0.512    80\n",
      "   happy     0.526     0.500     0.617    81\n",
      " neutral     0.526     0.651     0.667    84\n",
      "     sad     0.526     0.393     0.379    87\n",
      "surprise     0.526     0.589     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.526     0.536     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.716149 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.592139  [ 1200/ 4873]\n",
      "loss: 0.414686  [ 2400/ 4873]\n",
      "loss: 0.605764  [ 3600/ 4873]\n",
      "loss: 0.451155  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.515     0.670     0.562    105\n",
      " disgust     0.515     0.452     0.349    109\n",
      "    fear     0.515     0.347     0.537    80\n",
      "   happy     0.515     0.490     0.617    81\n",
      " neutral     0.515     0.699     0.690    84\n",
      "     sad     0.515     0.438     0.368    87\n",
      "surprise     0.515     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.515     0.529     0.522    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.628283 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.405510  [ 1200/ 4873]\n",
      "loss: 0.484062  [ 2400/ 4873]\n",
      "loss: 0.634106  [ 3600/ 4873]\n",
      "loss: 0.748323  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.604     0.610    105\n",
      " disgust     0.539     0.635     0.431    109\n",
      "    fear     0.539     0.360     0.500    80\n",
      "   happy     0.539     0.500     0.617    81\n",
      " neutral     0.539     0.695     0.679    84\n",
      "     sad     0.539     0.485     0.368    87\n",
      "surprise     0.539     0.549     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.547     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.656342 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.587838  [ 1200/ 4873]\n",
      "loss: 0.640044  [ 2400/ 4873]\n",
      "loss: 0.734493  [ 3600/ 4873]\n",
      "loss: 0.620875  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.670     0.600    105\n",
      " disgust     0.544     0.535     0.422    109\n",
      "    fear     0.544     0.426     0.537    80\n",
      "   happy     0.544     0.547     0.580    81\n",
      " neutral     0.544     0.667     0.690    84\n",
      "     sad     0.544     0.410     0.368    87\n",
      "surprise     0.544     0.551     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.544     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 1.728217 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep194_acc_54.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep177_acc_54\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep194_acc_54\"! Old accuracy: 54.1, new accuracy: 54.4\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.683765  [ 1200/ 4873]\n",
      "loss: 0.890112  [ 2400/ 4873]\n",
      "loss: 0.579510  [ 3600/ 4873]\n",
      "loss: 0.789585  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.510     0.653     0.448    105\n",
      " disgust     0.510     0.547     0.376    109\n",
      "    fear     0.510     0.391     0.562    80\n",
      "   happy     0.510     0.426     0.679    81\n",
      " neutral     0.510     0.659     0.643    84\n",
      "     sad     0.510     0.410     0.368    87\n",
      "surprise     0.510     0.627     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.510     0.530     0.522    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.729060 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.596962  [ 1200/ 4873]\n",
      "loss: 0.301807  [ 2400/ 4873]\n",
      "loss: 0.630729  [ 3600/ 4873]\n",
      "loss: 0.518645  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.658     0.495    105\n",
      " disgust     0.528     0.578     0.440    109\n",
      "    fear     0.528     0.375     0.450    80\n",
      "   happy     0.528     0.468     0.630    81\n",
      " neutral     0.528     0.632     0.714    84\n",
      "     sad     0.528     0.455     0.402    87\n",
      "surprise     0.528     0.563     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.533     0.537    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.732946 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.545934  [ 1200/ 4873]\n",
      "loss: 1.084555  [ 2400/ 4873]\n",
      "loss: 0.405069  [ 3600/ 4873]\n",
      "loss: 0.532177  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.526     0.595     0.476    105\n",
      " disgust     0.526     0.565     0.477    109\n",
      "    fear     0.526     0.359     0.463    80\n",
      "   happy     0.526     0.549     0.617    81\n",
      " neutral     0.526     0.596     0.667    84\n",
      "     sad     0.526     0.493     0.425    87\n",
      "surprise     0.526     0.549     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.526     0.530     0.533    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.757671 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.425633  [ 1200/ 4873]\n",
      "loss: 0.615759  [ 2400/ 4873]\n",
      "loss: 0.554171  [ 3600/ 4873]\n",
      "loss: 0.385230  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.627     0.495    105\n",
      " disgust     0.533     0.560     0.514    109\n",
      "    fear     0.533     0.402     0.562    80\n",
      "   happy     0.533     0.440     0.630    81\n",
      " neutral     0.533     0.696     0.655    84\n",
      "     sad     0.533     0.462     0.345    87\n",
      "surprise     0.533     0.655     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.549     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.728162 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.570511  [ 1200/ 4873]\n",
      "loss: 0.626024  [ 2400/ 4873]\n",
      "loss: 0.464511  [ 3600/ 4873]\n",
      "loss: 0.706513  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.508     0.651     0.533    105\n",
      " disgust     0.508     0.562     0.413    109\n",
      "    fear     0.508     0.310     0.487    80\n",
      "   happy     0.508     0.505     0.617    81\n",
      " neutral     0.508     0.688     0.655    84\n",
      "     sad     0.508     0.420     0.333    87\n",
      "surprise     0.508     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.508     0.521     0.515    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.736183 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.461329  [ 1200/ 4873]\n",
      "loss: 0.583978  [ 2400/ 4873]\n",
      "loss: 0.396350  [ 3600/ 4873]\n",
      "loss: 0.496681  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.507     0.750     0.486    105\n",
      " disgust     0.507     0.521     0.349    109\n",
      "    fear     0.507     0.344     0.525    80\n",
      "   happy     0.507     0.410     0.617    81\n",
      " neutral     0.507     0.747     0.667    84\n",
      "     sad     0.507     0.400     0.414    87\n",
      "surprise     0.507     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.507     0.539     0.517    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.719156 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 1.186879  [ 1200/ 4873]\n",
      "loss: 1.161981  [ 2400/ 4873]\n",
      "loss: 0.492209  [ 3600/ 4873]\n",
      "loss: 0.797601  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.764     0.524    105\n",
      " disgust     0.528     0.565     0.358    109\n",
      "    fear     0.528     0.410     0.512    80\n",
      "   happy     0.528     0.437     0.642    81\n",
      " neutral     0.528     0.659     0.667    84\n",
      "     sad     0.528     0.394     0.425    87\n",
      "surprise     0.528     0.592     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.546     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.688181 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.271825  [ 1200/ 4873]\n",
      "loss: 0.550718  [ 2400/ 4873]\n",
      "loss: 0.587261  [ 3600/ 4873]\n",
      "loss: 0.513501  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.516     0.600     0.486    105\n",
      " disgust     0.516     0.542     0.413    109\n",
      "    fear     0.516     0.389     0.525    80\n",
      "   happy     0.516     0.455     0.617    81\n",
      " neutral     0.516     0.683     0.667    84\n",
      "     sad     0.516     0.471     0.368    87\n",
      "surprise     0.516     0.527     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.516     0.524     0.526    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.740337 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 1.019979  [ 1200/ 4873]\n",
      "loss: 0.536193  [ 2400/ 4873]\n",
      "loss: 0.757369  [ 3600/ 4873]\n",
      "loss: 0.521046  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.510     0.717     0.410    105\n",
      " disgust     0.510     0.621     0.330    109\n",
      "    fear     0.510     0.374     0.463    80\n",
      "   happy     0.510     0.397     0.691    81\n",
      " neutral     0.510     0.644     0.690    84\n",
      "     sad     0.510     0.449     0.460    87\n",
      "surprise     0.510     0.562     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.510     0.538     0.526    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.789187 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.624499  [ 1200/ 4873]\n",
      "loss: 0.612636  [ 2400/ 4873]\n",
      "loss: 0.836570  [ 3600/ 4873]\n",
      "loss: 0.633096  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.679     0.543    105\n",
      " disgust     0.531     0.590     0.450    109\n",
      "    fear     0.531     0.358     0.487    80\n",
      "   happy     0.531     0.446     0.617    81\n",
      " neutral     0.531     0.659     0.690    84\n",
      "     sad     0.531     0.474     0.414    87\n",
      "surprise     0.531     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.544     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.696321 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.438757  [ 1200/ 4873]\n",
      "loss: 0.761650  [ 2400/ 4873]\n",
      "loss: 0.632168  [ 3600/ 4873]\n",
      "loss: 1.062897  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.516     0.680     0.486    105\n",
      " disgust     0.516     0.597     0.422    109\n",
      "    fear     0.516     0.344     0.525    80\n",
      "   happy     0.516     0.385     0.617    81\n",
      " neutral     0.516     0.695     0.679    84\n",
      "     sad     0.516     0.492     0.368    87\n",
      "surprise     0.516     0.627     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.516     0.546     0.525    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.658164 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.407224  [ 1200/ 4873]\n",
      "loss: 0.826603  [ 2400/ 4873]\n",
      "loss: 0.504359  [ 3600/ 4873]\n",
      "loss: 0.593579  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.520     0.696     0.457    105\n",
      " disgust     0.520     0.490     0.468    109\n",
      "    fear     0.520     0.366     0.463    80\n",
      "   happy     0.520     0.473     0.654    81\n",
      " neutral     0.520     0.675     0.643    84\n",
      "     sad     0.520     0.444     0.414    87\n",
      "surprise     0.520     0.603     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.520     0.535     0.527    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.705557 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.467494  [ 1200/ 4873]\n",
      "loss: 0.512847  [ 2400/ 4873]\n",
      "loss: 0.763894  [ 3600/ 4873]\n",
      "loss: 1.030430  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.502     0.593     0.486    105\n",
      " disgust     0.502     0.577     0.376    109\n",
      "    fear     0.502     0.386     0.487    80\n",
      "   happy     0.502     0.414     0.679    81\n",
      " neutral     0.502     0.636     0.667    84\n",
      "     sad     0.502     0.438     0.368    87\n",
      "surprise     0.502     0.552     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.502     0.514     0.509    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 1.743538 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.732311  [ 1200/ 4873]\n",
      "loss: 0.642246  [ 2400/ 4873]\n",
      "loss: 0.414476  [ 3600/ 4873]\n",
      "loss: 0.686985  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.518     0.711     0.514    105\n",
      " disgust     0.518     0.612     0.376    109\n",
      "    fear     0.518     0.347     0.512    80\n",
      "   happy     0.518     0.455     0.679    81\n",
      " neutral     0.518     0.655     0.655    84\n",
      "     sad     0.518     0.447     0.391    87\n",
      "surprise     0.518     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.518     0.537     0.527    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.714146 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.839033  [ 1200/ 4873]\n",
      "loss: 0.323410  [ 2400/ 4873]\n",
      "loss: 0.854908  [ 3600/ 4873]\n",
      "loss: 0.405127  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.500     0.725     0.476    105\n",
      " disgust     0.500     0.477     0.284    109\n",
      "    fear     0.500     0.339     0.512    80\n",
      "   happy     0.500     0.421     0.630    81\n",
      " neutral     0.500     0.713     0.679    84\n",
      "     sad     0.500     0.400     0.437    87\n",
      "surprise     0.500     0.627     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.500     0.529     0.514    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.790414 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.475775  [ 1200/ 4873]\n",
      "loss: 0.497173  [ 2400/ 4873]\n",
      "loss: 0.399327  [ 3600/ 4873]\n",
      "loss: 0.803923  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.617     0.476    105\n",
      " disgust     0.528     0.658     0.459    109\n",
      "    fear     0.528     0.333     0.588    80\n",
      "   happy     0.528     0.485     0.605    81\n",
      " neutral     0.528     0.744     0.690    84\n",
      "     sad     0.528     0.464     0.368    87\n",
      "surprise     0.528     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.552     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.728494 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.559585  [ 1200/ 4873]\n",
      "loss: 1.698905  [ 2400/ 4873]\n",
      "loss: 0.681490  [ 3600/ 4873]\n",
      "loss: 0.694217  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.507     0.653     0.448    105\n",
      " disgust     0.507     0.567     0.349    109\n",
      "    fear     0.507     0.353     0.525    80\n",
      "   happy     0.507     0.476     0.605    81\n",
      " neutral     0.507     0.659     0.667    84\n",
      "     sad     0.507     0.432     0.437    87\n",
      "surprise     0.507     0.513     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.507     0.522     0.520    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.780354 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.300439  [ 1200/ 4873]\n",
      "loss: 0.784889  [ 2400/ 4873]\n",
      "loss: 0.730696  [ 3600/ 4873]\n",
      "loss: 0.789305  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.625     0.524    105\n",
      " disgust     0.536     0.551     0.450    109\n",
      "    fear     0.536     0.436     0.512    80\n",
      "   happy     0.536     0.473     0.642    81\n",
      " neutral     0.536     0.634     0.702    84\n",
      "     sad     0.536     0.516     0.368    87\n",
      "surprise     0.536     0.527     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.537     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.747961 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.463355  [ 1200/ 4873]\n",
      "loss: 0.399316  [ 2400/ 4873]\n",
      "loss: 0.784817  [ 3600/ 4873]\n",
      "loss: 0.518152  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.663     0.524    105\n",
      " disgust     0.531     0.571     0.477    109\n",
      "    fear     0.531     0.346     0.562    80\n",
      "   happy     0.531     0.543     0.617    81\n",
      " neutral     0.531     0.705     0.655    84\n",
      "     sad     0.531     0.417     0.345    87\n",
      "surprise     0.531     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.546     0.537    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.677634 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.514006  [ 1200/ 4873]\n",
      "loss: 0.754381  [ 2400/ 4873]\n",
      "loss: 0.579880  [ 3600/ 4873]\n",
      "loss: 0.674124  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.628     0.514    105\n",
      " disgust     0.531     0.644     0.514    109\n",
      "    fear     0.531     0.376     0.512    80\n",
      "   happy     0.531     0.429     0.630    81\n",
      " neutral     0.531     0.697     0.631    84\n",
      "     sad     0.531     0.508     0.345    87\n",
      "surprise     0.531     0.527     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.544     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.718857 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.609726  [ 1200/ 4873]\n",
      "loss: 1.109668  [ 2400/ 4873]\n",
      "loss: 0.331930  [ 3600/ 4873]\n",
      "loss: 0.895583  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.655     0.524    105\n",
      " disgust     0.528     0.610     0.431    109\n",
      "    fear     0.528     0.363     0.512    80\n",
      "   happy     0.528     0.465     0.654    81\n",
      " neutral     0.528     0.691     0.667    84\n",
      "     sad     0.528     0.493     0.391    87\n",
      "surprise     0.528     0.500     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.540     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.749619 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.560774  [ 1200/ 4873]\n",
      "loss: 0.673716  [ 2400/ 4873]\n",
      "loss: 0.531340  [ 3600/ 4873]\n",
      "loss: 0.380787  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.707     0.505    105\n",
      " disgust     0.533     0.596     0.486    109\n",
      "    fear     0.533     0.343     0.600    80\n",
      "   happy     0.533     0.521     0.605    81\n",
      " neutral     0.533     0.769     0.595    84\n",
      "     sad     0.533     0.413     0.356    87\n",
      "surprise     0.533     0.569     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.560     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.771573 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.642917  [ 1200/ 4873]\n",
      "loss: 0.742569  [ 2400/ 4873]\n",
      "loss: 0.474878  [ 3600/ 4873]\n",
      "loss: 0.638506  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.687     0.438    105\n",
      " disgust     0.528     0.577     0.514    109\n",
      "    fear     0.528     0.389     0.438    80\n",
      "   happy     0.528     0.439     0.617    81\n",
      " neutral     0.528     0.647     0.655    84\n",
      "     sad     0.528     0.463     0.425    87\n",
      "surprise     0.528     0.558     0.672    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.537     0.537    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.801270 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.574844  [ 1200/ 4873]\n",
      "loss: 0.593207  [ 2400/ 4873]\n",
      "loss: 0.786134  [ 3600/ 4873]\n",
      "loss: 0.527483  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.526     0.595     0.476    105\n",
      " disgust     0.526     0.531     0.477    109\n",
      "    fear     0.526     0.328     0.512    80\n",
      "   happy     0.526     0.544     0.605    81\n",
      " neutral     0.526     0.706     0.714    84\n",
      "     sad     0.526     0.478     0.368    87\n",
      "surprise     0.526     0.607     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.526     0.541     0.533    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.764907 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.628911  [ 1200/ 4873]\n",
      "loss: 0.302081  [ 2400/ 4873]\n",
      "loss: 0.947419  [ 3600/ 4873]\n",
      "loss: 0.596873  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.591     0.495    105\n",
      " disgust     0.528     0.578     0.477    109\n",
      "    fear     0.528     0.389     0.525    80\n",
      "   happy     0.528     0.451     0.630    81\n",
      " neutral     0.528     0.659     0.667    84\n",
      "     sad     0.528     0.554     0.356    87\n",
      "surprise     0.528     0.543     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.538     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.731501 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.525033  [ 1200/ 4873]\n",
      "loss: 0.894181  [ 2400/ 4873]\n",
      "loss: 0.198429  [ 3600/ 4873]\n",
      "loss: 0.552603  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.794     0.514    105\n",
      " disgust     0.528     0.528     0.431    109\n",
      "    fear     0.528     0.393     0.550    80\n",
      "   happy     0.528     0.441     0.605    81\n",
      " neutral     0.528     0.739     0.607    84\n",
      "     sad     0.528     0.421     0.460    87\n",
      "surprise     0.528     0.561     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.554     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.796825 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.402578  [ 1200/ 4873]\n",
      "loss: 0.304718  [ 2400/ 4873]\n",
      "loss: 0.330153  [ 3600/ 4873]\n",
      "loss: 0.972539  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.548     0.543    105\n",
      " disgust     0.561     0.679     0.523    109\n",
      "    fear     0.561     0.360     0.625    80\n",
      "   happy     0.561     0.578     0.642    81\n",
      " neutral     0.561     0.730     0.643    84\n",
      "     sad     0.561     0.636     0.402    87\n",
      "surprise     0.561     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.587     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.747495 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep221_acc_56.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep194_acc_54\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep221_acc_56\"! Old accuracy: 54.4, new accuracy: 56.1\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.508510  [ 1200/ 4873]\n",
      "loss: 0.437852  [ 2400/ 4873]\n",
      "loss: 0.583463  [ 3600/ 4873]\n",
      "loss: 0.583984  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.630     0.552    105\n",
      " disgust     0.551     0.532     0.532    109\n",
      "    fear     0.551     0.355     0.487    80\n",
      "   happy     0.551     0.632     0.593    81\n",
      " neutral     0.551     0.648     0.702    84\n",
      "     sad     0.551     0.569     0.379    87\n",
      "surprise     0.551     0.554     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.560     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.744959 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.769514  [ 1200/ 4873]\n",
      "loss: 0.546442  [ 2400/ 4873]\n",
      "loss: 0.329426  [ 3600/ 4873]\n",
      "loss: 0.925308  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.622     0.486    105\n",
      " disgust     0.539     0.646     0.486    109\n",
      "    fear     0.539     0.385     0.500    80\n",
      "   happy     0.539     0.441     0.691    81\n",
      " neutral     0.539     0.679     0.679    84\n",
      "     sad     0.539     0.567     0.391    87\n",
      "surprise     0.539     0.535     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.553     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.760810 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.563738  [ 1200/ 4873]\n",
      "loss: 0.861068  [ 2400/ 4873]\n",
      "loss: 0.769764  [ 3600/ 4873]\n",
      "loss: 0.798848  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.679     0.543    105\n",
      " disgust     0.539     0.500     0.468    109\n",
      "    fear     0.539     0.370     0.588    80\n",
      "   happy     0.539     0.560     0.580    81\n",
      " neutral     0.539     0.775     0.655    84\n",
      "     sad     0.539     0.442     0.391    87\n",
      "surprise     0.539     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.558     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.744901 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.232854  [ 1200/ 4873]\n",
      "loss: 0.649644  [ 2400/ 4873]\n",
      "loss: 0.512037  [ 3600/ 4873]\n",
      "loss: 0.363605  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.643     0.514    105\n",
      " disgust     0.534     0.662     0.431    109\n",
      "    fear     0.534     0.368     0.525    80\n",
      "   happy     0.534     0.471     0.605    81\n",
      " neutral     0.534     0.645     0.714    84\n",
      "     sad     0.534     0.507     0.437    87\n",
      "surprise     0.534     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.545     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.750074 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.764662  [ 1200/ 4873]\n",
      "loss: 0.324642  [ 2400/ 4873]\n",
      "loss: 0.402364  [ 3600/ 4873]\n",
      "loss: 0.511468  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.633     0.543    105\n",
      " disgust     0.538     0.543     0.459    109\n",
      "    fear     0.538     0.336     0.525    80\n",
      "   happy     0.538     0.560     0.630    81\n",
      " neutral     0.538     0.659     0.667    84\n",
      "     sad     0.538     0.574     0.356    87\n",
      "surprise     0.538     0.562     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.553     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.809957 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.638110  [ 1200/ 4873]\n",
      "loss: 0.161803  [ 2400/ 4873]\n",
      "loss: 0.354672  [ 3600/ 4873]\n",
      "loss: 0.685750  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.521     0.617     0.476    105\n",
      " disgust     0.521     0.538     0.514    109\n",
      "    fear     0.521     0.341     0.588    80\n",
      "   happy     0.521     0.495     0.617    81\n",
      " neutral     0.521     0.726     0.631    84\n",
      "     sad     0.521     0.562     0.310    87\n",
      "surprise     0.521     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.521     0.545     0.526    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 1.797705 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.372154  [ 1200/ 4873]\n",
      "loss: 0.473615  [ 2400/ 4873]\n",
      "loss: 0.460373  [ 3600/ 4873]\n",
      "loss: 0.891123  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.653     0.467    105\n",
      " disgust     0.533     0.571     0.477    109\n",
      "    fear     0.533     0.373     0.588    80\n",
      "   happy     0.533     0.510     0.630    81\n",
      " neutral     0.533     0.670     0.702    84\n",
      "     sad     0.533     0.485     0.368    87\n",
      "surprise     0.533     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.544     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.819620 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.507200  [ 1200/ 4873]\n",
      "loss: 0.788827  [ 2400/ 4873]\n",
      "loss: 0.878971  [ 3600/ 4873]\n",
      "loss: 0.893729  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.667     0.533    105\n",
      " disgust     0.539     0.614     0.495    109\n",
      "    fear     0.539     0.373     0.550    80\n",
      "   happy     0.539     0.445     0.605    81\n",
      " neutral     0.539     0.724     0.655    84\n",
      "     sad     0.539     0.479     0.391    87\n",
      "surprise     0.539     0.587     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.555     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.757052 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.710585  [ 1200/ 4873]\n",
      "loss: 0.348564  [ 2400/ 4873]\n",
      "loss: 0.537602  [ 3600/ 4873]\n",
      "loss: 0.263198  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.525     0.688     0.524    105\n",
      " disgust     0.525     0.575     0.422    109\n",
      "    fear     0.525     0.408     0.525    80\n",
      "   happy     0.525     0.466     0.593    81\n",
      " neutral     0.525     0.632     0.655    84\n",
      "     sad     0.525     0.459     0.391    87\n",
      "surprise     0.525     0.482     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.525     0.530     0.533    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.814613 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.571580  [ 1200/ 4873]\n",
      "loss: 0.830049  [ 2400/ 4873]\n",
      "loss: 0.527705  [ 3600/ 4873]\n",
      "loss: 0.281399  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.716     0.505    105\n",
      " disgust     0.534     0.696     0.440    109\n",
      "    fear     0.534     0.438     0.525    80\n",
      "   happy     0.534     0.380     0.704    81\n",
      " neutral     0.534     0.692     0.643    84\n",
      "     sad     0.534     0.455     0.402    87\n",
      "surprise     0.534     0.561     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.562     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.753020 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.582676  [ 1200/ 4873]\n",
      "loss: 0.479276  [ 2400/ 4873]\n",
      "loss: 0.701366  [ 3600/ 4873]\n",
      "loss: 0.214470  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.515     0.675     0.495    105\n",
      " disgust     0.515     0.577     0.413    109\n",
      "    fear     0.515     0.374     0.463    80\n",
      "   happy     0.515     0.439     0.617    81\n",
      " neutral     0.515     0.574     0.690    84\n",
      "     sad     0.515     0.583     0.402    87\n",
      "surprise     0.515     0.457     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.515     0.526     0.523    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.828838 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.460372  [ 1200/ 4873]\n",
      "loss: 0.431046  [ 2400/ 4873]\n",
      "loss: 0.677248  [ 3600/ 4873]\n",
      "loss: 0.415543  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.654     0.486    105\n",
      " disgust     0.541     0.585     0.505    109\n",
      "    fear     0.541     0.394     0.512    80\n",
      "   happy     0.541     0.511     0.593    81\n",
      " neutral     0.541     0.663     0.655    84\n",
      "     sad     0.541     0.438     0.448    87\n",
      "surprise     0.541     0.603     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.550     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.833114 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.432846  [ 1200/ 4873]\n",
      "loss: 0.462264  [ 2400/ 4873]\n",
      "loss: 0.390291  [ 3600/ 4873]\n",
      "loss: 0.555699  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.523     0.640     0.457    105\n",
      " disgust     0.523     0.628     0.450    109\n",
      "    fear     0.523     0.344     0.525    80\n",
      "   happy     0.523     0.469     0.654    81\n",
      " neutral     0.523     0.663     0.679    84\n",
      "     sad     0.523     0.507     0.402    87\n",
      "surprise     0.523     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.523     0.539     0.531    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.777974 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.310205  [ 1200/ 4873]\n",
      "loss: 0.651521  [ 2400/ 4873]\n",
      "loss: 0.386844  [ 3600/ 4873]\n",
      "loss: 0.380525  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.662     0.467    105\n",
      " disgust     0.533     0.519     0.505    109\n",
      "    fear     0.533     0.367     0.500    80\n",
      "   happy     0.533     0.515     0.617    81\n",
      " neutral     0.533     0.671     0.655    84\n",
      "     sad     0.533     0.562     0.414    87\n",
      "surprise     0.533     0.513     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.544     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.851084 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.622869  [ 1200/ 4873]\n",
      "loss: 0.943723  [ 2400/ 4873]\n",
      "loss: 0.299498  [ 3600/ 4873]\n",
      "loss: 1.076202  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.680     0.486    105\n",
      " disgust     0.530     0.576     0.486    109\n",
      "    fear     0.530     0.402     0.463    80\n",
      "   happy     0.530     0.422     0.605    81\n",
      " neutral     0.530     0.628     0.702    84\n",
      "     sad     0.530     0.487     0.425    87\n",
      "surprise     0.530     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.530     0.538     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.840733 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.937117  [ 1200/ 4873]\n",
      "loss: 0.314765  [ 2400/ 4873]\n",
      "loss: 0.236864  [ 3600/ 4873]\n",
      "loss: 0.541089  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.663     0.543    105\n",
      " disgust     0.536     0.600     0.523    109\n",
      "    fear     0.536     0.373     0.550    80\n",
      "   happy     0.536     0.439     0.617    81\n",
      " neutral     0.536     0.710     0.583    84\n",
      "     sad     0.536     0.472     0.391    87\n",
      "surprise     0.536     0.643     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.557     0.539    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.812229 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.310960  [ 1200/ 4873]\n",
      "loss: 0.197973  [ 2400/ 4873]\n",
      "loss: 0.625192  [ 3600/ 4873]\n",
      "loss: 0.368939  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.680     0.486    105\n",
      " disgust     0.541     0.530     0.486    109\n",
      "    fear     0.541     0.384     0.537    80\n",
      "   happy     0.541     0.464     0.630    81\n",
      " neutral     0.541     0.734     0.690    84\n",
      "     sad     0.541     0.507     0.437    87\n",
      "surprise     0.541     0.610     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.558     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.841459 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.553752  [ 1200/ 4873]\n",
      "loss: 0.343247  [ 2400/ 4873]\n",
      "loss: 0.474845  [ 3600/ 4873]\n",
      "loss: 0.260869  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.632     0.571    105\n",
      " disgust     0.551     0.578     0.477    109\n",
      "    fear     0.551     0.357     0.637    80\n",
      "   happy     0.551     0.590     0.568    81\n",
      " neutral     0.551     0.779     0.631    84\n",
      "     sad     0.551     0.480     0.414    87\n",
      "surprise     0.551     0.623     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.577     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.737868 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.592291  [ 1200/ 4873]\n",
      "loss: 1.144870  [ 2400/ 4873]\n",
      "loss: 0.468175  [ 3600/ 4873]\n",
      "loss: 0.433339  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.662     0.505    105\n",
      " disgust     0.534     0.563     0.450    109\n",
      "    fear     0.534     0.422     0.537    80\n",
      "   happy     0.534     0.468     0.642    81\n",
      " neutral     0.534     0.684     0.643    84\n",
      "     sad     0.534     0.409     0.437    87\n",
      "surprise     0.534     0.638     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.549     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.851020 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.546218  [ 1200/ 4873]\n",
      "loss: 0.489055  [ 2400/ 4873]\n",
      "loss: 0.653683  [ 3600/ 4873]\n",
      "loss: 0.456816  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.510     0.658     0.476    105\n",
      " disgust     0.510     0.584     0.413    109\n",
      "    fear     0.510     0.421     0.500    80\n",
      "   happy     0.510     0.394     0.642    81\n",
      " neutral     0.510     0.583     0.667    84\n",
      "     sad     0.510     0.493     0.402    87\n",
      "surprise     0.510     0.524     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.510     0.522     0.517    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.928807 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.553251  [ 1200/ 4873]\n",
      "loss: 0.498081  [ 2400/ 4873]\n",
      "loss: 0.762812  [ 3600/ 4873]\n",
      "loss: 0.602073  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.526     0.722     0.543    105\n",
      " disgust     0.526     0.561     0.422    109\n",
      "    fear     0.526     0.376     0.475    80\n",
      "   happy     0.526     0.451     0.630    81\n",
      " neutral     0.526     0.663     0.679    84\n",
      "     sad     0.526     0.420     0.425    87\n",
      "surprise     0.526     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.526     0.538     0.531    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.826695 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.515634  [ 1200/ 4873]\n",
      "loss: 0.569265  [ 2400/ 4873]\n",
      "loss: 0.325941  [ 3600/ 4873]\n",
      "loss: 0.288934  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.598     0.524    105\n",
      " disgust     0.543     0.596     0.569    109\n",
      "    fear     0.543     0.343     0.600    80\n",
      "   happy     0.543     0.557     0.605    81\n",
      " neutral     0.543     0.712     0.619    84\n",
      "     sad     0.543     0.544     0.356    87\n",
      "surprise     0.543     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.565     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.848806 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.473299  [ 1200/ 4873]\n",
      "loss: 0.257556  [ 2400/ 4873]\n",
      "loss: 0.148533  [ 3600/ 4873]\n",
      "loss: 0.547361  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.622     0.486    105\n",
      " disgust     0.528     0.524     0.505    109\n",
      "    fear     0.528     0.372     0.562    80\n",
      "   happy     0.528     0.566     0.580    81\n",
      " neutral     0.528     0.700     0.667    84\n",
      "     sad     0.528     0.472     0.391    87\n",
      "surprise     0.528     0.507     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.538     0.532    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.963824 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.823358  [ 1200/ 4873]\n",
      "loss: 0.927045  [ 2400/ 4873]\n",
      "loss: 0.389719  [ 3600/ 4873]\n",
      "loss: 0.824498  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.520     0.686     0.457    105\n",
      " disgust     0.520     0.606     0.394    109\n",
      "    fear     0.520     0.373     0.512    80\n",
      "   happy     0.520     0.431     0.617    81\n",
      " neutral     0.520     0.700     0.667    84\n",
      "     sad     0.520     0.443     0.448    87\n",
      "surprise     0.520     0.533     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.520     0.539     0.532    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.862659 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.664303  [ 1200/ 4873]\n",
      "loss: 0.474614  [ 2400/ 4873]\n",
      "loss: 0.558931  [ 3600/ 4873]\n",
      "loss: 0.451318  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.663     0.581    105\n",
      " disgust     0.548     0.663     0.523    109\n",
      "    fear     0.548     0.381     0.500    80\n",
      "   happy     0.548     0.459     0.630    81\n",
      " neutral     0.548     0.622     0.667    84\n",
      "     sad     0.548     0.507     0.391    87\n",
      "surprise     0.548     0.593     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.556     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 1.802458 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.599098  [ 1200/ 4873]\n",
      "loss: 0.490298  [ 2400/ 4873]\n",
      "loss: 0.818060  [ 3600/ 4873]\n",
      "loss: 0.606836  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.525     0.685     0.476    105\n",
      " disgust     0.525     0.538     0.459    109\n",
      "    fear     0.525     0.406     0.487    80\n",
      "   happy     0.525     0.458     0.679    81\n",
      " neutral     0.525     0.684     0.619    84\n",
      "     sad     0.525     0.455     0.460    87\n",
      "surprise     0.525     0.531     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.525     0.537     0.530    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.972661 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.673344  [ 1200/ 4873]\n",
      "loss: 0.543711  [ 2400/ 4873]\n",
      "loss: 0.577718  [ 3600/ 4873]\n",
      "loss: 0.273060  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.663     0.562    105\n",
      " disgust     0.548     0.634     0.477    109\n",
      "    fear     0.548     0.392     0.500    80\n",
      "   happy     0.548     0.442     0.617    81\n",
      " neutral     0.548     0.691     0.667    84\n",
      "     sad     0.548     0.507     0.425    87\n",
      "surprise     0.548     0.571     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.557     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 1.823566 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.720614  [ 1200/ 4873]\n",
      "loss: 0.416017  [ 2400/ 4873]\n",
      "loss: 1.523363  [ 3600/ 4873]\n",
      "loss: 0.405595  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.628     0.514    105\n",
      " disgust     0.554     0.622     0.514    109\n",
      "    fear     0.554     0.398     0.537    80\n",
      "   happy     0.554     0.514     0.667    81\n",
      " neutral     0.554     0.683     0.667    84\n",
      "     sad     0.554     0.493     0.391    87\n",
      "surprise     0.554     0.586     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.561     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.912215 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.698151  [ 1200/ 4873]\n",
      "loss: 0.497764  [ 2400/ 4873]\n",
      "loss: 0.365904  [ 3600/ 4873]\n",
      "loss: 0.477097  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.667     0.514    105\n",
      " disgust     0.562     0.587     0.560    109\n",
      "    fear     0.562     0.392     0.613    80\n",
      "   happy     0.562     0.515     0.630    81\n",
      " neutral     0.562     0.711     0.643    84\n",
      "     sad     0.562     0.537     0.414    87\n",
      "surprise     0.562     0.655     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.580     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 1.789866 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep250_acc_56.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep221_acc_56\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep250_acc_56\"! Old accuracy: 56.1, new accuracy: 56.2\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 1.188337  [ 1200/ 4873]\n",
      "loss: 0.315370  [ 2400/ 4873]\n",
      "loss: 0.360385  [ 3600/ 4873]\n",
      "loss: 0.261605  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.667     0.552    105\n",
      " disgust     0.548     0.621     0.495    109\n",
      "    fear     0.548     0.430     0.463    80\n",
      "   happy     0.548     0.454     0.605    81\n",
      " neutral     0.548     0.606     0.679    84\n",
      "     sad     0.548     0.569     0.425    87\n",
      "surprise     0.548     0.506     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.550     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 1.897683 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.171431  [ 1200/ 4873]\n",
      "loss: 1.067777  [ 2400/ 4873]\n",
      "loss: 0.270719  [ 3600/ 4873]\n",
      "loss: 0.216240  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.707     0.505    105\n",
      " disgust     0.528     0.610     0.431    109\n",
      "    fear     0.528     0.351     0.500    80\n",
      "   happy     0.528     0.423     0.642    81\n",
      " neutral     0.528     0.692     0.643    84\n",
      "     sad     0.528     0.459     0.448    87\n",
      "surprise     0.528     0.638     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.554     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.843968 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.524685  [ 1200/ 4873]\n",
      "loss: 0.751019  [ 2400/ 4873]\n",
      "loss: 0.684101  [ 3600/ 4873]\n",
      "loss: 0.247600  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.693     0.495    105\n",
      " disgust     0.552     0.567     0.505    109\n",
      "    fear     0.552     0.412     0.525    80\n",
      "   happy     0.552     0.472     0.617    81\n",
      " neutral     0.552     0.670     0.702    84\n",
      "     sad     0.552     0.489     0.506    87\n",
      "surprise     0.552     0.673     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.568     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 1.893682 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.508855  [ 1200/ 4873]\n",
      "loss: 0.244479  [ 2400/ 4873]\n",
      "loss: 0.216302  [ 3600/ 4873]\n",
      "loss: 0.260942  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.736     0.505    105\n",
      " disgust     0.544     0.585     0.505    109\n",
      "    fear     0.544     0.420     0.463    80\n",
      "   happy     0.544     0.448     0.642    81\n",
      " neutral     0.544     0.663     0.679    84\n",
      "     sad     0.544     0.514     0.437    87\n",
      "surprise     0.544     0.500     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.552     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 1.869434 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.283990  [ 1200/ 4873]\n",
      "loss: 0.369158  [ 2400/ 4873]\n",
      "loss: 0.475709  [ 3600/ 4873]\n",
      "loss: 0.402108  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.617     0.552    105\n",
      " disgust     0.554     0.613     0.523    109\n",
      "    fear     0.554     0.396     0.525    80\n",
      "   happy     0.554     0.557     0.605    81\n",
      " neutral     0.554     0.635     0.726    84\n",
      "     sad     0.554     0.556     0.402    87\n",
      "surprise     0.554     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.955585 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.382206  [ 1200/ 4873]\n",
      "loss: 0.380074  [ 2400/ 4873]\n",
      "loss: 0.500562  [ 3600/ 4873]\n",
      "loss: 0.733106  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.691     0.448    105\n",
      " disgust     0.530     0.622     0.422    109\n",
      "    fear     0.530     0.423     0.550    80\n",
      "   happy     0.530     0.433     0.642    81\n",
      " neutral     0.530     0.618     0.655    84\n",
      "     sad     0.530     0.526     0.460    87\n",
      "surprise     0.530     0.494     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.530     0.544     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.940861 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.509165  [ 1200/ 4873]\n",
      "loss: 0.394618  [ 2400/ 4873]\n",
      "loss: 0.363438  [ 3600/ 4873]\n",
      "loss: 0.316293  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.684     0.514    105\n",
      " disgust     0.528     0.609     0.486    109\n",
      "    fear     0.528     0.407     0.463    80\n",
      "   happy     0.528     0.430     0.605    81\n",
      " neutral     0.528     0.607     0.643    84\n",
      "     sad     0.528     0.471     0.460    87\n",
      "surprise     0.528     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.535     0.531    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.949034 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.451037  [ 1200/ 4873]\n",
      "loss: 0.861519  [ 2400/ 4873]\n",
      "loss: 0.616604  [ 3600/ 4873]\n",
      "loss: 0.307406  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.654     0.505    105\n",
      " disgust     0.530     0.587     0.495    109\n",
      "    fear     0.530     0.390     0.487    80\n",
      "   happy     0.530     0.459     0.617    81\n",
      " neutral     0.530     0.588     0.679    84\n",
      "     sad     0.530     0.521     0.437    87\n",
      "surprise     0.530     0.552     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.530     0.536     0.531    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.907549 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.181353  [ 1200/ 4873]\n",
      "loss: 0.148005  [ 2400/ 4873]\n",
      "loss: 0.363220  [ 3600/ 4873]\n",
      "loss: 0.355412  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.625     0.524    105\n",
      " disgust     0.543     0.607     0.495    109\n",
      "    fear     0.543     0.408     0.613    80\n",
      "   happy     0.543     0.486     0.654    81\n",
      " neutral     0.543     0.675     0.667    84\n",
      "     sad     0.543     0.615     0.368    87\n",
      "surprise     0.543     0.464     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.554     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.900877 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.402012  [ 1200/ 4873]\n",
      "loss: 0.465773  [ 2400/ 4873]\n",
      "loss: 0.140163  [ 3600/ 4873]\n",
      "loss: 0.493600  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.710     0.467    105\n",
      " disgust     0.533     0.504     0.560    109\n",
      "    fear     0.533     0.349     0.562    80\n",
      "   happy     0.533     0.547     0.580    81\n",
      " neutral     0.533     0.769     0.595    84\n",
      "     sad     0.533     0.460     0.460    87\n",
      "surprise     0.533     0.623     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.566     0.534    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.941712 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.282840  [ 1200/ 4873]\n",
      "loss: 0.285237  [ 2400/ 4873]\n",
      "loss: 0.452910  [ 3600/ 4873]\n",
      "loss: 0.446637  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.621     0.514    105\n",
      " disgust     0.546     0.610     0.459    109\n",
      "    fear     0.546     0.381     0.537    80\n",
      "   happy     0.546     0.515     0.617    81\n",
      " neutral     0.546     0.718     0.667    84\n",
      "     sad     0.546     0.526     0.471    87\n",
      "surprise     0.546     0.520     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.556     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 1.961145 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.229585  [ 1200/ 4873]\n",
      "loss: 0.489139  [ 2400/ 4873]\n",
      "loss: 0.555272  [ 3600/ 4873]\n",
      "loss: 0.362745  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.634     0.610    105\n",
      " disgust     0.551     0.488     0.550    109\n",
      "    fear     0.551     0.353     0.512    80\n",
      "   happy     0.551     0.681     0.580    81\n",
      " neutral     0.551     0.740     0.679    84\n",
      "     sad     0.551     0.515     0.402    87\n",
      "surprise     0.551     0.571     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.569     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.004576 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 1.275836  [ 1200/ 4873]\n",
      "loss: 0.650248  [ 2400/ 4873]\n",
      "loss: 0.433082  [ 3600/ 4873]\n",
      "loss: 0.411920  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.587     0.514    105\n",
      " disgust     0.531     0.626     0.523    109\n",
      "    fear     0.531     0.378     0.463    80\n",
      "   happy     0.531     0.468     0.630    81\n",
      " neutral     0.531     0.648     0.679    84\n",
      "     sad     0.531     0.472     0.391    87\n",
      "surprise     0.531     0.567     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.535     0.533    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.937097 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.368549  [ 1200/ 4873]\n",
      "loss: 0.334601  [ 2400/ 4873]\n",
      "loss: 0.373657  [ 3600/ 4873]\n",
      "loss: 0.391380  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.712     0.495    105\n",
      " disgust     0.541     0.544     0.514    109\n",
      "    fear     0.541     0.367     0.550    80\n",
      "   happy     0.541     0.514     0.667    81\n",
      " neutral     0.541     0.757     0.631    84\n",
      "     sad     0.541     0.456     0.414    87\n",
      "surprise     0.541     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.562     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.899153 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.544497  [ 1200/ 4873]\n",
      "loss: 0.504532  [ 2400/ 4873]\n",
      "loss: 0.688613  [ 3600/ 4873]\n",
      "loss: 0.430290  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.606     0.600    105\n",
      " disgust     0.552     0.508     0.578    109\n",
      "    fear     0.552     0.367     0.500    80\n",
      "   happy     0.552     0.667     0.543    81\n",
      " neutral     0.552     0.704     0.679    84\n",
      "     sad     0.552     0.540     0.391    87\n",
      "surprise     0.552     0.571     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.566     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 1.956262 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.204121  [ 1200/ 4873]\n",
      "loss: 0.542978  [ 2400/ 4873]\n",
      "loss: 0.363942  [ 3600/ 4873]\n",
      "loss: 0.579175  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.525     0.618     0.524    105\n",
      " disgust     0.525     0.654     0.486    109\n",
      "    fear     0.525     0.384     0.475    80\n",
      "   happy     0.525     0.447     0.568    81\n",
      " neutral     0.525     0.637     0.690    84\n",
      "     sad     0.525     0.448     0.448    87\n",
      "surprise     0.525     0.517     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.525     0.529     0.525    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 2.038319 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.190994  [ 1200/ 4873]\n",
      "loss: 0.250217  [ 2400/ 4873]\n",
      "loss: 0.353976  [ 3600/ 4873]\n",
      "loss: 0.369015  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.614     0.514    105\n",
      " disgust     0.549     0.722     0.523    109\n",
      "    fear     0.549     0.392     0.588    80\n",
      "   happy     0.549     0.462     0.593    81\n",
      " neutral     0.549     0.624     0.690    84\n",
      "     sad     0.549     0.587     0.425    87\n",
      "surprise     0.549     0.540     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.563     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.948606 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.557806  [ 1200/ 4873]\n",
      "loss: 0.697851  [ 2400/ 4873]\n",
      "loss: 0.404086  [ 3600/ 4873]\n",
      "loss: 0.254639  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.702     0.562    105\n",
      " disgust     0.538     0.551     0.450    109\n",
      "    fear     0.538     0.418     0.575    80\n",
      "   happy     0.538     0.505     0.580    81\n",
      " neutral     0.538     0.639     0.631    84\n",
      "     sad     0.538     0.488     0.460    87\n",
      "surprise     0.538     0.493     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.542     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.057404 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.556150  [ 1200/ 4873]\n",
      "loss: 0.304915  [ 2400/ 4873]\n",
      "loss: 0.155023  [ 3600/ 4873]\n",
      "loss: 0.298032  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.667     0.552    105\n",
      " disgust     0.533     0.559     0.477    109\n",
      "    fear     0.533     0.417     0.500    80\n",
      "   happy     0.533     0.472     0.617    81\n",
      " neutral     0.533     0.626     0.679    84\n",
      "     sad     0.533     0.500     0.414    87\n",
      "surprise     0.533     0.492     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.533     0.534    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.966872 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.597999  [ 1200/ 4873]\n",
      "loss: 0.588976  [ 2400/ 4873]\n",
      "loss: 0.761679  [ 3600/ 4873]\n",
      "loss: 0.377228  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.663     0.562    105\n",
      " disgust     0.543     0.578     0.541    109\n",
      "    fear     0.543     0.345     0.512    80\n",
      "   happy     0.543     0.549     0.556    81\n",
      " neutral     0.543     0.659     0.667    84\n",
      "     sad     0.543     0.556     0.402    87\n",
      "surprise     0.543     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.552     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.984750 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.248894  [ 1200/ 4873]\n",
      "loss: 0.248455  [ 2400/ 4873]\n",
      "loss: 0.497661  [ 3600/ 4873]\n",
      "loss: 0.827892  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.700     0.533    105\n",
      " disgust     0.551     0.621     0.541    109\n",
      "    fear     0.551     0.409     0.562    80\n",
      "   happy     0.551     0.510     0.605    81\n",
      " neutral     0.551     0.740     0.643    84\n",
      "     sad     0.551     0.442     0.437    87\n",
      "surprise     0.551     0.500     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.560     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.980913 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.237340  [ 1200/ 4873]\n",
      "loss: 0.450029  [ 2400/ 4873]\n",
      "loss: 0.236354  [ 3600/ 4873]\n",
      "loss: 0.234334  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.625     0.476    105\n",
      " disgust     0.530     0.622     0.468    109\n",
      "    fear     0.530     0.415     0.487    80\n",
      "   happy     0.530     0.431     0.617    81\n",
      " neutral     0.530     0.621     0.702    84\n",
      "     sad     0.530     0.544     0.425    87\n",
      "surprise     0.530     0.493     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.530     0.536     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.027173 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.541189  [ 1200/ 4873]\n",
      "loss: 0.201226  [ 2400/ 4873]\n",
      "loss: 0.942089  [ 3600/ 4873]\n",
      "loss: 0.223030  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.690     0.571    105\n",
      " disgust     0.552     0.602     0.486    109\n",
      "    fear     0.552     0.440     0.500    80\n",
      "   happy     0.552     0.469     0.654    81\n",
      " neutral     0.552     0.679     0.679    84\n",
      "     sad     0.552     0.522     0.402    87\n",
      "surprise     0.552     0.487     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.556     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 1.943815 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.408792  [ 1200/ 4873]\n",
      "loss: 0.462937  [ 2400/ 4873]\n",
      "loss: 0.596524  [ 3600/ 4873]\n",
      "loss: 0.668119  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.663     0.562    105\n",
      " disgust     0.544     0.533     0.523    109\n",
      "    fear     0.544     0.417     0.537    80\n",
      "   happy     0.544     0.610     0.580    81\n",
      " neutral     0.544     0.642     0.619    84\n",
      "     sad     0.544     0.453     0.448    87\n",
      "surprise     0.544     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.549     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 1.955596 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.423507  [ 1200/ 4873]\n",
      "loss: 0.335232  [ 2400/ 4873]\n",
      "loss: 0.298768  [ 3600/ 4873]\n",
      "loss: 0.143121  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.637     0.552    105\n",
      " disgust     0.546     0.604     0.587    109\n",
      "    fear     0.546     0.370     0.500    80\n",
      "   happy     0.546     0.495     0.568    81\n",
      " neutral     0.546     0.663     0.679    84\n",
      "     sad     0.546     0.508     0.368    87\n",
      "surprise     0.546     0.571     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.550     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 1.940428 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.979348  [ 1200/ 4873]\n",
      "loss: 0.753473  [ 2400/ 4873]\n",
      "loss: 0.205341  [ 3600/ 4873]\n",
      "loss: 0.262861  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.707     0.505    105\n",
      " disgust     0.549     0.609     0.486    109\n",
      "    fear     0.549     0.386     0.550    80\n",
      "   happy     0.549     0.486     0.654    81\n",
      " neutral     0.549     0.724     0.655    84\n",
      "     sad     0.549     0.471     0.471    87\n",
      "surprise     0.549     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.566     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.898744 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.615358  [ 1200/ 4873]\n",
      "loss: 0.351296  [ 2400/ 4873]\n",
      "loss: 0.489600  [ 3600/ 4873]\n",
      "loss: 0.393531  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.648     0.562    105\n",
      " disgust     0.543     0.618     0.505    109\n",
      "    fear     0.543     0.396     0.475    80\n",
      "   happy     0.543     0.500     0.605    81\n",
      " neutral     0.543     0.671     0.631    84\n",
      "     sad     0.543     0.470     0.448    87\n",
      "surprise     0.543     0.514     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.545     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.982816 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.754574  [ 1200/ 4873]\n",
      "loss: 0.417662  [ 2400/ 4873]\n",
      "loss: 0.366192  [ 3600/ 4873]\n",
      "loss: 0.558317  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.696     0.457    105\n",
      " disgust     0.530     0.634     0.541    109\n",
      "    fear     0.530     0.374     0.425    80\n",
      "   happy     0.530     0.370     0.630    81\n",
      " neutral     0.530     0.690     0.690    84\n",
      "     sad     0.530     0.542     0.448    87\n",
      "surprise     0.530     0.540     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.530     0.549     0.532    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.002479 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.142991  [ 1200/ 4873]\n",
      "loss: 0.424853  [ 2400/ 4873]\n",
      "loss: 0.571070  [ 3600/ 4873]\n",
      "loss: 0.240732  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.651     0.533    105\n",
      " disgust     0.554     0.590     0.541    109\n",
      "    fear     0.554     0.415     0.487    80\n",
      "   happy     0.554     0.515     0.642    81\n",
      " neutral     0.554     0.639     0.631    84\n",
      "     sad     0.554     0.512     0.483    87\n",
      "surprise     0.554     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.557     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.967976 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.283130  [ 1200/ 4873]\n",
      "loss: 0.221093  [ 2400/ 4873]\n",
      "loss: 0.824362  [ 3600/ 4873]\n",
      "loss: 0.341492  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.604     0.581    105\n",
      " disgust     0.552     0.611     0.532    109\n",
      "    fear     0.552     0.393     0.575    80\n",
      "   happy     0.552     0.490     0.593    81\n",
      " neutral     0.552     0.683     0.667    84\n",
      "     sad     0.552     0.561     0.425    87\n",
      "surprise     0.552     0.608     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.564     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.016278 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.126038  [ 1200/ 4873]\n",
      "loss: 0.210734  [ 2400/ 4873]\n",
      "loss: 0.527415  [ 3600/ 4873]\n",
      "loss: 0.258522  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.699     0.552    105\n",
      " disgust     0.559     0.579     0.505    109\n",
      "    fear     0.559     0.417     0.562    80\n",
      "   happy     0.559     0.490     0.593    81\n",
      " neutral     0.559     0.713     0.679    84\n",
      "     sad     0.559     0.519     0.471    87\n",
      "surprise     0.559     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.567     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.972797 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.078385  [ 1200/ 4873]\n",
      "loss: 0.837652  [ 2400/ 4873]\n",
      "loss: 0.320286  [ 3600/ 4873]\n",
      "loss: 0.269130  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.590     0.562    105\n",
      " disgust     0.557     0.617     0.532    109\n",
      "    fear     0.557     0.412     0.525    80\n",
      "   happy     0.557     0.521     0.605    81\n",
      " neutral     0.557     0.741     0.714    84\n",
      "     sad     0.557     0.528     0.437    87\n",
      "surprise     0.557     0.507     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.559     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.017033 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.510742  [ 1200/ 4873]\n",
      "loss: 1.076030  [ 2400/ 4873]\n",
      "loss: 0.447328  [ 3600/ 4873]\n",
      "loss: 0.690964  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.581     0.514    105\n",
      " disgust     0.544     0.598     0.560    109\n",
      "    fear     0.544     0.351     0.575    80\n",
      "   happy     0.544     0.595     0.580    81\n",
      " neutral     0.544     0.675     0.643    84\n",
      "     sad     0.544     0.567     0.437    87\n",
      "surprise     0.544     0.552     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.560     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.017474 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.352011  [ 1200/ 4873]\n",
      "loss: 0.471816  [ 2400/ 4873]\n",
      "loss: 0.556110  [ 3600/ 4873]\n",
      "loss: 0.455285  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.633     0.543    105\n",
      " disgust     0.552     0.594     0.578    109\n",
      "    fear     0.552     0.406     0.487    80\n",
      "   happy     0.552     0.536     0.556    81\n",
      " neutral     0.552     0.626     0.679    84\n",
      "     sad     0.552     0.507     0.437    87\n",
      "surprise     0.552     0.559     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.552     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 1.988427 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.437610  [ 1200/ 4873]\n",
      "loss: 0.525438  [ 2400/ 4873]\n",
      "loss: 0.515427  [ 3600/ 4873]\n",
      "loss: 0.191444  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.696     0.524    105\n",
      " disgust     0.549     0.535     0.560    109\n",
      "    fear     0.549     0.380     0.512    80\n",
      "   happy     0.549     0.575     0.617    81\n",
      " neutral     0.549     0.648     0.679    84\n",
      "     sad     0.549     0.529     0.414    87\n",
      "surprise     0.549     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.556     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.052371 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.530832  [ 1200/ 4873]\n",
      "loss: 0.344232  [ 2400/ 4873]\n",
      "loss: 0.357139  [ 3600/ 4873]\n",
      "loss: 0.598180  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.679     0.524    105\n",
      " disgust     0.559     0.580     0.468    109\n",
      "    fear     0.559     0.463     0.625    80\n",
      "   happy     0.559     0.515     0.654    81\n",
      " neutral     0.559     0.640     0.679    84\n",
      "     sad     0.559     0.470     0.448    87\n",
      "surprise     0.559     0.621     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.567     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.956170 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.497663  [ 1200/ 4873]\n",
      "loss: 0.296614  [ 2400/ 4873]\n",
      "loss: 0.483815  [ 3600/ 4873]\n",
      "loss: 0.424106  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.583     0.533    105\n",
      " disgust     0.536     0.613     0.450    109\n",
      "    fear     0.536     0.409     0.475    80\n",
      "   happy     0.536     0.525     0.642    81\n",
      " neutral     0.536     0.628     0.702    84\n",
      "     sad     0.536     0.514     0.437    87\n",
      "surprise     0.536     0.473     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.535     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.118579 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.155468  [ 1200/ 4873]\n",
      "loss: 0.313741  [ 2400/ 4873]\n",
      "loss: 0.359253  [ 3600/ 4873]\n",
      "loss: 0.139799  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.655     0.524    105\n",
      " disgust     0.536     0.598     0.450    109\n",
      "    fear     0.536     0.427     0.512    80\n",
      "   happy     0.536     0.453     0.654    81\n",
      " neutral     0.536     0.714     0.655    84\n",
      "     sad     0.536     0.461     0.471    87\n",
      "surprise     0.536     0.508     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.545     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.975762 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.480681  [ 1200/ 4873]\n",
      "loss: 0.489056  [ 2400/ 4873]\n",
      "loss: 0.248129  [ 3600/ 4873]\n",
      "loss: 0.448466  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.740     0.543    105\n",
      " disgust     0.546     0.523     0.523    109\n",
      "    fear     0.546     0.361     0.537    80\n",
      "   happy     0.546     0.505     0.605    81\n",
      " neutral     0.546     0.783     0.643    84\n",
      "     sad     0.546     0.446     0.425    87\n",
      "surprise     0.546     0.643     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.572     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.035052 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.226187  [ 1200/ 4873]\n",
      "loss: 0.363052  [ 2400/ 4873]\n",
      "loss: 0.180770  [ 3600/ 4873]\n",
      "loss: 0.556104  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.659     0.533    105\n",
      " disgust     0.533     0.500     0.495    109\n",
      "    fear     0.533     0.383     0.512    80\n",
      "   happy     0.533     0.522     0.580    81\n",
      " neutral     0.533     0.667     0.619    84\n",
      "     sad     0.533     0.488     0.460    87\n",
      "surprise     0.533     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.543     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 2.074921 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 1.074161  [ 1200/ 4873]\n",
      "loss: 0.254201  [ 2400/ 4873]\n",
      "loss: 0.266676  [ 3600/ 4873]\n",
      "loss: 0.379084  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.659     0.514    105\n",
      " disgust     0.539     0.651     0.495    109\n",
      "    fear     0.539     0.411     0.487    80\n",
      "   happy     0.539     0.455     0.617    81\n",
      " neutral     0.539     0.632     0.655    84\n",
      "     sad     0.539     0.477     0.471    87\n",
      "surprise     0.539     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.546     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.028104 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.443649  [ 1200/ 4873]\n",
      "loss: 0.661443  [ 2400/ 4873]\n",
      "loss: 0.446746  [ 3600/ 4873]\n",
      "loss: 0.132224  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.663     0.619    105\n",
      " disgust     0.546     0.583     0.514    109\n",
      "    fear     0.546     0.409     0.450    80\n",
      "   happy     0.546     0.500     0.593    81\n",
      " neutral     0.546     0.586     0.690    84\n",
      "     sad     0.546     0.589     0.379    87\n",
      "surprise     0.546     0.481     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.544     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.038527 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.455929  [ 1200/ 4873]\n",
      "loss: 0.368854  [ 2400/ 4873]\n",
      "loss: 0.121700  [ 3600/ 4873]\n",
      "loss: 0.239127  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.607     0.486    105\n",
      " disgust     0.541     0.556     0.596    109\n",
      "    fear     0.541     0.376     0.475    80\n",
      "   happy     0.541     0.556     0.617    81\n",
      " neutral     0.541     0.670     0.702    84\n",
      "     sad     0.541     0.552     0.368    87\n",
      "surprise     0.541     0.486     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.543     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.041584 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.519424  [ 1200/ 4873]\n",
      "loss: 1.447644  [ 2400/ 4873]\n",
      "loss: 0.729473  [ 3600/ 4873]\n",
      "loss: 0.377964  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.684     0.514    105\n",
      " disgust     0.551     0.617     0.532    109\n",
      "    fear     0.551     0.429     0.487    80\n",
      "   happy     0.551     0.515     0.617    81\n",
      " neutral     0.551     0.630     0.690    84\n",
      "     sad     0.551     0.470     0.448    87\n",
      "surprise     0.551     0.514     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.551     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.080708 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.284962  [ 1200/ 4873]\n",
      "loss: 0.137648  [ 2400/ 4873]\n",
      "loss: 0.240361  [ 3600/ 4873]\n",
      "loss: 0.533223  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.687     0.543    105\n",
      " disgust     0.546     0.560     0.514    109\n",
      "    fear     0.546     0.381     0.537    80\n",
      "   happy     0.546     0.545     0.593    81\n",
      " neutral     0.546     0.671     0.631    84\n",
      "     sad     0.546     0.449     0.460    87\n",
      "surprise     0.546     0.621     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.559     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.018800 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.272142  [ 1200/ 4873]\n",
      "loss: 0.363393  [ 2400/ 4873]\n",
      "loss: 0.464904  [ 3600/ 4873]\n",
      "loss: 0.327107  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.562     0.514    105\n",
      " disgust     0.548     0.591     0.596    109\n",
      "    fear     0.548     0.350     0.525    80\n",
      "   happy     0.548     0.662     0.605    81\n",
      " neutral     0.548     0.671     0.655    84\n",
      "     sad     0.548     0.556     0.402    87\n",
      "surprise     0.548     0.523     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.559     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.125151 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.208709  [ 1200/ 4873]\n",
      "loss: 0.486712  [ 2400/ 4873]\n",
      "loss: 0.645664  [ 3600/ 4873]\n",
      "loss: 0.756510  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.654     0.486    105\n",
      " disgust     0.538     0.647     0.505    109\n",
      "    fear     0.538     0.365     0.525    80\n",
      "   happy     0.538     0.469     0.654    81\n",
      " neutral     0.538     0.724     0.655    84\n",
      "     sad     0.538     0.471     0.460    87\n",
      "surprise     0.538     0.552     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.554     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.088658 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.364328  [ 1200/ 4873]\n",
      "loss: 1.090801  [ 2400/ 4873]\n",
      "loss: 0.539522  [ 3600/ 4873]\n",
      "loss: 0.604118  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.561     0.524    105\n",
      " disgust     0.528     0.537     0.468    109\n",
      "    fear     0.528     0.481     0.475    80\n",
      "   happy     0.528     0.529     0.568    81\n",
      " neutral     0.528     0.596     0.702    84\n",
      "     sad     0.528     0.552     0.425    87\n",
      "surprise     0.528     0.424     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.526     0.532    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.096801 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.407687  [ 1200/ 4873]\n",
      "loss: 0.292406  [ 2400/ 4873]\n",
      "loss: 0.113695  [ 3600/ 4873]\n",
      "loss: 0.427050  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.637     0.552    105\n",
      " disgust     0.546     0.581     0.495    109\n",
      "    fear     0.546     0.400     0.475    80\n",
      "   happy     0.546     0.505     0.605    81\n",
      " neutral     0.546     0.691     0.667    84\n",
      "     sad     0.546     0.455     0.460    87\n",
      "surprise     0.546     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.551     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.029414 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.368597  [ 1200/ 4873]\n",
      "loss: 0.052069  [ 2400/ 4873]\n",
      "loss: 0.421064  [ 3600/ 4873]\n",
      "loss: 0.358621  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.632     0.571    105\n",
      " disgust     0.552     0.607     0.495    109\n",
      "    fear     0.552     0.429     0.525    80\n",
      "   happy     0.552     0.525     0.654    81\n",
      " neutral     0.552     0.615     0.702    84\n",
      "     sad     0.552     0.500     0.391    87\n",
      "surprise     0.552     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.552     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.113157 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 1.194287  [ 1200/ 4873]\n",
      "loss: 0.888706  [ 2400/ 4873]\n",
      "loss: 0.240684  [ 3600/ 4873]\n",
      "loss: 0.207986  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.697     0.505    105\n",
      " disgust     0.544     0.586     0.532    109\n",
      "    fear     0.544     0.416     0.463    80\n",
      "   happy     0.544     0.490     0.605    81\n",
      " neutral     0.544     0.630     0.690    84\n",
      "     sad     0.544     0.463     0.425    87\n",
      "surprise     0.544     0.541     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.546     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.050905 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.279259  [ 1200/ 4873]\n",
      "loss: 0.486728  [ 2400/ 4873]\n",
      "loss: 0.210181  [ 3600/ 4873]\n",
      "loss: 0.123338  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.584     0.562    105\n",
      " disgust     0.541     0.513     0.550    109\n",
      "    fear     0.541     0.483     0.525    80\n",
      "   happy     0.541     0.605     0.568    81\n",
      " neutral     0.541     0.684     0.643    84\n",
      "     sad     0.541     0.448     0.448    87\n",
      "surprise     0.541     0.476     0.469    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.542     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.288413 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.452121  [ 1200/ 4873]\n",
      "loss: 0.407252  [ 2400/ 4873]\n",
      "loss: 0.360770  [ 3600/ 4873]\n",
      "loss: 0.310758  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.694     0.562    105\n",
      " disgust     0.557     0.596     0.541    109\n",
      "    fear     0.557     0.404     0.550    80\n",
      "   happy     0.557     0.533     0.593    81\n",
      " neutral     0.557     0.655     0.679    84\n",
      "     sad     0.557     0.488     0.460    87\n",
      "surprise     0.557     0.569     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.563     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.076212 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.468472  [ 1200/ 4873]\n",
      "loss: 0.370929  [ 2400/ 4873]\n",
      "loss: 0.145790  [ 3600/ 4873]\n",
      "loss: 0.348278  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.600     0.543    105\n",
      " disgust     0.554     0.648     0.523    109\n",
      "    fear     0.554     0.468     0.463    80\n",
      "   happy     0.554     0.510     0.630    81\n",
      " neutral     0.554     0.577     0.714    84\n",
      "     sad     0.554     0.532     0.471    87\n",
      "surprise     0.554     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.551     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.150223 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.229603  [ 1200/ 4873]\n",
      "loss: 0.700142  [ 2400/ 4873]\n",
      "loss: 0.052827  [ 3600/ 4873]\n",
      "loss: 0.601711  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.605     0.495    105\n",
      " disgust     0.543     0.573     0.541    109\n",
      "    fear     0.543     0.474     0.450    80\n",
      "   happy     0.543     0.490     0.605    81\n",
      " neutral     0.543     0.594     0.714    84\n",
      "     sad     0.543     0.487     0.448    87\n",
      "surprise     0.543     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.541     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.132298 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.133892  [ 1200/ 4873]\n",
      "loss: 0.122757  [ 2400/ 4873]\n",
      "loss: 0.519763  [ 3600/ 4873]\n",
      "loss: 0.366538  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.511     0.635     0.448    105\n",
      " disgust     0.511     0.620     0.450    109\n",
      "    fear     0.511     0.424     0.450    80\n",
      "   happy     0.511     0.406     0.667    81\n",
      " neutral     0.511     0.617     0.690    84\n",
      "     sad     0.511     0.468     0.425    87\n",
      "surprise     0.511     0.470     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.511     0.520     0.516    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 2.117850 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.442808  [ 1200/ 4873]\n",
      "loss: 0.486970  [ 2400/ 4873]\n",
      "loss: 0.264580  [ 3600/ 4873]\n",
      "loss: 0.910522  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.617     0.476    105\n",
      " disgust     0.548     0.663     0.523    109\n",
      "    fear     0.548     0.422     0.537    80\n",
      "   happy     0.548     0.490     0.617    81\n",
      " neutral     0.548     0.663     0.679    84\n",
      "     sad     0.548     0.500     0.448    87\n",
      "surprise     0.548     0.507     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.552     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.156676 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.394678  [ 1200/ 4873]\n",
      "loss: 0.486717  [ 2400/ 4873]\n",
      "loss: 0.826572  [ 3600/ 4873]\n",
      "loss: 0.245867  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.621     0.514    105\n",
      " disgust     0.549     0.538     0.523    109\n",
      "    fear     0.549     0.422     0.575    80\n",
      "   happy     0.549     0.573     0.580    81\n",
      " neutral     0.549     0.671     0.655    84\n",
      "     sad     0.549     0.488     0.460    87\n",
      "surprise     0.549     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.556     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.211895 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.603879  [ 1200/ 4873]\n",
      "loss: 0.249683  [ 2400/ 4873]\n",
      "loss: 0.365014  [ 3600/ 4873]\n",
      "loss: 0.172106  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.671     0.543    105\n",
      " disgust     0.548     0.579     0.505    109\n",
      "    fear     0.548     0.380     0.512    80\n",
      "   happy     0.548     0.542     0.556    81\n",
      " neutral     0.548     0.621     0.702    84\n",
      "     sad     0.548     0.500     0.448    87\n",
      "surprise     0.548     0.576     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.553     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.245167 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.261735  [ 1200/ 4873]\n",
      "loss: 0.238994  [ 2400/ 4873]\n",
      "loss: 0.464883  [ 3600/ 4873]\n",
      "loss: 0.589755  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.732     0.571    105\n",
      " disgust     0.543     0.545     0.495    109\n",
      "    fear     0.543     0.387     0.537    80\n",
      "   happy     0.543     0.490     0.580    81\n",
      " neutral     0.543     0.716     0.631    84\n",
      "     sad     0.543     0.441     0.471    87\n",
      "surprise     0.543     0.600     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.559     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.123323 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.295049  [ 1200/ 4873]\n",
      "loss: 0.264601  [ 2400/ 4873]\n",
      "loss: 0.710830  [ 3600/ 4873]\n",
      "loss: 0.104252  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.711     0.514    105\n",
      " disgust     0.541     0.519     0.514    109\n",
      "    fear     0.541     0.447     0.475    80\n",
      "   happy     0.541     0.510     0.605    81\n",
      " neutral     0.541     0.691     0.667    84\n",
      "     sad     0.541     0.442     0.437    87\n",
      "surprise     0.541     0.500     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.546     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.148232 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.159305  [ 1200/ 4873]\n",
      "loss: 0.355410  [ 2400/ 4873]\n",
      "loss: 0.598949  [ 3600/ 4873]\n",
      "loss: 0.361440  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.645     0.571    105\n",
      " disgust     0.556     0.594     0.523    109\n",
      "    fear     0.556     0.413     0.537    80\n",
      "   happy     0.556     0.531     0.630    81\n",
      " neutral     0.556     0.626     0.679    84\n",
      "     sad     0.556     0.475     0.437    87\n",
      "surprise     0.556     0.660     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.564     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.065291 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.241540  [ 1200/ 4873]\n",
      "loss: 0.358042  [ 2400/ 4873]\n",
      "loss: 0.359860  [ 3600/ 4873]\n",
      "loss: 0.199676  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.679     0.505    105\n",
      " disgust     0.538     0.587     0.495    109\n",
      "    fear     0.538     0.402     0.512    80\n",
      "   happy     0.538     0.478     0.679    81\n",
      " neutral     0.538     0.684     0.643    84\n",
      "     sad     0.538     0.448     0.448    87\n",
      "surprise     0.538     0.561     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.549     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.136910 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.117342  [ 1200/ 4873]\n",
      "loss: 0.268937  [ 2400/ 4873]\n",
      "loss: 0.213910  [ 3600/ 4873]\n",
      "loss: 0.181712  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.612     0.571    105\n",
      " disgust     0.551     0.577     0.550    109\n",
      "    fear     0.551     0.423     0.512    80\n",
      "   happy     0.551     0.535     0.568    81\n",
      " neutral     0.551     0.671     0.655    84\n",
      "     sad     0.551     0.468     0.425    87\n",
      "surprise     0.551     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.552     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.179514 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.482629  [ 1200/ 4873]\n",
      "loss: 0.374449  [ 2400/ 4873]\n",
      "loss: 0.161969  [ 3600/ 4873]\n",
      "loss: 0.140140  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.622     0.533    105\n",
      " disgust     0.549     0.543     0.523    109\n",
      "    fear     0.549     0.404     0.475    80\n",
      "   happy     0.549     0.511     0.580    81\n",
      " neutral     0.549     0.707     0.690    84\n",
      "     sad     0.549     0.500     0.483    87\n",
      "surprise     0.549     0.587     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.554     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.192098 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.066464  [ 1200/ 4873]\n",
      "loss: 0.051999  [ 2400/ 4873]\n",
      "loss: 0.553774  [ 3600/ 4873]\n",
      "loss: 0.429128  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.612     0.571    105\n",
      " disgust     0.556     0.614     0.569    109\n",
      "    fear     0.556     0.453     0.537    80\n",
      "   happy     0.556     0.545     0.593    81\n",
      " neutral     0.556     0.588     0.679    84\n",
      "     sad     0.556     0.540     0.391    87\n",
      "surprise     0.556     0.515     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.552     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.191243 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.572803  [ 1200/ 4873]\n",
      "loss: 0.274537  [ 2400/ 4873]\n",
      "loss: 0.660483  [ 3600/ 4873]\n",
      "loss: 0.337738  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.577     0.610    105\n",
      " disgust     0.556     0.622     0.514    109\n",
      "    fear     0.556     0.413     0.562    80\n",
      "   happy     0.556     0.547     0.580    81\n",
      " neutral     0.556     0.659     0.667    84\n",
      "     sad     0.556     0.571     0.414    87\n",
      "surprise     0.556     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.560     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.173434 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.139264  [ 1200/ 4873]\n",
      "loss: 0.605562  [ 2400/ 4873]\n",
      "loss: 0.227098  [ 3600/ 4873]\n",
      "loss: 0.280988  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.720     0.514    105\n",
      " disgust     0.569     0.589     0.578    109\n",
      "    fear     0.569     0.455     0.500    80\n",
      "   happy     0.569     0.510     0.617    81\n",
      " neutral     0.569     0.648     0.679    84\n",
      "     sad     0.569     0.517     0.529    87\n",
      "surprise     0.569     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.572     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.243178 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep318_acc_57.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep250_acc_56\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep318_acc_57\"! Old accuracy: 56.2, new accuracy: 56.9\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.327545  [ 1200/ 4873]\n",
      "loss: 0.339205  [ 2400/ 4873]\n",
      "loss: 0.060060  [ 3600/ 4873]\n",
      "loss: 0.394243  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.675     0.533    105\n",
      " disgust     0.544     0.626     0.523    109\n",
      "    fear     0.544     0.463     0.463    80\n",
      "   happy     0.544     0.461     0.580    81\n",
      " neutral     0.544     0.544     0.667    84\n",
      "     sad     0.544     0.524     0.494    87\n",
      "surprise     0.544     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.545     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.135234 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.494153  [ 1200/ 4873]\n",
      "loss: 0.265839  [ 2400/ 4873]\n",
      "loss: 0.191343  [ 3600/ 4873]\n",
      "loss: 0.842757  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.583     0.533    105\n",
      " disgust     0.533     0.514     0.505    109\n",
      "    fear     0.533     0.413     0.475    80\n",
      "   happy     0.533     0.539     0.593    81\n",
      " neutral     0.533     0.671     0.655    84\n",
      "     sad     0.533     0.487     0.437    87\n",
      "surprise     0.533     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.534     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 2.194492 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.310838  [ 1200/ 4873]\n",
      "loss: 0.237604  [ 2400/ 4873]\n",
      "loss: 0.278117  [ 3600/ 4873]\n",
      "loss: 0.462243  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.720     0.514    105\n",
      " disgust     0.546     0.578     0.541    109\n",
      "    fear     0.546     0.427     0.438    80\n",
      "   happy     0.546     0.527     0.605    81\n",
      " neutral     0.546     0.577     0.667    84\n",
      "     sad     0.546     0.476     0.460    87\n",
      "surprise     0.546     0.519     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.546     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.199886 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.229784  [ 1200/ 4873]\n",
      "loss: 0.352328  [ 2400/ 4873]\n",
      "loss: 0.465518  [ 3600/ 4873]\n",
      "loss: 0.341907  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.671     0.524    105\n",
      " disgust     0.554     0.554     0.514    109\n",
      "    fear     0.554     0.435     0.500    80\n",
      "   happy     0.554     0.471     0.691    81\n",
      " neutral     0.554     0.647     0.655    84\n",
      "     sad     0.554     0.538     0.483    87\n",
      "surprise     0.554     0.642     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.565     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.130197 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.312622  [ 1200/ 4873]\n",
      "loss: 0.233883  [ 2400/ 4873]\n",
      "loss: 0.362375  [ 3600/ 4873]\n",
      "loss: 0.137391  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.667     0.590    105\n",
      " disgust     0.552     0.544     0.514    109\n",
      "    fear     0.552     0.450     0.562    80\n",
      "   happy     0.552     0.548     0.568    81\n",
      " neutral     0.552     0.675     0.667    84\n",
      "     sad     0.552     0.507     0.437    87\n",
      "surprise     0.552     0.472     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.552     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.248829 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.641047  [ 1200/ 4873]\n",
      "loss: 0.413086  [ 2400/ 4873]\n",
      "loss: 0.141031  [ 3600/ 4873]\n",
      "loss: 0.329210  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.716     0.552    105\n",
      " disgust     0.554     0.529     0.495    109\n",
      "    fear     0.554     0.446     0.512    80\n",
      "   happy     0.554     0.548     0.630    81\n",
      " neutral     0.554     0.679     0.655    84\n",
      "     sad     0.554     0.462     0.494    87\n",
      "surprise     0.554     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.559     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.163563 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.382469  [ 1200/ 4873]\n",
      "loss: 0.155713  [ 2400/ 4873]\n",
      "loss: 0.467442  [ 3600/ 4873]\n",
      "loss: 0.094013  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.704     0.543    105\n",
      " disgust     0.554     0.539     0.505    109\n",
      "    fear     0.554     0.446     0.463    80\n",
      "   happy     0.554     0.500     0.642    81\n",
      " neutral     0.554     0.733     0.655    84\n",
      "     sad     0.554     0.443     0.494    87\n",
      "surprise     0.554     0.574     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.563     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.204209 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.414631  [ 1200/ 4873]\n",
      "loss: 0.092616  [ 2400/ 4873]\n",
      "loss: 0.313772  [ 3600/ 4873]\n",
      "loss: 0.140891  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.632     0.524    105\n",
      " disgust     0.543     0.541     0.541    109\n",
      "    fear     0.543     0.471     0.512    80\n",
      "   happy     0.543     0.520     0.630    81\n",
      " neutral     0.543     0.611     0.655    84\n",
      "     sad     0.543     0.515     0.402    87\n",
      "surprise     0.543     0.493     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.541     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.162859 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.117545  [ 1200/ 4873]\n",
      "loss: 0.311377  [ 2400/ 4873]\n",
      "loss: 0.107507  [ 3600/ 4873]\n",
      "loss: 0.814186  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.579     0.524    105\n",
      " disgust     0.536     0.544     0.450    109\n",
      "    fear     0.536     0.431     0.588    80\n",
      "   happy     0.536     0.516     0.580    81\n",
      " neutral     0.536     0.696     0.655    84\n",
      "     sad     0.536     0.506     0.483    87\n",
      "surprise     0.536     0.508     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.540     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.212719 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.446422  [ 1200/ 4873]\n",
      "loss: 0.149498  [ 2400/ 4873]\n",
      "loss: 0.354121  [ 3600/ 4873]\n",
      "loss: 0.218244  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.723     0.571    105\n",
      " disgust     0.561     0.510     0.468    109\n",
      "    fear     0.561     0.500     0.525    80\n",
      "   happy     0.561     0.549     0.617    81\n",
      " neutral     0.561     0.630     0.690    84\n",
      "     sad     0.561     0.551     0.494    87\n",
      "surprise     0.561     0.463     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.561     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.200994 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.549505  [ 1200/ 4873]\n",
      "loss: 0.322316  [ 2400/ 4873]\n",
      "loss: 0.082501  [ 3600/ 4873]\n",
      "loss: 0.196041  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.629     0.533    105\n",
      " disgust     0.554     0.598     0.532    109\n",
      "    fear     0.554     0.438     0.487    80\n",
      "   happy     0.554     0.515     0.654    81\n",
      " neutral     0.554     0.600     0.679    84\n",
      "     sad     0.554     0.547     0.471    87\n",
      "surprise     0.554     0.548     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.554     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.190339 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.330773  [ 1200/ 4873]\n",
      "loss: 0.363983  [ 2400/ 4873]\n",
      "loss: 0.205609  [ 3600/ 4873]\n",
      "loss: 1.001277  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.663     0.543    105\n",
      " disgust     0.557     0.567     0.505    109\n",
      "    fear     0.557     0.477     0.525    80\n",
      "   happy     0.557     0.477     0.642    81\n",
      " neutral     0.557     0.615     0.667    84\n",
      "     sad     0.557     0.556     0.460    87\n",
      "surprise     0.557     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.133889 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.409689  [ 1200/ 4873]\n",
      "loss: 0.209676  [ 2400/ 4873]\n",
      "loss: 0.234793  [ 3600/ 4873]\n",
      "loss: 0.286804  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.577     0.670     0.581    105\n",
      " disgust     0.577     0.549     0.615    109\n",
      "    fear     0.577     0.420     0.525    80\n",
      "   happy     0.577     0.628     0.605    81\n",
      " neutral     0.577     0.679     0.679    84\n",
      "     sad     0.577     0.567     0.437    87\n",
      "surprise     0.577     0.559     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.577     0.582     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 2.100964 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep331_acc_58.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep318_acc_57\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep331_acc_58\"! Old accuracy: 56.9, new accuracy: 57.7\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.121262  [ 1200/ 4873]\n",
      "loss: 0.148122  [ 2400/ 4873]\n",
      "loss: 0.453356  [ 3600/ 4873]\n",
      "loss: 0.157931  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.682     0.571    105\n",
      " disgust     0.543     0.533     0.450    109\n",
      "    fear     0.543     0.396     0.475    80\n",
      "   happy     0.543     0.510     0.642    81\n",
      " neutral     0.543     0.675     0.643    84\n",
      "     sad     0.543     0.478     0.494    87\n",
      "surprise     0.543     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.548     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.167341 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.186426  [ 1200/ 4873]\n",
      "loss: 0.172691  [ 2400/ 4873]\n",
      "loss: 0.421932  [ 3600/ 4873]\n",
      "loss: 0.075007  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.652     0.571    105\n",
      " disgust     0.543     0.582     0.523    109\n",
      "    fear     0.543     0.430     0.463    80\n",
      "   happy     0.543     0.490     0.593    81\n",
      " neutral     0.543     0.663     0.655    84\n",
      "     sad     0.543     0.427     0.437    87\n",
      "surprise     0.543     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.544     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.162621 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.144264  [ 1200/ 4873]\n",
      "loss: 0.106083  [ 2400/ 4873]\n",
      "loss: 0.434112  [ 3600/ 4873]\n",
      "loss: 0.315583  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.561     0.524    105\n",
      " disgust     0.543     0.539     0.569    109\n",
      "    fear     0.543     0.433     0.525    80\n",
      "   happy     0.543     0.527     0.593    81\n",
      " neutral     0.543     0.667     0.690    84\n",
      "     sad     0.543     0.536     0.425    87\n",
      "surprise     0.543     0.547     0.453    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.544     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.264841 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.541905  [ 1200/ 4873]\n",
      "loss: 0.374395  [ 2400/ 4873]\n",
      "loss: 0.645955  [ 3600/ 4873]\n",
      "loss: 0.650061  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.675     0.514    105\n",
      " disgust     0.531     0.538     0.514    109\n",
      "    fear     0.531     0.409     0.475    80\n",
      "   happy     0.531     0.479     0.568    81\n",
      " neutral     0.531     0.655     0.655    84\n",
      "     sad     0.531     0.450     0.414    87\n",
      "surprise     0.531     0.534     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.534     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 2.193467 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.473397  [ 1200/ 4873]\n",
      "loss: 0.416198  [ 2400/ 4873]\n",
      "loss: 0.320647  [ 3600/ 4873]\n",
      "loss: 0.978108  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.685     0.581    105\n",
      " disgust     0.557     0.589     0.514    109\n",
      "    fear     0.557     0.444     0.500    80\n",
      "   happy     0.557     0.527     0.593    81\n",
      " neutral     0.557     0.604     0.690    84\n",
      "     sad     0.557     0.500     0.437    87\n",
      "surprise     0.557     0.534     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.555     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.261176 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.526937  [ 1200/ 4873]\n",
      "loss: 0.192088  [ 2400/ 4873]\n",
      "loss: 0.123946  [ 3600/ 4873]\n",
      "loss: 0.518902  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.656     0.562    105\n",
      " disgust     0.531     0.559     0.523    109\n",
      "    fear     0.531     0.411     0.463    80\n",
      "   happy     0.531     0.500     0.568    81\n",
      " neutral     0.531     0.576     0.679    84\n",
      "     sad     0.531     0.479     0.391    87\n",
      "surprise     0.531     0.515     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.528     0.531    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 2.324663 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.555460  [ 1200/ 4873]\n",
      "loss: 0.193571  [ 2400/ 4873]\n",
      "loss: 0.241369  [ 3600/ 4873]\n",
      "loss: 0.302891  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.586     0.552    105\n",
      " disgust     0.536     0.542     0.532    109\n",
      "    fear     0.536     0.423     0.512    80\n",
      "   happy     0.536     0.524     0.543    81\n",
      " neutral     0.536     0.671     0.679    84\n",
      "     sad     0.536     0.507     0.391    87\n",
      "surprise     0.536     0.493     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.535     0.537    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.270119 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.178715  [ 1200/ 4873]\n",
      "loss: 0.471198  [ 2400/ 4873]\n",
      "loss: 0.166325  [ 3600/ 4873]\n",
      "loss: 0.378591  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.598     0.524    105\n",
      " disgust     0.544     0.578     0.541    109\n",
      "    fear     0.544     0.447     0.475    80\n",
      "   happy     0.544     0.495     0.568    81\n",
      " neutral     0.544     0.656     0.702    84\n",
      "     sad     0.544     0.487     0.448    87\n",
      "surprise     0.544     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.541     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.316897 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.284242  [ 1200/ 4873]\n",
      "loss: 0.992134  [ 2400/ 4873]\n",
      "loss: 0.357200  [ 3600/ 4873]\n",
      "loss: 0.618115  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.646     0.505    105\n",
      " disgust     0.541     0.618     0.505    109\n",
      "    fear     0.541     0.451     0.463    80\n",
      "   happy     0.541     0.422     0.605    81\n",
      " neutral     0.541     0.619     0.714    84\n",
      "     sad     0.541     0.478     0.494    87\n",
      "surprise     0.541     0.611     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.549     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.214337 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.271384  [ 1200/ 4873]\n",
      "loss: 0.333619  [ 2400/ 4873]\n",
      "loss: 0.151018  [ 3600/ 4873]\n",
      "loss: 0.332212  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.667     0.552    105\n",
      " disgust     0.557     0.571     0.550    109\n",
      "    fear     0.557     0.437     0.475    80\n",
      "   happy     0.557     0.495     0.593    81\n",
      " neutral     0.557     0.724     0.655    84\n",
      "     sad     0.557     0.460     0.460    87\n",
      "surprise     0.557     0.577     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.562     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.170079 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.298244  [ 1200/ 4873]\n",
      "loss: 0.109839  [ 2400/ 4873]\n",
      "loss: 0.668879  [ 3600/ 4873]\n",
      "loss: 0.134899  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.577     0.533    105\n",
      " disgust     0.544     0.537     0.532    109\n",
      "    fear     0.544     0.434     0.450    80\n",
      "   happy     0.544     0.608     0.593    81\n",
      " neutral     0.544     0.594     0.714    84\n",
      "     sad     0.544     0.500     0.437    87\n",
      "surprise     0.544     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.542     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.283123 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.291960  [ 1200/ 4873]\n",
      "loss: 0.123332  [ 2400/ 4873]\n",
      "loss: 0.178661  [ 3600/ 4873]\n",
      "loss: 0.482981  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.682     0.571    105\n",
      " disgust     0.549     0.570     0.523    109\n",
      "    fear     0.549     0.436     0.512    80\n",
      "   happy     0.549     0.505     0.605    81\n",
      " neutral     0.549     0.667     0.643    84\n",
      "     sad     0.549     0.452     0.437    87\n",
      "surprise     0.549     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.551     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.162139 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.306849  [ 1200/ 4873]\n",
      "loss: 0.309833  [ 2400/ 4873]\n",
      "loss: 0.277505  [ 3600/ 4873]\n",
      "loss: 0.620682  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.616     0.581    105\n",
      " disgust     0.544     0.532     0.541    109\n",
      "    fear     0.544     0.406     0.487    80\n",
      "   happy     0.544     0.548     0.568    81\n",
      " neutral     0.544     0.629     0.667    84\n",
      "     sad     0.544     0.521     0.437    87\n",
      "surprise     0.544     0.569     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.546     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.229535 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.295255  [ 1200/ 4873]\n",
      "loss: 0.289312  [ 2400/ 4873]\n",
      "loss: 0.944669  [ 3600/ 4873]\n",
      "loss: 0.446602  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.697     0.505    105\n",
      " disgust     0.556     0.547     0.587    109\n",
      "    fear     0.556     0.513     0.500    80\n",
      "   happy     0.556     0.495     0.605    81\n",
      " neutral     0.556     0.701     0.643    84\n",
      "     sad     0.556     0.440     0.506    87\n",
      "surprise     0.556     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.564     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.219632 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.304527  [ 1200/ 4873]\n",
      "loss: 0.313624  [ 2400/ 4873]\n",
      "loss: 0.404717  [ 3600/ 4873]\n",
      "loss: 0.233277  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.646     0.505    105\n",
      " disgust     0.541     0.617     0.459    109\n",
      "    fear     0.541     0.429     0.487    80\n",
      "   happy     0.541     0.500     0.679    81\n",
      " neutral     0.541     0.540     0.726    84\n",
      "     sad     0.541     0.514     0.425    87\n",
      "surprise     0.541     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.546     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.272079 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.176036  [ 1200/ 4873]\n",
      "loss: 0.561331  [ 2400/ 4873]\n",
      "loss: 0.189009  [ 3600/ 4873]\n",
      "loss: 0.226977  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.674     0.552    105\n",
      " disgust     0.543     0.500     0.523    109\n",
      "    fear     0.543     0.417     0.500    80\n",
      "   happy     0.543     0.556     0.556    81\n",
      " neutral     0.543     0.705     0.655    84\n",
      "     sad     0.543     0.455     0.460    87\n",
      "surprise     0.543     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.549     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.299098 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.292114  [ 1200/ 4873]\n",
      "loss: 0.106867  [ 2400/ 4873]\n",
      "loss: 0.253506  [ 3600/ 4873]\n",
      "loss: 0.228027  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.644     0.533    105\n",
      " disgust     0.543     0.546     0.486    109\n",
      "    fear     0.543     0.487     0.487    80\n",
      "   happy     0.543     0.511     0.568    81\n",
      " neutral     0.543     0.596     0.702    84\n",
      "     sad     0.543     0.471     0.460    87\n",
      "surprise     0.543     0.528     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.540     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.320829 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.618687  [ 1200/ 4873]\n",
      "loss: 0.207835  [ 2400/ 4873]\n",
      "loss: 0.098444  [ 3600/ 4873]\n",
      "loss: 0.125050  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.526     0.679     0.524    105\n",
      " disgust     0.526     0.547     0.431    109\n",
      "    fear     0.526     0.521     0.475    80\n",
      "   happy     0.526     0.439     0.617    81\n",
      " neutral     0.526     0.589     0.667    84\n",
      "     sad     0.526     0.488     0.471    87\n",
      "surprise     0.526     0.442     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.526     0.529     0.531    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 2.290526 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.317138  [ 1200/ 4873]\n",
      "loss: 0.664944  [ 2400/ 4873]\n",
      "loss: 0.120709  [ 3600/ 4873]\n",
      "loss: 0.277481  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.523     0.573     0.524    105\n",
      " disgust     0.523     0.589     0.514    109\n",
      "    fear     0.523     0.375     0.450    80\n",
      "   happy     0.523     0.527     0.593    81\n",
      " neutral     0.523     0.607     0.643    84\n",
      "     sad     0.523     0.500     0.448    87\n",
      "surprise     0.523     0.477     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.523     0.521     0.522    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 2.488985 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.054901  [ 1200/ 4873]\n",
      "loss: 0.390363  [ 2400/ 4873]\n",
      "loss: 0.360500  [ 3600/ 4873]\n",
      "loss: 0.330322  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.521     0.644     0.533    105\n",
      " disgust     0.521     0.500     0.450    109\n",
      "    fear     0.521     0.411     0.463    80\n",
      "   happy     0.521     0.489     0.568    81\n",
      " neutral     0.521     0.622     0.667    84\n",
      "     sad     0.521     0.475     0.437    87\n",
      "surprise     0.521     0.507     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.521     0.521     0.526    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 2.308665 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.284296  [ 1200/ 4873]\n",
      "loss: 0.430163  [ 2400/ 4873]\n",
      "loss: 0.368048  [ 3600/ 4873]\n",
      "loss: 0.413972  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.650     0.619    105\n",
      " disgust     0.564     0.620     0.523    109\n",
      "    fear     0.564     0.404     0.500    80\n",
      "   happy     0.564     0.535     0.568    81\n",
      " neutral     0.564     0.648     0.679    84\n",
      "     sad     0.564     0.506     0.494    87\n",
      "surprise     0.564     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.566     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.201783 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.306760  [ 1200/ 4873]\n",
      "loss: 0.199238  [ 2400/ 4873]\n",
      "loss: 0.263267  [ 3600/ 4873]\n",
      "loss: 0.339412  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.685     0.600    105\n",
      " disgust     0.574     0.613     0.523    109\n",
      "    fear     0.574     0.500     0.438    80\n",
      "   happy     0.574     0.505     0.630    81\n",
      " neutral     0.574     0.614     0.738    84\n",
      "     sad     0.574     0.522     0.540    87\n",
      "surprise     0.574     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.571     0.574    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 2.239261 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.579712  [ 1200/ 4873]\n",
      "loss: 0.283600  [ 2400/ 4873]\n",
      "loss: 0.326425  [ 3600/ 4873]\n",
      "loss: 0.593024  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.655     0.524    105\n",
      " disgust     0.548     0.522     0.550    109\n",
      "    fear     0.548     0.394     0.463    80\n",
      "   happy     0.548     0.567     0.630    81\n",
      " neutral     0.548     0.718     0.667    84\n",
      "     sad     0.548     0.443     0.448    87\n",
      "surprise     0.548     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.555     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.322405 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.215137  [ 1200/ 4873]\n",
      "loss: 0.294952  [ 2400/ 4873]\n",
      "loss: 0.055195  [ 3600/ 4873]\n",
      "loss: 0.341035  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.590     0.562    105\n",
      " disgust     0.544     0.509     0.495    109\n",
      "    fear     0.544     0.421     0.562    80\n",
      "   happy     0.544     0.600     0.630    81\n",
      " neutral     0.544     0.667     0.667    84\n",
      "     sad     0.544     0.507     0.391    87\n",
      "surprise     0.544     0.541     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.548     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.296435 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.320337  [ 1200/ 4873]\n",
      "loss: 0.182776  [ 2400/ 4873]\n",
      "loss: 0.403870  [ 3600/ 4873]\n",
      "loss: 0.173959  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.681     0.590    105\n",
      " disgust     0.559     0.533     0.523    109\n",
      "    fear     0.559     0.507     0.438    80\n",
      "   happy     0.559     0.477     0.654    81\n",
      " neutral     0.559     0.716     0.690    84\n",
      "     sad     0.559     0.482     0.460    87\n",
      "surprise     0.559     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.561     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.205565 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.109730  [ 1200/ 4873]\n",
      "loss: 0.267213  [ 2400/ 4873]\n",
      "loss: 0.428398  [ 3600/ 4873]\n",
      "loss: 0.219873  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.725     0.552    105\n",
      " disgust     0.554     0.555     0.560    109\n",
      "    fear     0.554     0.439     0.450    80\n",
      "   happy     0.554     0.510     0.605    81\n",
      " neutral     0.554     0.692     0.643    84\n",
      "     sad     0.554     0.434     0.494    87\n",
      "surprise     0.554     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.561     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.294850 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.236574  [ 1200/ 4873]\n",
      "loss: 0.083738  [ 2400/ 4873]\n",
      "loss: 0.253052  [ 3600/ 4873]\n",
      "loss: 0.316430  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.675     0.533    105\n",
      " disgust     0.534     0.571     0.477    109\n",
      "    fear     0.534     0.432     0.400    80\n",
      "   happy     0.534     0.490     0.617    81\n",
      " neutral     0.534     0.606     0.714    84\n",
      "     sad     0.534     0.451     0.471    87\n",
      "surprise     0.534     0.500     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.532     0.537    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.310842 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.153292  [ 1200/ 4873]\n",
      "loss: 0.353200  [ 2400/ 4873]\n",
      "loss: 0.396091  [ 3600/ 4873]\n",
      "loss: 0.258509  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.722     0.495    105\n",
      " disgust     0.552     0.542     0.587    109\n",
      "    fear     0.552     0.432     0.475    80\n",
      "   happy     0.552     0.533     0.593    81\n",
      " neutral     0.552     0.615     0.667    84\n",
      "     sad     0.552     0.473     0.506    87\n",
      "surprise     0.552     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.560     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.246444 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.166753  [ 1200/ 4873]\n",
      "loss: 0.139163  [ 2400/ 4873]\n",
      "loss: 0.078042  [ 3600/ 4873]\n",
      "loss: 0.476286  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.746     0.505    105\n",
      " disgust     0.554     0.536     0.541    109\n",
      "    fear     0.554     0.453     0.425    80\n",
      "   happy     0.554     0.541     0.654    81\n",
      " neutral     0.554     0.598     0.690    84\n",
      "     sad     0.554     0.451     0.471    87\n",
      "surprise     0.554     0.588     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.559     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.282012 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.466706  [ 1200/ 4873]\n",
      "loss: 0.162198  [ 2400/ 4873]\n",
      "loss: 0.550325  [ 3600/ 4873]\n",
      "loss: 0.151138  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.638     0.571    105\n",
      " disgust     0.551     0.529     0.505    109\n",
      "    fear     0.551     0.457     0.525    80\n",
      "   happy     0.551     0.571     0.593    81\n",
      " neutral     0.551     0.659     0.690    84\n",
      "     sad     0.551     0.427     0.437    87\n",
      "surprise     0.551     0.593     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.553     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.397091 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.245365  [ 1200/ 4873]\n",
      "loss: 0.852535  [ 2400/ 4873]\n",
      "loss: 0.535748  [ 3600/ 4873]\n",
      "loss: 0.382324  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.621     0.562    105\n",
      " disgust     0.548     0.588     0.523    109\n",
      "    fear     0.548     0.423     0.412    80\n",
      "   happy     0.548     0.557     0.605    81\n",
      " neutral     0.548     0.634     0.702    84\n",
      "     sad     0.548     0.476     0.460    87\n",
      "surprise     0.548     0.493     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.542     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.355351 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.142626  [ 1200/ 4873]\n",
      "loss: 0.236208  [ 2400/ 4873]\n",
      "loss: 0.192043  [ 3600/ 4873]\n",
      "loss: 0.252471  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.634     0.495    105\n",
      " disgust     0.543     0.559     0.523    109\n",
      "    fear     0.543     0.523     0.425    80\n",
      "   happy     0.543     0.430     0.605    81\n",
      " neutral     0.543     0.637     0.690    84\n",
      "     sad     0.543     0.500     0.471    87\n",
      "surprise     0.543     0.541     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.546     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.342719 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.406712  [ 1200/ 4873]\n",
      "loss: 0.112554  [ 2400/ 4873]\n",
      "loss: 0.237603  [ 3600/ 4873]\n",
      "loss: 0.199267  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.620     0.543    105\n",
      " disgust     0.544     0.605     0.477    109\n",
      "    fear     0.544     0.446     0.512    80\n",
      "   happy     0.544     0.477     0.630    81\n",
      " neutral     0.544     0.683     0.667    84\n",
      "     sad     0.544     0.419     0.448    87\n",
      "surprise     0.544     0.621     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.553     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.315380 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.460132  [ 1200/ 4873]\n",
      "loss: 0.083184  [ 2400/ 4873]\n",
      "loss: 0.912412  [ 3600/ 4873]\n",
      "loss: 0.710822  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.688     0.524    105\n",
      " disgust     0.539     0.478     0.495    109\n",
      "    fear     0.539     0.465     0.412    80\n",
      "   happy     0.539     0.495     0.654    81\n",
      " neutral     0.539     0.628     0.643    84\n",
      "     sad     0.539     0.484     0.506    87\n",
      "surprise     0.539     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.545     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.334133 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.543349  [ 1200/ 4873]\n",
      "loss: 0.203491  [ 2400/ 4873]\n",
      "loss: 0.133751  [ 3600/ 4873]\n",
      "loss: 0.122294  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.602     0.533    105\n",
      " disgust     0.544     0.540     0.495    109\n",
      "    fear     0.544     0.411     0.550    80\n",
      "   happy     0.544     0.595     0.580    81\n",
      " neutral     0.544     0.683     0.667    84\n",
      "     sad     0.544     0.443     0.448    87\n",
      "surprise     0.544     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.552     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.318978 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.267618  [ 1200/ 4873]\n",
      "loss: 0.536247  [ 2400/ 4873]\n",
      "loss: 0.403567  [ 3600/ 4873]\n",
      "loss: 0.251190  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.702     0.562    105\n",
      " disgust     0.549     0.565     0.477    109\n",
      "    fear     0.549     0.424     0.487    80\n",
      "   happy     0.549     0.521     0.605    81\n",
      " neutral     0.549     0.582     0.679    84\n",
      "     sad     0.549     0.512     0.483    87\n",
      "surprise     0.549     0.544     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.550     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.357819 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.419667  [ 1200/ 4873]\n",
      "loss: 0.367329  [ 2400/ 4873]\n",
      "loss: 0.169989  [ 3600/ 4873]\n",
      "loss: 0.095498  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.622     0.581    105\n",
      " disgust     0.541     0.477     0.477    109\n",
      "    fear     0.541     0.482     0.512    80\n",
      "   happy     0.541     0.521     0.605    81\n",
      " neutral     0.541     0.737     0.667    84\n",
      "     sad     0.541     0.452     0.437    87\n",
      "surprise     0.541     0.516     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.544     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.329993 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.319829  [ 1200/ 4873]\n",
      "loss: 0.578556  [ 2400/ 4873]\n",
      "loss: 0.441134  [ 3600/ 4873]\n",
      "loss: 0.741704  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.610     0.476    105\n",
      " disgust     0.538     0.514     0.523    109\n",
      "    fear     0.538     0.393     0.550    80\n",
      "   happy     0.538     0.551     0.605    81\n",
      " neutral     0.538     0.747     0.702    84\n",
      "     sad     0.538     0.506     0.460    87\n",
      "surprise     0.538     0.500     0.453    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.546     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.461011 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.271764  [ 1200/ 4873]\n",
      "loss: 0.626120  [ 2400/ 4873]\n",
      "loss: 0.347971  [ 3600/ 4873]\n",
      "loss: 0.185164  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.679     0.543    105\n",
      " disgust     0.533     0.542     0.477    109\n",
      "    fear     0.533     0.418     0.412    80\n",
      "   happy     0.533     0.463     0.617    81\n",
      " neutral     0.533     0.667     0.667    84\n",
      "     sad     0.533     0.439     0.494    87\n",
      "surprise     0.533     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.538     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 2.387922 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.044544  [ 1200/ 4873]\n",
      "loss: 0.070302  [ 2400/ 4873]\n",
      "loss: 0.576819  [ 3600/ 4873]\n",
      "loss: 0.115993  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.651     0.533    105\n",
      " disgust     0.549     0.564     0.486    109\n",
      "    fear     0.549     0.487     0.475    80\n",
      "   happy     0.549     0.520     0.630    81\n",
      " neutral     0.549     0.606     0.714    84\n",
      "     sad     0.549     0.476     0.460    87\n",
      "surprise     0.549     0.521     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.547     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.337817 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.203566  [ 1200/ 4873]\n",
      "loss: 0.231566  [ 2400/ 4873]\n",
      "loss: 0.418923  [ 3600/ 4873]\n",
      "loss: 0.098210  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.589     0.533    105\n",
      " disgust     0.561     0.596     0.541    109\n",
      "    fear     0.561     0.477     0.512    80\n",
      "   happy     0.561     0.554     0.630    81\n",
      " neutral     0.561     0.644     0.690    84\n",
      "     sad     0.561     0.500     0.448    87\n",
      "surprise     0.561     0.543     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.558     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.340155 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.394023  [ 1200/ 4873]\n",
      "loss: 0.436743  [ 2400/ 4873]\n",
      "loss: 0.106858  [ 3600/ 4873]\n",
      "loss: 0.222845  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.622     0.581    105\n",
      " disgust     0.538     0.583     0.450    109\n",
      "    fear     0.538     0.424     0.487    80\n",
      "   happy     0.538     0.485     0.605    81\n",
      " neutral     0.538     0.659     0.667    84\n",
      "     sad     0.538     0.435     0.425    87\n",
      "surprise     0.538     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.540     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.390936 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.287860  [ 1200/ 4873]\n",
      "loss: 0.412714  [ 2400/ 4873]\n",
      "loss: 0.406654  [ 3600/ 4873]\n",
      "loss: 0.269878  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.620     0.543    105\n",
      " disgust     0.533     0.573     0.468    109\n",
      "    fear     0.533     0.402     0.463    80\n",
      "   happy     0.533     0.490     0.630    81\n",
      " neutral     0.533     0.638     0.714    84\n",
      "     sad     0.533     0.440     0.425    87\n",
      "surprise     0.533     0.582     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.535     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 2.321562 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.861630  [ 1200/ 4873]\n",
      "loss: 0.369678  [ 2400/ 4873]\n",
      "loss: 0.625875  [ 3600/ 4873]\n",
      "loss: 0.424886  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.629     0.533    105\n",
      " disgust     0.530     0.514     0.505    109\n",
      "    fear     0.530     0.384     0.475    80\n",
      "   happy     0.530     0.551     0.605    81\n",
      " neutral     0.530     0.709     0.667    84\n",
      "     sad     0.530     0.418     0.437    87\n",
      "surprise     0.530     0.554     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.530     0.537     0.529    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.439712 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.524486  [ 1200/ 4873]\n",
      "loss: 0.118391  [ 2400/ 4873]\n",
      "loss: 0.412098  [ 3600/ 4873]\n",
      "loss: 0.171908  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.660     0.590    105\n",
      " disgust     0.575     0.547     0.587    109\n",
      "    fear     0.575     0.436     0.512    80\n",
      "   happy     0.575     0.593     0.630    81\n",
      " neutral     0.575     0.714     0.714    84\n",
      "     sad     0.575     0.506     0.460    87\n",
      "surprise     0.575     0.589     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.578     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 2.341870 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.278716  [ 1200/ 4873]\n",
      "loss: 0.046975  [ 2400/ 4873]\n",
      "loss: 0.227776  [ 3600/ 4873]\n",
      "loss: 0.322326  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.644     0.533    105\n",
      " disgust     0.554     0.573     0.541    109\n",
      "    fear     0.554     0.408     0.500    80\n",
      "   happy     0.554     0.500     0.605    81\n",
      " neutral     0.554     0.690     0.690    84\n",
      "     sad     0.554     0.532     0.471    87\n",
      "surprise     0.554     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.558     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.286665 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.203281  [ 1200/ 4873]\n",
      "loss: 0.091098  [ 2400/ 4873]\n",
      "loss: 0.243993  [ 3600/ 4873]\n",
      "loss: 0.328434  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.613     0.543    105\n",
      " disgust     0.566     0.577     0.587    109\n",
      "    fear     0.566     0.452     0.475    80\n",
      "   happy     0.566     0.627     0.580    81\n",
      " neutral     0.566     0.610     0.726    84\n",
      "     sad     0.566     0.513     0.460    87\n",
      "surprise     0.566     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.563     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.372890 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.070439  [ 1200/ 4873]\n",
      "loss: 0.128627  [ 2400/ 4873]\n",
      "loss: 0.537967  [ 3600/ 4873]\n",
      "loss: 0.048186  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.728     0.562    105\n",
      " disgust     0.562     0.569     0.532    109\n",
      "    fear     0.562     0.476     0.500    80\n",
      "   happy     0.562     0.481     0.617    81\n",
      " neutral     0.562     0.700     0.667    84\n",
      "     sad     0.562     0.426     0.494    87\n",
      "surprise     0.562     0.638     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.574     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.358847 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.223936  [ 1200/ 4873]\n",
      "loss: 0.184710  [ 2400/ 4873]\n",
      "loss: 0.203327  [ 3600/ 4873]\n",
      "loss: 0.240241  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.693     0.495    105\n",
      " disgust     0.534     0.536     0.477    109\n",
      "    fear     0.534     0.388     0.500    80\n",
      "   happy     0.534     0.510     0.642    81\n",
      " neutral     0.534     0.655     0.679    84\n",
      "     sad     0.534     0.451     0.471    87\n",
      "surprise     0.534     0.582     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.545     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.314962 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.217489  [ 1200/ 4873]\n",
      "loss: 0.096292  [ 2400/ 4873]\n",
      "loss: 0.957533  [ 3600/ 4873]\n",
      "loss: 0.596871  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.670     0.562    105\n",
      " disgust     0.567     0.514     0.523    109\n",
      "    fear     0.567     0.483     0.525    80\n",
      "   happy     0.567     0.510     0.642    81\n",
      " neutral     0.567     0.725     0.690    84\n",
      "     sad     0.567     0.467     0.483    87\n",
      "surprise     0.567     0.692     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.580     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.251413 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.192259  [ 1200/ 4873]\n",
      "loss: 0.421748  [ 2400/ 4873]\n",
      "loss: 0.370824  [ 3600/ 4873]\n",
      "loss: 0.149315  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.594     0.543    105\n",
      " disgust     0.552     0.574     0.532    109\n",
      "    fear     0.552     0.429     0.450    80\n",
      "   happy     0.552     0.588     0.617    81\n",
      " neutral     0.552     0.648     0.702    84\n",
      "     sad     0.552     0.456     0.471    87\n",
      "surprise     0.552     0.571     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.551     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.447884 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.139629  [ 1200/ 4873]\n",
      "loss: 0.195575  [ 2400/ 4873]\n",
      "loss: 0.374862  [ 3600/ 4873]\n",
      "loss: 0.477076  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.610     0.610    105\n",
      " disgust     0.572     0.564     0.606    109\n",
      "    fear     0.572     0.500     0.500    80\n",
      "   happy     0.572     0.603     0.580    81\n",
      " neutral     0.572     0.675     0.667    84\n",
      "     sad     0.572     0.514     0.437    87\n",
      "surprise     0.572     0.521     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.569     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.499537 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.319000  [ 1200/ 4873]\n",
      "loss: 0.114070  [ 2400/ 4873]\n",
      "loss: 0.240066  [ 3600/ 4873]\n",
      "loss: 0.177596  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.604     0.581    105\n",
      " disgust     0.557     0.545     0.495    109\n",
      "    fear     0.557     0.487     0.463    80\n",
      "   happy     0.557     0.533     0.593    81\n",
      " neutral     0.557     0.628     0.702    84\n",
      "     sad     0.557     0.500     0.517    87\n",
      "surprise     0.557     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.557     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.362249 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.160573  [ 1200/ 4873]\n",
      "loss: 0.686099  [ 2400/ 4873]\n",
      "loss: 0.139891  [ 3600/ 4873]\n",
      "loss: 0.377288  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.592     0.552    105\n",
      " disgust     0.562     0.500     0.578    109\n",
      "    fear     0.562     0.405     0.562    80\n",
      "   happy     0.562     0.690     0.605    81\n",
      " neutral     0.562     0.744     0.690    84\n",
      "     sad     0.562     0.487     0.425    87\n",
      "surprise     0.562     0.660     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.583     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.441061 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.163832  [ 1200/ 4873]\n",
      "loss: 0.237534  [ 2400/ 4873]\n",
      "loss: 0.395437  [ 3600/ 4873]\n",
      "loss: 0.355308  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.598     0.495    105\n",
      " disgust     0.554     0.549     0.514    109\n",
      "    fear     0.554     0.426     0.500    80\n",
      "   happy     0.554     0.559     0.642    81\n",
      " neutral     0.554     0.694     0.702    84\n",
      "     sad     0.554     0.483     0.494    87\n",
      "surprise     0.554     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.558     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.372382 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.246748  [ 1200/ 4873]\n",
      "loss: 0.101118  [ 2400/ 4873]\n",
      "loss: 0.202094  [ 3600/ 4873]\n",
      "loss: 0.143674  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.658     0.476    105\n",
      " disgust     0.528     0.480     0.541    109\n",
      "    fear     0.528     0.476     0.487    80\n",
      "   happy     0.528     0.547     0.580    81\n",
      " neutral     0.528     0.695     0.679    84\n",
      "     sad     0.528     0.382     0.448    87\n",
      "surprise     0.528     0.525     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.538     0.528    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.533005 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.217867  [ 1200/ 4873]\n",
      "loss: 0.213234  [ 2400/ 4873]\n",
      "loss: 0.284516  [ 3600/ 4873]\n",
      "loss: 0.159035  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.657     0.619    105\n",
      " disgust     0.554     0.481     0.578    109\n",
      "    fear     0.554     0.387     0.450    80\n",
      "   happy     0.554     0.642     0.531    81\n",
      " neutral     0.554     0.709     0.667    84\n",
      "     sad     0.554     0.494     0.471    87\n",
      "surprise     0.554     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.565     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.583270 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.132283  [ 1200/ 4873]\n",
      "loss: 0.282802  [ 2400/ 4873]\n",
      "loss: 1.394891  [ 3600/ 4873]\n",
      "loss: 0.547644  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.518     0.609     0.505    105\n",
      " disgust     0.518     0.560     0.468    109\n",
      "    fear     0.518     0.440     0.500    80\n",
      "   happy     0.518     0.484     0.568    81\n",
      " neutral     0.518     0.616     0.631    84\n",
      "     sad     0.518     0.394     0.448    87\n",
      "surprise     0.518     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.518     0.523     0.522    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.440505 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.592134  [ 1200/ 4873]\n",
      "loss: 0.131948  [ 2400/ 4873]\n",
      "loss: 0.242454  [ 3600/ 4873]\n",
      "loss: 0.304390  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.698     0.571    105\n",
      " disgust     0.546     0.573     0.505    109\n",
      "    fear     0.546     0.463     0.475    80\n",
      "   happy     0.546     0.495     0.605    81\n",
      " neutral     0.546     0.651     0.667    84\n",
      "     sad     0.546     0.417     0.460    87\n",
      "surprise     0.546     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.548     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.381853 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.301828  [ 1200/ 4873]\n",
      "loss: 0.163479  [ 2400/ 4873]\n",
      "loss: 0.397401  [ 3600/ 4873]\n",
      "loss: 0.519316  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.598     0.552    105\n",
      " disgust     0.551     0.514     0.505    109\n",
      "    fear     0.551     0.484     0.550    80\n",
      "   happy     0.551     0.563     0.605    81\n",
      " neutral     0.551     0.644     0.667    84\n",
      "     sad     0.551     0.453     0.448    87\n",
      "surprise     0.551     0.636     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.556     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.394924 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.426184  [ 1200/ 4873]\n",
      "loss: 0.226964  [ 2400/ 4873]\n",
      "loss: 0.178376  [ 3600/ 4873]\n",
      "loss: 0.610138  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.678     0.581    105\n",
      " disgust     0.556     0.589     0.486    109\n",
      "    fear     0.556     0.455     0.500    80\n",
      "   happy     0.556     0.468     0.642    81\n",
      " neutral     0.556     0.644     0.690    84\n",
      "     sad     0.556     0.462     0.483    87\n",
      "surprise     0.556     0.660     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.565     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.311538 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.227007  [ 1200/ 4873]\n",
      "loss: 0.207810  [ 2400/ 4873]\n",
      "loss: 0.280326  [ 3600/ 4873]\n",
      "loss: 0.733701  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.644     0.533    105\n",
      " disgust     0.543     0.509     0.505    109\n",
      "    fear     0.543     0.469     0.475    80\n",
      "   happy     0.543     0.532     0.617    81\n",
      " neutral     0.543     0.575     0.726    84\n",
      "     sad     0.543     0.500     0.437    87\n",
      "surprise     0.543     0.569     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.543     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.299436 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.466221  [ 1200/ 4873]\n",
      "loss: 0.132463  [ 2400/ 4873]\n",
      "loss: 0.352205  [ 3600/ 4873]\n",
      "loss: 0.180116  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.687     0.543    105\n",
      " disgust     0.556     0.545     0.550    109\n",
      "    fear     0.556     0.465     0.500    80\n",
      "   happy     0.556     0.539     0.593    81\n",
      " neutral     0.556     0.690     0.690    84\n",
      "     sad     0.556     0.426     0.460    87\n",
      "surprise     0.556     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.559     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.428770 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.230392  [ 1200/ 4873]\n",
      "loss: 0.550422  [ 2400/ 4873]\n",
      "loss: 0.244239  [ 3600/ 4873]\n",
      "loss: 0.162424  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.613     0.543    105\n",
      " disgust     0.546     0.559     0.477    109\n",
      "    fear     0.546     0.479     0.425    80\n",
      "   happy     0.546     0.477     0.654    81\n",
      " neutral     0.546     0.652     0.690    84\n",
      "     sad     0.546     0.488     0.471    87\n",
      "surprise     0.546     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.546     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.403373 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.778124  [ 1200/ 4873]\n",
      "loss: 0.130078  [ 2400/ 4873]\n",
      "loss: 0.226422  [ 3600/ 4873]\n",
      "loss: 0.298377  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.626     0.543    105\n",
      " disgust     0.536     0.553     0.477    109\n",
      "    fear     0.536     0.453     0.487    80\n",
      "   happy     0.536     0.500     0.593    81\n",
      " neutral     0.536     0.640     0.655    84\n",
      "     sad     0.536     0.441     0.471    87\n",
      "surprise     0.536     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.537     0.539    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.461288 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.267527  [ 1200/ 4873]\n",
      "loss: 0.154677  [ 2400/ 4873]\n",
      "loss: 0.292628  [ 3600/ 4873]\n",
      "loss: 0.368136  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.682     0.552    105\n",
      " disgust     0.569     0.529     0.587    109\n",
      "    fear     0.569     0.462     0.450    80\n",
      "   happy     0.569     0.547     0.642    81\n",
      " neutral     0.569     0.693     0.726    84\n",
      "     sad     0.569     0.477     0.483    87\n",
      "surprise     0.569     0.618     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.573     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.413712 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.261243  [ 1200/ 4873]\n",
      "loss: 0.242737  [ 2400/ 4873]\n",
      "loss: 0.124594  [ 3600/ 4873]\n",
      "loss: 0.100480  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.634     0.562    105\n",
      " disgust     0.539     0.521     0.450    109\n",
      "    fear     0.539     0.519     0.512    80\n",
      "   happy     0.539     0.500     0.617    81\n",
      " neutral     0.539     0.574     0.738    84\n",
      "     sad     0.539     0.493     0.414    87\n",
      "surprise     0.539     0.508     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.536     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.562194 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.229571  [ 1200/ 4873]\n",
      "loss: 0.335376  [ 2400/ 4873]\n",
      "loss: 0.201155  [ 3600/ 4873]\n",
      "loss: 0.545429  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.525     0.628     0.514    105\n",
      " disgust     0.525     0.543     0.468    109\n",
      "    fear     0.525     0.424     0.487    80\n",
      "   happy     0.525     0.450     0.617    81\n",
      " neutral     0.525     0.671     0.655    84\n",
      "     sad     0.525     0.433     0.448    87\n",
      "surprise     0.525     0.582     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.525     0.533     0.527    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 2.468510 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.085242  [ 1200/ 4873]\n",
      "loss: 0.556454  [ 2400/ 4873]\n",
      "loss: 0.026475  [ 3600/ 4873]\n",
      "loss: 0.284961  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.615     0.562    105\n",
      " disgust     0.530     0.495     0.477    109\n",
      "    fear     0.530     0.447     0.425    80\n",
      "   happy     0.530     0.527     0.593    81\n",
      " neutral     0.530     0.611     0.655    84\n",
      "     sad     0.530     0.506     0.460    87\n",
      "surprise     0.530     0.479     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.530     0.526     0.531    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.377968 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.436424  [ 1200/ 4873]\n",
      "loss: 0.021105  [ 2400/ 4873]\n",
      "loss: 0.257133  [ 3600/ 4873]\n",
      "loss: 0.151956  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.655     0.543    105\n",
      " disgust     0.548     0.538     0.514    109\n",
      "    fear     0.548     0.481     0.487    80\n",
      "   happy     0.548     0.527     0.593    81\n",
      " neutral     0.548     0.643     0.643    84\n",
      "     sad     0.548     0.494     0.494    87\n",
      "surprise     0.548     0.487     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.547     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.488748 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.586877  [ 1200/ 4873]\n",
      "loss: 0.083138  [ 2400/ 4873]\n",
      "loss: 0.335717  [ 3600/ 4873]\n",
      "loss: 0.055401  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.645     0.467    105\n",
      " disgust     0.549     0.574     0.495    109\n",
      "    fear     0.549     0.461     0.512    80\n",
      "   happy     0.549     0.477     0.642    81\n",
      " neutral     0.549     0.630     0.690    84\n",
      "     sad     0.549     0.511     0.517    87\n",
      "surprise     0.549     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.554     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.432476 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.077483  [ 1200/ 4873]\n",
      "loss: 0.305562  [ 2400/ 4873]\n",
      "loss: 0.190611  [ 3600/ 4873]\n",
      "loss: 0.375104  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.683     0.533    105\n",
      " disgust     0.543     0.519     0.514    109\n",
      "    fear     0.543     0.479     0.438    80\n",
      "   happy     0.543     0.535     0.667    81\n",
      " neutral     0.543     0.590     0.702    84\n",
      "     sad     0.543     0.446     0.425    87\n",
      "surprise     0.543     0.540     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.542     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.367935 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.633433  [ 1200/ 4873]\n",
      "loss: 0.040531  [ 2400/ 4873]\n",
      "loss: 0.442618  [ 3600/ 4873]\n",
      "loss: 0.182260  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.613     0.467    105\n",
      " disgust     0.554     0.570     0.560    109\n",
      "    fear     0.554     0.400     0.450    80\n",
      "   happy     0.554     0.602     0.654    81\n",
      " neutral     0.554     0.625     0.655    84\n",
      "     sad     0.554     0.523     0.517    87\n",
      "surprise     0.554     0.549     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.536645 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.282641  [ 1200/ 4873]\n",
      "loss: 0.402713  [ 2400/ 4873]\n",
      "loss: 0.235335  [ 3600/ 4873]\n",
      "loss: 0.500594  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.526     0.706     0.457    105\n",
      " disgust     0.526     0.520     0.486    109\n",
      "    fear     0.526     0.467     0.438    80\n",
      "   happy     0.526     0.490     0.630    81\n",
      " neutral     0.526     0.684     0.643    84\n",
      "     sad     0.526     0.384     0.494    87\n",
      "surprise     0.526     0.529     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.526     0.540     0.532    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 2.512536 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.305234  [ 1200/ 4873]\n",
      "loss: 0.282759  [ 2400/ 4873]\n",
      "loss: 0.694899  [ 3600/ 4873]\n",
      "loss: 0.307879  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.595     0.476    105\n",
      " disgust     0.546     0.534     0.505    109\n",
      "    fear     0.546     0.494     0.487    80\n",
      "   happy     0.546     0.557     0.667    81\n",
      " neutral     0.546     0.674     0.690    84\n",
      "     sad     0.546     0.460     0.460    87\n",
      "surprise     0.546     0.500     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.545     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.431493 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.307152  [ 1200/ 4873]\n",
      "loss: 0.499202  [ 2400/ 4873]\n",
      "loss: 0.178264  [ 3600/ 4873]\n",
      "loss: 0.496791  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.663     0.562    105\n",
      " disgust     0.557     0.527     0.541    109\n",
      "    fear     0.557     0.500     0.500    80\n",
      "   happy     0.557     0.539     0.593    81\n",
      " neutral     0.557     0.580     0.690    84\n",
      "     sad     0.557     0.506     0.460    87\n",
      "surprise     0.557     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.558     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.390441 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.046262  [ 1200/ 4873]\n",
      "loss: 0.229154  [ 2400/ 4873]\n",
      "loss: 0.433179  [ 3600/ 4873]\n",
      "loss: 0.473864  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.634     0.562    105\n",
      " disgust     0.561     0.542     0.532    109\n",
      "    fear     0.561     0.459     0.487    80\n",
      "   happy     0.561     0.565     0.593    81\n",
      " neutral     0.561     0.610     0.726    84\n",
      "     sad     0.561     0.494     0.437    87\n",
      "surprise     0.561     0.619     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.560     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.335625 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.222485  [ 1200/ 4873]\n",
      "loss: 0.355763  [ 2400/ 4873]\n",
      "loss: 0.259281  [ 3600/ 4873]\n",
      "loss: 0.077939  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.538     0.543    105\n",
      " disgust     0.534     0.584     0.477    109\n",
      "    fear     0.534     0.462     0.450    80\n",
      "   happy     0.534     0.533     0.605    81\n",
      " neutral     0.534     0.586     0.690    84\n",
      "     sad     0.534     0.513     0.448    87\n",
      "surprise     0.534     0.500     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.531     0.537    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.587083 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.141833  [ 1200/ 4873]\n",
      "loss: 0.119010  [ 2400/ 4873]\n",
      "loss: 0.194950  [ 3600/ 4873]\n",
      "loss: 0.121666  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.695     0.543    105\n",
      " disgust     0.549     0.514     0.514    109\n",
      "    fear     0.549     0.480     0.450    80\n",
      "   happy     0.549     0.486     0.630    81\n",
      " neutral     0.549     0.633     0.679    84\n",
      "     sad     0.549     0.500     0.460    87\n",
      "surprise     0.549     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.551     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.505546 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.469757  [ 1200/ 4873]\n",
      "loss: 0.264728  [ 2400/ 4873]\n",
      "loss: 0.144872  [ 3600/ 4873]\n",
      "loss: 0.159171  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.695     0.543    105\n",
      " disgust     0.556     0.529     0.505    109\n",
      "    fear     0.556     0.475     0.475    80\n",
      "   happy     0.556     0.562     0.617    81\n",
      " neutral     0.556     0.648     0.679    84\n",
      "     sad     0.556     0.442     0.529    87\n",
      "surprise     0.556     0.571     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.560     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.480741 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.382115  [ 1200/ 4873]\n",
      "loss: 0.156347  [ 2400/ 4873]\n",
      "loss: 0.377166  [ 3600/ 4873]\n",
      "loss: 0.285758  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.578     0.562    105\n",
      " disgust     0.562     0.574     0.569    109\n",
      "    fear     0.562     0.494     0.525    80\n",
      "   happy     0.562     0.628     0.605    81\n",
      " neutral     0.562     0.626     0.679    84\n",
      "     sad     0.562     0.488     0.471    87\n",
      "surprise     0.562     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.560     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.481639 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.076038  [ 1200/ 4873]\n",
      "loss: 0.299919  [ 2400/ 4873]\n",
      "loss: 0.263041  [ 3600/ 4873]\n",
      "loss: 0.309973  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.671     0.505    105\n",
      " disgust     0.551     0.558     0.532    109\n",
      "    fear     0.551     0.458     0.475    80\n",
      "   happy     0.551     0.525     0.654    81\n",
      " neutral     0.551     0.659     0.714    84\n",
      "     sad     0.551     0.456     0.471    87\n",
      "surprise     0.551     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.551     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.355146 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.214634  [ 1200/ 4873]\n",
      "loss: 0.383043  [ 2400/ 4873]\n",
      "loss: 0.546642  [ 3600/ 4873]\n",
      "loss: 0.193014  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.523     0.584     0.429    105\n",
      " disgust     0.523     0.500     0.486    109\n",
      "    fear     0.523     0.481     0.487    80\n",
      "   happy     0.523     0.495     0.617    81\n",
      " neutral     0.523     0.635     0.643    84\n",
      "     sad     0.523     0.442     0.483    87\n",
      "surprise     0.523     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.523     0.527     0.530    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 2.548338 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.538192  [ 1200/ 4873]\n",
      "loss: 0.570760  [ 2400/ 4873]\n",
      "loss: 0.311665  [ 3600/ 4873]\n",
      "loss: 0.039703  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.611     0.524    105\n",
      " disgust     0.539     0.520     0.468    109\n",
      "    fear     0.539     0.467     0.525    80\n",
      "   happy     0.539     0.645     0.605    81\n",
      " neutral     0.539     0.641     0.702    84\n",
      "     sad     0.539     0.404     0.414    87\n",
      "surprise     0.539     0.493     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.540     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.558633 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.448027  [ 1200/ 4873]\n",
      "loss: 0.330947  [ 2400/ 4873]\n",
      "loss: 0.180589  [ 3600/ 4873]\n",
      "loss: 0.408100  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.718     0.533    105\n",
      " disgust     0.551     0.552     0.532    109\n",
      "    fear     0.551     0.447     0.475    80\n",
      "   happy     0.551     0.462     0.605    81\n",
      " neutral     0.551     0.720     0.643    84\n",
      "     sad     0.551     0.460     0.529    87\n",
      "surprise     0.551     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.562     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.411533 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.234461  [ 1200/ 4873]\n",
      "loss: 0.291730  [ 2400/ 4873]\n",
      "loss: 0.095332  [ 3600/ 4873]\n",
      "loss: 0.199488  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.636     0.533    105\n",
      " disgust     0.556     0.522     0.541    109\n",
      "    fear     0.556     0.535     0.475    80\n",
      "   happy     0.556     0.480     0.593    81\n",
      " neutral     0.556     0.679     0.679    84\n",
      "     sad     0.556     0.511     0.540    87\n",
      "surprise     0.556     0.548     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.559     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.417976 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.249387  [ 1200/ 4873]\n",
      "loss: 0.777144  [ 2400/ 4873]\n",
      "loss: 0.197882  [ 3600/ 4873]\n",
      "loss: 0.373123  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.641     0.562    105\n",
      " disgust     0.536     0.560     0.514    109\n",
      "    fear     0.536     0.507     0.438    80\n",
      "   happy     0.536     0.475     0.580    81\n",
      " neutral     0.536     0.611     0.690    84\n",
      "     sad     0.536     0.458     0.437    87\n",
      "surprise     0.536     0.472     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.532     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.552972 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.299038  [ 1200/ 4873]\n",
      "loss: 0.499615  [ 2400/ 4873]\n",
      "loss: 0.078590  [ 3600/ 4873]\n",
      "loss: 0.138816  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.612     0.571    105\n",
      " disgust     0.559     0.555     0.560    109\n",
      "    fear     0.559     0.460     0.575    80\n",
      "   happy     0.559     0.560     0.580    81\n",
      " neutral     0.559     0.667     0.690    84\n",
      "     sad     0.559     0.500     0.414    87\n",
      "surprise     0.559     0.559     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.559     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.509547 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.167933  [ 1200/ 4873]\n",
      "loss: 0.068425  [ 2400/ 4873]\n",
      "loss: 0.419073  [ 3600/ 4873]\n",
      "loss: 0.114790  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.540     0.514    105\n",
      " disgust     0.543     0.522     0.541    109\n",
      "    fear     0.543     0.471     0.412    80\n",
      "   happy     0.543     0.563     0.605    81\n",
      " neutral     0.543     0.652     0.690    84\n",
      "     sad     0.543     0.471     0.471    87\n",
      "surprise     0.543     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.543     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.572612 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.499616  [ 1200/ 4873]\n",
      "loss: 0.513779  [ 2400/ 4873]\n",
      "loss: 0.180080  [ 3600/ 4873]\n",
      "loss: 0.394333  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.674     0.571    105\n",
      " disgust     0.567     0.594     0.550    109\n",
      "    fear     0.567     0.434     0.537    80\n",
      "   happy     0.567     0.528     0.580    81\n",
      " neutral     0.567     0.690     0.714    84\n",
      "     sad     0.567     0.478     0.506    87\n",
      "surprise     0.567     0.604     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.572     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.391036 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.196470  [ 1200/ 4873]\n",
      "loss: 0.565819  [ 2400/ 4873]\n",
      "loss: 0.236357  [ 3600/ 4873]\n",
      "loss: 0.066552  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.609     0.533    105\n",
      " disgust     0.556     0.560     0.514    109\n",
      "    fear     0.556     0.438     0.487    80\n",
      "   happy     0.556     0.553     0.642    81\n",
      " neutral     0.556     0.651     0.667    84\n",
      "     sad     0.556     0.459     0.517    87\n",
      "surprise     0.556     0.686     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.565     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.423002 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.377519  [ 1200/ 4873]\n",
      "loss: 0.165710  [ 2400/ 4873]\n",
      "loss: 0.089434  [ 3600/ 4873]\n",
      "loss: 0.083918  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.667     0.590    105\n",
      " disgust     0.561     0.553     0.523    109\n",
      "    fear     0.561     0.454     0.550    80\n",
      "   happy     0.561     0.597     0.568    81\n",
      " neutral     0.561     0.648     0.679    84\n",
      "     sad     0.561     0.476     0.448    87\n",
      "surprise     0.561     0.529     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.560     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.477033 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.056895  [ 1200/ 4873]\n",
      "loss: 0.696879  [ 2400/ 4873]\n",
      "loss: 0.440823  [ 3600/ 4873]\n",
      "loss: 0.198509  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.656     0.562    105\n",
      " disgust     0.551     0.514     0.523    109\n",
      "    fear     0.551     0.437     0.475    80\n",
      "   happy     0.551     0.543     0.630    81\n",
      " neutral     0.551     0.704     0.679    84\n",
      "     sad     0.551     0.456     0.414    87\n",
      "surprise     0.551     0.559     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.552     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.449802 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.393122  [ 1200/ 4873]\n",
      "loss: 0.596543  [ 2400/ 4873]\n",
      "loss: 0.219296  [ 3600/ 4873]\n",
      "loss: 0.353744  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.526     0.640     0.543    105\n",
      " disgust     0.526     0.481     0.468    109\n",
      "    fear     0.526     0.410     0.512    80\n",
      "   happy     0.526     0.570     0.556    81\n",
      " neutral     0.526     0.700     0.667    84\n",
      "     sad     0.526     0.429     0.448    87\n",
      "surprise     0.526     0.492     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.526     0.532     0.528    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 2.543230 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.058593  [ 1200/ 4873]\n",
      "loss: 0.258463  [ 2400/ 4873]\n",
      "loss: 0.159227  [ 3600/ 4873]\n",
      "loss: 0.107929  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.651     0.533    105\n",
      " disgust     0.554     0.585     0.569    109\n",
      "    fear     0.554     0.443     0.487    80\n",
      "   happy     0.554     0.532     0.617    81\n",
      " neutral     0.554     0.598     0.655    84\n",
      "     sad     0.554     0.513     0.460    87\n",
      "surprise     0.554     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.552     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.532545 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.042920  [ 1200/ 4873]\n",
      "loss: 0.208620  [ 2400/ 4873]\n",
      "loss: 0.664717  [ 3600/ 4873]\n",
      "loss: 0.072586  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.617     0.552    105\n",
      " disgust     0.538     0.557     0.495    109\n",
      "    fear     0.538     0.444     0.500    80\n",
      "   happy     0.538     0.550     0.543    81\n",
      " neutral     0.538     0.714     0.655    84\n",
      "     sad     0.538     0.391     0.517    87\n",
      "surprise     0.538     0.561     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.548     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.560564 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.823517  [ 1200/ 4873]\n",
      "loss: 0.610807  [ 2400/ 4873]\n",
      "loss: 0.229218  [ 3600/ 4873]\n",
      "loss: 0.453439  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.685     0.581    105\n",
      " disgust     0.566     0.567     0.505    109\n",
      "    fear     0.566     0.457     0.537    80\n",
      "   happy     0.566     0.556     0.617    81\n",
      " neutral     0.566     0.633     0.679    84\n",
      "     sad     0.566     0.506     0.517    87\n",
      "surprise     0.566     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.566     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.445482 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.136133  [ 1200/ 4873]\n",
      "loss: 0.726349  [ 2400/ 4873]\n",
      "loss: 0.249450  [ 3600/ 4873]\n",
      "loss: 0.331042  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.722     0.543    105\n",
      " disgust     0.562     0.529     0.578    109\n",
      "    fear     0.562     0.464     0.487    80\n",
      "   happy     0.562     0.533     0.605    81\n",
      " neutral     0.562     0.679     0.631    84\n",
      "     sad     0.562     0.455     0.529    87\n",
      "surprise     0.562     0.632     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.573     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.428285 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.384869  [ 1200/ 4873]\n",
      "loss: 0.047160  [ 2400/ 4873]\n",
      "loss: 0.731972  [ 3600/ 4873]\n",
      "loss: 0.165604  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.592     0.581    105\n",
      " disgust     0.559     0.539     0.569    109\n",
      "    fear     0.559     0.386     0.487    80\n",
      "   happy     0.559     0.644     0.580    81\n",
      " neutral     0.559     0.711     0.702    84\n",
      "     sad     0.559     0.521     0.437    87\n",
      "surprise     0.559     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.565     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.435954 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.137018  [ 1200/ 4873]\n",
      "loss: 0.027678  [ 2400/ 4873]\n",
      "loss: 0.704955  [ 3600/ 4873]\n",
      "loss: 0.077926  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.708     0.486    105\n",
      " disgust     0.556     0.589     0.514    109\n",
      "    fear     0.556     0.506     0.500    80\n",
      "   happy     0.556     0.462     0.593    81\n",
      " neutral     0.556     0.663     0.679    84\n",
      "     sad     0.556     0.453     0.552    87\n",
      "surprise     0.556     0.574     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.565     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.475743 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.223641  [ 1200/ 4873]\n",
      "loss: 0.535996  [ 2400/ 4873]\n",
      "loss: 0.610473  [ 3600/ 4873]\n",
      "loss: 0.154127  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.588     0.543    105\n",
      " disgust     0.536     0.541     0.486    109\n",
      "    fear     0.536     0.435     0.463    80\n",
      "   happy     0.536     0.544     0.605    81\n",
      " neutral     0.536     0.619     0.714    84\n",
      "     sad     0.536     0.449     0.460    87\n",
      "surprise     0.536     0.574     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.536     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.572283 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.998623  [ 1200/ 4873]\n",
      "loss: 0.260232  [ 2400/ 4873]\n",
      "loss: 0.568458  [ 3600/ 4873]\n",
      "loss: 0.206540  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.611     0.552    105\n",
      " disgust     0.549     0.500     0.523    109\n",
      "    fear     0.549     0.455     0.500    80\n",
      "   happy     0.549     0.595     0.617    81\n",
      " neutral     0.549     0.705     0.655    84\n",
      "     sad     0.549     0.489     0.494    87\n",
      "surprise     0.549     0.508     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.552     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.657311 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.359500  [ 1200/ 4873]\n",
      "loss: 0.159239  [ 2400/ 4873]\n",
      "loss: 0.250142  [ 3600/ 4873]\n",
      "loss: 0.211980  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.625     0.524    105\n",
      " disgust     0.557     0.525     0.578    109\n",
      "    fear     0.557     0.446     0.463    80\n",
      "   happy     0.557     0.553     0.642    81\n",
      " neutral     0.557     0.771     0.643    84\n",
      "     sad     0.557     0.451     0.529    87\n",
      "surprise     0.557     0.623     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.571     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.534126 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.272988  [ 1200/ 4873]\n",
      "loss: 0.272692  [ 2400/ 4873]\n",
      "loss: 0.253550  [ 3600/ 4873]\n",
      "loss: 0.078129  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.606     0.543    105\n",
      " disgust     0.534     0.510     0.486    109\n",
      "    fear     0.534     0.494     0.475    80\n",
      "   happy     0.534     0.457     0.593    81\n",
      " neutral     0.534     0.632     0.655    84\n",
      "     sad     0.534     0.494     0.471    87\n",
      "surprise     0.534     0.567     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.537     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.576851 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.606168  [ 1200/ 4873]\n",
      "loss: 0.274343  [ 2400/ 4873]\n",
      "loss: 0.082769  [ 3600/ 4873]\n",
      "loss: 0.096663  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.688     0.505    105\n",
      " disgust     0.548     0.568     0.495    109\n",
      "    fear     0.548     0.507     0.463    80\n",
      "   happy     0.548     0.467     0.617    81\n",
      " neutral     0.548     0.667     0.667    84\n",
      "     sad     0.548     0.427     0.540    87\n",
      "surprise     0.548     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.558     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.453571 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.148182  [ 1200/ 4873]\n",
      "loss: 0.172608  [ 2400/ 4873]\n",
      "loss: 0.119416  [ 3600/ 4873]\n",
      "loss: 0.157130  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.682     0.571    105\n",
      " disgust     0.561     0.553     0.578    109\n",
      "    fear     0.561     0.476     0.500    80\n",
      "   happy     0.561     0.571     0.593    81\n",
      " neutral     0.561     0.678     0.702    84\n",
      "     sad     0.561     0.429     0.414    87\n",
      "surprise     0.561     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.559     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.508113 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.630872  [ 1200/ 4873]\n",
      "loss: 0.188537  [ 2400/ 4873]\n",
      "loss: 0.422881  [ 3600/ 4873]\n",
      "loss: 0.028830  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.618     0.524    105\n",
      " disgust     0.562     0.526     0.560    109\n",
      "    fear     0.562     0.473     0.550    80\n",
      "   happy     0.562     0.557     0.605    81\n",
      " neutral     0.562     0.743     0.655    84\n",
      "     sad     0.562     0.454     0.506    87\n",
      "surprise     0.562     0.660     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.576     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.458494 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.300867  [ 1200/ 4873]\n",
      "loss: 0.462732  [ 2400/ 4873]\n",
      "loss: 0.510664  [ 3600/ 4873]\n",
      "loss: 0.104450  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.525     0.624     0.505    105\n",
      " disgust     0.525     0.595     0.431    109\n",
      "    fear     0.525     0.450     0.450    80\n",
      "   happy     0.525     0.458     0.667    81\n",
      " neutral     0.525     0.569     0.690    84\n",
      "     sad     0.525     0.481     0.448    87\n",
      "surprise     0.525     0.508     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.525     0.526     0.530    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 2.518203 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.232440  [ 1200/ 4873]\n",
      "loss: 0.271918  [ 2400/ 4873]\n",
      "loss: 0.078159  [ 3600/ 4873]\n",
      "loss: 0.308900  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.644     0.552    105\n",
      " disgust     0.549     0.522     0.550    109\n",
      "    fear     0.549     0.427     0.400    80\n",
      "   happy     0.549     0.593     0.630    81\n",
      " neutral     0.549     0.596     0.702    84\n",
      "     sad     0.549     0.475     0.437    87\n",
      "surprise     0.549     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.547     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.519597 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.606718  [ 1200/ 4873]\n",
      "loss: 0.376113  [ 2400/ 4873]\n",
      "loss: 0.321165  [ 3600/ 4873]\n",
      "loss: 0.312371  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.671     0.543    105\n",
      " disgust     0.566     0.594     0.550    109\n",
      "    fear     0.566     0.552     0.463    80\n",
      "   happy     0.566     0.581     0.617    81\n",
      " neutral     0.566     0.561     0.714    84\n",
      "     sad     0.566     0.471     0.460    87\n",
      "surprise     0.566     0.519     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.564     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.562357 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.639698  [ 1200/ 4873]\n",
      "loss: 0.351423  [ 2400/ 4873]\n",
      "loss: 0.218955  [ 3600/ 4873]\n",
      "loss: 0.201689  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.644     0.533    105\n",
      " disgust     0.554     0.577     0.514    109\n",
      "    fear     0.554     0.544     0.463    80\n",
      "   happy     0.554     0.505     0.654    81\n",
      " neutral     0.554     0.645     0.714    84\n",
      "     sad     0.554     0.430     0.460    87\n",
      "surprise     0.554     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.478325 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.185080  [ 1200/ 4873]\n",
      "loss: 0.525385  [ 2400/ 4873]\n",
      "loss: 0.237733  [ 3600/ 4873]\n",
      "loss: 0.272808  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.617     0.552    105\n",
      " disgust     0.549     0.517     0.550    109\n",
      "    fear     0.549     0.500     0.412    80\n",
      "   happy     0.549     0.565     0.593    81\n",
      " neutral     0.549     0.628     0.702    84\n",
      "     sad     0.549     0.477     0.483    87\n",
      "surprise     0.549     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.547     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.598558 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.204332  [ 1200/ 4873]\n",
      "loss: 0.233633  [ 2400/ 4873]\n",
      "loss: 0.132147  [ 3600/ 4873]\n",
      "loss: 0.394628  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.629     0.533    105\n",
      " disgust     0.551     0.533     0.514    109\n",
      "    fear     0.551     0.506     0.525    80\n",
      "   happy     0.551     0.511     0.593    81\n",
      " neutral     0.551     0.640     0.679    84\n",
      "     sad     0.551     0.447     0.483    87\n",
      "surprise     0.551     0.625     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.556     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.583468 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.122450  [ 1200/ 4873]\n",
      "loss: 0.154946  [ 2400/ 4873]\n",
      "loss: 0.435876  [ 3600/ 4873]\n",
      "loss: 0.058371  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.639     0.505    105\n",
      " disgust     0.543     0.581     0.495    109\n",
      "    fear     0.543     0.493     0.438    80\n",
      "   happy     0.543     0.468     0.642    81\n",
      " neutral     0.543     0.621     0.702    84\n",
      "     sad     0.543     0.473     0.494    87\n",
      "surprise     0.543     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.544     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.566236 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.113810  [ 1200/ 4873]\n",
      "loss: 0.097724  [ 2400/ 4873]\n",
      "loss: 0.556388  [ 3600/ 4873]\n",
      "loss: 0.029070  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.583     0.533    105\n",
      " disgust     0.559     0.566     0.587    109\n",
      "    fear     0.559     0.487     0.487    80\n",
      "   happy     0.559     0.590     0.605    81\n",
      " neutral     0.559     0.629     0.667    84\n",
      "     sad     0.559     0.512     0.483    87\n",
      "surprise     0.559     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.556     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.657721 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.037080  [ 1200/ 4873]\n",
      "loss: 0.124450  [ 2400/ 4873]\n",
      "loss: 0.320717  [ 3600/ 4873]\n",
      "loss: 0.712355  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.734     0.552    105\n",
      " disgust     0.561     0.516     0.578    109\n",
      "    fear     0.561     0.526     0.512    80\n",
      "   happy     0.561     0.522     0.593    81\n",
      " neutral     0.561     0.722     0.679    84\n",
      "     sad     0.561     0.426     0.494    87\n",
      "surprise     0.561     0.542     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.570     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.603917 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.346646  [ 1200/ 4873]\n",
      "loss: 0.123285  [ 2400/ 4873]\n",
      "loss: 0.086350  [ 3600/ 4873]\n",
      "loss: 0.191810  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.625     0.524    105\n",
      " disgust     0.541     0.523     0.532    109\n",
      "    fear     0.541     0.451     0.463    80\n",
      "   happy     0.541     0.541     0.568    81\n",
      " neutral     0.541     0.659     0.643    84\n",
      "     sad     0.541     0.457     0.494    87\n",
      "surprise     0.541     0.544     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.543     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.585432 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.153372  [ 1200/ 4873]\n",
      "loss: 0.138425  [ 2400/ 4873]\n",
      "loss: 0.293715  [ 3600/ 4873]\n",
      "loss: 0.258308  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.604     0.552    105\n",
      " disgust     0.567     0.557     0.587    109\n",
      "    fear     0.567     0.422     0.475    80\n",
      "   happy     0.567     0.619     0.642    81\n",
      " neutral     0.567     0.682     0.690    84\n",
      "     sad     0.567     0.560     0.483    87\n",
      "surprise     0.567     0.523     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.567     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.518641 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.190325  [ 1200/ 4873]\n",
      "loss: 0.511836  [ 2400/ 4873]\n",
      "loss: 0.024460  [ 3600/ 4873]\n",
      "loss: 0.329398  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.707     0.552    105\n",
      " disgust     0.534     0.485     0.450    109\n",
      "    fear     0.534     0.429     0.450    80\n",
      "   happy     0.534     0.523     0.556    81\n",
      " neutral     0.534     0.718     0.667    84\n",
      "     sad     0.534     0.395     0.540    87\n",
      "surprise     0.534     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.549     0.537    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.686010 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.239245  [ 1200/ 4873]\n",
      "loss: 0.298987  [ 2400/ 4873]\n",
      "loss: 0.359232  [ 3600/ 4873]\n",
      "loss: 0.345844  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.675     0.533    105\n",
      " disgust     0.551     0.508     0.560    109\n",
      "    fear     0.551     0.481     0.463    80\n",
      "   happy     0.551     0.562     0.617    81\n",
      " neutral     0.551     0.707     0.631    84\n",
      "     sad     0.551     0.407     0.506    87\n",
      "surprise     0.551     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.563     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.641238 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.237386  [ 1200/ 4873]\n",
      "loss: 0.060094  [ 2400/ 4873]\n",
      "loss: 0.062494  [ 3600/ 4873]\n",
      "loss: 0.178251  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.674     0.571    105\n",
      " disgust     0.544     0.591     0.505    109\n",
      "    fear     0.544     0.467     0.438    80\n",
      "   happy     0.544     0.489     0.568    81\n",
      " neutral     0.544     0.594     0.679    84\n",
      "     sad     0.544     0.457     0.483    87\n",
      "surprise     0.544     0.521     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.542     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.530598 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.121067  [ 1200/ 4873]\n",
      "loss: 0.281827  [ 2400/ 4873]\n",
      "loss: 0.159251  [ 3600/ 4873]\n",
      "loss: 0.399668  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.644     0.619    105\n",
      " disgust     0.543     0.523     0.523    109\n",
      "    fear     0.543     0.472     0.425    80\n",
      "   happy     0.543     0.500     0.580    81\n",
      " neutral     0.543     0.686     0.702    84\n",
      "     sad     0.543     0.419     0.414    87\n",
      "surprise     0.543     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.539     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.631546 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.090043  [ 1200/ 4873]\n",
      "loss: 0.069398  [ 2400/ 4873]\n",
      "loss: 0.158305  [ 3600/ 4873]\n",
      "loss: 0.326331  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.617     0.552    105\n",
      " disgust     0.559     0.518     0.532    109\n",
      "    fear     0.559     0.457     0.463    80\n",
      "   happy     0.559     0.573     0.630    81\n",
      " neutral     0.559     0.706     0.714    84\n",
      "     sad     0.559     0.464     0.448    87\n",
      "surprise     0.559     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.560     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.606537 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.175186  [ 1200/ 4873]\n",
      "loss: 0.295585  [ 2400/ 4873]\n",
      "loss: 0.435101  [ 3600/ 4873]\n",
      "loss: 0.175382  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.663     0.543    105\n",
      " disgust     0.546     0.560     0.514    109\n",
      "    fear     0.546     0.456     0.450    80\n",
      "   happy     0.546     0.495     0.593    81\n",
      " neutral     0.546     0.600     0.679    84\n",
      "     sad     0.546     0.506     0.494    87\n",
      "surprise     0.546     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.544     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.664044 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.109609  [ 1200/ 4873]\n",
      "loss: 0.167182  [ 2400/ 4873]\n",
      "loss: 0.116375  [ 3600/ 4873]\n",
      "loss: 0.335905  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.637     0.552    105\n",
      " disgust     0.556     0.542     0.532    109\n",
      "    fear     0.556     0.543     0.475    80\n",
      "   happy     0.556     0.515     0.630    81\n",
      " neutral     0.556     0.682     0.714    84\n",
      "     sad     0.556     0.418     0.471    87\n",
      "surprise     0.556     0.579     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.560     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.551519 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.251312  [ 1200/ 4873]\n",
      "loss: 0.110063  [ 2400/ 4873]\n",
      "loss: 0.705730  [ 3600/ 4873]\n",
      "loss: 0.245313  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.580     0.634     0.562    105\n",
      " disgust     0.580     0.557     0.624    109\n",
      "    fear     0.580     0.468     0.463    80\n",
      "   happy     0.580     0.612     0.642    81\n",
      " neutral     0.580     0.648     0.702    84\n",
      "     sad     0.580     0.532     0.483    87\n",
      "surprise     0.580     0.607     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.580     0.580     0.579    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 2.545885 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep457_acc_58.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep331_acc_58\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep457_acc_58\"! Old accuracy: 57.7, new accuracy: 58.0\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.133129  [ 1200/ 4873]\n",
      "loss: 0.285726  [ 2400/ 4873]\n",
      "loss: 0.108934  [ 3600/ 4873]\n",
      "loss: 0.384952  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.606     0.571    105\n",
      " disgust     0.546     0.576     0.486    109\n",
      "    fear     0.546     0.450     0.450    80\n",
      "   happy     0.546     0.453     0.593    81\n",
      " neutral     0.546     0.626     0.679    84\n",
      "     sad     0.546     0.525     0.483    87\n",
      "surprise     0.546     0.597     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.548     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.484824 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.139979  [ 1200/ 4873]\n",
      "loss: 0.495866  [ 2400/ 4873]\n",
      "loss: 0.899785  [ 3600/ 4873]\n",
      "loss: 0.290399  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.611     0.552    105\n",
      " disgust     0.546     0.537     0.606    109\n",
      "    fear     0.546     0.449     0.388    80\n",
      "   happy     0.546     0.500     0.543    81\n",
      " neutral     0.546     0.705     0.655    84\n",
      "     sad     0.546     0.511     0.517    87\n",
      "surprise     0.546     0.493     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.544     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.645619 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.220250  [ 1200/ 4873]\n",
      "loss: 0.340458  [ 2400/ 4873]\n",
      "loss: 0.157338  [ 3600/ 4873]\n",
      "loss: 0.136369  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.625     0.524    105\n",
      " disgust     0.551     0.544     0.569    109\n",
      "    fear     0.551     0.400     0.500    80\n",
      "   happy     0.551     0.540     0.580    81\n",
      " neutral     0.551     0.760     0.679    84\n",
      "     sad     0.551     0.440     0.460    87\n",
      "surprise     0.551     0.636     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.564     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.530364 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.060518  [ 1200/ 4873]\n",
      "loss: 0.544936  [ 2400/ 4873]\n",
      "loss: 0.078741  [ 3600/ 4873]\n",
      "loss: 0.393090  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.656     0.581    105\n",
      " disgust     0.562     0.530     0.569    109\n",
      "    fear     0.562     0.485     0.400    80\n",
      "   happy     0.562     0.538     0.617    81\n",
      " neutral     0.562     0.649     0.726    84\n",
      "     sad     0.562     0.460     0.460    87\n",
      "surprise     0.562     0.617     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.562     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.579013 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.099673  [ 1200/ 4873]\n",
      "loss: 0.108275  [ 2400/ 4873]\n",
      "loss: 0.241749  [ 3600/ 4873]\n",
      "loss: 0.449973  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.634     0.495    105\n",
      " disgust     0.543     0.505     0.477    109\n",
      "    fear     0.543     0.487     0.487    80\n",
      "   happy     0.543     0.500     0.642    81\n",
      " neutral     0.543     0.690     0.714    84\n",
      "     sad     0.543     0.448     0.494    87\n",
      "surprise     0.543     0.569     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.548     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.610688 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.148906  [ 1200/ 4873]\n",
      "loss: 0.323338  [ 2400/ 4873]\n",
      "loss: 0.166161  [ 3600/ 4873]\n",
      "loss: 0.109496  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.655     0.524    105\n",
      " disgust     0.548     0.534     0.505    109\n",
      "    fear     0.548     0.493     0.438    80\n",
      "   happy     0.548     0.500     0.605    81\n",
      " neutral     0.548     0.682     0.714    84\n",
      "     sad     0.548     0.440     0.506    87\n",
      "surprise     0.548     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.550     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.781902 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.536170  [ 1200/ 4873]\n",
      "loss: 0.048092  [ 2400/ 4873]\n",
      "loss: 0.366773  [ 3600/ 4873]\n",
      "loss: 0.136123  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.615     0.562    105\n",
      " disgust     0.564     0.581     0.495    109\n",
      "    fear     0.564     0.506     0.537    80\n",
      "   happy     0.564     0.514     0.667    81\n",
      " neutral     0.564     0.663     0.702    84\n",
      "     sad     0.564     0.489     0.494    87\n",
      "surprise     0.564     0.593     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.566     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.645886 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.065620  [ 1200/ 4873]\n",
      "loss: 0.587000  [ 2400/ 4873]\n",
      "loss: 0.088508  [ 3600/ 4873]\n",
      "loss: 0.260572  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.571     0.495    105\n",
      " disgust     0.551     0.544     0.569    109\n",
      "    fear     0.551     0.446     0.512    80\n",
      "   happy     0.551     0.533     0.593    81\n",
      " neutral     0.551     0.683     0.667    84\n",
      "     sad     0.551     0.568     0.483    87\n",
      "surprise     0.551     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.552     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.717513 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.342539  [ 1200/ 4873]\n",
      "loss: 0.259939  [ 2400/ 4873]\n",
      "loss: 0.267769  [ 3600/ 4873]\n",
      "loss: 0.134781  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.617     0.552    105\n",
      " disgust     0.554     0.600     0.523    109\n",
      "    fear     0.554     0.426     0.500    80\n",
      "   happy     0.554     0.539     0.593    81\n",
      " neutral     0.554     0.619     0.714    84\n",
      "     sad     0.554     0.487     0.448    87\n",
      "surprise     0.554     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.554     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.581913 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.427448  [ 1200/ 4873]\n",
      "loss: 0.157500  [ 2400/ 4873]\n",
      "loss: 0.356257  [ 3600/ 4873]\n",
      "loss: 0.245501  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.646     0.505    105\n",
      " disgust     0.544     0.551     0.541    109\n",
      "    fear     0.544     0.406     0.487    80\n",
      "   happy     0.544     0.522     0.593    81\n",
      " neutral     0.544     0.705     0.655    84\n",
      "     sad     0.544     0.455     0.529    87\n",
      "surprise     0.544     0.593     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.554     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.588746 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.218749  [ 1200/ 4873]\n",
      "loss: 0.762125  [ 2400/ 4873]\n",
      "loss: 0.174559  [ 3600/ 4873]\n",
      "loss: 0.662445  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.667     0.552    105\n",
      " disgust     0.557     0.582     0.587    109\n",
      "    fear     0.557     0.439     0.450    80\n",
      "   happy     0.557     0.522     0.593    81\n",
      " neutral     0.557     0.640     0.655    84\n",
      "     sad     0.557     0.525     0.483    87\n",
      "surprise     0.557     0.507     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.554     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.622176 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.051271  [ 1200/ 4873]\n",
      "loss: 0.042314  [ 2400/ 4873]\n",
      "loss: 0.063840  [ 3600/ 4873]\n",
      "loss: 0.152981  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.558     0.505    105\n",
      " disgust     0.559     0.545     0.560    109\n",
      "    fear     0.559     0.473     0.550    80\n",
      "   happy     0.559     0.632     0.593    81\n",
      " neutral     0.559     0.683     0.667    84\n",
      "     sad     0.559     0.500     0.540    87\n",
      "surprise     0.559     0.552     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.563     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.614260 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.034867  [ 1200/ 4873]\n",
      "loss: 0.174967  [ 2400/ 4873]\n",
      "loss: 0.084235  [ 3600/ 4873]\n",
      "loss: 0.088868  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.573     0.486    105\n",
      " disgust     0.536     0.518     0.523    109\n",
      "    fear     0.536     0.458     0.475    80\n",
      "   happy     0.536     0.539     0.593    81\n",
      " neutral     0.536     0.690     0.690    84\n",
      "     sad     0.536     0.526     0.460    87\n",
      "surprise     0.536     0.443     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.535     0.539    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.715753 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.289206  [ 1200/ 4873]\n",
      "loss: 0.235973  [ 2400/ 4873]\n",
      "loss: 0.484467  [ 3600/ 4873]\n",
      "loss: 0.297596  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.631     0.505    105\n",
      " disgust     0.536     0.576     0.486    109\n",
      "    fear     0.536     0.436     0.512    80\n",
      "   happy     0.536     0.505     0.617    81\n",
      " neutral     0.536     0.636     0.667    84\n",
      "     sad     0.536     0.471     0.460    87\n",
      "surprise     0.536     0.500     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.536     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.624837 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.052779  [ 1200/ 4873]\n",
      "loss: 0.104709  [ 2400/ 4873]\n",
      "loss: 0.018107  [ 3600/ 4873]\n",
      "loss: 0.248046  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.626     0.543    105\n",
      " disgust     0.562     0.586     0.532    109\n",
      "    fear     0.562     0.419     0.450    80\n",
      "   happy     0.562     0.614     0.630    81\n",
      " neutral     0.562     0.624     0.750    84\n",
      "     sad     0.562     0.500     0.494    87\n",
      "surprise     0.562     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.559     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.589140 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.583241  [ 1200/ 4873]\n",
      "loss: 0.122140  [ 2400/ 4873]\n",
      "loss: 0.022882  [ 3600/ 4873]\n",
      "loss: 0.468510  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.568     0.514    105\n",
      " disgust     0.559     0.581     0.560    109\n",
      "    fear     0.559     0.462     0.450    80\n",
      "   happy     0.559     0.567     0.630    81\n",
      " neutral     0.559     0.579     0.738    84\n",
      "     sad     0.559     0.533     0.460    87\n",
      "surprise     0.559     0.617     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.558     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.626919 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.110433  [ 1200/ 4873]\n",
      "loss: 0.453858  [ 2400/ 4873]\n",
      "loss: 0.362129  [ 3600/ 4873]\n",
      "loss: 0.047381  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.602     0.562    105\n",
      " disgust     0.556     0.554     0.514    109\n",
      "    fear     0.556     0.418     0.512    80\n",
      "   happy     0.556     0.617     0.617    81\n",
      " neutral     0.556     0.648     0.679    84\n",
      "     sad     0.556     0.534     0.448    87\n",
      "surprise     0.556     0.521     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.556     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.615635 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.279839  [ 1200/ 4873]\n",
      "loss: 0.173687  [ 2400/ 4873]\n",
      "loss: 0.217031  [ 3600/ 4873]\n",
      "loss: 0.348910  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.654     0.505    105\n",
      " disgust     0.559     0.604     0.587    109\n",
      "    fear     0.559     0.449     0.438    80\n",
      "   happy     0.559     0.546     0.654    81\n",
      " neutral     0.559     0.600     0.714    84\n",
      "     sad     0.559     0.456     0.471    87\n",
      "surprise     0.559     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.559     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.459879 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.028735  [ 1200/ 4873]\n",
      "loss: 0.196109  [ 2400/ 4873]\n",
      "loss: 0.145204  [ 3600/ 4873]\n",
      "loss: 0.193214  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.667     0.533    105\n",
      " disgust     0.552     0.604     0.532    109\n",
      "    fear     0.552     0.456     0.450    80\n",
      "   happy     0.552     0.477     0.642    81\n",
      " neutral     0.552     0.598     0.690    84\n",
      "     sad     0.552     0.467     0.494    87\n",
      "surprise     0.552     0.642     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.559     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.494758 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.107129  [ 1200/ 4873]\n",
      "loss: 0.216972  [ 2400/ 4873]\n",
      "loss: 0.116915  [ 3600/ 4873]\n",
      "loss: 0.535757  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.702     0.562    105\n",
      " disgust     0.562     0.583     0.550    109\n",
      "    fear     0.562     0.521     0.463    80\n",
      "   happy     0.562     0.510     0.605    81\n",
      " neutral     0.562     0.648     0.702    84\n",
      "     sad     0.562     0.438     0.483    87\n",
      "surprise     0.562     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.563     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.560436 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.454622  [ 1200/ 4873]\n",
      "loss: 0.111711  [ 2400/ 4873]\n",
      "loss: 1.188904  [ 3600/ 4873]\n",
      "loss: 0.189817  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.634     0.562    105\n",
      " disgust     0.566     0.527     0.541    109\n",
      "    fear     0.566     0.475     0.475    80\n",
      "   happy     0.566     0.593     0.630    81\n",
      " neutral     0.566     0.663     0.726    84\n",
      "     sad     0.566     0.500     0.448    87\n",
      "surprise     0.566     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.563     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.628669 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.250326  [ 1200/ 4873]\n",
      "loss: 0.235272  [ 2400/ 4873]\n",
      "loss: 0.294426  [ 3600/ 4873]\n",
      "loss: 0.123282  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.620     0.543    105\n",
      " disgust     0.561     0.637     0.532    109\n",
      "    fear     0.561     0.446     0.463    80\n",
      "   happy     0.561     0.543     0.617    81\n",
      " neutral     0.561     0.606     0.714    84\n",
      "     sad     0.561     0.478     0.506    87\n",
      "surprise     0.561     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.560     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.578950 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.063790  [ 1200/ 4873]\n",
      "loss: 0.035828  [ 2400/ 4873]\n",
      "loss: 0.078845  [ 3600/ 4873]\n",
      "loss: 0.014229  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.654     0.505    105\n",
      " disgust     0.569     0.632     0.550    109\n",
      "    fear     0.569     0.487     0.487    80\n",
      "   happy     0.569     0.542     0.642    81\n",
      " neutral     0.569     0.608     0.702    84\n",
      "     sad     0.569     0.494     0.506    87\n",
      "surprise     0.569     0.556     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.568     0.574    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.531180 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.109743  [ 1200/ 4873]\n",
      "loss: 0.229178  [ 2400/ 4873]\n",
      "loss: 0.346366  [ 3600/ 4873]\n",
      "loss: 0.242825  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.702     0.562    105\n",
      " disgust     0.574     0.598     0.560    109\n",
      "    fear     0.574     0.486     0.450    80\n",
      "   happy     0.574     0.558     0.593    81\n",
      " neutral     0.574     0.612     0.714    84\n",
      "     sad     0.574     0.511     0.552    87\n",
      "surprise     0.574     0.528     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.571     0.575    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 2.596788 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.078789  [ 1200/ 4873]\n",
      "loss: 0.182072  [ 2400/ 4873]\n",
      "loss: 0.031962  [ 3600/ 4873]\n",
      "loss: 0.483903  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.678     0.562    105\n",
      " disgust     0.552     0.536     0.541    109\n",
      "    fear     0.552     0.448     0.487    80\n",
      "   happy     0.552     0.571     0.543    81\n",
      " neutral     0.552     0.691     0.667    84\n",
      "     sad     0.552     0.447     0.529    87\n",
      "surprise     0.552     0.523     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.556     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.719408 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.026506  [ 1200/ 4873]\n",
      "loss: 0.520301  [ 2400/ 4873]\n",
      "loss: 0.440260  [ 3600/ 4873]\n",
      "loss: 0.235038  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.614     0.590    105\n",
      " disgust     0.557     0.568     0.459    109\n",
      "    fear     0.557     0.478     0.537    80\n",
      "   happy     0.557     0.511     0.556    81\n",
      " neutral     0.557     0.734     0.690    84\n",
      "     sad     0.557     0.469     0.529    87\n",
      "surprise     0.557     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.640633 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.355253  [ 1200/ 4873]\n",
      "loss: 0.229716  [ 2400/ 4873]\n",
      "loss: 0.221575  [ 3600/ 4873]\n",
      "loss: 0.326979  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.652     0.552    105\n",
      " disgust     0.548     0.544     0.514    109\n",
      "    fear     0.548     0.479     0.438    80\n",
      "   happy     0.548     0.490     0.593    81\n",
      " neutral     0.548     0.679     0.655    84\n",
      "     sad     0.548     0.467     0.563    87\n",
      "surprise     0.548     0.541     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.550     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.665886 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.075645  [ 1200/ 4873]\n",
      "loss: 0.307912  [ 2400/ 4873]\n",
      "loss: 0.298336  [ 3600/ 4873]\n",
      "loss: 0.474365  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.630     0.552    105\n",
      " disgust     0.536     0.545     0.495    109\n",
      "    fear     0.536     0.415     0.487    80\n",
      "   happy     0.536     0.471     0.605    81\n",
      " neutral     0.536     0.652     0.690    84\n",
      "     sad     0.536     0.473     0.402    87\n",
      "surprise     0.536     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.539     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 2.678948 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.055295  [ 1200/ 4873]\n",
      "loss: 0.443400  [ 2400/ 4873]\n",
      "loss: 0.037446  [ 3600/ 4873]\n",
      "loss: 0.111287  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.615     0.533    105\n",
      " disgust     0.552     0.504     0.560    109\n",
      "    fear     0.552     0.461     0.438    80\n",
      "   happy     0.552     0.590     0.568    81\n",
      " neutral     0.552     0.694     0.702    84\n",
      "     sad     0.552     0.478     0.494    87\n",
      "surprise     0.552     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.554     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.712575 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.202774  [ 1200/ 4873]\n",
      "loss: 0.082720  [ 2400/ 4873]\n",
      "loss: 0.086881  [ 3600/ 4873]\n",
      "loss: 0.563583  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.714     0.524    105\n",
      " disgust     0.569     0.568     0.578    109\n",
      "    fear     0.569     0.507     0.475    80\n",
      "   happy     0.569     0.521     0.605    81\n",
      " neutral     0.569     0.632     0.714    84\n",
      "     sad     0.569     0.537     0.494    87\n",
      "surprise     0.569     0.500     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.568     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.619474 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.135989  [ 1200/ 4873]\n",
      "loss: 0.382445  [ 2400/ 4873]\n",
      "loss: 0.152225  [ 3600/ 4873]\n",
      "loss: 0.029610  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.571     0.533    105\n",
      " disgust     0.559     0.632     0.550    109\n",
      "    fear     0.559     0.440     0.500    80\n",
      "   happy     0.559     0.549     0.556    81\n",
      " neutral     0.559     0.671     0.679    84\n",
      "     sad     0.559     0.505     0.552    87\n",
      "surprise     0.559     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.559     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.595960 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.111468  [ 1200/ 4873]\n",
      "loss: 0.274918  [ 2400/ 4873]\n",
      "loss: 0.538277  [ 3600/ 4873]\n",
      "loss: 0.061676  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.699     0.552    105\n",
      " disgust     0.544     0.594     0.523    109\n",
      "    fear     0.544     0.434     0.412    80\n",
      "   happy     0.544     0.475     0.580    81\n",
      " neutral     0.544     0.622     0.667    84\n",
      "     sad     0.544     0.456     0.471    87\n",
      "surprise     0.544     0.526     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.544     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.617775 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.306553  [ 1200/ 4873]\n",
      "loss: 0.082879  [ 2400/ 4873]\n",
      "loss: 0.257949  [ 3600/ 4873]\n",
      "loss: 0.136979  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.577     0.656     0.562    105\n",
      " disgust     0.577     0.577     0.587    109\n",
      "    fear     0.577     0.513     0.487    80\n",
      "   happy     0.577     0.560     0.630    81\n",
      " neutral     0.577     0.694     0.702    84\n",
      "     sad     0.577     0.455     0.529    87\n",
      "surprise     0.577     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.577     0.580     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 2.604243 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.263221  [ 1200/ 4873]\n",
      "loss: 0.287044  [ 2400/ 4873]\n",
      "loss: 0.108302  [ 3600/ 4873]\n",
      "loss: 0.023382  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.583     0.533    105\n",
      " disgust     0.557     0.585     0.569    109\n",
      "    fear     0.557     0.438     0.525    80\n",
      "   happy     0.557     0.562     0.617    81\n",
      " neutral     0.557     0.645     0.714    84\n",
      "     sad     0.557     0.519     0.460    87\n",
      "surprise     0.557     0.566     0.469    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.557     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.612249 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.277256  [ 1200/ 4873]\n",
      "loss: 0.118019  [ 2400/ 4873]\n",
      "loss: 0.343759  [ 3600/ 4873]\n",
      "loss: 0.043436  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.678     0.581    105\n",
      " disgust     0.556     0.592     0.532    109\n",
      "    fear     0.556     0.514     0.475    80\n",
      "   happy     0.556     0.454     0.605    81\n",
      " neutral     0.556     0.663     0.679    84\n",
      "     sad     0.556     0.443     0.448    87\n",
      "surprise     0.556     0.561     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.558     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.583953 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.223785  [ 1200/ 4873]\n",
      "loss: 0.548474  [ 2400/ 4873]\n",
      "loss: 0.493674  [ 3600/ 4873]\n",
      "loss: 0.224574  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.632     0.524    105\n",
      " disgust     0.559     0.558     0.578    109\n",
      "    fear     0.559     0.536     0.463    80\n",
      "   happy     0.559     0.511     0.580    81\n",
      " neutral     0.559     0.624     0.750    84\n",
      "     sad     0.559     0.519     0.483    87\n",
      "surprise     0.559     0.507     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.555     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.685240 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.134261  [ 1200/ 4873]\n",
      "loss: 0.389040  [ 2400/ 4873]\n",
      "loss: 0.159870  [ 3600/ 4873]\n",
      "loss: 0.854275  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.578     0.495    105\n",
      " disgust     0.551     0.615     0.514    109\n",
      "    fear     0.551     0.487     0.487    80\n",
      "   happy     0.551     0.500     0.630    81\n",
      " neutral     0.551     0.612     0.714    84\n",
      "     sad     0.551     0.494     0.483    87\n",
      "surprise     0.551     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.550     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.650537 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.140360  [ 1200/ 4873]\n",
      "loss: 0.394002  [ 2400/ 4873]\n",
      "loss: 0.053647  [ 3600/ 4873]\n",
      "loss: 0.174913  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.675     0.533    105\n",
      " disgust     0.566     0.612     0.578    109\n",
      "    fear     0.566     0.506     0.512    80\n",
      "   happy     0.566     0.515     0.642    81\n",
      " neutral     0.566     0.643     0.643    84\n",
      "     sad     0.566     0.422     0.494    87\n",
      "surprise     0.566     0.643     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.574     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.543386 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.056015  [ 1200/ 4873]\n",
      "loss: 1.424356  [ 2400/ 4873]\n",
      "loss: 0.273756  [ 3600/ 4873]\n",
      "loss: 0.093329  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.609     0.533    105\n",
      " disgust     0.567     0.553     0.578    109\n",
      "    fear     0.567     0.494     0.512    80\n",
      "   happy     0.567     0.575     0.617    81\n",
      " neutral     0.567     0.699     0.690    84\n",
      "     sad     0.567     0.541     0.460    87\n",
      "surprise     0.567     0.494     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.566     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.640742 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.060179  [ 1200/ 4873]\n",
      "loss: 0.507882  [ 2400/ 4873]\n",
      "loss: 0.216890  [ 3600/ 4873]\n",
      "loss: 0.106925  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.651     0.533    105\n",
      " disgust     0.572     0.548     0.633    109\n",
      "    fear     0.572     0.453     0.487    80\n",
      "   happy     0.572     0.649     0.593    81\n",
      " neutral     0.572     0.723     0.714    84\n",
      "     sad     0.572     0.465     0.460    87\n",
      "surprise     0.572     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.575     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.681934 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.265202  [ 1200/ 4873]\n",
      "loss: 0.483596  [ 2400/ 4873]\n",
      "loss: 0.195704  [ 3600/ 4873]\n",
      "loss: 0.235723  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.580     0.652     0.552    105\n",
      " disgust     0.580     0.568     0.615    109\n",
      "    fear     0.580     0.444     0.500    80\n",
      "   happy     0.580     0.640     0.593    81\n",
      " neutral     0.580     0.701     0.726    84\n",
      "     sad     0.580     0.483     0.494    87\n",
      "surprise     0.580     0.597     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.580     0.584     0.580    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 2.632137 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.165570  [ 1200/ 4873]\n",
      "loss: 0.132613  [ 2400/ 4873]\n",
      "loss: 0.235212  [ 3600/ 4873]\n",
      "loss: 0.808748  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.621     0.514    105\n",
      " disgust     0.543     0.571     0.514    109\n",
      "    fear     0.543     0.411     0.487    80\n",
      "   happy     0.543     0.561     0.568    81\n",
      " neutral     0.543     0.630     0.690    84\n",
      "     sad     0.543     0.472     0.483    87\n",
      "surprise     0.543     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.543     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.750889 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.295546  [ 1200/ 4873]\n",
      "loss: 0.112319  [ 2400/ 4873]\n",
      "loss: 0.240819  [ 3600/ 4873]\n",
      "loss: 0.147292  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.590     0.590    105\n",
      " disgust     0.554     0.564     0.569    109\n",
      "    fear     0.554     0.500     0.487    80\n",
      "   happy     0.554     0.512     0.543    81\n",
      " neutral     0.554     0.604     0.690    84\n",
      "     sad     0.554     0.535     0.437    87\n",
      "surprise     0.554     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.550     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.779737 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.119565  [ 1200/ 4873]\n",
      "loss: 0.032463  [ 2400/ 4873]\n",
      "loss: 0.079689  [ 3600/ 4873]\n",
      "loss: 0.242629  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.548     0.600    105\n",
      " disgust     0.562     0.549     0.514    109\n",
      "    fear     0.562     0.487     0.487    80\n",
      "   happy     0.562     0.575     0.568    81\n",
      " neutral     0.562     0.677     0.750    84\n",
      "     sad     0.562     0.582     0.448    87\n",
      "surprise     0.562     0.507     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.561     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.671120 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.054748  [ 1200/ 4873]\n",
      "loss: 0.069587  [ 2400/ 4873]\n",
      "loss: 0.278820  [ 3600/ 4873]\n",
      "loss: 0.543101  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.620     0.543    105\n",
      " disgust     0.552     0.536     0.541    109\n",
      "    fear     0.552     0.545     0.450    80\n",
      "   happy     0.552     0.597     0.568    81\n",
      " neutral     0.552     0.686     0.702    84\n",
      "     sad     0.552     0.422     0.529    87\n",
      "surprise     0.552     0.486     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.556     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.747038 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.078091  [ 1200/ 4873]\n",
      "loss: 0.087181  [ 2400/ 4873]\n",
      "loss: 0.056045  [ 3600/ 4873]\n",
      "loss: 0.264110  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.560     0.486    105\n",
      " disgust     0.557     0.587     0.560    109\n",
      "    fear     0.557     0.494     0.500    80\n",
      "   happy     0.557     0.505     0.642    81\n",
      " neutral     0.557     0.675     0.643    84\n",
      "     sad     0.557     0.524     0.506    87\n",
      "surprise     0.557     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.559     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.697962 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.286394  [ 1200/ 4873]\n",
      "loss: 0.088676  [ 2400/ 4873]\n",
      "loss: 0.355047  [ 3600/ 4873]\n",
      "loss: 0.376945  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.622     0.533    105\n",
      " disgust     0.561     0.536     0.541    109\n",
      "    fear     0.561     0.543     0.475    80\n",
      "   happy     0.561     0.588     0.580    81\n",
      " neutral     0.561     0.670     0.726    84\n",
      "     sad     0.561     0.489     0.506    87\n",
      "surprise     0.561     0.468     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.560     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.799990 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.071854  [ 1200/ 4873]\n",
      "loss: 0.024473  [ 2400/ 4873]\n",
      "loss: 0.053088  [ 3600/ 4873]\n",
      "loss: 0.064558  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.584     0.663     0.543    105\n",
      " disgust     0.584     0.585     0.661    109\n",
      "    fear     0.584     0.500     0.487    80\n",
      "   happy     0.584     0.547     0.580    81\n",
      " neutral     0.584     0.632     0.714    84\n",
      "     sad     0.584     0.558     0.494    87\n",
      "surprise     0.584     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.584     0.581     0.582    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 2.638492 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep505_acc_58.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep457_acc_58\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep505_acc_58\"! Old accuracy: 58.0, new accuracy: 58.4\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.449585  [ 1200/ 4873]\n",
      "loss: 0.339414  [ 2400/ 4873]\n",
      "loss: 0.373482  [ 3600/ 4873]\n",
      "loss: 0.067578  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.631     0.505    105\n",
      " disgust     0.552     0.528     0.523    109\n",
      "    fear     0.552     0.481     0.487    80\n",
      "   happy     0.552     0.538     0.605    81\n",
      " neutral     0.552     0.711     0.702    84\n",
      "     sad     0.552     0.448     0.494    87\n",
      "surprise     0.552     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.556     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.779329 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.148298  [ 1200/ 4873]\n",
      "loss: 0.770131  [ 2400/ 4873]\n",
      "loss: 0.645984  [ 3600/ 4873]\n",
      "loss: 0.201657  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.616     0.505    105\n",
      " disgust     0.549     0.532     0.541    109\n",
      "    fear     0.549     0.486     0.425    80\n",
      "   happy     0.549     0.556     0.617    81\n",
      " neutral     0.549     0.587     0.726    84\n",
      "     sad     0.549     0.542     0.448    87\n",
      "surprise     0.549     0.506     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.546     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.814866 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.347521  [ 1200/ 4873]\n",
      "loss: 0.117116  [ 2400/ 4873]\n",
      "loss: 0.424274  [ 3600/ 4873]\n",
      "loss: 0.304948  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.640     0.524    105\n",
      " disgust     0.548     0.526     0.550    109\n",
      "    fear     0.548     0.449     0.438    80\n",
      "   happy     0.548     0.517     0.568    81\n",
      " neutral     0.548     0.644     0.690    84\n",
      "     sad     0.548     0.526     0.471    87\n",
      "surprise     0.548     0.520     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.546     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.712078 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.101690  [ 1200/ 4873]\n",
      "loss: 0.305140  [ 2400/ 4873]\n",
      "loss: 0.250369  [ 3600/ 4873]\n",
      "loss: 0.355511  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.570     0.505    105\n",
      " disgust     0.554     0.565     0.560    109\n",
      "    fear     0.554     0.456     0.450    80\n",
      "   happy     0.554     0.543     0.617    81\n",
      " neutral     0.554     0.688     0.655    84\n",
      "     sad     0.554     0.473     0.506    87\n",
      "surprise     0.554     0.600     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.556     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.769618 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.113828  [ 1200/ 4873]\n",
      "loss: 0.077794  [ 2400/ 4873]\n",
      "loss: 0.297764  [ 3600/ 4873]\n",
      "loss: 0.252107  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.589     0.505    105\n",
      " disgust     0.552     0.560     0.560    109\n",
      "    fear     0.552     0.500     0.463    80\n",
      "   happy     0.552     0.556     0.556    81\n",
      " neutral     0.552     0.679     0.679    84\n",
      "     sad     0.552     0.474     0.529    87\n",
      "surprise     0.552     0.507     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.552     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.903444 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.287213  [ 1200/ 4873]\n",
      "loss: 0.060145  [ 2400/ 4873]\n",
      "loss: 0.134763  [ 3600/ 4873]\n",
      "loss: 0.056088  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.580     0.639     0.505    105\n",
      " disgust     0.580     0.545     0.606    109\n",
      "    fear     0.580     0.488     0.525    80\n",
      "   happy     0.580     0.546     0.654    81\n",
      " neutral     0.580     0.723     0.714    84\n",
      "     sad     0.580     0.547     0.540    87\n",
      "surprise     0.580     0.611     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.580     0.586     0.580    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 2.629083 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.332527  [ 1200/ 4873]\n",
      "loss: 0.058170  [ 2400/ 4873]\n",
      "loss: 0.627751  [ 3600/ 4873]\n",
      "loss: 0.057597  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.638     0.571    105\n",
      " disgust     0.554     0.560     0.514    109\n",
      "    fear     0.554     0.453     0.487    80\n",
      "   happy     0.554     0.563     0.605    81\n",
      " neutral     0.554     0.638     0.714    84\n",
      "     sad     0.554     0.475     0.437    87\n",
      "surprise     0.554     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.550     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.691755 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.242359  [ 1200/ 4873]\n",
      "loss: 0.098954  [ 2400/ 4873]\n",
      "loss: 0.330323  [ 3600/ 4873]\n",
      "loss: 0.276701  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.671     0.505    105\n",
      " disgust     0.557     0.591     0.596    109\n",
      "    fear     0.557     0.465     0.412    80\n",
      "   happy     0.557     0.505     0.617    81\n",
      " neutral     0.557     0.687     0.679    84\n",
      "     sad     0.557     0.462     0.494    87\n",
      "surprise     0.557     0.520     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.557     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.801534 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.241522  [ 1200/ 4873]\n",
      "loss: 0.054168  [ 2400/ 4873]\n",
      "loss: 0.180369  [ 3600/ 4873]\n",
      "loss: 0.152733  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.674     0.590    105\n",
      " disgust     0.575     0.592     0.560    109\n",
      "    fear     0.575     0.482     0.512    80\n",
      "   happy     0.575     0.598     0.642    81\n",
      " neutral     0.575     0.690     0.690    84\n",
      "     sad     0.575     0.430     0.494    87\n",
      "surprise     0.575     0.576     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.578     0.574    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 2.707413 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.582767  [ 1200/ 4873]\n",
      "loss: 0.309316  [ 2400/ 4873]\n",
      "loss: 0.055864  [ 3600/ 4873]\n",
      "loss: 0.128484  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.648     0.543    105\n",
      " disgust     0.554     0.548     0.578    109\n",
      "    fear     0.554     0.447     0.475    80\n",
      "   happy     0.554     0.548     0.568    81\n",
      " neutral     0.554     0.695     0.679    84\n",
      "     sad     0.554     0.429     0.483    87\n",
      "surprise     0.554     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.560     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.796874 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.302735  [ 1200/ 4873]\n",
      "loss: 0.294483  [ 2400/ 4873]\n",
      "loss: 0.149353  [ 3600/ 4873]\n",
      "loss: 0.373876  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.607     0.514    105\n",
      " disgust     0.544     0.542     0.532    109\n",
      "    fear     0.544     0.477     0.512    80\n",
      "   happy     0.544     0.597     0.568    81\n",
      " neutral     0.544     0.600     0.714    84\n",
      "     sad     0.544     0.460     0.460    87\n",
      "surprise     0.544     0.516     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.543     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.816558 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.195503  [ 1200/ 4873]\n",
      "loss: 0.059849  [ 2400/ 4873]\n",
      "loss: 0.100190  [ 3600/ 4873]\n",
      "loss: 0.128154  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.580     0.655     0.543    105\n",
      " disgust     0.580     0.553     0.624    109\n",
      "    fear     0.580     0.494     0.487    80\n",
      "   happy     0.580     0.571     0.593    81\n",
      " neutral     0.580     0.656     0.726    84\n",
      "     sad     0.580     0.524     0.506    87\n",
      "surprise     0.580     0.617     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.580     0.581     0.580    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 2.633556 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.132001  [ 1200/ 4873]\n",
      "loss: 0.200122  [ 2400/ 4873]\n",
      "loss: 0.071566  [ 3600/ 4873]\n",
      "loss: 0.259735  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.582     0.694     0.476    105\n",
      " disgust     0.582     0.641     0.606    109\n",
      "    fear     0.582     0.600     0.450    80\n",
      "   happy     0.582     0.510     0.654    81\n",
      " neutral     0.582     0.630     0.750    84\n",
      "     sad     0.582     0.495     0.517    87\n",
      "surprise     0.582     0.525     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.582     0.585     0.587    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 2.804290 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.147282  [ 1200/ 4873]\n",
      "loss: 0.217284  [ 2400/ 4873]\n",
      "loss: 0.081782  [ 3600/ 4873]\n",
      "loss: 0.572800  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.619     0.495    105\n",
      " disgust     0.543     0.556     0.505    109\n",
      "    fear     0.543     0.478     0.412    80\n",
      "   happy     0.543     0.495     0.679    81\n",
      " neutral     0.543     0.582     0.679    84\n",
      "     sad     0.543     0.473     0.494    87\n",
      "surprise     0.543     0.621     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.546     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.704903 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.077154  [ 1200/ 4873]\n",
      "loss: 0.208573  [ 2400/ 4873]\n",
      "loss: 0.073463  [ 3600/ 4873]\n",
      "loss: 0.024872  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.651     0.514    105\n",
      " disgust     0.557     0.578     0.541    109\n",
      "    fear     0.557     0.488     0.500    80\n",
      "   happy     0.557     0.549     0.617    81\n",
      " neutral     0.557     0.686     0.702    84\n",
      "     sad     0.557     0.407     0.506    87\n",
      "surprise     0.557     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.564     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.793853 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.253516  [ 1200/ 4873]\n",
      "loss: 0.046590  [ 2400/ 4873]\n",
      "loss: 0.332438  [ 3600/ 4873]\n",
      "loss: 0.128474  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.667     0.495    105\n",
      " disgust     0.554     0.561     0.587    109\n",
      "    fear     0.554     0.507     0.450    80\n",
      "   happy     0.554     0.522     0.580    81\n",
      " neutral     0.554     0.686     0.702    84\n",
      "     sad     0.554     0.419     0.506    87\n",
      "surprise     0.554     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.558     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.775373 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.127893  [ 1200/ 4873]\n",
      "loss: 0.277906  [ 2400/ 4873]\n",
      "loss: 0.529965  [ 3600/ 4873]\n",
      "loss: 0.450289  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.630     0.486    105\n",
      " disgust     0.533     0.574     0.495    109\n",
      "    fear     0.533     0.419     0.450    80\n",
      "   happy     0.533     0.457     0.654    81\n",
      " neutral     0.533     0.663     0.702    84\n",
      "     sad     0.533     0.464     0.448    87\n",
      "surprise     0.533     0.550     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.537     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 2.705978 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.042208  [ 1200/ 4873]\n",
      "loss: 0.072433  [ 2400/ 4873]\n",
      "loss: 0.197044  [ 3600/ 4873]\n",
      "loss: 0.057876  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.606     0.571    105\n",
      " disgust     0.552     0.513     0.550    109\n",
      "    fear     0.552     0.479     0.438    80\n",
      "   happy     0.552     0.563     0.605    81\n",
      " neutral     0.552     0.671     0.679    84\n",
      "     sad     0.552     0.494     0.471    87\n",
      "surprise     0.552     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.551     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.709870 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.375241  [ 1200/ 4873]\n",
      "loss: 0.058041  [ 2400/ 4873]\n",
      "loss: 0.322935  [ 3600/ 4873]\n",
      "loss: 0.133880  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.598     0.581    105\n",
      " disgust     0.561     0.524     0.606    109\n",
      "    fear     0.561     0.442     0.475    80\n",
      "   happy     0.561     0.616     0.556    81\n",
      " neutral     0.561     0.722     0.679    84\n",
      "     sad     0.561     0.487     0.448    87\n",
      "surprise     0.561     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.565     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.740047 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.098780  [ 1200/ 4873]\n",
      "loss: 0.077667  [ 2400/ 4873]\n",
      "loss: 0.071932  [ 3600/ 4873]\n",
      "loss: 0.206122  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.598     0.524    105\n",
      " disgust     0.548     0.590     0.569    109\n",
      "    fear     0.548     0.424     0.450    80\n",
      "   happy     0.548     0.505     0.593    81\n",
      " neutral     0.548     0.621     0.702    84\n",
      "     sad     0.548     0.487     0.448    87\n",
      "surprise     0.548     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.547     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.724634 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.057152  [ 1200/ 4873]\n",
      "loss: 0.295977  [ 2400/ 4873]\n",
      "loss: 0.035792  [ 3600/ 4873]\n",
      "loss: 0.158612  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.632     0.524    105\n",
      " disgust     0.566     0.558     0.615    109\n",
      "    fear     0.566     0.472     0.425    80\n",
      "   happy     0.566     0.573     0.580    81\n",
      " neutral     0.566     0.682     0.690    84\n",
      "     sad     0.566     0.479     0.517    87\n",
      "surprise     0.566     0.557     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.565     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.751199 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.049814  [ 1200/ 4873]\n",
      "loss: 0.037423  [ 2400/ 4873]\n",
      "loss: 0.093764  [ 3600/ 4873]\n",
      "loss: 0.018555  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.600     0.514    105\n",
      " disgust     0.556     0.583     0.550    109\n",
      "    fear     0.556     0.444     0.500    80\n",
      "   happy     0.556     0.540     0.580    81\n",
      " neutral     0.556     0.691     0.667    84\n",
      "     sad     0.556     0.454     0.563    87\n",
      "surprise     0.556     0.647     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.566     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.790899 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.040017  [ 1200/ 4873]\n",
      "loss: 0.340255  [ 2400/ 4873]\n",
      "loss: 0.190493  [ 3600/ 4873]\n",
      "loss: 0.052198  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.586     0.552    105\n",
      " disgust     0.543     0.555     0.560    109\n",
      "    fear     0.543     0.419     0.450    80\n",
      "   happy     0.543     0.553     0.580    81\n",
      " neutral     0.543     0.667     0.667    84\n",
      "     sad     0.543     0.433     0.483    87\n",
      "surprise     0.543     0.633     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.549     0.539    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.738644 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.096335  [ 1200/ 4873]\n",
      "loss: 0.063853  [ 2400/ 4873]\n",
      "loss: 0.187210  [ 3600/ 4873]\n",
      "loss: 0.381466  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.654     0.505    105\n",
      " disgust     0.539     0.552     0.532    109\n",
      "    fear     0.539     0.479     0.438    80\n",
      "   happy     0.539     0.469     0.568    81\n",
      " neutral     0.539     0.613     0.679    84\n",
      "     sad     0.539     0.461     0.540    87\n",
      "surprise     0.539     0.569     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.543     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.844038 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 1.852775  [ 1200/ 4873]\n",
      "loss: 0.023769  [ 2400/ 4873]\n",
      "loss: 0.283951  [ 3600/ 4873]\n",
      "loss: 0.439720  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.602     0.476    105\n",
      " disgust     0.546     0.513     0.550    109\n",
      "    fear     0.546     0.438     0.487    80\n",
      "   happy     0.546     0.600     0.593    81\n",
      " neutral     0.546     0.682     0.690    84\n",
      "     sad     0.546     0.474     0.517    87\n",
      "surprise     0.546     0.541     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.550     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.923815 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.066217  [ 1200/ 4873]\n",
      "loss: 0.070547  [ 2400/ 4873]\n",
      "loss: 0.585017  [ 3600/ 4873]\n",
      "loss: 0.120909  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.621     0.514    105\n",
      " disgust     0.549     0.543     0.523    109\n",
      "    fear     0.549     0.493     0.438    80\n",
      "   happy     0.549     0.511     0.580    81\n",
      " neutral     0.549     0.641     0.702    84\n",
      "     sad     0.549     0.500     0.517    87\n",
      "surprise     0.549     0.521     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.547     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.856959 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.482671  [ 1200/ 4873]\n",
      "loss: 0.134844  [ 2400/ 4873]\n",
      "loss: 0.291859  [ 3600/ 4873]\n",
      "loss: 0.051223  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.628     0.514    105\n",
      " disgust     0.579     0.557     0.624    109\n",
      "    fear     0.579     0.506     0.512    80\n",
      "   happy     0.579     0.593     0.593    81\n",
      " neutral     0.579     0.674     0.714    84\n",
      "     sad     0.579     0.529     0.529    87\n",
      "surprise     0.579     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.578     0.578    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 2.835240 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.133747  [ 1200/ 4873]\n",
      "loss: 0.112983  [ 2400/ 4873]\n",
      "loss: 0.032542  [ 3600/ 4873]\n",
      "loss: 0.201253  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.644     0.533    105\n",
      " disgust     0.556     0.606     0.523    109\n",
      "    fear     0.556     0.547     0.438    80\n",
      "   happy     0.556     0.481     0.630    81\n",
      " neutral     0.556     0.596     0.702    84\n",
      "     sad     0.556     0.465     0.540    87\n",
      "surprise     0.556     0.576     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.559     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.610397 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.155318  [ 1200/ 4873]\n",
      "loss: 0.101302  [ 2400/ 4873]\n",
      "loss: 0.122434  [ 3600/ 4873]\n",
      "loss: 0.057025  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.622     0.486    105\n",
      " disgust     0.543     0.519     0.505    109\n",
      "    fear     0.543     0.446     0.512    80\n",
      "   happy     0.543     0.562     0.617    81\n",
      " neutral     0.543     0.682     0.690    84\n",
      "     sad     0.543     0.468     0.506    87\n",
      "surprise     0.543     0.516     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.545     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.908396 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.048285  [ 1200/ 4873]\n",
      "loss: 0.612559  [ 2400/ 4873]\n",
      "loss: 0.429521  [ 3600/ 4873]\n",
      "loss: 0.054127  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.526     0.694     0.476    105\n",
      " disgust     0.526     0.571     0.477    109\n",
      "    fear     0.526     0.439     0.450    80\n",
      "   happy     0.526     0.451     0.630    81\n",
      " neutral     0.526     0.671     0.631    84\n",
      "     sad     0.526     0.398     0.540    87\n",
      "surprise     0.526     0.582     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.526     0.544     0.529    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 2.893045 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.172038  [ 1200/ 4873]\n",
      "loss: 0.367641  [ 2400/ 4873]\n",
      "loss: 0.444979  [ 3600/ 4873]\n",
      "loss: 0.418264  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.655     0.524    105\n",
      " disgust     0.562     0.552     0.587    109\n",
      "    fear     0.562     0.494     0.487    80\n",
      "   happy     0.562     0.468     0.630    81\n",
      " neutral     0.562     0.743     0.655    84\n",
      "     sad     0.562     0.495     0.529    87\n",
      "surprise     0.562     0.600     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.572     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.778676 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.052241  [ 1200/ 4873]\n",
      "loss: 0.311987  [ 2400/ 4873]\n",
      "loss: 0.060591  [ 3600/ 4873]\n",
      "loss: 0.014220  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.726     0.505    105\n",
      " disgust     0.559     0.579     0.569    109\n",
      "    fear     0.559     0.500     0.537    80\n",
      "   happy     0.559     0.495     0.605    81\n",
      " neutral     0.559     0.667     0.667    84\n",
      "     sad     0.559     0.447     0.529    87\n",
      "surprise     0.559     0.552     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.566     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.684453 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.125162  [ 1200/ 4873]\n",
      "loss: 0.390578  [ 2400/ 4873]\n",
      "loss: 0.270871  [ 3600/ 4873]\n",
      "loss: 0.032064  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.659     0.552    105\n",
      " disgust     0.556     0.559     0.523    109\n",
      "    fear     0.556     0.481     0.475    80\n",
      "   happy     0.556     0.570     0.605    81\n",
      " neutral     0.556     0.675     0.643    84\n",
      "     sad     0.556     0.450     0.563    87\n",
      "surprise     0.556     0.515     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.558     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.816985 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.273287  [ 1200/ 4873]\n",
      "loss: 0.082119  [ 2400/ 4873]\n",
      "loss: 0.251424  [ 3600/ 4873]\n",
      "loss: 0.063569  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.594     0.543    105\n",
      " disgust     0.561     0.569     0.642    109\n",
      "    fear     0.561     0.432     0.438    80\n",
      "   happy     0.561     0.622     0.568    81\n",
      " neutral     0.561     0.698     0.714    84\n",
      "     sad     0.561     0.476     0.448    87\n",
      "surprise     0.561     0.515     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.558     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.924796 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.066614  [ 1200/ 4873]\n",
      "loss: 0.075870  [ 2400/ 4873]\n",
      "loss: 0.014745  [ 3600/ 4873]\n",
      "loss: 0.030767  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.682     0.552    105\n",
      " disgust     0.551     0.549     0.569    109\n",
      "    fear     0.551     0.448     0.487    80\n",
      "   happy     0.551     0.506     0.556    81\n",
      " neutral     0.551     0.663     0.655    84\n",
      "     sad     0.551     0.442     0.483    87\n",
      "surprise     0.551     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.556     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.721002 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.144254  [ 1200/ 4873]\n",
      "loss: 0.041838  [ 2400/ 4873]\n",
      "loss: 0.324285  [ 3600/ 4873]\n",
      "loss: 0.246895  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.615     0.533    105\n",
      " disgust     0.559     0.589     0.606    109\n",
      "    fear     0.559     0.459     0.487    80\n",
      "   happy     0.559     0.582     0.568    81\n",
      " neutral     0.559     0.652     0.714    84\n",
      "     sad     0.559     0.506     0.460    87\n",
      "surprise     0.559     0.472     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.554     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.871044 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.344723  [ 1200/ 4873]\n",
      "loss: 0.077014  [ 2400/ 4873]\n",
      "loss: 0.052610  [ 3600/ 4873]\n",
      "loss: 0.174089  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.625     0.571    105\n",
      " disgust     0.552     0.558     0.532    109\n",
      "    fear     0.552     0.480     0.450    80\n",
      "   happy     0.552     0.489     0.568    81\n",
      " neutral     0.552     0.622     0.726    84\n",
      "     sad     0.552     0.512     0.483    87\n",
      "surprise     0.552     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.549     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.809282 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.057678  [ 1200/ 4873]\n",
      "loss: 0.362939  [ 2400/ 4873]\n",
      "loss: 0.073434  [ 3600/ 4873]\n",
      "loss: 0.978376  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.593     0.486    105\n",
      " disgust     0.530     0.479     0.532    109\n",
      "    fear     0.530     0.494     0.500    80\n",
      "   happy     0.530     0.518     0.543    81\n",
      " neutral     0.530     0.684     0.643    84\n",
      "     sad     0.530     0.465     0.460    87\n",
      "surprise     0.530     0.500     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.530     0.533     0.532    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.899880 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.007748  [ 1200/ 4873]\n",
      "loss: 0.185846  [ 2400/ 4873]\n",
      "loss: 0.109792  [ 3600/ 4873]\n",
      "loss: 0.185545  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.604     0.552    105\n",
      " disgust     0.567     0.552     0.587    109\n",
      "    fear     0.567     0.519     0.500    80\n",
      "   happy     0.567     0.600     0.556    81\n",
      " neutral     0.567     0.618     0.750    84\n",
      "     sad     0.567     0.541     0.460    87\n",
      "surprise     0.567     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.564     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.880508 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.452791  [ 1200/ 4873]\n",
      "loss: 0.034188  [ 2400/ 4873]\n",
      "loss: 0.168357  [ 3600/ 4873]\n",
      "loss: 0.468243  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.606     0.571    105\n",
      " disgust     0.562     0.566     0.587    109\n",
      "    fear     0.562     0.488     0.500    80\n",
      "   happy     0.562     0.542     0.556    81\n",
      " neutral     0.562     0.617     0.690    84\n",
      "     sad     0.562     0.526     0.471    87\n",
      "surprise     0.562     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.560     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.797704 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.047628  [ 1200/ 4873]\n",
      "loss: 0.491266  [ 2400/ 4873]\n",
      "loss: 0.351312  [ 3600/ 4873]\n",
      "loss: 0.102456  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.659     0.571    105\n",
      " disgust     0.569     0.610     0.560    109\n",
      "    fear     0.569     0.468     0.463    80\n",
      "   happy     0.569     0.540     0.667    81\n",
      " neutral     0.569     0.622     0.667    84\n",
      "     sad     0.569     0.524     0.494    87\n",
      "surprise     0.569     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.565     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.893602 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.295827  [ 1200/ 4873]\n",
      "loss: 0.406614  [ 2400/ 4873]\n",
      "loss: 0.759413  [ 3600/ 4873]\n",
      "loss: 0.060877  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.663     0.524    105\n",
      " disgust     0.561     0.552     0.587    109\n",
      "    fear     0.561     0.515     0.438    80\n",
      "   happy     0.561     0.523     0.568    81\n",
      " neutral     0.561     0.625     0.714    84\n",
      "     sad     0.561     0.474     0.517    87\n",
      "surprise     0.561     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.561     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.791553 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.165623  [ 1200/ 4873]\n",
      "loss: 0.290106  [ 2400/ 4873]\n",
      "loss: 0.627968  [ 3600/ 4873]\n",
      "loss: 0.148842  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.621     0.514    105\n",
      " disgust     0.572     0.581     0.624    109\n",
      "    fear     0.572     0.529     0.463    80\n",
      "   happy     0.572     0.568     0.617    81\n",
      " neutral     0.572     0.667     0.714    84\n",
      "     sad     0.572     0.511     0.517    87\n",
      "surprise     0.572     0.500     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.568     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.827913 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.070117  [ 1200/ 4873]\n",
      "loss: 0.064569  [ 2400/ 4873]\n",
      "loss: 0.064573  [ 3600/ 4873]\n",
      "loss: 0.211233  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.598     0.581    105\n",
      " disgust     0.570     0.588     0.550    109\n",
      "    fear     0.570     0.536     0.463    80\n",
      "   happy     0.570     0.551     0.605    81\n",
      " neutral     0.570     0.690     0.690    84\n",
      "     sad     0.570     0.474     0.529    87\n",
      "surprise     0.570     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.570     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 2.691847 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.431855  [ 1200/ 4873]\n",
      "loss: 0.340051  [ 2400/ 4873]\n",
      "loss: 0.408276  [ 3600/ 4873]\n",
      "loss: 0.342344  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.596     0.562    105\n",
      " disgust     0.574     0.598     0.587    109\n",
      "    fear     0.574     0.542     0.487    80\n",
      "   happy     0.574     0.562     0.617    81\n",
      " neutral     0.574     0.651     0.667    84\n",
      "     sad     0.574     0.495     0.529    87\n",
      "surprise     0.574     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.572     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 2.821110 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.354571  [ 1200/ 4873]\n",
      "loss: 0.097521  [ 2400/ 4873]\n",
      "loss: 0.027685  [ 3600/ 4873]\n",
      "loss: 0.310789  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.663     0.562    105\n",
      " disgust     0.566     0.602     0.514    109\n",
      "    fear     0.566     0.529     0.463    80\n",
      "   happy     0.566     0.544     0.605    81\n",
      " neutral     0.566     0.644     0.667    84\n",
      "     sad     0.566     0.453     0.552    87\n",
      "surprise     0.566     0.533     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.567     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.696489 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.190132  [ 1200/ 4873]\n",
      "loss: 0.302319  [ 2400/ 4873]\n",
      "loss: 0.063640  [ 3600/ 4873]\n",
      "loss: 0.132320  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.679     0.524    105\n",
      " disgust     0.559     0.585     0.569    109\n",
      "    fear     0.559     0.455     0.438    80\n",
      "   happy     0.559     0.477     0.642    81\n",
      " neutral     0.559     0.687     0.679    84\n",
      "     sad     0.559     0.479     0.517    87\n",
      "surprise     0.559     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.563     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.799402 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.041085  [ 1200/ 4873]\n",
      "loss: 0.209344  [ 2400/ 4873]\n",
      "loss: 0.223730  [ 3600/ 4873]\n",
      "loss: 0.482253  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.619     0.571    105\n",
      " disgust     0.572     0.559     0.569    109\n",
      "    fear     0.572     0.500     0.500    80\n",
      "   happy     0.572     0.522     0.580    81\n",
      " neutral     0.572     0.753     0.762    84\n",
      "     sad     0.572     0.489     0.506    87\n",
      "surprise     0.572     0.561     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.572     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.754533 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.082400  [ 1200/ 4873]\n",
      "loss: 0.179086  [ 2400/ 4873]\n",
      "loss: 0.387354  [ 3600/ 4873]\n",
      "loss: 0.171424  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.626     0.590    105\n",
      " disgust     0.579     0.567     0.541    109\n",
      "    fear     0.579     0.532     0.512    80\n",
      "   happy     0.579     0.576     0.605    81\n",
      " neutral     0.579     0.711     0.702    84\n",
      "     sad     0.579     0.480     0.540    87\n",
      "surprise     0.579     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.579     0.579    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 2.812192 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.057175  [ 1200/ 4873]\n",
      "loss: 0.016599  [ 2400/ 4873]\n",
      "loss: 0.065357  [ 3600/ 4873]\n",
      "loss: 0.261033  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.635     0.581    105\n",
      " disgust     0.572     0.578     0.541    109\n",
      "    fear     0.572     0.521     0.475    80\n",
      "   happy     0.572     0.495     0.580    81\n",
      " neutral     0.572     0.640     0.679    84\n",
      "     sad     0.572     0.578     0.552    87\n",
      "surprise     0.572     0.542     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.570     0.574    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.708734 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.082530  [ 1200/ 4873]\n",
      "loss: 0.293980  [ 2400/ 4873]\n",
      "loss: 0.061934  [ 3600/ 4873]\n",
      "loss: 0.161137  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.626     0.590    105\n",
      " disgust     0.559     0.544     0.514    109\n",
      "    fear     0.559     0.522     0.450    80\n",
      "   happy     0.559     0.545     0.593    81\n",
      " neutral     0.559     0.674     0.714    84\n",
      "     sad     0.559     0.440     0.506    87\n",
      "surprise     0.559     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.559     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.910378 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.127819  [ 1200/ 4873]\n",
      "loss: 0.401178  [ 2400/ 4873]\n",
      "loss: 0.208172  [ 3600/ 4873]\n",
      "loss: 0.027668  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.577     0.533    105\n",
      " disgust     0.556     0.594     0.550    109\n",
      "    fear     0.556     0.487     0.463    80\n",
      "   happy     0.556     0.565     0.593    81\n",
      " neutral     0.556     0.608     0.702    84\n",
      "     sad     0.556     0.500     0.506    87\n",
      "surprise     0.556     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.552     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.803032 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.192494  [ 1200/ 4873]\n",
      "loss: 0.059383  [ 2400/ 4873]\n",
      "loss: 0.687762  [ 3600/ 4873]\n",
      "loss: 0.567521  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.609     0.533    105\n",
      " disgust     0.534     0.573     0.541    109\n",
      "    fear     0.534     0.515     0.438    80\n",
      "   happy     0.534     0.467     0.617    81\n",
      " neutral     0.534     0.615     0.667    84\n",
      "     sad     0.534     0.415     0.448    87\n",
      "surprise     0.534     0.564     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.537     0.533    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.709751 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.378249  [ 1200/ 4873]\n",
      "loss: 0.248274  [ 2400/ 4873]\n",
      "loss: 0.318464  [ 3600/ 4873]\n",
      "loss: 0.210304  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.709     0.533    105\n",
      " disgust     0.552     0.527     0.532    109\n",
      "    fear     0.552     0.514     0.450    80\n",
      "   happy     0.552     0.547     0.580    81\n",
      " neutral     0.552     0.694     0.702    84\n",
      "     sad     0.552     0.439     0.540    87\n",
      "surprise     0.552     0.466     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.557     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.920031 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.345620  [ 1200/ 4873]\n",
      "loss: 0.099446  [ 2400/ 4873]\n",
      "loss: 0.080089  [ 3600/ 4873]\n",
      "loss: 0.064300  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.634     0.495    105\n",
      " disgust     0.561     0.574     0.532    109\n",
      "    fear     0.561     0.476     0.500    80\n",
      "   happy     0.561     0.505     0.617    81\n",
      " neutral     0.561     0.645     0.714    84\n",
      "     sad     0.561     0.528     0.540    87\n",
      "surprise     0.561     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.561     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.705801 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.036319  [ 1200/ 4873]\n",
      "loss: 0.316684  [ 2400/ 4873]\n",
      "loss: 0.049891  [ 3600/ 4873]\n",
      "loss: 0.654051  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.671     0.486    105\n",
      " disgust     0.546     0.562     0.495    109\n",
      "    fear     0.546     0.507     0.463    80\n",
      "   happy     0.546     0.505     0.605    81\n",
      " neutral     0.546     0.706     0.714    84\n",
      "     sad     0.546     0.423     0.540    87\n",
      "surprise     0.546     0.486     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.552     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.895903 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.023073  [ 1200/ 4873]\n",
      "loss: 0.388000  [ 2400/ 4873]\n",
      "loss: 0.531706  [ 3600/ 4873]\n",
      "loss: 0.340946  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.648     0.562    105\n",
      " disgust     0.567     0.520     0.606    109\n",
      "    fear     0.567     0.519     0.500    80\n",
      "   happy     0.567     0.667     0.543    81\n",
      " neutral     0.567     0.737     0.667    84\n",
      "     sad     0.567     0.471     0.563    87\n",
      "surprise     0.567     0.464     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.575     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.777404 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.331388  [ 1200/ 4873]\n",
      "loss: 0.119164  [ 2400/ 4873]\n",
      "loss: 0.246095  [ 3600/ 4873]\n",
      "loss: 0.515569  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.644     0.533    105\n",
      " disgust     0.569     0.582     0.587    109\n",
      "    fear     0.569     0.418     0.475    80\n",
      "   happy     0.569     0.649     0.593    81\n",
      " neutral     0.569     0.694     0.702    84\n",
      "     sad     0.569     0.480     0.540    87\n",
      "surprise     0.569     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.572     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.728404 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.191553  [ 1200/ 4873]\n",
      "loss: 0.087148  [ 2400/ 4873]\n",
      "loss: 0.253866  [ 3600/ 4873]\n",
      "loss: 0.121994  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.606     0.543    105\n",
      " disgust     0.557     0.545     0.495    109\n",
      "    fear     0.557     0.506     0.487    80\n",
      "   happy     0.557     0.516     0.580    81\n",
      " neutral     0.557     0.625     0.714    84\n",
      "     sad     0.557     0.511     0.517    87\n",
      "surprise     0.557     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.557     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.826194 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.079982  [ 1200/ 4873]\n",
      "loss: 0.474362  [ 2400/ 4873]\n",
      "loss: 0.279735  [ 3600/ 4873]\n",
      "loss: 0.164917  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.616     0.505    105\n",
      " disgust     0.541     0.622     0.468    109\n",
      "    fear     0.541     0.479     0.425    80\n",
      "   happy     0.541     0.467     0.617    81\n",
      " neutral     0.541     0.625     0.714    84\n",
      "     sad     0.541     0.473     0.506    87\n",
      "surprise     0.541     0.507     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.541     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.733864 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.225055  [ 1200/ 4873]\n",
      "loss: 0.226240  [ 2400/ 4873]\n",
      "loss: 0.816714  [ 3600/ 4873]\n",
      "loss: 0.060583  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.606     0.543    105\n",
      " disgust     0.566     0.531     0.624    109\n",
      "    fear     0.566     0.514     0.463    80\n",
      "   happy     0.566     0.562     0.556    81\n",
      " neutral     0.566     0.659     0.643    84\n",
      "     sad     0.566     0.495     0.517    87\n",
      "surprise     0.566     0.619     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.569     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.840166 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.378507  [ 1200/ 4873]\n",
      "loss: 0.204246  [ 2400/ 4873]\n",
      "loss: 0.068006  [ 3600/ 4873]\n",
      "loss: 0.082144  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.701     0.514    105\n",
      " disgust     0.572     0.519     0.633    109\n",
      "    fear     0.572     0.534     0.487    80\n",
      "   happy     0.572     0.568     0.568    81\n",
      " neutral     0.572     0.711     0.702    84\n",
      "     sad     0.572     0.469     0.517    87\n",
      "surprise     0.572     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.579     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.828341 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.362051  [ 1200/ 4873]\n",
      "loss: 0.126635  [ 2400/ 4873]\n",
      "loss: 0.167901  [ 3600/ 4873]\n",
      "loss: 0.234180  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.659     0.552    105\n",
      " disgust     0.572     0.538     0.578    109\n",
      "    fear     0.572     0.507     0.475    80\n",
      "   happy     0.572     0.598     0.605    81\n",
      " neutral     0.572     0.651     0.667    84\n",
      "     sad     0.572     0.516     0.552    87\n",
      "surprise     0.572     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.572     0.572    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.841450 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.377940  [ 1200/ 4873]\n",
      "loss: 0.147217  [ 2400/ 4873]\n",
      "loss: 0.020494  [ 3600/ 4873]\n",
      "loss: 0.805092  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.714     0.524    105\n",
      " disgust     0.572     0.556     0.596    109\n",
      "    fear     0.572     0.551     0.475    80\n",
      "   happy     0.572     0.522     0.593    81\n",
      " neutral     0.572     0.634     0.702    84\n",
      "     sad     0.572     0.505     0.540    87\n",
      "surprise     0.572     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.574     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.820464 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.217841  [ 1200/ 4873]\n",
      "loss: 0.381809  [ 2400/ 4873]\n",
      "loss: 0.098158  [ 3600/ 4873]\n",
      "loss: 0.248819  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.659     0.552    105\n",
      " disgust     0.566     0.549     0.569    109\n",
      "    fear     0.566     0.500     0.475    80\n",
      "   happy     0.566     0.562     0.617    81\n",
      " neutral     0.566     0.688     0.655    84\n",
      "     sad     0.566     0.484     0.529    87\n",
      "surprise     0.566     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.566     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.905286 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.155309  [ 1200/ 4873]\n",
      "loss: 0.029008  [ 2400/ 4873]\n",
      "loss: 0.126508  [ 3600/ 4873]\n",
      "loss: 0.038626  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.560     0.448    105\n",
      " disgust     0.554     0.508     0.587    109\n",
      "    fear     0.554     0.473     0.550    80\n",
      "   happy     0.554     0.630     0.568    81\n",
      " neutral     0.554     0.686     0.702    84\n",
      "     sad     0.554     0.474     0.529    87\n",
      "surprise     0.554     0.627     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.565     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.952876 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.033607  [ 1200/ 4873]\n",
      "loss: 0.099241  [ 2400/ 4873]\n",
      "loss: 0.252286  [ 3600/ 4873]\n",
      "loss: 0.013519  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.649     0.600    105\n",
      " disgust     0.566     0.574     0.532    109\n",
      "    fear     0.566     0.500     0.475    80\n",
      "   happy     0.566     0.548     0.630    81\n",
      " neutral     0.566     0.682     0.714    84\n",
      "     sad     0.566     0.446     0.517    87\n",
      "surprise     0.566     0.556     0.469    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.565     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.875679 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.039321  [ 1200/ 4873]\n",
      "loss: 0.231032  [ 2400/ 4873]\n",
      "loss: 0.146515  [ 3600/ 4873]\n",
      "loss: 0.266321  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.663     0.581    105\n",
      " disgust     0.562     0.551     0.596    109\n",
      "    fear     0.562     0.471     0.400    80\n",
      "   happy     0.562     0.539     0.593    81\n",
      " neutral     0.562     0.652     0.690    84\n",
      "     sad     0.562     0.532     0.483    87\n",
      "surprise     0.562     0.493     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.557     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.817039 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.163711  [ 1200/ 4873]\n",
      "loss: 0.040806  [ 2400/ 4873]\n",
      "loss: 0.219788  [ 3600/ 4873]\n",
      "loss: 0.184968  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.583     0.571    105\n",
      " disgust     0.564     0.521     0.670    109\n",
      "    fear     0.564     0.424     0.525    80\n",
      "   happy     0.564     0.667     0.494    81\n",
      " neutral     0.564     0.738     0.702    84\n",
      "     sad     0.564     0.494     0.437    87\n",
      "surprise     0.564     0.627     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.579     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.911200 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.778536  [ 1200/ 4873]\n",
      "loss: 0.674935  [ 2400/ 4873]\n",
      "loss: 0.128575  [ 3600/ 4873]\n",
      "loss: 0.221319  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.615     0.562    105\n",
      " disgust     0.572     0.577     0.587    109\n",
      "    fear     0.572     0.477     0.512    80\n",
      "   happy     0.572     0.603     0.580    81\n",
      " neutral     0.572     0.648     0.702    84\n",
      "     sad     0.572     0.524     0.494    87\n",
      "surprise     0.572     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.570     0.572    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.697255 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.076711  [ 1200/ 4873]\n",
      "loss: 0.516876  [ 2400/ 4873]\n",
      "loss: 0.020720  [ 3600/ 4873]\n",
      "loss: 0.233135  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.609     0.533    105\n",
      " disgust     0.564     0.509     0.532    109\n",
      "    fear     0.564     0.494     0.500    80\n",
      "   happy     0.564     0.526     0.617    81\n",
      " neutral     0.564     0.678     0.702    84\n",
      "     sad     0.564     0.523     0.529    87\n",
      "surprise     0.564     0.660     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.571     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.741940 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.119975  [ 1200/ 4873]\n",
      "loss: 0.077227  [ 2400/ 4873]\n",
      "loss: 0.177445  [ 3600/ 4873]\n",
      "loss: 0.088745  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.605     0.495    105\n",
      " disgust     0.546     0.521     0.560    109\n",
      "    fear     0.546     0.452     0.525    80\n",
      "   happy     0.546     0.542     0.556    81\n",
      " neutral     0.546     0.659     0.643    84\n",
      "     sad     0.546     0.540     0.540    87\n",
      "surprise     0.546     0.516     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.548     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.814603 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.072468  [ 1200/ 4873]\n",
      "loss: 0.359091  [ 2400/ 4873]\n",
      "loss: 0.136540  [ 3600/ 4873]\n",
      "loss: 0.018349  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.662     0.505    105\n",
      " disgust     0.539     0.553     0.523    109\n",
      "    fear     0.539     0.494     0.475    80\n",
      "   happy     0.539     0.485     0.580    81\n",
      " neutral     0.539     0.635     0.643    84\n",
      "     sad     0.539     0.429     0.517    87\n",
      "surprise     0.539     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.545     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.908878 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.458044  [ 1200/ 4873]\n",
      "loss: 0.099229  [ 2400/ 4873]\n",
      "loss: 0.102919  [ 3600/ 4873]\n",
      "loss: 0.218431  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.695     0.543    105\n",
      " disgust     0.557     0.543     0.523    109\n",
      "    fear     0.557     0.500     0.475    80\n",
      "   happy     0.557     0.543     0.617    81\n",
      " neutral     0.557     0.620     0.679    84\n",
      "     sad     0.557     0.460     0.529    87\n",
      "surprise     0.557     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.634956 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.064014  [ 1200/ 4873]\n",
      "loss: 0.061869  [ 2400/ 4873]\n",
      "loss: 0.138029  [ 3600/ 4873]\n",
      "loss: 0.448780  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.725     0.552    105\n",
      " disgust     0.559     0.523     0.532    109\n",
      "    fear     0.559     0.512     0.525    80\n",
      "   happy     0.559     0.490     0.580    81\n",
      " neutral     0.559     0.696     0.655    84\n",
      "     sad     0.559     0.449     0.506    87\n",
      "surprise     0.559     0.578     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.568     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.790769 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.197433  [ 1200/ 4873]\n",
      "loss: 0.028712  [ 2400/ 4873]\n",
      "loss: 0.077462  [ 3600/ 4873]\n",
      "loss: 0.066643  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.596     0.533    105\n",
      " disgust     0.548     0.537     0.532    109\n",
      "    fear     0.548     0.432     0.475    80\n",
      "   happy     0.548     0.545     0.593    81\n",
      " neutral     0.548     0.663     0.679    84\n",
      "     sad     0.548     0.494     0.494    87\n",
      "surprise     0.548     0.576     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.549     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.799336 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.127900  [ 1200/ 4873]\n",
      "loss: 0.058902  [ 2400/ 4873]\n",
      "loss: 0.243574  [ 3600/ 4873]\n",
      "loss: 0.088703  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.667     0.457    105\n",
      " disgust     0.538     0.604     0.505    109\n",
      "    fear     0.538     0.478     0.412    80\n",
      "   happy     0.538     0.468     0.630    81\n",
      " neutral     0.538     0.655     0.679    84\n",
      "     sad     0.538     0.449     0.552    87\n",
      "surprise     0.538     0.480     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.543     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.985367 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.025813  [ 1200/ 4873]\n",
      "loss: 0.404859  [ 2400/ 4873]\n",
      "loss: 0.112017  [ 3600/ 4873]\n",
      "loss: 0.182476  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.552     0.505    105\n",
      " disgust     0.562     0.637     0.596    109\n",
      "    fear     0.562     0.500     0.537    80\n",
      "   happy     0.562     0.485     0.593    81\n",
      " neutral     0.562     0.626     0.679    84\n",
      "     sad     0.562     0.553     0.483    87\n",
      "surprise     0.562     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.562     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.791173 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.100253  [ 1200/ 4873]\n",
      "loss: 0.037786  [ 2400/ 4873]\n",
      "loss: 0.441330  [ 3600/ 4873]\n",
      "loss: 0.874062  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.679     0.543    105\n",
      " disgust     0.574     0.557     0.587    109\n",
      "    fear     0.574     0.514     0.475    80\n",
      "   happy     0.574     0.578     0.593    81\n",
      " neutral     0.574     0.624     0.690    84\n",
      "     sad     0.574     0.500     0.563    87\n",
      "surprise     0.574     0.571     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.575     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 2.791689 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.819666  [ 1200/ 4873]\n",
      "loss: 0.171630  [ 2400/ 4873]\n",
      "loss: 0.107208  [ 3600/ 4873]\n",
      "loss: 0.351688  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.679     0.543    105\n",
      " disgust     0.569     0.583     0.578    109\n",
      "    fear     0.569     0.471     0.512    80\n",
      "   happy     0.569     0.543     0.543    81\n",
      " neutral     0.569     0.737     0.667    84\n",
      "     sad     0.569     0.480     0.552    87\n",
      "surprise     0.569     0.514     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.572     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.832760 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.488785  [ 1200/ 4873]\n",
      "loss: 0.315911  [ 2400/ 4873]\n",
      "loss: 0.041808  [ 3600/ 4873]\n",
      "loss: 0.062360  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.616     0.581    105\n",
      " disgust     0.579     0.600     0.578    109\n",
      "    fear     0.579     0.443     0.537    80\n",
      "   happy     0.579     0.605     0.568    81\n",
      " neutral     0.579     0.694     0.702    84\n",
      "     sad     0.579     0.505     0.529    87\n",
      "surprise     0.579     0.614     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.583     0.577    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 2.877440 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.088327  [ 1200/ 4873]\n",
      "loss: 0.287154  [ 2400/ 4873]\n",
      "loss: 0.014173  [ 3600/ 4873]\n",
      "loss: 0.218516  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.598     0.552    105\n",
      " disgust     0.562     0.525     0.587    109\n",
      "    fear     0.562     0.481     0.487    80\n",
      "   happy     0.562     0.611     0.543    81\n",
      " neutral     0.562     0.690     0.690    84\n",
      "     sad     0.562     0.500     0.517    87\n",
      "surprise     0.562     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.565     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.877622 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.048111  [ 1200/ 4873]\n",
      "loss: 0.096028  [ 2400/ 4873]\n",
      "loss: 0.110460  [ 3600/ 4873]\n",
      "loss: 0.107553  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.625     0.476    105\n",
      " disgust     0.552     0.625     0.550    109\n",
      "    fear     0.552     0.520     0.487    80\n",
      "   happy     0.552     0.500     0.605    81\n",
      " neutral     0.552     0.557     0.702    84\n",
      "     sad     0.552     0.537     0.494    87\n",
      "surprise     0.552     0.493     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.551     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.836191 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.115639  [ 1200/ 4873]\n",
      "loss: 0.017542  [ 2400/ 4873]\n",
      "loss: 0.031662  [ 3600/ 4873]\n",
      "loss: 0.084972  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.659     0.514    105\n",
      " disgust     0.567     0.554     0.569    109\n",
      "    fear     0.567     0.541     0.500    80\n",
      "   happy     0.567     0.521     0.605    81\n",
      " neutral     0.567     0.596     0.738    84\n",
      "     sad     0.567     0.569     0.471    87\n",
      "surprise     0.567     0.528     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.567     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.857549 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.151467  [ 1200/ 4873]\n",
      "loss: 0.036165  [ 2400/ 4873]\n",
      "loss: 0.597813  [ 3600/ 4873]\n",
      "loss: 0.307173  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.612     0.495    105\n",
      " disgust     0.554     0.551     0.596    109\n",
      "    fear     0.554     0.455     0.500    80\n",
      "   happy     0.554     0.577     0.556    81\n",
      " neutral     0.554     0.671     0.679    84\n",
      "     sad     0.554     0.483     0.494    87\n",
      "surprise     0.554     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.997854 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.757562  [ 1200/ 4873]\n",
      "loss: 0.104204  [ 2400/ 4873]\n",
      "loss: 0.210334  [ 3600/ 4873]\n",
      "loss: 0.023924  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.667     0.514    105\n",
      " disgust     0.559     0.579     0.569    109\n",
      "    fear     0.559     0.507     0.438    80\n",
      "   happy     0.559     0.495     0.580    81\n",
      " neutral     0.559     0.632     0.714    84\n",
      "     sad     0.559     0.519     0.471    87\n",
      "surprise     0.559     0.500     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.557     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.877217 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.042359  [ 1200/ 4873]\n",
      "loss: 0.084455  [ 2400/ 4873]\n",
      "loss: 0.122494  [ 3600/ 4873]\n",
      "loss: 0.492021  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.684     0.495    105\n",
      " disgust     0.570     0.571     0.624    109\n",
      "    fear     0.570     0.463     0.463    80\n",
      "   happy     0.570     0.605     0.605    81\n",
      " neutral     0.570     0.659     0.690    84\n",
      "     sad     0.570     0.494     0.506    87\n",
      "surprise     0.570     0.519     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.571     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 2.849806 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.078195  [ 1200/ 4873]\n",
      "loss: 0.089027  [ 2400/ 4873]\n",
      "loss: 0.357505  [ 3600/ 4873]\n",
      "loss: 0.086957  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.653     0.590    105\n",
      " disgust     0.572     0.626     0.569    109\n",
      "    fear     0.572     0.451     0.512    80\n",
      "   happy     0.572     0.549     0.556    81\n",
      " neutral     0.572     0.678     0.702    84\n",
      "     sad     0.572     0.454     0.506    87\n",
      "surprise     0.572     0.610     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.574     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.780155 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.023142  [ 1200/ 4873]\n",
      "loss: 0.087354  [ 2400/ 4873]\n",
      "loss: 0.239997  [ 3600/ 4873]\n",
      "loss: 0.035469  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.577     0.682     0.571    105\n",
      " disgust     0.577     0.591     0.596    109\n",
      "    fear     0.577     0.507     0.463    80\n",
      "   happy     0.577     0.511     0.580    81\n",
      " neutral     0.577     0.711     0.702    84\n",
      "     sad     0.577     0.471     0.552    87\n",
      "surprise     0.577     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.577     0.579     0.575    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 2.838397 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.184577  [ 1200/ 4873]\n",
      "loss: 0.032621  [ 2400/ 4873]\n",
      "loss: 0.343604  [ 3600/ 4873]\n",
      "loss: 0.015716  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.646     0.505    105\n",
      " disgust     0.549     0.512     0.578    109\n",
      "    fear     0.549     0.493     0.463    80\n",
      "   happy     0.549     0.581     0.617    81\n",
      " neutral     0.549     0.667     0.690    84\n",
      "     sad     0.549     0.432     0.471    87\n",
      "surprise     0.549     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.552     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.989140 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.077091  [ 1200/ 4873]\n",
      "loss: 0.314697  [ 2400/ 4873]\n",
      "loss: 0.101536  [ 3600/ 4873]\n",
      "loss: 0.018408  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.625     0.524    105\n",
      " disgust     0.572     0.545     0.606    109\n",
      "    fear     0.572     0.548     0.500    80\n",
      "   happy     0.572     0.620     0.605    81\n",
      " neutral     0.572     0.652     0.690    84\n",
      "     sad     0.572     0.484     0.506    87\n",
      "surprise     0.572     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.573     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.912908 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.184261  [ 1200/ 4873]\n",
      "loss: 1.024231  [ 2400/ 4873]\n",
      "loss: 0.039227  [ 3600/ 4873]\n",
      "loss: 0.106465  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.700     0.533    105\n",
      " disgust     0.543     0.534     0.505    109\n",
      "    fear     0.543     0.468     0.450    80\n",
      "   happy     0.543     0.474     0.568    81\n",
      " neutral     0.543     0.611     0.690    84\n",
      "     sad     0.543     0.460     0.529    87\n",
      "surprise     0.543     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.547     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.962523 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.127876  [ 1200/ 4873]\n",
      "loss: 0.066156  [ 2400/ 4873]\n",
      "loss: 0.244678  [ 3600/ 4873]\n",
      "loss: 0.204987  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.589     0.533    105\n",
      " disgust     0.566     0.569     0.642    109\n",
      "    fear     0.566     0.473     0.438    80\n",
      "   happy     0.566     0.583     0.605    81\n",
      " neutral     0.566     0.634     0.702    84\n",
      "     sad     0.566     0.562     0.471    87\n",
      "surprise     0.566     0.515     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.561     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.967383 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.075605  [ 1200/ 4873]\n",
      "loss: 0.218376  [ 2400/ 4873]\n",
      "loss: 0.022058  [ 3600/ 4873]\n",
      "loss: 0.439121  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.622     0.533    105\n",
      " disgust     0.554     0.545     0.550    109\n",
      "    fear     0.554     0.436     0.512    80\n",
      "   happy     0.554     0.610     0.580    81\n",
      " neutral     0.554     0.688     0.655    84\n",
      "     sad     0.554     0.478     0.506    87\n",
      "surprise     0.554     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.557     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.994400 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.064334  [ 1200/ 4873]\n",
      "loss: 0.422675  [ 2400/ 4873]\n",
      "loss: 0.122674  [ 3600/ 4873]\n",
      "loss: 0.390235  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.565     0.457    105\n",
      " disgust     0.539     0.526     0.560    109\n",
      "    fear     0.539     0.432     0.512    80\n",
      "   happy     0.539     0.608     0.556    81\n",
      " neutral     0.539     0.671     0.679    84\n",
      "     sad     0.539     0.462     0.494    87\n",
      "surprise     0.539     0.548     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.545     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 3.024539 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.131459  [ 1200/ 4873]\n",
      "loss: 0.134992  [ 2400/ 4873]\n",
      "loss: 0.444291  [ 3600/ 4873]\n",
      "loss: 0.053485  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.679     0.505    105\n",
      " disgust     0.561     0.619     0.550    109\n",
      "    fear     0.561     0.471     0.412    80\n",
      "   happy     0.561     0.500     0.642    81\n",
      " neutral     0.561     0.699     0.690    84\n",
      "     sad     0.561     0.445     0.563    87\n",
      "surprise     0.561     0.544     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.565     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.850693 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.215085  [ 1200/ 4873]\n",
      "loss: 0.143729  [ 2400/ 4873]\n",
      "loss: 0.151014  [ 3600/ 4873]\n",
      "loss: 0.234545  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.643     0.514    105\n",
      " disgust     0.549     0.519     0.495    109\n",
      "    fear     0.549     0.433     0.562    80\n",
      "   happy     0.549     0.500     0.630    81\n",
      " neutral     0.549     0.746     0.631    84\n",
      "     sad     0.549     0.477     0.483    87\n",
      "surprise     0.549     0.632     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.564     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.963368 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.042018  [ 1200/ 4873]\n",
      "loss: 0.080640  [ 2400/ 4873]\n",
      "loss: 0.209479  [ 3600/ 4873]\n",
      "loss: 0.381580  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.629     0.533    105\n",
      " disgust     0.551     0.567     0.541    109\n",
      "    fear     0.551     0.426     0.500    80\n",
      "   happy     0.551     0.516     0.593    81\n",
      " neutral     0.551     0.675     0.667    84\n",
      "     sad     0.551     0.506     0.506    87\n",
      "surprise     0.551     0.550     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.553     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.901128 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.114820  [ 1200/ 4873]\n",
      "loss: 0.165254  [ 2400/ 4873]\n",
      "loss: 0.010453  [ 3600/ 4873]\n",
      "loss: 0.525092  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.659     0.533    105\n",
      " disgust     0.561     0.606     0.550    109\n",
      "    fear     0.561     0.526     0.500    80\n",
      "   happy     0.561     0.495     0.617    81\n",
      " neutral     0.561     0.648     0.702    84\n",
      "     sad     0.561     0.457     0.483    87\n",
      "surprise     0.561     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.560     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.790813 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.108881  [ 1200/ 4873]\n",
      "loss: 0.095219  [ 2400/ 4873]\n",
      "loss: 0.033992  [ 3600/ 4873]\n",
      "loss: 0.085154  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.630     0.552    105\n",
      " disgust     0.566     0.590     0.569    109\n",
      "    fear     0.566     0.475     0.475    80\n",
      "   happy     0.566     0.570     0.605    81\n",
      " neutral     0.566     0.616     0.726    84\n",
      "     sad     0.566     0.495     0.517    87\n",
      "surprise     0.566     0.561     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.563     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.812570 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.128443  [ 1200/ 4873]\n",
      "loss: 0.063065  [ 2400/ 4873]\n",
      "loss: 0.159009  [ 3600/ 4873]\n",
      "loss: 0.427562  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.670     0.600    105\n",
      " disgust     0.552     0.615     0.541    109\n",
      "    fear     0.552     0.438     0.438    80\n",
      "   happy     0.552     0.528     0.580    81\n",
      " neutral     0.552     0.622     0.667    84\n",
      "     sad     0.552     0.464     0.517    87\n",
      "surprise     0.552     0.500     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.548     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.914187 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.036928  [ 1200/ 4873]\n",
      "loss: 0.104101  [ 2400/ 4873]\n",
      "loss: 0.329927  [ 3600/ 4873]\n",
      "loss: 0.042327  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.636     0.600    105\n",
      " disgust     0.579     0.557     0.587    109\n",
      "    fear     0.579     0.534     0.487    80\n",
      "   happy     0.579     0.584     0.556    81\n",
      " neutral     0.579     0.690     0.714    84\n",
      "     sad     0.579     0.523     0.517    87\n",
      "surprise     0.579     0.507     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.576     0.577    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 2.839035 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.082799  [ 1200/ 4873]\n",
      "loss: 0.145727  [ 2400/ 4873]\n",
      "loss: 0.268055  [ 3600/ 4873]\n",
      "loss: 0.382359  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.679     0.505    105\n",
      " disgust     0.561     0.532     0.606    109\n",
      "    fear     0.561     0.432     0.475    80\n",
      "   happy     0.561     0.558     0.593    81\n",
      " neutral     0.561     0.740     0.679    84\n",
      "     sad     0.561     0.455     0.529    87\n",
      "surprise     0.561     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.572     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.845757 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.052487  [ 1200/ 4873]\n",
      "loss: 0.026537  [ 2400/ 4873]\n",
      "loss: 0.328165  [ 3600/ 4873]\n",
      "loss: 0.031753  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.587     0.585     0.590    105\n",
      " disgust     0.587     0.563     0.615    109\n",
      "    fear     0.587     0.494     0.550    80\n",
      "   happy     0.587     0.671     0.605    81\n",
      " neutral     0.587     0.720     0.702    84\n",
      "     sad     0.587     0.513     0.460    87\n",
      "surprise     0.587     0.587     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.587     0.590     0.586    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 2.896694 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep609_acc_59.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep505_acc_58\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep609_acc_59\"! Old accuracy: 58.4, new accuracy: 58.7\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.053632  [ 1200/ 4873]\n",
      "loss: 0.175375  [ 2400/ 4873]\n",
      "loss: 0.139065  [ 3600/ 4873]\n",
      "loss: 0.103928  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.640     0.524    105\n",
      " disgust     0.543     0.632     0.505    109\n",
      "    fear     0.543     0.500     0.463    80\n",
      "   happy     0.543     0.467     0.605    81\n",
      " neutral     0.543     0.618     0.655    84\n",
      "     sad     0.543     0.446     0.517    87\n",
      "surprise     0.543     0.515     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.545     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.925896 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.129481  [ 1200/ 4873]\n",
      "loss: 0.500096  [ 2400/ 4873]\n",
      "loss: 0.066791  [ 3600/ 4873]\n",
      "loss: 0.434080  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.671     0.505    105\n",
      " disgust     0.539     0.591     0.505    109\n",
      "    fear     0.539     0.434     0.450    80\n",
      "   happy     0.539     0.495     0.617    81\n",
      " neutral     0.539     0.643     0.643    84\n",
      "     sad     0.539     0.421     0.552    87\n",
      "surprise     0.539     0.589     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.549     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.875256 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.393233  [ 1200/ 4873]\n",
      "loss: 0.054321  [ 2400/ 4873]\n",
      "loss: 0.520217  [ 3600/ 4873]\n",
      "loss: 0.160414  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.683     0.533    105\n",
      " disgust     0.561     0.574     0.532    109\n",
      "    fear     0.561     0.561     0.463    80\n",
      "   happy     0.561     0.500     0.642    81\n",
      " neutral     0.561     0.640     0.679    84\n",
      "     sad     0.561     0.471     0.552    87\n",
      "surprise     0.561     0.515     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.563     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.767202 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.054742  [ 1200/ 4873]\n",
      "loss: 0.090682  [ 2400/ 4873]\n",
      "loss: 0.065655  [ 3600/ 4873]\n",
      "loss: 0.024237  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.690     0.552    105\n",
      " disgust     0.561     0.531     0.550    109\n",
      "    fear     0.561     0.525     0.400    80\n",
      "   happy     0.561     0.530     0.654    81\n",
      " neutral     0.561     0.701     0.726    84\n",
      "     sad     0.561     0.423     0.506    87\n",
      "surprise     0.561     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.565     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.905522 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.049760  [ 1200/ 4873]\n",
      "loss: 0.257122  [ 2400/ 4873]\n",
      "loss: 0.147640  [ 3600/ 4873]\n",
      "loss: 0.070724  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.655     0.524    105\n",
      " disgust     0.567     0.528     0.688    109\n",
      "    fear     0.567     0.461     0.512    80\n",
      "   happy     0.567     0.630     0.568    81\n",
      " neutral     0.567     0.743     0.655    84\n",
      "     sad     0.567     0.463     0.506    87\n",
      "surprise     0.567     0.566     0.469    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.578     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.011929 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.016270  [ 1200/ 4873]\n",
      "loss: 0.158052  [ 2400/ 4873]\n",
      "loss: 0.078144  [ 3600/ 4873]\n",
      "loss: 0.074450  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.593     0.514    105\n",
      " disgust     0.549     0.544     0.514    109\n",
      "    fear     0.549     0.457     0.463    80\n",
      "   happy     0.549     0.571     0.593    81\n",
      " neutral     0.549     0.642     0.726    84\n",
      "     sad     0.549     0.477     0.483    87\n",
      "surprise     0.549     0.544     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.547     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.944561 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.134022  [ 1200/ 4873]\n",
      "loss: 0.055185  [ 2400/ 4873]\n",
      "loss: 0.700800  [ 3600/ 4873]\n",
      "loss: 0.052689  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.679     0.543    105\n",
      " disgust     0.548     0.530     0.569    109\n",
      "    fear     0.548     0.452     0.475    80\n",
      "   happy     0.548     0.500     0.593    81\n",
      " neutral     0.548     0.691     0.667    84\n",
      "     sad     0.548     0.436     0.471    87\n",
      "surprise     0.548     0.593     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.554     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.878392 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.263258  [ 1200/ 4873]\n",
      "loss: 0.231542  [ 2400/ 4873]\n",
      "loss: 0.037714  [ 3600/ 4873]\n",
      "loss: 0.870796  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.603     0.419    105\n",
      " disgust     0.528     0.538     0.514    109\n",
      "    fear     0.528     0.424     0.487    80\n",
      "   happy     0.528     0.481     0.617    81\n",
      " neutral     0.528     0.682     0.690    84\n",
      "     sad     0.528     0.442     0.483    87\n",
      "surprise     0.528     0.579     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.536     0.532    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.866281 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.028266  [ 1200/ 4873]\n",
      "loss: 0.086292  [ 2400/ 4873]\n",
      "loss: 0.103209  [ 3600/ 4873]\n",
      "loss: 0.219378  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.687     0.543    105\n",
      " disgust     0.559     0.491     0.523    109\n",
      "    fear     0.559     0.535     0.475    80\n",
      "   happy     0.559     0.511     0.568    81\n",
      " neutral     0.559     0.728     0.702    84\n",
      "     sad     0.559     0.479     0.529    87\n",
      "surprise     0.559     0.521     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.565     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.896907 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.105170  [ 1200/ 4873]\n",
      "loss: 0.210340  [ 2400/ 4873]\n",
      "loss: 0.213457  [ 3600/ 4873]\n",
      "loss: 0.019968  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.649     0.476    105\n",
      " disgust     0.539     0.528     0.523    109\n",
      "    fear     0.539     0.464     0.487    80\n",
      "   happy     0.539     0.500     0.568    81\n",
      " neutral     0.539     0.720     0.702    84\n",
      "     sad     0.539     0.437     0.517    87\n",
      "surprise     0.539     0.516     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.545     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.974889 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.031228  [ 1200/ 4873]\n",
      "loss: 0.356777  [ 2400/ 4873]\n",
      "loss: 0.360893  [ 3600/ 4873]\n",
      "loss: 0.646044  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.613     0.467    105\n",
      " disgust     0.546     0.564     0.523    109\n",
      "    fear     0.546     0.488     0.525    80\n",
      "   happy     0.546     0.505     0.630    81\n",
      " neutral     0.546     0.640     0.679    84\n",
      "     sad     0.546     0.478     0.506    87\n",
      "surprise     0.546     0.541     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.547     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.920061 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.104094  [ 1200/ 4873]\n",
      "loss: 0.116482  [ 2400/ 4873]\n",
      "loss: 0.188050  [ 3600/ 4873]\n",
      "loss: 0.315523  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.690     0.552    105\n",
      " disgust     0.567     0.513     0.532    109\n",
      "    fear     0.567     0.514     0.475    80\n",
      "   happy     0.567     0.515     0.617    81\n",
      " neutral     0.567     0.659     0.714    84\n",
      "     sad     0.567     0.518     0.506    87\n",
      "surprise     0.567     0.576     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.569     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.828695 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.079440  [ 1200/ 4873]\n",
      "loss: 0.146869  [ 2400/ 4873]\n",
      "loss: 0.101445  [ 3600/ 4873]\n",
      "loss: 0.091517  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.628     0.514    105\n",
      " disgust     0.559     0.536     0.541    109\n",
      "    fear     0.559     0.472     0.525    80\n",
      "   happy     0.559     0.557     0.543    81\n",
      " neutral     0.559     0.667     0.690    84\n",
      "     sad     0.559     0.500     0.563    87\n",
      "surprise     0.559     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.562     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.889842 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.007133  [ 1200/ 4873]\n",
      "loss: 0.572660  [ 2400/ 4873]\n",
      "loss: 0.023936  [ 3600/ 4873]\n",
      "loss: 0.091652  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.650     0.495    105\n",
      " disgust     0.551     0.568     0.578    109\n",
      "    fear     0.551     0.440     0.500    80\n",
      "   happy     0.551     0.522     0.580    81\n",
      " neutral     0.551     0.690     0.690    84\n",
      "     sad     0.551     0.449     0.506    87\n",
      "surprise     0.551     0.571     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.556     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.883882 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.024025  [ 1200/ 4873]\n",
      "loss: 0.066050  [ 2400/ 4873]\n",
      "loss: 0.215946  [ 3600/ 4873]\n",
      "loss: 0.268496  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.652     0.571    105\n",
      " disgust     0.570     0.549     0.569    109\n",
      "    fear     0.570     0.500     0.450    80\n",
      "   happy     0.570     0.560     0.580    81\n",
      " neutral     0.570     0.663     0.702    84\n",
      "     sad     0.570     0.534     0.540    87\n",
      "surprise     0.570     0.514     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.567     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 3.006880 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.199933  [ 1200/ 4873]\n",
      "loss: 0.075448  [ 2400/ 4873]\n",
      "loss: 0.350966  [ 3600/ 4873]\n",
      "loss: 0.510045  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.667     0.495    105\n",
      " disgust     0.562     0.551     0.541    109\n",
      "    fear     0.562     0.554     0.512    80\n",
      "   happy     0.562     0.490     0.630    81\n",
      " neutral     0.562     0.682     0.714    84\n",
      "     sad     0.562     0.494     0.483    87\n",
      "surprise     0.562     0.514     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.565     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.881830 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.120950  [ 1200/ 4873]\n",
      "loss: 0.055431  [ 2400/ 4873]\n",
      "loss: 0.217567  [ 3600/ 4873]\n",
      "loss: 0.172958  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.619     0.571    105\n",
      " disgust     0.570     0.592     0.532    109\n",
      "    fear     0.570     0.562     0.450    80\n",
      "   happy     0.570     0.505     0.642    81\n",
      " neutral     0.570     0.639     0.738    84\n",
      "     sad     0.570     0.524     0.494    87\n",
      "surprise     0.570     0.536     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.568     0.572    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 2.870012 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.154874  [ 1200/ 4873]\n",
      "loss: 0.471580  [ 2400/ 4873]\n",
      "loss: 0.053703  [ 3600/ 4873]\n",
      "loss: 0.058282  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.728     0.562    105\n",
      " disgust     0.548     0.617     0.532    109\n",
      "    fear     0.548     0.436     0.425    80\n",
      "   happy     0.548     0.475     0.593    81\n",
      " neutral     0.548     0.606     0.714    84\n",
      "     sad     0.548     0.453     0.494    87\n",
      "surprise     0.548     0.516     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.547     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.794209 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.134908  [ 1200/ 4873]\n",
      "loss: 0.044775  [ 2400/ 4873]\n",
      "loss: 0.254974  [ 3600/ 4873]\n",
      "loss: 0.079399  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.724     0.524    105\n",
      " disgust     0.552     0.554     0.514    109\n",
      "    fear     0.552     0.494     0.512    80\n",
      "   happy     0.552     0.511     0.593    81\n",
      " neutral     0.552     0.663     0.679    84\n",
      "     sad     0.552     0.439     0.540    87\n",
      "surprise     0.552     0.524     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.558     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.009431 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.055212  [ 1200/ 4873]\n",
      "loss: 0.108551  [ 2400/ 4873]\n",
      "loss: 0.166144  [ 3600/ 4873]\n",
      "loss: 0.132388  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.616     0.581    105\n",
      " disgust     0.579     0.611     0.606    109\n",
      "    fear     0.579     0.453     0.487    80\n",
      "   happy     0.579     0.553     0.580    81\n",
      " neutral     0.579     0.653     0.738    84\n",
      "     sad     0.579     0.557     0.506    87\n",
      "surprise     0.579     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.576     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 2.730796 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.056076  [ 1200/ 4873]\n",
      "loss: 0.129965  [ 2400/ 4873]\n",
      "loss: 0.125772  [ 3600/ 4873]\n",
      "loss: 0.045491  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.626     0.543    105\n",
      " disgust     0.579     0.589     0.606    109\n",
      "    fear     0.579     0.469     0.475    80\n",
      "   happy     0.579     0.545     0.593    81\n",
      " neutral     0.579     0.678     0.726    84\n",
      "     sad     0.579     0.543     0.575    87\n",
      "surprise     0.579     0.589     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.577     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 2.816667 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.032925  [ 1200/ 4873]\n",
      "loss: 1.022046  [ 2400/ 4873]\n",
      "loss: 0.357345  [ 3600/ 4873]\n",
      "loss: 0.061903  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.589     0.630     0.600    105\n",
      " disgust     0.589     0.589     0.670    109\n",
      "    fear     0.589     0.468     0.463    80\n",
      "   happy     0.589     0.620     0.543    81\n",
      " neutral     0.589     0.729     0.738    84\n",
      "     sad     0.589     0.518     0.506    87\n",
      "surprise     0.589     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.589     0.586     0.583    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 2.857668 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep631_acc_59.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep609_acc_59\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/emo_reco_best_ep631_acc_59\"! Old accuracy: 58.7, new accuracy: 58.9\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.109734  [ 1200/ 4873]\n",
      "loss: 0.239009  [ 2400/ 4873]\n",
      "loss: 0.092960  [ 3600/ 4873]\n",
      "loss: 0.374741  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.662     0.486    105\n",
      " disgust     0.556     0.589     0.486    109\n",
      "    fear     0.556     0.551     0.537    80\n",
      "   happy     0.556     0.536     0.642    81\n",
      " neutral     0.556     0.679     0.631    84\n",
      "     sad     0.556     0.411     0.529    87\n",
      "surprise     0.556     0.526     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.565     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.848179 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.114457  [ 1200/ 4873]\n",
      "loss: 0.058537  [ 2400/ 4873]\n",
      "loss: 0.034813  [ 3600/ 4873]\n",
      "loss: 0.230076  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.695     0.543    105\n",
      " disgust     0.561     0.548     0.578    109\n",
      "    fear     0.561     0.466     0.425    80\n",
      "   happy     0.561     0.505     0.605    81\n",
      " neutral     0.561     0.630     0.690    84\n",
      "     sad     0.561     0.495     0.552    87\n",
      "surprise     0.561     0.611     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.564     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.797918 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.013467  [ 1200/ 4873]\n",
      "loss: 0.258111  [ 2400/ 4873]\n",
      "loss: 0.079681  [ 3600/ 4873]\n",
      "loss: 0.273005  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.722     0.495    105\n",
      " disgust     0.554     0.542     0.587    109\n",
      "    fear     0.554     0.469     0.475    80\n",
      "   happy     0.554     0.534     0.580    81\n",
      " neutral     0.554     0.637     0.690    84\n",
      "     sad     0.554     0.477     0.483    87\n",
      "surprise     0.554     0.514     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.557     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.009020 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.501647  [ 1200/ 4873]\n",
      "loss: 0.336326  [ 2400/ 4873]\n",
      "loss: 0.344732  [ 3600/ 4873]\n",
      "loss: 0.067503  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.690     0.552    105\n",
      " disgust     0.552     0.629     0.514    109\n",
      "    fear     0.552     0.544     0.463    80\n",
      "   happy     0.552     0.452     0.580    81\n",
      " neutral     0.552     0.655     0.679    84\n",
      "     sad     0.552     0.440     0.552    87\n",
      "surprise     0.552     0.493     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.558     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.851272 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.340874  [ 1200/ 4873]\n",
      "loss: 0.616912  [ 2400/ 4873]\n",
      "loss: 0.179915  [ 3600/ 4873]\n",
      "loss: 0.336863  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.615     0.457    105\n",
      " disgust     0.541     0.606     0.523    109\n",
      "    fear     0.541     0.453     0.487    80\n",
      "   happy     0.541     0.435     0.617    81\n",
      " neutral     0.541     0.606     0.679    84\n",
      "     sad     0.541     0.561     0.529    87\n",
      "surprise     0.541     0.541     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.545     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.895752 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.089281  [ 1200/ 4873]\n",
      "loss: 0.121241  [ 2400/ 4873]\n",
      "loss: 0.328513  [ 3600/ 4873]\n",
      "loss: 0.055972  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.615     0.562    105\n",
      " disgust     0.544     0.487     0.523    109\n",
      "    fear     0.544     0.460     0.500    80\n",
      "   happy     0.544     0.597     0.531    81\n",
      " neutral     0.544     0.695     0.679    84\n",
      "     sad     0.544     0.469     0.529    87\n",
      "surprise     0.544     0.517     0.469    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.549     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.156379 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.085561  [ 1200/ 4873]\n",
      "loss: 0.068384  [ 2400/ 4873]\n",
      "loss: 0.265874  [ 3600/ 4873]\n",
      "loss: 0.032952  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.627     0.495    105\n",
      " disgust     0.559     0.566     0.587    109\n",
      "    fear     0.559     0.507     0.463    80\n",
      "   happy     0.559     0.505     0.605    81\n",
      " neutral     0.559     0.655     0.679    84\n",
      "     sad     0.559     0.532     0.575    87\n",
      "surprise     0.559     0.508     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.557     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.025215 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.104335  [ 1200/ 4873]\n",
      "loss: 0.376152  [ 2400/ 4873]\n",
      "loss: 0.093164  [ 3600/ 4873]\n",
      "loss: 0.041076  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.659     0.552    105\n",
      " disgust     0.562     0.608     0.541    109\n",
      "    fear     0.562     0.459     0.487    80\n",
      "   happy     0.562     0.486     0.630    81\n",
      " neutral     0.562     0.702     0.702    84\n",
      "     sad     0.562     0.468     0.506    87\n",
      "surprise     0.562     0.579     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.566     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.902635 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.088292  [ 1200/ 4873]\n",
      "loss: 0.042574  [ 2400/ 4873]\n",
      "loss: 0.224372  [ 3600/ 4873]\n",
      "loss: 0.030670  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.606     0.543    105\n",
      " disgust     0.564     0.585     0.569    109\n",
      "    fear     0.564     0.493     0.450    80\n",
      "   happy     0.564     0.608     0.593    81\n",
      " neutral     0.564     0.641     0.702    84\n",
      "     sad     0.564     0.479     0.517    87\n",
      "surprise     0.564     0.514     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.561     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.898231 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.110130  [ 1200/ 4873]\n",
      "loss: 0.089599  [ 2400/ 4873]\n",
      "loss: 0.097635  [ 3600/ 4873]\n",
      "loss: 0.170283  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.633     0.476    105\n",
      " disgust     0.548     0.529     0.587    109\n",
      "    fear     0.548     0.451     0.512    80\n",
      "   happy     0.548     0.527     0.593    81\n",
      " neutral     0.548     0.674     0.690    84\n",
      "     sad     0.548     0.471     0.460    87\n",
      "surprise     0.548     0.579     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.552     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 2.957235 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.020205  [ 1200/ 4873]\n",
      "loss: 0.057543  [ 2400/ 4873]\n",
      "loss: 0.047675  [ 3600/ 4873]\n",
      "loss: 0.063854  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.583     0.467    105\n",
      " disgust     0.544     0.518     0.532    109\n",
      "    fear     0.544     0.526     0.500    80\n",
      "   happy     0.544     0.510     0.617    81\n",
      " neutral     0.544     0.644     0.667    84\n",
      "     sad     0.544     0.484     0.517    87\n",
      "surprise     0.544     0.567     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.547     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.016712 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.203550  [ 1200/ 4873]\n",
      "loss: 0.170527  [ 2400/ 4873]\n",
      "loss: 0.503105  [ 3600/ 4873]\n",
      "loss: 0.035883  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.596     0.505    105\n",
      " disgust     0.554     0.530     0.569    109\n",
      "    fear     0.554     0.477     0.512    80\n",
      "   happy     0.554     0.595     0.543    81\n",
      " neutral     0.554     0.609     0.667    84\n",
      "     sad     0.554     0.548     0.529    87\n",
      "surprise     0.554     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.064624 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.050777  [ 1200/ 4873]\n",
      "loss: 0.013106  [ 2400/ 4873]\n",
      "loss: 0.099693  [ 3600/ 4873]\n",
      "loss: 0.420518  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.626     0.543    105\n",
      " disgust     0.575     0.586     0.532    109\n",
      "    fear     0.575     0.441     0.512    80\n",
      "   happy     0.575     0.593     0.630    81\n",
      " neutral     0.575     0.694     0.702    84\n",
      "     sad     0.575     0.490     0.540    87\n",
      "surprise     0.575     0.633     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.580     0.579    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 2.704032 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.265276  [ 1200/ 4873]\n",
      "loss: 0.050051  [ 2400/ 4873]\n",
      "loss: 0.096962  [ 3600/ 4873]\n",
      "loss: 0.135762  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.616     0.505    105\n",
      " disgust     0.549     0.540     0.560    109\n",
      "    fear     0.549     0.456     0.450    80\n",
      "   happy     0.549     0.510     0.642    81\n",
      " neutral     0.549     0.688     0.655    84\n",
      "     sad     0.549     0.494     0.506    87\n",
      "surprise     0.549     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.552     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.888076 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.109317  [ 1200/ 4873]\n",
      "loss: 0.393218  [ 2400/ 4873]\n",
      "loss: 0.206097  [ 3600/ 4873]\n",
      "loss: 0.144151  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.676     0.476    105\n",
      " disgust     0.549     0.590     0.541    109\n",
      "    fear     0.549     0.444     0.500    80\n",
      "   happy     0.549     0.495     0.617    81\n",
      " neutral     0.549     0.740     0.643    84\n",
      "     sad     0.549     0.429     0.552    87\n",
      "surprise     0.549     0.567     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.563     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.993851 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.210508  [ 1200/ 4873]\n",
      "loss: 0.041361  [ 2400/ 4873]\n",
      "loss: 0.019982  [ 3600/ 4873]\n",
      "loss: 0.009641  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.558     0.505    105\n",
      " disgust     0.552     0.568     0.578    109\n",
      "    fear     0.552     0.432     0.438    80\n",
      "   happy     0.552     0.576     0.605    81\n",
      " neutral     0.552     0.682     0.690    84\n",
      "     sad     0.552     0.494     0.506    87\n",
      "surprise     0.552     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.551     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.020058 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.141403  [ 1200/ 4873]\n",
      "loss: 0.192101  [ 2400/ 4873]\n",
      "loss: 0.078767  [ 3600/ 4873]\n",
      "loss: 0.027043  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.651     0.533    105\n",
      " disgust     0.562     0.541     0.486    109\n",
      "    fear     0.562     0.506     0.525    80\n",
      "   happy     0.562     0.573     0.580    81\n",
      " neutral     0.562     0.604     0.690    84\n",
      "     sad     0.562     0.510     0.598    87\n",
      "surprise     0.562     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.563     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.859118 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.304429  [ 1200/ 4873]\n",
      "loss: 0.322726  [ 2400/ 4873]\n",
      "loss: 0.214302  [ 3600/ 4873]\n",
      "loss: 0.011389  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.617     0.476    105\n",
      " disgust     0.551     0.500     0.578    109\n",
      "    fear     0.551     0.594     0.475    80\n",
      "   happy     0.551     0.548     0.630    81\n",
      " neutral     0.551     0.667     0.667    84\n",
      "     sad     0.551     0.479     0.517    87\n",
      "surprise     0.551     0.485     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.556     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.020877 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.416124  [ 1200/ 4873]\n",
      "loss: 0.161390  [ 2400/ 4873]\n",
      "loss: 0.297484  [ 3600/ 4873]\n",
      "loss: 0.481860  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.580     0.646     0.610    105\n",
      " disgust     0.580     0.537     0.596    109\n",
      "    fear     0.580     0.488     0.500    80\n",
      "   happy     0.580     0.582     0.568    81\n",
      " neutral     0.580     0.656     0.702    84\n",
      "     sad     0.580     0.550     0.506    87\n",
      "surprise     0.580     0.610     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.580     0.581     0.578    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 2.855325 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.175892  [ 1200/ 4873]\n",
      "loss: 0.271085  [ 2400/ 4873]\n",
      "loss: 0.040474  [ 3600/ 4873]\n",
      "loss: 0.273603  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.611     0.524    105\n",
      " disgust     0.561     0.581     0.560    109\n",
      "    fear     0.561     0.519     0.500    80\n",
      "   happy     0.561     0.505     0.593    81\n",
      " neutral     0.561     0.630     0.690    84\n",
      "     sad     0.561     0.483     0.494    87\n",
      "surprise     0.561     0.597     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.561     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.916333 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.023589  [ 1200/ 4873]\n",
      "loss: 0.055955  [ 2400/ 4873]\n",
      "loss: 0.333767  [ 3600/ 4873]\n",
      "loss: 0.135823  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.732     0.571    105\n",
      " disgust     0.561     0.554     0.569    109\n",
      "    fear     0.561     0.486     0.450    80\n",
      "   happy     0.561     0.517     0.556    81\n",
      " neutral     0.561     0.615     0.667    84\n",
      "     sad     0.561     0.479     0.517    87\n",
      "surprise     0.561     0.543     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.561     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.936820 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.066934  [ 1200/ 4873]\n",
      "loss: 0.072557  [ 2400/ 4873]\n",
      "loss: 0.128840  [ 3600/ 4873]\n",
      "loss: 0.176186  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.689     0.486    105\n",
      " disgust     0.566     0.602     0.596    109\n",
      "    fear     0.566     0.556     0.500    80\n",
      "   happy     0.566     0.495     0.605    81\n",
      " neutral     0.566     0.620     0.679    84\n",
      "     sad     0.566     0.450     0.517    87\n",
      "surprise     0.566     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.571     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.847763 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.310486  [ 1200/ 4873]\n",
      "loss: 0.197089  [ 2400/ 4873]\n",
      "loss: 0.090644  [ 3600/ 4873]\n",
      "loss: 0.072197  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.568     0.514    105\n",
      " disgust     0.564     0.535     0.633    109\n",
      "    fear     0.564     0.569     0.463    80\n",
      "   happy     0.564     0.544     0.531    81\n",
      " neutral     0.564     0.674     0.690    84\n",
      "     sad     0.564     0.557     0.506    87\n",
      "surprise     0.564     0.506     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.565     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.004794 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.049521  [ 1200/ 4873]\n",
      "loss: 0.310804  [ 2400/ 4873]\n",
      "loss: 0.012636  [ 3600/ 4873]\n",
      "loss: 0.369567  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.611     0.524    105\n",
      " disgust     0.569     0.593     0.587    109\n",
      "    fear     0.569     0.482     0.512    80\n",
      "   happy     0.569     0.517     0.556    81\n",
      " neutral     0.569     0.649     0.726    84\n",
      "     sad     0.569     0.523     0.529    87\n",
      "surprise     0.569     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.568     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.907150 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.081555  [ 1200/ 4873]\n",
      "loss: 0.125517  [ 2400/ 4873]\n",
      "loss: 0.036463  [ 3600/ 4873]\n",
      "loss: 0.017465  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.548     0.543    105\n",
      " disgust     0.557     0.564     0.569    109\n",
      "    fear     0.557     0.481     0.463    80\n",
      "   happy     0.557     0.573     0.580    81\n",
      " neutral     0.557     0.674     0.690    84\n",
      "     sad     0.557     0.483     0.494    87\n",
      "surprise     0.557     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.558     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.925194 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.315703  [ 1200/ 4873]\n",
      "loss: 0.116767  [ 2400/ 4873]\n",
      "loss: 0.028167  [ 3600/ 4873]\n",
      "loss: 0.212441  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.635     0.514    105\n",
      " disgust     0.557     0.627     0.633    109\n",
      "    fear     0.557     0.520     0.487    80\n",
      "   happy     0.557     0.456     0.580    81\n",
      " neutral     0.557     0.585     0.655    84\n",
      "     sad     0.557     0.519     0.471    87\n",
      "surprise     0.557     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.556     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.955223 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.327233  [ 1200/ 4873]\n",
      "loss: 0.424954  [ 2400/ 4873]\n",
      "loss: 0.048341  [ 3600/ 4873]\n",
      "loss: 0.433094  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.620     0.590    105\n",
      " disgust     0.554     0.556     0.550    109\n",
      "    fear     0.554     0.500     0.512    80\n",
      "   happy     0.554     0.566     0.580    81\n",
      " neutral     0.554     0.588     0.679    84\n",
      "     sad     0.554     0.500     0.437    87\n",
      "surprise     0.554     0.516     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.549     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.885908 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.059986  [ 1200/ 4873]\n",
      "loss: 0.602923  [ 2400/ 4873]\n",
      "loss: 0.046897  [ 3600/ 4873]\n",
      "loss: 0.006369  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.617     0.552    105\n",
      " disgust     0.552     0.561     0.505    109\n",
      "    fear     0.552     0.514     0.475    80\n",
      "   happy     0.552     0.500     0.605    81\n",
      " neutral     0.552     0.655     0.655    84\n",
      "     sad     0.552     0.484     0.529    87\n",
      "surprise     0.552     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.553     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.036770 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.117339  [ 1200/ 4873]\n",
      "loss: 0.620368  [ 2400/ 4873]\n",
      "loss: 0.024900  [ 3600/ 4873]\n",
      "loss: 0.222784  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.716     0.552    105\n",
      " disgust     0.561     0.551     0.541    109\n",
      "    fear     0.561     0.468     0.463    80\n",
      "   happy     0.561     0.527     0.593    81\n",
      " neutral     0.561     0.690     0.714    84\n",
      "     sad     0.561     0.441     0.517    87\n",
      "surprise     0.561     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.564     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.967557 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.108148  [ 1200/ 4873]\n",
      "loss: 0.041010  [ 2400/ 4873]\n",
      "loss: 0.049906  [ 3600/ 4873]\n",
      "loss: 0.533373  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.683     0.533    105\n",
      " disgust     0.561     0.596     0.486    109\n",
      "    fear     0.561     0.529     0.450    80\n",
      "   happy     0.561     0.465     0.654    81\n",
      " neutral     0.561     0.638     0.714    84\n",
      "     sad     0.561     0.522     0.540    87\n",
      "surprise     0.561     0.507     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.563     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.993271 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.093681  [ 1200/ 4873]\n",
      "loss: 0.098831  [ 2400/ 4873]\n",
      "loss: 0.097793  [ 3600/ 4873]\n",
      "loss: 0.499317  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.637     0.552    105\n",
      " disgust     0.569     0.550     0.606    109\n",
      "    fear     0.569     0.500     0.487    80\n",
      "   happy     0.569     0.598     0.605    81\n",
      " neutral     0.569     0.651     0.667    84\n",
      "     sad     0.569     0.537     0.494    87\n",
      "surprise     0.569     0.493     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.567     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.947815 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.027689  [ 1200/ 4873]\n",
      "loss: 0.442558  [ 2400/ 4873]\n",
      "loss: 0.377882  [ 3600/ 4873]\n",
      "loss: 0.658097  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.650     0.495    105\n",
      " disgust     0.539     0.559     0.477    109\n",
      "    fear     0.539     0.476     0.500    80\n",
      "   happy     0.539     0.476     0.617    81\n",
      " neutral     0.539     0.663     0.655    84\n",
      "     sad     0.539     0.444     0.506    87\n",
      "surprise     0.539     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.545     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 2.900269 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.066744  [ 1200/ 4873]\n",
      "loss: 0.194466  [ 2400/ 4873]\n",
      "loss: 0.625856  [ 3600/ 4873]\n",
      "loss: 0.988413  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.653     0.467    105\n",
      " disgust     0.562     0.590     0.569    109\n",
      "    fear     0.562     0.432     0.475    80\n",
      "   happy     0.562     0.542     0.642    81\n",
      " neutral     0.562     0.674     0.690    84\n",
      "     sad     0.562     0.539     0.552    87\n",
      "surprise     0.562     0.507     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.563     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.021951 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.233837  [ 1200/ 4873]\n",
      "loss: 0.290962  [ 2400/ 4873]\n",
      "loss: 0.040180  [ 3600/ 4873]\n",
      "loss: 0.025781  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.679     0.505    105\n",
      " disgust     0.575     0.557     0.541    109\n",
      "    fear     0.575     0.558     0.537    80\n",
      "   happy     0.575     0.531     0.642    81\n",
      " neutral     0.575     0.659     0.714    84\n",
      "     sad     0.575     0.505     0.540    87\n",
      "surprise     0.575     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.577     0.580    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 2.919638 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.598107  [ 1200/ 4873]\n",
      "loss: 0.388283  [ 2400/ 4873]\n",
      "loss: 0.050100  [ 3600/ 4873]\n",
      "loss: 0.275565  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.701     0.514    105\n",
      " disgust     0.564     0.595     0.606    109\n",
      "    fear     0.564     0.442     0.475    80\n",
      "   happy     0.564     0.532     0.617    81\n",
      " neutral     0.564     0.671     0.655    84\n",
      "     sad     0.564     0.511     0.517    87\n",
      "surprise     0.564     0.500     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.565     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.972342 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.158925  [ 1200/ 4873]\n",
      "loss: 0.135101  [ 2400/ 4873]\n",
      "loss: 0.331471  [ 3600/ 4873]\n",
      "loss: 0.637621  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.698     0.571    105\n",
      " disgust     0.574     0.587     0.587    109\n",
      "    fear     0.574     0.536     0.463    80\n",
      "   happy     0.574     0.445     0.605    81\n",
      " neutral     0.574     0.698     0.714    84\n",
      "     sad     0.574     0.489     0.529    87\n",
      "surprise     0.574     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.580     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 2.896455 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.263672  [ 1200/ 4873]\n",
      "loss: 0.204140  [ 2400/ 4873]\n",
      "loss: 0.076369  [ 3600/ 4873]\n",
      "loss: 0.309029  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.619     0.495    105\n",
      " disgust     0.544     0.591     0.505    109\n",
      "    fear     0.544     0.468     0.450    80\n",
      "   happy     0.544     0.495     0.642    81\n",
      " neutral     0.544     0.648     0.702    84\n",
      "     sad     0.544     0.457     0.494    87\n",
      "surprise     0.544     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.544     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.869081 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.024677  [ 1200/ 4873]\n",
      "loss: 1.750578  [ 2400/ 4873]\n",
      "loss: 0.033960  [ 3600/ 4873]\n",
      "loss: 0.092109  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.659     0.514    105\n",
      " disgust     0.562     0.577     0.514    109\n",
      "    fear     0.562     0.423     0.512    80\n",
      "   happy     0.562     0.546     0.654    81\n",
      " neutral     0.562     0.731     0.679    84\n",
      "     sad     0.562     0.471     0.552    87\n",
      "surprise     0.562     0.596     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.572     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.845636 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.105605  [ 1200/ 4873]\n",
      "loss: 0.020608  [ 2400/ 4873]\n",
      "loss: 0.014613  [ 3600/ 4873]\n",
      "loss: 0.039648  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.636     0.533    105\n",
      " disgust     0.554     0.566     0.514    109\n",
      "    fear     0.554     0.469     0.475    80\n",
      "   happy     0.554     0.520     0.630    81\n",
      " neutral     0.554     0.671     0.679    84\n",
      "     sad     0.554     0.451     0.529    87\n",
      "surprise     0.554     0.596     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.559     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.002033 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.203332  [ 1200/ 4873]\n",
      "loss: 0.149435  [ 2400/ 4873]\n",
      "loss: 0.817160  [ 3600/ 4873]\n",
      "loss: 0.417928  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.662     0.486    105\n",
      " disgust     0.561     0.551     0.596    109\n",
      "    fear     0.561     0.477     0.525    80\n",
      "   happy     0.561     0.558     0.593    81\n",
      " neutral     0.561     0.682     0.690    84\n",
      "     sad     0.561     0.459     0.517    87\n",
      "surprise     0.561     0.569     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.566     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 2.961729 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.028802  [ 1200/ 4873]\n",
      "loss: 0.274623  [ 2400/ 4873]\n",
      "loss: 0.220016  [ 3600/ 4873]\n",
      "loss: 0.498360  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.658     0.495    105\n",
      " disgust     0.570     0.556     0.550    109\n",
      "    fear     0.570     0.506     0.525    80\n",
      "   happy     0.570     0.549     0.617    81\n",
      " neutral     0.570     0.690     0.714    84\n",
      "     sad     0.570     0.485     0.552    87\n",
      "surprise     0.570     0.571     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.574     0.574    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 2.947816 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.189406  [ 1200/ 4873]\n",
      "loss: 0.221818  [ 2400/ 4873]\n",
      "loss: 0.052775  [ 3600/ 4873]\n",
      "loss: 0.046859  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.688     0.524    105\n",
      " disgust     0.566     0.534     0.569    109\n",
      "    fear     0.566     0.449     0.500    80\n",
      "   happy     0.566     0.558     0.593    81\n",
      " neutral     0.566     0.670     0.702    84\n",
      "     sad     0.566     0.484     0.529    87\n",
      "surprise     0.566     0.625     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.573     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.953242 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.200142  [ 1200/ 4873]\n",
      "loss: 0.443057  [ 2400/ 4873]\n",
      "loss: 0.051011  [ 3600/ 4873]\n",
      "loss: 0.250240  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.631     0.505    105\n",
      " disgust     0.546     0.573     0.505    109\n",
      "    fear     0.546     0.520     0.487    80\n",
      "   happy     0.546     0.500     0.642    81\n",
      " neutral     0.546     0.637     0.690    84\n",
      "     sad     0.546     0.432     0.471    87\n",
      "surprise     0.546     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.547     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 2.938613 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.244431  [ 1200/ 4873]\n",
      "loss: 0.235550  [ 2400/ 4873]\n",
      "loss: 0.015632  [ 3600/ 4873]\n",
      "loss: 0.403713  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.630     0.486    105\n",
      " disgust     0.566     0.578     0.615    109\n",
      "    fear     0.566     0.425     0.463    80\n",
      "   happy     0.566     0.563     0.605    81\n",
      " neutral     0.566     0.686     0.702    84\n",
      "     sad     0.566     0.511     0.540    87\n",
      "surprise     0.566     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.567     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.932398 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.541085  [ 1200/ 4873]\n",
      "loss: 0.726018  [ 2400/ 4873]\n",
      "loss: 0.646615  [ 3600/ 4873]\n",
      "loss: 0.114478  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.577     0.662     0.505    105\n",
      " disgust     0.577     0.577     0.587    109\n",
      "    fear     0.577     0.500     0.512    80\n",
      "   happy     0.577     0.613     0.605    81\n",
      " neutral     0.577     0.663     0.702    84\n",
      "     sad     0.577     0.500     0.563    87\n",
      "surprise     0.577     0.529     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.577     0.578     0.579    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 2.960706 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.017886  [ 1200/ 4873]\n",
      "loss: 0.236193  [ 2400/ 4873]\n",
      "loss: 0.161030  [ 3600/ 4873]\n",
      "loss: 0.716686  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.640     0.543    105\n",
      " disgust     0.546     0.538     0.514    109\n",
      "    fear     0.546     0.556     0.438    80\n",
      "   happy     0.546     0.522     0.580    81\n",
      " neutral     0.546     0.632     0.714    84\n",
      "     sad     0.546     0.500     0.517    87\n",
      "surprise     0.546     0.418     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.544     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.175833 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.074655  [ 1200/ 4873]\n",
      "loss: 0.012965  [ 2400/ 4873]\n",
      "loss: 0.102525  [ 3600/ 4873]\n",
      "loss: 0.257224  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.740     0.514    105\n",
      " disgust     0.551     0.495     0.495    109\n",
      "    fear     0.551     0.507     0.425    80\n",
      "   happy     0.551     0.526     0.617    81\n",
      " neutral     0.551     0.648     0.702    84\n",
      "     sad     0.551     0.441     0.517    87\n",
      "surprise     0.551     0.548     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.558     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.055371 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.619282  [ 1200/ 4873]\n",
      "loss: 0.184935  [ 2400/ 4873]\n",
      "loss: 0.117132  [ 3600/ 4873]\n",
      "loss: 0.357978  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.624     0.552    105\n",
      " disgust     0.556     0.563     0.532    109\n",
      "    fear     0.556     0.465     0.500    80\n",
      "   happy     0.556     0.590     0.568    81\n",
      " neutral     0.556     0.655     0.679    84\n",
      "     sad     0.556     0.484     0.506    87\n",
      "surprise     0.556     0.500     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.554     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.972546 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.231269  [ 1200/ 4873]\n",
      "loss: 0.330024  [ 2400/ 4873]\n",
      "loss: 0.060313  [ 3600/ 4873]\n",
      "loss: 0.156853  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.675     0.495    105\n",
      " disgust     0.539     0.513     0.541    109\n",
      "    fear     0.539     0.514     0.463    80\n",
      "   happy     0.539     0.505     0.593    81\n",
      " neutral     0.539     0.658     0.619    84\n",
      "     sad     0.539     0.436     0.506    87\n",
      "surprise     0.539     0.521     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.546     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 3.027143 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.023261  [ 1200/ 4873]\n",
      "loss: 0.108202  [ 2400/ 4873]\n",
      "loss: 0.147079  [ 3600/ 4873]\n",
      "loss: 0.276750  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.674     0.552    105\n",
      " disgust     0.554     0.536     0.541    109\n",
      "    fear     0.554     0.474     0.450    80\n",
      "   happy     0.554     0.510     0.605    81\n",
      " neutral     0.554     0.598     0.690    84\n",
      "     sad     0.554     0.494     0.506    87\n",
      "surprise     0.554     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.556     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.048900 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.185652  [ 1200/ 4873]\n",
      "loss: 0.160047  [ 2400/ 4873]\n",
      "loss: 0.171228  [ 3600/ 4873]\n",
      "loss: 0.243778  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.675     0.495    105\n",
      " disgust     0.549     0.524     0.505    109\n",
      "    fear     0.549     0.493     0.450    80\n",
      "   happy     0.549     0.510     0.630    81\n",
      " neutral     0.549     0.648     0.679    84\n",
      "     sad     0.549     0.489     0.506    87\n",
      "surprise     0.549     0.519     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.551     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.067683 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.213043  [ 1200/ 4873]\n",
      "loss: 0.036243  [ 2400/ 4873]\n",
      "loss: 0.092137  [ 3600/ 4873]\n",
      "loss: 0.152641  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.753     0.552    105\n",
      " disgust     0.570     0.621     0.495    109\n",
      "    fear     0.570     0.466     0.512    80\n",
      "   happy     0.570     0.491     0.642    81\n",
      " neutral     0.570     0.727     0.667    84\n",
      "     sad     0.570     0.425     0.586    87\n",
      "surprise     0.570     0.655     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.591     0.574    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 2.895043 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.122059  [ 1200/ 4873]\n",
      "loss: 0.825311  [ 2400/ 4873]\n",
      "loss: 0.238491  [ 3600/ 4873]\n",
      "loss: 0.079871  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.667     0.514    105\n",
      " disgust     0.534     0.517     0.422    109\n",
      "    fear     0.534     0.543     0.550    80\n",
      "   happy     0.534     0.465     0.580    81\n",
      " neutral     0.534     0.675     0.643    84\n",
      "     sad     0.534     0.412     0.540    87\n",
      "surprise     0.534     0.531     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.544     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.077938 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.079456  [ 1200/ 4873]\n",
      "loss: 0.171245  [ 2400/ 4873]\n",
      "loss: 0.098954  [ 3600/ 4873]\n",
      "loss: 0.073348  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.684     0.514    105\n",
      " disgust     0.567     0.564     0.569    109\n",
      "    fear     0.567     0.458     0.475    80\n",
      "   happy     0.567     0.510     0.654    81\n",
      " neutral     0.567     0.652     0.690    84\n",
      "     sad     0.567     0.524     0.506    87\n",
      "surprise     0.567     0.607     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.571     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.900200 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.038412  [ 1200/ 4873]\n",
      "loss: 0.078417  [ 2400/ 4873]\n",
      "loss: 0.084598  [ 3600/ 4873]\n",
      "loss: 0.058692  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.562     0.476    105\n",
      " disgust     0.539     0.496     0.560    109\n",
      "    fear     0.539     0.507     0.475    80\n",
      "   happy     0.539     0.516     0.580    81\n",
      " neutral     0.539     0.683     0.667    84\n",
      "     sad     0.539     0.592     0.483    87\n",
      "surprise     0.539     0.443     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.543     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 3.051915 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.171794  [ 1200/ 4873]\n",
      "loss: 0.087218  [ 2400/ 4873]\n",
      "loss: 0.048133  [ 3600/ 4873]\n",
      "loss: 0.060681  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.620     0.590    105\n",
      " disgust     0.559     0.545     0.550    109\n",
      "    fear     0.559     0.470     0.487    80\n",
      "   happy     0.559     0.521     0.605    81\n",
      " neutral     0.559     0.658     0.619    84\n",
      "     sad     0.559     0.482     0.471    87\n",
      "surprise     0.559     0.644     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.563     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.905321 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.224252  [ 1200/ 4873]\n",
      "loss: 0.023631  [ 2400/ 4873]\n",
      "loss: 0.159246  [ 3600/ 4873]\n",
      "loss: 0.204138  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.638     0.571    105\n",
      " disgust     0.572     0.602     0.514    109\n",
      "    fear     0.572     0.529     0.575    80\n",
      "   happy     0.572     0.521     0.605    81\n",
      " neutral     0.572     0.625     0.714    84\n",
      "     sad     0.572     0.513     0.460    87\n",
      "surprise     0.572     0.559     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.570     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.943378 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.314908  [ 1200/ 4873]\n",
      "loss: 0.099155  [ 2400/ 4873]\n",
      "loss: 0.277628  [ 3600/ 4873]\n",
      "loss: 0.243129  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.645     0.467    105\n",
      " disgust     0.543     0.549     0.514    109\n",
      "    fear     0.543     0.500     0.500    80\n",
      "   happy     0.543     0.481     0.617    81\n",
      " neutral     0.543     0.629     0.667    84\n",
      "     sad     0.543     0.467     0.483    87\n",
      "surprise     0.543     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.546     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.008589 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.374462  [ 1200/ 4873]\n",
      "loss: 0.099960  [ 2400/ 4873]\n",
      "loss: 0.268889  [ 3600/ 4873]\n",
      "loss: 0.225538  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.643     0.514    105\n",
      " disgust     0.552     0.553     0.523    109\n",
      "    fear     0.552     0.465     0.500    80\n",
      "   happy     0.552     0.522     0.580    81\n",
      " neutral     0.552     0.630     0.750    84\n",
      "     sad     0.552     0.512     0.483    87\n",
      "surprise     0.552     0.523     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.550     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.031299 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.043126  [ 1200/ 4873]\n",
      "loss: 0.025138  [ 2400/ 4873]\n",
      "loss: 0.401104  [ 3600/ 4873]\n",
      "loss: 0.033064  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.695     0.543    105\n",
      " disgust     0.557     0.598     0.505    109\n",
      "    fear     0.557     0.500     0.487    80\n",
      "   happy     0.557     0.495     0.593    81\n",
      " neutral     0.557     0.629     0.667    84\n",
      "     sad     0.557     0.452     0.540    87\n",
      "surprise     0.557     0.559     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.561     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.998241 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.021287  [ 1200/ 4873]\n",
      "loss: 0.319081  [ 2400/ 4873]\n",
      "loss: 0.269558  [ 3600/ 4873]\n",
      "loss: 0.088478  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.651     0.533    105\n",
      " disgust     0.559     0.538     0.587    109\n",
      "    fear     0.559     0.527     0.487    80\n",
      "   happy     0.559     0.494     0.543    81\n",
      " neutral     0.559     0.630     0.690    84\n",
      "     sad     0.559     0.545     0.483    87\n",
      "surprise     0.559     0.521     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.558     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.069160 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.095212  [ 1200/ 4873]\n",
      "loss: 0.125853  [ 2400/ 4873]\n",
      "loss: 0.021710  [ 3600/ 4873]\n",
      "loss: 0.032643  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.689     0.486    105\n",
      " disgust     0.557     0.532     0.615    109\n",
      "    fear     0.557     0.438     0.438    80\n",
      "   happy     0.557     0.526     0.617    81\n",
      " neutral     0.557     0.690     0.714    84\n",
      "     sad     0.557     0.494     0.460    87\n",
      "surprise     0.557     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.898561 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.017906  [ 1200/ 4873]\n",
      "loss: 0.032667  [ 2400/ 4873]\n",
      "loss: 0.124890  [ 3600/ 4873]\n",
      "loss: 0.052003  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.640     0.543    105\n",
      " disgust     0.564     0.600     0.550    109\n",
      "    fear     0.564     0.440     0.500    80\n",
      "   happy     0.564     0.588     0.617    81\n",
      " neutral     0.564     0.704     0.679    84\n",
      "     sad     0.564     0.446     0.471    87\n",
      "surprise     0.564     0.542     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.566     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.992833 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.050977  [ 1200/ 4873]\n",
      "loss: 0.054817  [ 2400/ 4873]\n",
      "loss: 0.081851  [ 3600/ 4873]\n",
      "loss: 0.338558  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.621     0.562    105\n",
      " disgust     0.567     0.596     0.569    109\n",
      "    fear     0.567     0.461     0.438    80\n",
      "   happy     0.567     0.558     0.593    81\n",
      " neutral     0.567     0.686     0.702    84\n",
      "     sad     0.567     0.505     0.540    87\n",
      "surprise     0.567     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.563     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.176266 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.044462  [ 1200/ 4873]\n",
      "loss: 0.014149  [ 2400/ 4873]\n",
      "loss: 0.015263  [ 3600/ 4873]\n",
      "loss: 0.182741  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.640     0.543    105\n",
      " disgust     0.543     0.544     0.450    109\n",
      "    fear     0.543     0.512     0.537    80\n",
      "   happy     0.543     0.505     0.593    81\n",
      " neutral     0.543     0.602     0.702    84\n",
      "     sad     0.543     0.457     0.483    87\n",
      "surprise     0.543     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.542     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 2.897949 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.043346  [ 1200/ 4873]\n",
      "loss: 0.103540  [ 2400/ 4873]\n",
      "loss: 0.208442  [ 3600/ 4873]\n",
      "loss: 0.019459  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.616     0.505    105\n",
      " disgust     0.562     0.537     0.606    109\n",
      "    fear     0.562     0.434     0.450    80\n",
      "   happy     0.562     0.556     0.617    81\n",
      " neutral     0.562     0.743     0.655    84\n",
      "     sad     0.562     0.533     0.552    87\n",
      "surprise     0.562     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.567     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.155190 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.143905  [ 1200/ 4873]\n",
      "loss: 0.406293  [ 2400/ 4873]\n",
      "loss: 0.469321  [ 3600/ 4873]\n",
      "loss: 0.035372  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.576     0.543    105\n",
      " disgust     0.569     0.579     0.606    109\n",
      "    fear     0.569     0.526     0.500    80\n",
      "   happy     0.569     0.576     0.605    81\n",
      " neutral     0.569     0.648     0.702    84\n",
      "     sad     0.569     0.519     0.471    87\n",
      "surprise     0.569     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.565     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 3.060665 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.068089  [ 1200/ 4873]\n",
      "loss: 0.092378  [ 2400/ 4873]\n",
      "loss: 0.374530  [ 3600/ 4873]\n",
      "loss: 0.102872  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.570     0.505    105\n",
      " disgust     0.566     0.564     0.569    109\n",
      "    fear     0.566     0.494     0.512    80\n",
      "   happy     0.566     0.613     0.605    81\n",
      " neutral     0.566     0.621     0.702    84\n",
      "     sad     0.566     0.562     0.517    87\n",
      "surprise     0.566     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.564     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.087146 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.010430  [ 1200/ 4873]\n",
      "loss: 0.217366  [ 2400/ 4873]\n",
      "loss: 0.210392  [ 3600/ 4873]\n",
      "loss: 0.097602  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.670     0.562    105\n",
      " disgust     0.570     0.539     0.569    109\n",
      "    fear     0.570     0.562     0.512    80\n",
      "   happy     0.570     0.548     0.568    81\n",
      " neutral     0.570     0.629     0.667    84\n",
      "     sad     0.570     0.516     0.540    87\n",
      "surprise     0.570     0.529     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.570     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 2.953423 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.088899  [ 1200/ 4873]\n",
      "loss: 0.026474  [ 2400/ 4873]\n",
      "loss: 0.108090  [ 3600/ 4873]\n",
      "loss: 0.037334  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.678     0.562    105\n",
      " disgust     0.575     0.532     0.615    109\n",
      "    fear     0.575     0.487     0.487    80\n",
      "   happy     0.575     0.635     0.580    81\n",
      " neutral     0.575     0.714     0.655    84\n",
      "     sad     0.575     0.444     0.552    87\n",
      "surprise     0.575     0.621     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.587     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 3.037988 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.016757  [ 1200/ 4873]\n",
      "loss: 0.518467  [ 2400/ 4873]\n",
      "loss: 0.132279  [ 3600/ 4873]\n",
      "loss: 0.339007  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.638     0.571    105\n",
      " disgust     0.562     0.571     0.587    109\n",
      "    fear     0.562     0.435     0.500    80\n",
      "   happy     0.562     0.590     0.568    81\n",
      " neutral     0.562     0.690     0.690    84\n",
      "     sad     0.562     0.478     0.506    87\n",
      "surprise     0.562     0.534     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.562     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.989322 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.086128  [ 1200/ 4873]\n",
      "loss: 0.072647  [ 2400/ 4873]\n",
      "loss: 0.029678  [ 3600/ 4873]\n",
      "loss: 0.615858  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.624     0.505    105\n",
      " disgust     0.549     0.517     0.550    109\n",
      "    fear     0.549     0.468     0.450    80\n",
      "   happy     0.549     0.495     0.593    81\n",
      " neutral     0.549     0.686     0.702    84\n",
      "     sad     0.549     0.529     0.517    87\n",
      "surprise     0.549     0.531     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.550     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.068125 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.245262  [ 1200/ 4873]\n",
      "loss: 0.085257  [ 2400/ 4873]\n",
      "loss: 0.144225  [ 3600/ 4873]\n",
      "loss: 0.024104  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.659     0.514    105\n",
      " disgust     0.556     0.514     0.523    109\n",
      "    fear     0.556     0.459     0.487    80\n",
      "   happy     0.556     0.522     0.580    81\n",
      " neutral     0.556     0.679     0.679    84\n",
      "     sad     0.556     0.490     0.540    87\n",
      "surprise     0.556     0.613     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.562     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 2.904851 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.133330  [ 1200/ 4873]\n",
      "loss: 0.503275  [ 2400/ 4873]\n",
      "loss: 0.095694  [ 3600/ 4873]\n",
      "loss: 0.010919  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.622     0.533    105\n",
      " disgust     0.552     0.523     0.532    109\n",
      "    fear     0.552     0.506     0.550    80\n",
      "   happy     0.552     0.506     0.543    81\n",
      " neutral     0.552     0.757     0.667    84\n",
      "     sad     0.552     0.465     0.529    87\n",
      "surprise     0.552     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.559     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 2.920843 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.307328  [ 1200/ 4873]\n",
      "loss: 0.061887  [ 2400/ 4873]\n",
      "loss: 0.155560  [ 3600/ 4873]\n",
      "loss: 0.193724  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.675     0.533    105\n",
      " disgust     0.557     0.598     0.560    109\n",
      "    fear     0.557     0.404     0.475    80\n",
      "   happy     0.557     0.531     0.642    81\n",
      " neutral     0.557     0.617     0.690    84\n",
      "     sad     0.557     0.524     0.506    87\n",
      "surprise     0.557     0.564     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.559     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.033792 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.227682  [ 1200/ 4873]\n",
      "loss: 0.172508  [ 2400/ 4873]\n",
      "loss: 0.257759  [ 3600/ 4873]\n",
      "loss: 0.197755  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.588     0.476    105\n",
      " disgust     0.551     0.596     0.596    109\n",
      "    fear     0.551     0.520     0.487    80\n",
      "   happy     0.551     0.500     0.605    81\n",
      " neutral     0.551     0.529     0.655    84\n",
      "     sad     0.551     0.554     0.471    87\n",
      "surprise     0.551     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.551     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.934031 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.009472  [ 1200/ 4873]\n",
      "loss: 0.118870  [ 2400/ 4873]\n",
      "loss: 0.026274  [ 3600/ 4873]\n",
      "loss: 0.230556  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.602     0.476    105\n",
      " disgust     0.559     0.564     0.569    109\n",
      "    fear     0.559     0.494     0.475    80\n",
      "   happy     0.559     0.615     0.593    81\n",
      " neutral     0.559     0.632     0.714    84\n",
      "     sad     0.559     0.568     0.529    87\n",
      "surprise     0.559     0.430     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.558     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.149277 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.050319  [ 1200/ 4873]\n",
      "loss: 0.005055  [ 2400/ 4873]\n",
      "loss: 0.128709  [ 3600/ 4873]\n",
      "loss: 0.034899  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.663     0.562    105\n",
      " disgust     0.579     0.600     0.550    109\n",
      "    fear     0.579     0.494     0.512    80\n",
      "   happy     0.579     0.559     0.642    81\n",
      " neutral     0.579     0.653     0.738    84\n",
      "     sad     0.579     0.500     0.460    87\n",
      "surprise     0.579     0.557     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.575     0.582    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 3.019090 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.032894  [ 1200/ 4873]\n",
      "loss: 0.010337  [ 2400/ 4873]\n",
      "loss: 0.008622  [ 3600/ 4873]\n",
      "loss: 0.076995  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.679     0.543    105\n",
      " disgust     0.551     0.545     0.505    109\n",
      "    fear     0.551     0.469     0.475    80\n",
      "   happy     0.551     0.521     0.617    81\n",
      " neutral     0.551     0.626     0.679    84\n",
      "     sad     0.551     0.462     0.494    87\n",
      "surprise     0.551     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.552     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.946839 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.034271  [ 1200/ 4873]\n",
      "loss: 0.013851  [ 2400/ 4873]\n",
      "loss: 0.052541  [ 3600/ 4873]\n",
      "loss: 0.032836  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.635     0.581    105\n",
      " disgust     0.572     0.600     0.606    109\n",
      "    fear     0.572     0.521     0.475    80\n",
      "   happy     0.572     0.521     0.617    81\n",
      " neutral     0.572     0.611     0.655    84\n",
      "     sad     0.572     0.579     0.506    87\n",
      "surprise     0.572     0.507     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.568     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 2.928465 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.097043  [ 1200/ 4873]\n",
      "loss: 0.139774  [ 2400/ 4873]\n",
      "loss: 0.165065  [ 3600/ 4873]\n",
      "loss: 0.104876  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.606     0.543    105\n",
      " disgust     0.562     0.583     0.550    109\n",
      "    fear     0.562     0.488     0.525    80\n",
      "   happy     0.562     0.590     0.568    81\n",
      " neutral     0.562     0.663     0.655    84\n",
      "     sad     0.562     0.500     0.529    87\n",
      "surprise     0.562     0.500     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.561     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.990682 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.220689  [ 1200/ 4873]\n",
      "loss: 0.258957  [ 2400/ 4873]\n",
      "loss: 0.167005  [ 3600/ 4873]\n",
      "loss: 0.218487  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.625     0.524    105\n",
      " disgust     0.551     0.559     0.523    109\n",
      "    fear     0.551     0.526     0.512    80\n",
      "   happy     0.551     0.500     0.605    81\n",
      " neutral     0.551     0.612     0.714    84\n",
      "     sad     0.551     0.471     0.471    87\n",
      "surprise     0.551     0.559     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.550     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 2.978522 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.043405  [ 1200/ 4873]\n",
      "loss: 0.189143  [ 2400/ 4873]\n",
      "loss: 0.073024  [ 3600/ 4873]\n",
      "loss: 0.039321  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.640     0.524    105\n",
      " disgust     0.554     0.513     0.541    109\n",
      "    fear     0.554     0.444     0.450    80\n",
      "   happy     0.554     0.566     0.580    81\n",
      " neutral     0.554     0.663     0.726    84\n",
      "     sad     0.554     0.494     0.506    87\n",
      "surprise     0.554     0.562     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 2.977225 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.103536  [ 1200/ 4873]\n",
      "loss: 0.032273  [ 2400/ 4873]\n",
      "loss: 0.124286  [ 3600/ 4873]\n",
      "loss: 0.189565  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.613     0.543    105\n",
      " disgust     0.548     0.545     0.495    109\n",
      "    fear     0.548     0.460     0.500    80\n",
      "   happy     0.548     0.547     0.580    81\n",
      " neutral     0.548     0.686     0.702    84\n",
      "     sad     0.548     0.483     0.483    87\n",
      "surprise     0.548     0.486     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.546     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.039737 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.168676  [ 1200/ 4873]\n",
      "loss: 0.020185  [ 2400/ 4873]\n",
      "loss: 0.040652  [ 3600/ 4873]\n",
      "loss: 0.245800  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.671     0.524    105\n",
      " disgust     0.549     0.590     0.450    109\n",
      "    fear     0.549     0.478     0.550    80\n",
      "   happy     0.549     0.434     0.654    81\n",
      " neutral     0.549     0.621     0.702    84\n",
      "     sad     0.549     0.494     0.494    87\n",
      "surprise     0.549     0.653     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.563     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.974910 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.322663  [ 1200/ 4873]\n",
      "loss: 0.012995  [ 2400/ 4873]\n",
      "loss: 0.094041  [ 3600/ 4873]\n",
      "loss: 0.154054  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.590     0.562    105\n",
      " disgust     0.562     0.562     0.541    109\n",
      "    fear     0.562     0.459     0.487    80\n",
      "   happy     0.562     0.556     0.617    81\n",
      " neutral     0.562     0.626     0.738    84\n",
      "     sad     0.562     0.557     0.448    87\n",
      "surprise     0.562     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.560     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 2.961535 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.079881  [ 1200/ 4873]\n",
      "loss: 0.366128  [ 2400/ 4873]\n",
      "loss: 0.438303  [ 3600/ 4873]\n",
      "loss: 0.010239  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.578     0.562    105\n",
      " disgust     0.579     0.560     0.596    109\n",
      "    fear     0.579     0.477     0.525    80\n",
      "   happy     0.579     0.627     0.580    81\n",
      " neutral     0.579     0.645     0.714    84\n",
      "     sad     0.579     0.614     0.494    87\n",
      "surprise     0.579     0.561     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.580     0.579    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 3.008852 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.552697  [ 1200/ 4873]\n",
      "loss: 0.067466  [ 2400/ 4873]\n",
      "loss: 0.226527  [ 3600/ 4873]\n",
      "loss: 0.203509  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.699     0.552    105\n",
      " disgust     0.559     0.509     0.514    109\n",
      "    fear     0.559     0.507     0.475    80\n",
      "   happy     0.559     0.554     0.568    81\n",
      " neutral     0.559     0.727     0.667    84\n",
      "     sad     0.559     0.441     0.563    87\n",
      "surprise     0.559     0.535     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.568     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.048143 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.057372  [ 1200/ 4873]\n",
      "loss: 0.126914  [ 2400/ 4873]\n",
      "loss: 0.071677  [ 3600/ 4873]\n",
      "loss: 0.024772  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.620     0.590    105\n",
      " disgust     0.569     0.604     0.532    109\n",
      "    fear     0.569     0.506     0.562    80\n",
      "   happy     0.569     0.528     0.580    81\n",
      " neutral     0.569     0.620     0.679    84\n",
      "     sad     0.569     0.494     0.471    87\n",
      "surprise     0.569     0.607     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.568     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 2.878611 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.343245  [ 1200/ 4873]\n",
      "loss: 0.178448  [ 2400/ 4873]\n",
      "loss: 0.075961  [ 3600/ 4873]\n",
      "loss: 0.101050  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.648     0.562    105\n",
      " disgust     0.557     0.575     0.560    109\n",
      "    fear     0.557     0.487     0.475    80\n",
      "   happy     0.557     0.517     0.556    81\n",
      " neutral     0.557     0.641     0.702    84\n",
      "     sad     0.557     0.478     0.494    87\n",
      "surprise     0.557     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.554     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 2.972304 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.092750  [ 1200/ 4873]\n",
      "loss: 0.241688  [ 2400/ 4873]\n",
      "loss: 0.121269  [ 3600/ 4873]\n",
      "loss: 0.019329  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.582     0.591     0.619    105\n",
      " disgust     0.582     0.580     0.596    109\n",
      "    fear     0.582     0.466     0.512    80\n",
      "   happy     0.582     0.613     0.568    81\n",
      " neutral     0.582     0.716     0.690    84\n",
      "     sad     0.582     0.542     0.517    87\n",
      "surprise     0.582     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.582     0.583     0.579    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 3.007504 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.038127  [ 1200/ 4873]\n",
      "loss: 0.048870  [ 2400/ 4873]\n",
      "loss: 0.168363  [ 3600/ 4873]\n",
      "loss: 0.053825  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.709     0.581    105\n",
      " disgust     0.575     0.569     0.606    109\n",
      "    fear     0.575     0.513     0.500    80\n",
      "   happy     0.575     0.495     0.605    81\n",
      " neutral     0.575     0.722     0.679    84\n",
      "     sad     0.575     0.459     0.517    87\n",
      "surprise     0.575     0.611     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.583     0.572    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 2.943787 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.039987  [ 1200/ 4873]\n",
      "loss: 0.466008  [ 2400/ 4873]\n",
      "loss: 0.050722  [ 3600/ 4873]\n",
      "loss: 0.055662  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.655     0.524    105\n",
      " disgust     0.567     0.571     0.477    109\n",
      "    fear     0.567     0.432     0.475    80\n",
      "   happy     0.567     0.559     0.642    81\n",
      " neutral     0.567     0.725     0.690    84\n",
      "     sad     0.567     0.460     0.655    87\n",
      "surprise     0.567     0.680     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.583     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.852581 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.025722  [ 1200/ 4873]\n",
      "loss: 0.057388  [ 2400/ 4873]\n",
      "loss: 0.063982  [ 3600/ 4873]\n",
      "loss: 0.090723  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.635     0.514    105\n",
      " disgust     0.559     0.606     0.578    109\n",
      "    fear     0.559     0.494     0.475    80\n",
      "   happy     0.559     0.520     0.630    81\n",
      " neutral     0.559     0.613     0.679    84\n",
      "     sad     0.559     0.458     0.506    87\n",
      "surprise     0.559     0.596     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.560     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.957716 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.125977  [ 1200/ 4873]\n",
      "loss: 0.153796  [ 2400/ 4873]\n",
      "loss: 0.219391  [ 3600/ 4873]\n",
      "loss: 0.039550  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.650     0.495    105\n",
      " disgust     0.546     0.571     0.514    109\n",
      "    fear     0.546     0.468     0.450    80\n",
      "   happy     0.546     0.473     0.654    81\n",
      " neutral     0.546     0.622     0.726    84\n",
      "     sad     0.546     0.459     0.448    87\n",
      "surprise     0.546     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.549     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.064486 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.307755  [ 1200/ 4873]\n",
      "loss: 0.102604  [ 2400/ 4873]\n",
      "loss: 0.423928  [ 3600/ 4873]\n",
      "loss: 0.070779  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.655     0.543    105\n",
      " disgust     0.566     0.581     0.560    109\n",
      "    fear     0.566     0.494     0.475    80\n",
      "   happy     0.566     0.534     0.580    81\n",
      " neutral     0.566     0.645     0.714    84\n",
      "     sad     0.566     0.488     0.483    87\n",
      "surprise     0.566     0.541     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.563     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.069340 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.289650  [ 1200/ 4873]\n",
      "loss: 0.307903  [ 2400/ 4873]\n",
      "loss: 0.104462  [ 3600/ 4873]\n",
      "loss: 0.022206  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.591     0.524    105\n",
      " disgust     0.554     0.540     0.560    109\n",
      "    fear     0.554     0.468     0.450    80\n",
      "   happy     0.554     0.537     0.630    81\n",
      " neutral     0.554     0.702     0.702    84\n",
      "     sad     0.554     0.472     0.483    87\n",
      "surprise     0.554     0.576     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.090473 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.387660  [ 1200/ 4873]\n",
      "loss: 0.047350  [ 2400/ 4873]\n",
      "loss: 0.219115  [ 3600/ 4873]\n",
      "loss: 0.116370  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.573     0.524    105\n",
      " disgust     0.551     0.571     0.514    109\n",
      "    fear     0.551     0.526     0.500    80\n",
      "   happy     0.551     0.521     0.605    81\n",
      " neutral     0.551     0.610     0.726    84\n",
      "     sad     0.551     0.545     0.483    87\n",
      "surprise     0.551     0.478     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.547     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.164489 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.429117  [ 1200/ 4873]\n",
      "loss: 0.032350  [ 2400/ 4873]\n",
      "loss: 0.125772  [ 3600/ 4873]\n",
      "loss: 0.015236  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.654     0.486    105\n",
      " disgust     0.549     0.556     0.505    109\n",
      "    fear     0.549     0.483     0.525    80\n",
      "   happy     0.549     0.505     0.630    81\n",
      " neutral     0.549     0.674     0.690    84\n",
      "     sad     0.549     0.433     0.483    87\n",
      "surprise     0.549     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.555     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.907916 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.052756  [ 1200/ 4873]\n",
      "loss: 0.415786  [ 2400/ 4873]\n",
      "loss: 0.039031  [ 3600/ 4873]\n",
      "loss: 0.132054  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.667     0.590    105\n",
      " disgust     0.569     0.573     0.505    109\n",
      "    fear     0.569     0.476     0.500    80\n",
      "   happy     0.569     0.505     0.630    81\n",
      " neutral     0.569     0.645     0.714    84\n",
      "     sad     0.569     0.530     0.506    87\n",
      "surprise     0.569     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.568     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 3.016502 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.059715  [ 1200/ 4873]\n",
      "loss: 0.049528  [ 2400/ 4873]\n",
      "loss: 0.209834  [ 3600/ 4873]\n",
      "loss: 0.169553  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.622     0.533    105\n",
      " disgust     0.579     0.604     0.587    109\n",
      "    fear     0.579     0.519     0.512    80\n",
      "   happy     0.579     0.548     0.630    81\n",
      " neutral     0.579     0.641     0.702    84\n",
      "     sad     0.579     0.540     0.540    87\n",
      "surprise     0.579     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.576     0.579    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 2.997771 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.615831  [ 1200/ 4873]\n",
      "loss: 0.161974  [ 2400/ 4873]\n",
      "loss: 0.022691  [ 3600/ 4873]\n",
      "loss: 0.162110  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.587     0.581    105\n",
      " disgust     0.566     0.560     0.560    109\n",
      "    fear     0.566     0.488     0.500    80\n",
      "   happy     0.566     0.588     0.580    81\n",
      " neutral     0.566     0.634     0.702    84\n",
      "     sad     0.566     0.553     0.483    87\n",
      "surprise     0.566     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.563     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.070981 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.051475  [ 1200/ 4873]\n",
      "loss: 0.115278  [ 2400/ 4873]\n",
      "loss: 0.030882  [ 3600/ 4873]\n",
      "loss: 0.096879  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.628     0.562    105\n",
      " disgust     0.554     0.536     0.550    109\n",
      "    fear     0.554     0.460     0.500    80\n",
      "   happy     0.554     0.560     0.580    81\n",
      " neutral     0.554     0.663     0.679    84\n",
      "     sad     0.554     0.468     0.506    87\n",
      "surprise     0.554     0.585     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.557     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.080870 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.256699  [ 1200/ 4873]\n",
      "loss: 0.024700  [ 2400/ 4873]\n",
      "loss: 0.120728  [ 3600/ 4873]\n",
      "loss: 0.052129  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.630     0.486    105\n",
      " disgust     0.567     0.532     0.615    109\n",
      "    fear     0.567     0.520     0.487    80\n",
      "   happy     0.567     0.573     0.630    81\n",
      " neutral     0.567     0.757     0.667    84\n",
      "     sad     0.567     0.485     0.563    87\n",
      "surprise     0.567     0.516     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.573     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.010891 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.054659  [ 1200/ 4873]\n",
      "loss: 0.024456  [ 2400/ 4873]\n",
      "loss: 0.020508  [ 3600/ 4873]\n",
      "loss: 0.311009  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.663     0.543    105\n",
      " disgust     0.564     0.513     0.550    109\n",
      "    fear     0.564     0.545     0.525    80\n",
      "   happy     0.564     0.505     0.593    81\n",
      " neutral     0.564     0.690     0.690    84\n",
      "     sad     0.564     0.477     0.483    87\n",
      "surprise     0.564     0.587     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.569     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.033880 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.039468  [ 1200/ 4873]\n",
      "loss: 0.042114  [ 2400/ 4873]\n",
      "loss: 0.097968  [ 3600/ 4873]\n",
      "loss: 0.381656  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.606     0.543    105\n",
      " disgust     0.561     0.512     0.569    109\n",
      "    fear     0.561     0.526     0.512    80\n",
      "   happy     0.561     0.511     0.580    81\n",
      " neutral     0.561     0.757     0.667    84\n",
      "     sad     0.561     0.506     0.517    87\n",
      "surprise     0.561     0.548     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.567     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.017710 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.575603  [ 1200/ 4873]\n",
      "loss: 0.075448  [ 2400/ 4873]\n",
      "loss: 0.011876  [ 3600/ 4873]\n",
      "loss: 0.022817  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.617     0.476    105\n",
      " disgust     0.557     0.571     0.550    109\n",
      "    fear     0.557     0.518     0.537    80\n",
      "   happy     0.557     0.510     0.642    81\n",
      " neutral     0.557     0.706     0.714    84\n",
      "     sad     0.557     0.448     0.494    87\n",
      "surprise     0.557     0.552     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.024084 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.201726  [ 1200/ 4873]\n",
      "loss: 0.111742  [ 2400/ 4873]\n",
      "loss: 0.313158  [ 3600/ 4873]\n",
      "loss: 0.069137  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.641     0.476    105\n",
      " disgust     0.552     0.553     0.578    109\n",
      "    fear     0.552     0.569     0.463    80\n",
      "   happy     0.552     0.500     0.630    81\n",
      " neutral     0.552     0.611     0.690    84\n",
      "     sad     0.552     0.479     0.517    87\n",
      "surprise     0.552     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.555     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.111050 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.098217  [ 1200/ 4873]\n",
      "loss: 0.540916  [ 2400/ 4873]\n",
      "loss: 0.069865  [ 3600/ 4873]\n",
      "loss: 0.086882  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.655     0.543    105\n",
      " disgust     0.549     0.500     0.495    109\n",
      "    fear     0.549     0.500     0.500    80\n",
      "   happy     0.549     0.554     0.568    81\n",
      " neutral     0.549     0.700     0.667    84\n",
      "     sad     0.549     0.473     0.506    87\n",
      "surprise     0.549     0.481     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.552     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.056483 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.596020  [ 1200/ 4873]\n",
      "loss: 0.037048  [ 2400/ 4873]\n",
      "loss: 0.058240  [ 3600/ 4873]\n",
      "loss: 0.011306  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.636     0.533    105\n",
      " disgust     0.561     0.569     0.569    109\n",
      "    fear     0.561     0.494     0.500    80\n",
      "   happy     0.561     0.550     0.543    81\n",
      " neutral     0.561     0.652     0.714    84\n",
      "     sad     0.561     0.505     0.540    87\n",
      "surprise     0.561     0.493     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.557     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.124141 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.137192  [ 1200/ 4873]\n",
      "loss: 0.236027  [ 2400/ 4873]\n",
      "loss: 0.037745  [ 3600/ 4873]\n",
      "loss: 0.022259  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.632     0.524    105\n",
      " disgust     0.574     0.565     0.596    109\n",
      "    fear     0.574     0.448     0.487    80\n",
      "   happy     0.574     0.581     0.617    81\n",
      " neutral     0.574     0.722     0.679    84\n",
      "     sad     0.574     0.543     0.506    87\n",
      "surprise     0.574     0.533     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.575     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 3.031873 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.178587  [ 1200/ 4873]\n",
      "loss: 0.039209  [ 2400/ 4873]\n",
      "loss: 0.029653  [ 3600/ 4873]\n",
      "loss: 0.425462  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.602     0.533    105\n",
      " disgust     0.549     0.542     0.532    109\n",
      "    fear     0.549     0.500     0.487    80\n",
      "   happy     0.549     0.485     0.605    81\n",
      " neutral     0.549     0.663     0.679    84\n",
      "     sad     0.549     0.506     0.471    87\n",
      "surprise     0.549     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.549     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.034406 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.015109  [ 1200/ 4873]\n",
      "loss: 0.360810  [ 2400/ 4873]\n",
      "loss: 0.099275  [ 3600/ 4873]\n",
      "loss: 0.305034  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.614     0.486    105\n",
      " disgust     0.549     0.560     0.514    109\n",
      "    fear     0.549     0.430     0.500    80\n",
      "   happy     0.549     0.562     0.617    81\n",
      " neutral     0.549     0.709     0.667    84\n",
      "     sad     0.549     0.453     0.552    87\n",
      "surprise     0.549     0.567     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.556     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.097199 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.396144  [ 1200/ 4873]\n",
      "loss: 0.028204  [ 2400/ 4873]\n",
      "loss: 0.025207  [ 3600/ 4873]\n",
      "loss: 0.216527  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.612     0.571    105\n",
      " disgust     0.566     0.564     0.569    109\n",
      "    fear     0.566     0.451     0.463    80\n",
      "   happy     0.566     0.557     0.605    81\n",
      " neutral     0.566     0.695     0.679    84\n",
      "     sad     0.566     0.506     0.517    87\n",
      "surprise     0.566     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.565     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.884337 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.117271  [ 1200/ 4873]\n",
      "loss: 0.082253  [ 2400/ 4873]\n",
      "loss: 0.028400  [ 3600/ 4873]\n",
      "loss: 0.008960  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.613     0.543    105\n",
      " disgust     0.552     0.546     0.541    109\n",
      "    fear     0.552     0.500     0.537    80\n",
      "   happy     0.552     0.545     0.593    81\n",
      " neutral     0.552     0.679     0.679    84\n",
      "     sad     0.552     0.443     0.448    87\n",
      "surprise     0.552     0.540     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.552     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.095623 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.061509  [ 1200/ 4873]\n",
      "loss: 0.278129  [ 2400/ 4873]\n",
      "loss: 0.090293  [ 3600/ 4873]\n",
      "loss: 0.062829  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.584     0.646     0.505    105\n",
      " disgust     0.584     0.591     0.596    109\n",
      "    fear     0.584     0.526     0.500    80\n",
      "   happy     0.584     0.532     0.617    81\n",
      " neutral     0.584     0.690     0.714    84\n",
      "     sad     0.584     0.532     0.575    87\n",
      "surprise     0.584     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.584     0.583     0.586    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 3.034002 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.280485  [ 1200/ 4873]\n",
      "loss: 0.032108  [ 2400/ 4873]\n",
      "loss: 0.130619  [ 3600/ 4873]\n",
      "loss: 0.044361  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.648     0.543    105\n",
      " disgust     0.554     0.589     0.578    109\n",
      "    fear     0.554     0.494     0.500    80\n",
      "   happy     0.554     0.522     0.580    81\n",
      " neutral     0.554     0.720     0.643    84\n",
      "     sad     0.554     0.412     0.483    87\n",
      "surprise     0.554     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.558     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.114675 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.601360  [ 1200/ 4873]\n",
      "loss: 0.094399  [ 2400/ 4873]\n",
      "loss: 0.007941  [ 3600/ 4873]\n",
      "loss: 0.024406  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.618     0.448    105\n",
      " disgust     0.544     0.553     0.578    109\n",
      "    fear     0.544     0.468     0.463    80\n",
      "   happy     0.544     0.490     0.605    81\n",
      " neutral     0.544     0.709     0.667    84\n",
      "     sad     0.544     0.488     0.483    87\n",
      "surprise     0.544     0.500     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.547     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.042514 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.256211  [ 1200/ 4873]\n",
      "loss: 0.037972  [ 2400/ 4873]\n",
      "loss: 0.673573  [ 3600/ 4873]\n",
      "loss: 0.323960  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.594     0.543    105\n",
      " disgust     0.564     0.558     0.532    109\n",
      "    fear     0.564     0.519     0.512    80\n",
      "   happy     0.564     0.526     0.630    81\n",
      " neutral     0.564     0.682     0.714    84\n",
      "     sad     0.564     0.466     0.471    87\n",
      "surprise     0.564     0.621     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.566     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.883219 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.055054  [ 1200/ 4873]\n",
      "loss: 0.120777  [ 2400/ 4873]\n",
      "loss: 0.062673  [ 3600/ 4873]\n",
      "loss: 0.125021  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.614     0.486    105\n",
      " disgust     0.546     0.514     0.495    109\n",
      "    fear     0.546     0.449     0.500    80\n",
      "   happy     0.546     0.570     0.605    81\n",
      " neutral     0.546     0.704     0.679    84\n",
      "     sad     0.546     0.446     0.517    87\n",
      "surprise     0.546     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.552     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.072219 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.373262  [ 1200/ 4873]\n",
      "loss: 0.020045  [ 2400/ 4873]\n",
      "loss: 0.033277  [ 3600/ 4873]\n",
      "loss: 0.115884  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.619     0.495    105\n",
      " disgust     0.554     0.517     0.569    109\n",
      "    fear     0.554     0.476     0.487    80\n",
      "   happy     0.554     0.576     0.605    81\n",
      " neutral     0.554     0.648     0.702    84\n",
      "     sad     0.554     0.488     0.460    87\n",
      "surprise     0.554     0.561     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.064855 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.298521  [ 1200/ 4873]\n",
      "loss: 0.251108  [ 2400/ 4873]\n",
      "loss: 0.047952  [ 3600/ 4873]\n",
      "loss: 0.098615  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.614     0.486    105\n",
      " disgust     0.536     0.591     0.505    109\n",
      "    fear     0.536     0.432     0.475    80\n",
      "   happy     0.536     0.495     0.605    81\n",
      " neutral     0.536     0.637     0.690    84\n",
      "     sad     0.536     0.476     0.460    87\n",
      "surprise     0.536     0.500     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.535     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 3.078199 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.182635  [ 1200/ 4873]\n",
      "loss: 0.098753  [ 2400/ 4873]\n",
      "loss: 0.020307  [ 3600/ 4873]\n",
      "loss: 0.070631  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.646     0.505    105\n",
      " disgust     0.552     0.566     0.550    109\n",
      "    fear     0.552     0.482     0.500    80\n",
      "   happy     0.552     0.536     0.556    81\n",
      " neutral     0.552     0.663     0.679    84\n",
      "     sad     0.552     0.463     0.506    87\n",
      "surprise     0.552     0.514     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.553     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.170031 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.100715  [ 1200/ 4873]\n",
      "loss: 0.056026  [ 2400/ 4873]\n",
      "loss: 0.066894  [ 3600/ 4873]\n",
      "loss: 0.033499  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.593     0.514    105\n",
      " disgust     0.548     0.573     0.505    109\n",
      "    fear     0.548     0.549     0.487    80\n",
      "   happy     0.548     0.517     0.556    81\n",
      " neutral     0.548     0.640     0.679    84\n",
      "     sad     0.548     0.438     0.529    87\n",
      "surprise     0.548     0.535     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.550     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.103227 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.258867  [ 1200/ 4873]\n",
      "loss: 0.168292  [ 2400/ 4873]\n",
      "loss: 0.458635  [ 3600/ 4873]\n",
      "loss: 0.053836  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.609     0.505    105\n",
      " disgust     0.548     0.584     0.541    109\n",
      "    fear     0.548     0.529     0.463    80\n",
      "   happy     0.548     0.505     0.617    81\n",
      " neutral     0.548     0.644     0.667    84\n",
      "     sad     0.548     0.427     0.471    87\n",
      "surprise     0.548     0.543     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.549     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.085953 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.101801  [ 1200/ 4873]\n",
      "loss: 0.052152  [ 2400/ 4873]\n",
      "loss: 0.027008  [ 3600/ 4873]\n",
      "loss: 0.064977  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.628     0.514    105\n",
      " disgust     0.557     0.621     0.541    109\n",
      "    fear     0.557     0.500     0.475    80\n",
      "   happy     0.557     0.521     0.605    81\n",
      " neutral     0.557     0.679     0.679    84\n",
      "     sad     0.557     0.459     0.517    87\n",
      "surprise     0.557     0.494     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.557     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.215809 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.068385  [ 1200/ 4873]\n",
      "loss: 0.016227  [ 2400/ 4873]\n",
      "loss: 0.082207  [ 3600/ 4873]\n",
      "loss: 0.005738  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.671     0.543    105\n",
      " disgust     0.564     0.624     0.532    109\n",
      "    fear     0.564     0.489     0.550    80\n",
      "   happy     0.564     0.520     0.630    81\n",
      " neutral     0.564     0.655     0.655    84\n",
      "     sad     0.564     0.455     0.517    87\n",
      "surprise     0.564     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.567     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.064574 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.009059  [ 1200/ 4873]\n",
      "loss: 0.307794  [ 2400/ 4873]\n",
      "loss: 0.184639  [ 3600/ 4873]\n",
      "loss: 0.038137  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.577     0.648     0.543    105\n",
      " disgust     0.577     0.586     0.596    109\n",
      "    fear     0.577     0.536     0.463    80\n",
      "   happy     0.577     0.581     0.617    81\n",
      " neutral     0.577     0.744     0.690    84\n",
      "     sad     0.577     0.451     0.529    87\n",
      "surprise     0.577     0.513     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.577     0.580     0.578    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 3.225895 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.022026  [ 1200/ 4873]\n",
      "loss: 0.034742  [ 2400/ 4873]\n",
      "loss: 0.075888  [ 3600/ 4873]\n",
      "loss: 0.147532  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.618     0.524    105\n",
      " disgust     0.562     0.614     0.569    109\n",
      "    fear     0.562     0.474     0.450    80\n",
      "   happy     0.562     0.480     0.605    81\n",
      " neutral     0.562     0.678     0.702    84\n",
      "     sad     0.562     0.529     0.529    87\n",
      "surprise     0.562     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.560     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.069251 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.032479  [ 1200/ 4873]\n",
      "loss: 0.053177  [ 2400/ 4873]\n",
      "loss: 0.163839  [ 3600/ 4873]\n",
      "loss: 0.123422  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.604     0.524    105\n",
      " disgust     0.557     0.590     0.569    109\n",
      "    fear     0.557     0.487     0.475    80\n",
      "   happy     0.557     0.516     0.580    81\n",
      " neutral     0.557     0.670     0.702    84\n",
      "     sad     0.557     0.483     0.494    87\n",
      "surprise     0.557     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.555     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.169801 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.016827  [ 1200/ 4873]\n",
      "loss: 0.109625  [ 2400/ 4873]\n",
      "loss: 0.021464  [ 3600/ 4873]\n",
      "loss: 0.063456  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.633     0.476    105\n",
      " disgust     0.543     0.571     0.477    109\n",
      "    fear     0.543     0.487     0.487    80\n",
      "   happy     0.543     0.516     0.593    81\n",
      " neutral     0.543     0.667     0.690    84\n",
      "     sad     0.543     0.455     0.529    87\n",
      "surprise     0.543     0.481     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.544     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.107030 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.075758  [ 1200/ 4873]\n",
      "loss: 0.285234  [ 2400/ 4873]\n",
      "loss: 0.251669  [ 3600/ 4873]\n",
      "loss: 0.481232  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.622     0.486    105\n",
      " disgust     0.548     0.562     0.541    109\n",
      "    fear     0.548     0.449     0.500    80\n",
      "   happy     0.548     0.551     0.605    81\n",
      " neutral     0.548     0.674     0.690    84\n",
      "     sad     0.548     0.426     0.494    87\n",
      "surprise     0.548     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.553     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.015911 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.015076  [ 1200/ 4873]\n",
      "loss: 0.012774  [ 2400/ 4873]\n",
      "loss: 0.315796  [ 3600/ 4873]\n",
      "loss: 0.191730  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.667     0.533    105\n",
      " disgust     0.559     0.543     0.578    109\n",
      "    fear     0.559     0.469     0.562    80\n",
      "   happy     0.559     0.562     0.556    81\n",
      " neutral     0.559     0.687     0.679    84\n",
      "     sad     0.559     0.494     0.460    87\n",
      "surprise     0.559     0.500     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.560     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.016614 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.107332  [ 1200/ 4873]\n",
      "loss: 0.177795  [ 2400/ 4873]\n",
      "loss: 0.067049  [ 3600/ 4873]\n",
      "loss: 0.092342  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.625     0.524    105\n",
      " disgust     0.554     0.508     0.606    109\n",
      "    fear     0.554     0.451     0.463    80\n",
      "   happy     0.554     0.576     0.605    81\n",
      " neutral     0.554     0.718     0.667    84\n",
      "     sad     0.554     0.471     0.460    87\n",
      "surprise     0.554     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.559     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.266003 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.015264  [ 1200/ 4873]\n",
      "loss: 0.435450  [ 2400/ 4873]\n",
      "loss: 0.010445  [ 3600/ 4873]\n",
      "loss: 0.783371  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.655     0.543    105\n",
      " disgust     0.552     0.484     0.541    109\n",
      "    fear     0.552     0.500     0.463    80\n",
      "   happy     0.552     0.573     0.580    81\n",
      " neutral     0.552     0.663     0.726    84\n",
      "     sad     0.552     0.463     0.425    87\n",
      "surprise     0.552     0.534     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.553     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.152465 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.413746  [ 1200/ 4873]\n",
      "loss: 0.017148  [ 2400/ 4873]\n",
      "loss: 0.188862  [ 3600/ 4873]\n",
      "loss: 0.175839  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.609     0.505    105\n",
      " disgust     0.541     0.530     0.560    109\n",
      "    fear     0.541     0.449     0.500    80\n",
      "   happy     0.541     0.517     0.556    81\n",
      " neutral     0.541     0.655     0.679    84\n",
      "     sad     0.541     0.471     0.471    87\n",
      "surprise     0.541     0.569     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.543     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 3.195342 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.012980  [ 1200/ 4873]\n",
      "loss: 0.028236  [ 2400/ 4873]\n",
      "loss: 0.310597  [ 3600/ 4873]\n",
      "loss: 0.019524  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.614     0.514    105\n",
      " disgust     0.541     0.547     0.477    109\n",
      "    fear     0.541     0.479     0.425    80\n",
      "   happy     0.541     0.545     0.593    81\n",
      " neutral     0.541     0.700     0.667    84\n",
      "     sad     0.541     0.440     0.552    87\n",
      "surprise     0.541     0.481     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.544     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 3.196510 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.214109  [ 1200/ 4873]\n",
      "loss: 0.542687  [ 2400/ 4873]\n",
      "loss: 0.022960  [ 3600/ 4873]\n",
      "loss: 0.461720  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.530     0.505    105\n",
      " disgust     0.557     0.583     0.514    109\n",
      "    fear     0.557     0.484     0.575    80\n",
      "   happy     0.557     0.548     0.630    81\n",
      " neutral     0.557     0.731     0.679    84\n",
      "     sad     0.557     0.512     0.483    87\n",
      "surprise     0.557     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.137087 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.140961  [ 1200/ 4873]\n",
      "loss: 0.031480  [ 2400/ 4873]\n",
      "loss: 0.020246  [ 3600/ 4873]\n",
      "loss: 0.173030  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.663     0.524    105\n",
      " disgust     0.566     0.508     0.560    109\n",
      "    fear     0.566     0.527     0.487    80\n",
      "   happy     0.566     0.570     0.654    81\n",
      " neutral     0.566     0.716     0.690    84\n",
      "     sad     0.566     0.457     0.483    87\n",
      "surprise     0.566     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.570     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.005818 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.207083  [ 1200/ 4873]\n",
      "loss: 0.387713  [ 2400/ 4873]\n",
      "loss: 0.070393  [ 3600/ 4873]\n",
      "loss: 0.061394  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.570     0.543    105\n",
      " disgust     0.561     0.536     0.541    109\n",
      "    fear     0.561     0.506     0.512    80\n",
      "   happy     0.561     0.570     0.605    81\n",
      " neutral     0.561     0.695     0.679    84\n",
      "     sad     0.561     0.522     0.540    87\n",
      "surprise     0.561     0.525     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.561     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.132540 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.027824  [ 1200/ 4873]\n",
      "loss: 0.130590  [ 2400/ 4873]\n",
      "loss: 0.025933  [ 3600/ 4873]\n",
      "loss: 0.020785  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.646     0.486    105\n",
      " disgust     0.543     0.519     0.514    109\n",
      "    fear     0.543     0.493     0.425    80\n",
      "   happy     0.543     0.486     0.630    81\n",
      " neutral     0.543     0.674     0.714    84\n",
      "     sad     0.543     0.479     0.517    87\n",
      "surprise     0.543     0.515     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.544     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.163099 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.027828  [ 1200/ 4873]\n",
      "loss: 0.075989  [ 2400/ 4873]\n",
      "loss: 0.052619  [ 3600/ 4873]\n",
      "loss: 0.134719  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.580     0.486    105\n",
      " disgust     0.549     0.514     0.514    109\n",
      "    fear     0.549     0.440     0.500    80\n",
      "   happy     0.549     0.603     0.580    81\n",
      " neutral     0.549     0.750     0.714    84\n",
      "     sad     0.549     0.451     0.529    87\n",
      "surprise     0.549     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.557     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.173683 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.069535  [ 1200/ 4873]\n",
      "loss: 0.062666  [ 2400/ 4873]\n",
      "loss: 0.296412  [ 3600/ 4873]\n",
      "loss: 0.102336  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.632     0.524    105\n",
      " disgust     0.554     0.513     0.532    109\n",
      "    fear     0.554     0.477     0.512    80\n",
      "   happy     0.554     0.545     0.593    81\n",
      " neutral     0.554     0.699     0.690    84\n",
      "     sad     0.554     0.500     0.483    87\n",
      "surprise     0.554     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.231619 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.064881  [ 1200/ 4873]\n",
      "loss: 0.057229  [ 2400/ 4873]\n",
      "loss: 0.016506  [ 3600/ 4873]\n",
      "loss: 0.017647  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.625     0.524    105\n",
      " disgust     0.562     0.583     0.550    109\n",
      "    fear     0.562     0.468     0.550    80\n",
      "   happy     0.562     0.593     0.593    81\n",
      " neutral     0.562     0.644     0.690    84\n",
      "     sad     0.562     0.494     0.483    87\n",
      "surprise     0.562     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.561     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.154025 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.008212  [ 1200/ 4873]\n",
      "loss: 1.756538  [ 2400/ 4873]\n",
      "loss: 0.247709  [ 3600/ 4873]\n",
      "loss: 0.060044  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.663     0.543    105\n",
      " disgust     0.572     0.596     0.596    109\n",
      "    fear     0.572     0.500     0.537    80\n",
      "   happy     0.572     0.560     0.580    81\n",
      " neutral     0.572     0.667     0.667    84\n",
      "     sad     0.572     0.441     0.517    87\n",
      "surprise     0.572     0.610     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.577     0.572    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 3.060772 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.123698  [ 1200/ 4873]\n",
      "loss: 0.187050  [ 2400/ 4873]\n",
      "loss: 0.089009  [ 3600/ 4873]\n",
      "loss: 0.153288  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.594     0.543    105\n",
      " disgust     0.566     0.566     0.550    109\n",
      "    fear     0.566     0.556     0.500    80\n",
      "   happy     0.566     0.603     0.580    81\n",
      " neutral     0.566     0.626     0.738    84\n",
      "     sad     0.566     0.462     0.483    87\n",
      "surprise     0.566     0.544     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.564     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.088383 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.180455  [ 1200/ 4873]\n",
      "loss: 0.095807  [ 2400/ 4873]\n",
      "loss: 0.022394  [ 3600/ 4873]\n",
      "loss: 0.415533  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.605     0.495    105\n",
      " disgust     0.557     0.565     0.560    109\n",
      "    fear     0.557     0.472     0.525    80\n",
      "   happy     0.557     0.521     0.605    81\n",
      " neutral     0.557     0.705     0.655    84\n",
      "     sad     0.557     0.474     0.529    87\n",
      "surprise     0.557     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.564     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.071246 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.021433  [ 1200/ 4873]\n",
      "loss: 0.148096  [ 2400/ 4873]\n",
      "loss: 0.174049  [ 3600/ 4873]\n",
      "loss: 0.319142  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.615     0.457    105\n",
      " disgust     0.544     0.514     0.495    109\n",
      "    fear     0.544     0.449     0.550    80\n",
      "   happy     0.544     0.575     0.617    81\n",
      " neutral     0.544     0.621     0.702    84\n",
      "     sad     0.544     0.494     0.483    87\n",
      "surprise     0.544     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.548     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.089755 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.063087  [ 1200/ 4873]\n",
      "loss: 0.046069  [ 2400/ 4873]\n",
      "loss: 0.037525  [ 3600/ 4873]\n",
      "loss: 0.086457  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.650     0.495    105\n",
      " disgust     0.544     0.541     0.541    109\n",
      "    fear     0.544     0.456     0.512    80\n",
      "   happy     0.544     0.588     0.580    81\n",
      " neutral     0.544     0.644     0.690    84\n",
      "     sad     0.544     0.455     0.460    87\n",
      "surprise     0.544     0.479     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.545     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.231299 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.011891  [ 1200/ 4873]\n",
      "loss: 1.016869  [ 2400/ 4873]\n",
      "loss: 0.049042  [ 3600/ 4873]\n",
      "loss: 0.061038  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.671     0.467    105\n",
      " disgust     0.549     0.579     0.569    109\n",
      "    fear     0.549     0.453     0.487    80\n",
      "   happy     0.549     0.522     0.580    81\n",
      " neutral     0.549     0.670     0.726    84\n",
      "     sad     0.549     0.457     0.483    87\n",
      "surprise     0.549     0.493     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.549     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.133010 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.055589  [ 1200/ 4873]\n",
      "loss: 0.138117  [ 2400/ 4873]\n",
      "loss: 0.396082  [ 3600/ 4873]\n",
      "loss: 0.284057  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.667     0.571    105\n",
      " disgust     0.570     0.637     0.532    109\n",
      "    fear     0.570     0.443     0.487    80\n",
      "   happy     0.570     0.520     0.642    81\n",
      " neutral     0.570     0.667     0.738    84\n",
      "     sad     0.570     0.458     0.506    87\n",
      "surprise     0.570     0.635     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.575     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 3.003074 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.099504  [ 1200/ 4873]\n",
      "loss: 0.094779  [ 2400/ 4873]\n",
      "loss: 0.073460  [ 3600/ 4873]\n",
      "loss: 0.402759  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.613     0.543    105\n",
      " disgust     0.554     0.530     0.569    109\n",
      "    fear     0.554     0.469     0.475    80\n",
      "   happy     0.554     0.671     0.580    81\n",
      " neutral     0.554     0.633     0.679    84\n",
      "     sad     0.554     0.461     0.471    87\n",
      "surprise     0.554     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.556     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.248391 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.028156  [ 1200/ 4873]\n",
      "loss: 0.209307  [ 2400/ 4873]\n",
      "loss: 0.101953  [ 3600/ 4873]\n",
      "loss: 0.355449  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.658     0.495    105\n",
      " disgust     0.541     0.584     0.541    109\n",
      "    fear     0.541     0.465     0.500    80\n",
      "   happy     0.541     0.489     0.556    81\n",
      " neutral     0.541     0.705     0.655    84\n",
      "     sad     0.541     0.424     0.483    87\n",
      "surprise     0.541     0.493     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.546     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 3.320196 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.187836  [ 1200/ 4873]\n",
      "loss: 0.029290  [ 2400/ 4873]\n",
      "loss: 0.087465  [ 3600/ 4873]\n",
      "loss: 0.288405  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.671     0.543    105\n",
      " disgust     0.546     0.509     0.514    109\n",
      "    fear     0.546     0.526     0.512    80\n",
      "   happy     0.546     0.528     0.580    81\n",
      " neutral     0.546     0.644     0.690    84\n",
      "     sad     0.546     0.456     0.471    87\n",
      "surprise     0.546     0.485     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.546     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.202954 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.032039  [ 1200/ 4873]\n",
      "loss: 0.138630  [ 2400/ 4873]\n",
      "loss: 0.055749  [ 3600/ 4873]\n",
      "loss: 0.414635  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.578     0.457    105\n",
      " disgust     0.567     0.618     0.624    109\n",
      "    fear     0.567     0.533     0.500    80\n",
      "   happy     0.567     0.540     0.580    81\n",
      " neutral     0.567     0.652     0.690    84\n",
      "     sad     0.567     0.535     0.529    87\n",
      "surprise     0.567     0.487     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.563     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.177366 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.087380  [ 1200/ 4873]\n",
      "loss: 0.012544  [ 2400/ 4873]\n",
      "loss: 0.022661  [ 3600/ 4873]\n",
      "loss: 0.052283  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.602     0.533    105\n",
      " disgust     0.556     0.527     0.633    109\n",
      "    fear     0.556     0.392     0.500    80\n",
      "   happy     0.556     0.687     0.568    81\n",
      " neutral     0.556     0.696     0.655    84\n",
      "     sad     0.556     0.534     0.448    87\n",
      "surprise     0.556     0.523     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.566     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.199562 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.018435  [ 1200/ 4873]\n",
      "loss: 0.280790  [ 2400/ 4873]\n",
      "loss: 0.156327  [ 3600/ 4873]\n",
      "loss: 0.052240  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.692     0.514    105\n",
      " disgust     0.552     0.566     0.514    109\n",
      "    fear     0.552     0.494     0.512    80\n",
      "   happy     0.552     0.480     0.580    81\n",
      " neutral     0.552     0.678     0.702    84\n",
      "     sad     0.552     0.431     0.506    87\n",
      "surprise     0.552     0.571     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.559     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.006673 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.067269  [ 1200/ 4873]\n",
      "loss: 0.109986  [ 2400/ 4873]\n",
      "loss: 0.170799  [ 3600/ 4873]\n",
      "loss: 0.069192  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.600     0.486    105\n",
      " disgust     0.552     0.541     0.550    109\n",
      "    fear     0.552     0.506     0.500    80\n",
      "   happy     0.552     0.527     0.605    81\n",
      " neutral     0.552     0.679     0.655    84\n",
      "     sad     0.552     0.505     0.529    87\n",
      "surprise     0.552     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.553     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.028862 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.042635  [ 1200/ 4873]\n",
      "loss: 0.014272  [ 2400/ 4873]\n",
      "loss: 0.137323  [ 3600/ 4873]\n",
      "loss: 0.123857  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.642     0.495    105\n",
      " disgust     0.556     0.550     0.550    109\n",
      "    fear     0.556     0.483     0.537    80\n",
      "   happy     0.556     0.527     0.593    81\n",
      " neutral     0.556     0.724     0.655    84\n",
      "     sad     0.556     0.426     0.529    87\n",
      "surprise     0.556     0.625     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.568     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.030338 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.031117  [ 1200/ 4873]\n",
      "loss: 0.818475  [ 2400/ 4873]\n",
      "loss: 0.118459  [ 3600/ 4873]\n",
      "loss: 0.135551  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.651     0.533    105\n",
      " disgust     0.552     0.555     0.560    109\n",
      "    fear     0.552     0.488     0.512    80\n",
      "   happy     0.552     0.562     0.556    81\n",
      " neutral     0.552     0.641     0.702    84\n",
      "     sad     0.552     0.452     0.483    87\n",
      "surprise     0.552     0.508     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.551     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.030984 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.220584  [ 1200/ 4873]\n",
      "loss: 0.023525  [ 2400/ 4873]\n",
      "loss: 0.137564  [ 3600/ 4873]\n",
      "loss: 0.071916  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.628     0.514    105\n",
      " disgust     0.564     0.531     0.624    109\n",
      "    fear     0.564     0.567     0.475    80\n",
      "   happy     0.564     0.548     0.630    81\n",
      " neutral     0.564     0.624     0.690    84\n",
      "     sad     0.564     0.500     0.494    87\n",
      "surprise     0.564     0.561     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.566     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.116890 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.008911  [ 1200/ 4873]\n",
      "loss: 0.013610  [ 2400/ 4873]\n",
      "loss: 0.100043  [ 3600/ 4873]\n",
      "loss: 0.177932  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.725     0.476    105\n",
      " disgust     0.556     0.596     0.541    109\n",
      "    fear     0.556     0.597     0.463    80\n",
      "   happy     0.556     0.450     0.605    81\n",
      " neutral     0.556     0.581     0.726    84\n",
      "     sad     0.556     0.474     0.517    87\n",
      "surprise     0.556     0.535     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.565     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.003878 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.101483  [ 1200/ 4873]\n",
      "loss: 0.051998  [ 2400/ 4873]\n",
      "loss: 0.701734  [ 3600/ 4873]\n",
      "loss: 0.011630  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.600     0.571    105\n",
      " disgust     0.566     0.527     0.541    109\n",
      "    fear     0.566     0.429     0.562    80\n",
      "   happy     0.566     0.620     0.605    81\n",
      " neutral     0.566     0.718     0.667    84\n",
      "     sad     0.566     0.500     0.506    87\n",
      "surprise     0.566     0.667     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.580     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.037168 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.282276  [ 1200/ 4873]\n",
      "loss: 0.013877  [ 2400/ 4873]\n",
      "loss: 0.020626  [ 3600/ 4873]\n",
      "loss: 0.021156  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.612     0.495    105\n",
      " disgust     0.564     0.598     0.587    109\n",
      "    fear     0.564     0.538     0.525    80\n",
      "   happy     0.564     0.536     0.642    81\n",
      " neutral     0.564     0.633     0.679    84\n",
      "     sad     0.564     0.482     0.460    87\n",
      "surprise     0.564     0.529     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.561     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.057325 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.293299  [ 1200/ 4873]\n",
      "loss: 0.429807  [ 2400/ 4873]\n",
      "loss: 0.049491  [ 3600/ 4873]\n",
      "loss: 0.150698  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.622     0.533    105\n",
      " disgust     0.557     0.500     0.541    109\n",
      "    fear     0.557     0.519     0.500    80\n",
      "   happy     0.557     0.622     0.630    81\n",
      " neutral     0.557     0.682     0.690    84\n",
      "     sad     0.557     0.440     0.460    87\n",
      "surprise     0.557     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.108725 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.174863  [ 1200/ 4873]\n",
      "loss: 0.193770  [ 2400/ 4873]\n",
      "loss: 0.197138  [ 3600/ 4873]\n",
      "loss: 0.041916  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.679     0.505    105\n",
      " disgust     0.541     0.554     0.514    109\n",
      "    fear     0.541     0.494     0.550    80\n",
      "   happy     0.541     0.490     0.580    81\n",
      " neutral     0.541     0.667     0.619    84\n",
      "     sad     0.541     0.423     0.506    87\n",
      "surprise     0.541     0.531     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.548     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 3.009836 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.274527  [ 1200/ 4873]\n",
      "loss: 0.341570  [ 2400/ 4873]\n",
      "loss: 0.035249  [ 3600/ 4873]\n",
      "loss: 0.023019  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.591     0.495    105\n",
      " disgust     0.544     0.539     0.569    109\n",
      "    fear     0.544     0.469     0.475    80\n",
      "   happy     0.544     0.557     0.605    81\n",
      " neutral     0.544     0.707     0.631    84\n",
      "     sad     0.544     0.453     0.494    87\n",
      "surprise     0.544     0.515     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.547     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.341123 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.052004  [ 1200/ 4873]\n",
      "loss: 0.035173  [ 2400/ 4873]\n",
      "loss: 0.034827  [ 3600/ 4873]\n",
      "loss: 0.766254  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.619     0.571    105\n",
      " disgust     0.566     0.590     0.569    109\n",
      "    fear     0.566     0.467     0.525    80\n",
      "   happy     0.566     0.523     0.568    81\n",
      " neutral     0.566     0.682     0.690    84\n",
      "     sad     0.566     0.518     0.506    87\n",
      "surprise     0.566     0.550     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.564     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.049202 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.336898  [ 1200/ 4873]\n",
      "loss: 0.021560  [ 2400/ 4873]\n",
      "loss: 0.029386  [ 3600/ 4873]\n",
      "loss: 0.053402  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.611     0.552    105\n",
      " disgust     0.566     0.554     0.569    109\n",
      "    fear     0.566     0.477     0.525    80\n",
      "   happy     0.566     0.565     0.642    81\n",
      " neutral     0.566     0.684     0.643    84\n",
      "     sad     0.566     0.518     0.494    87\n",
      "surprise     0.566     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.567     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.011631 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.008376  [ 1200/ 4873]\n",
      "loss: 0.041640  [ 2400/ 4873]\n",
      "loss: 0.030342  [ 3600/ 4873]\n",
      "loss: 0.788711  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.658     0.495    105\n",
      " disgust     0.534     0.515     0.468    109\n",
      "    fear     0.534     0.429     0.450    80\n",
      "   happy     0.534     0.468     0.642    81\n",
      " neutral     0.534     0.707     0.690    84\n",
      "     sad     0.534     0.440     0.506    87\n",
      "surprise     0.534     0.600     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.545     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.077559 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.056392  [ 1200/ 4873]\n",
      "loss: 0.067745  [ 2400/ 4873]\n",
      "loss: 0.031493  [ 3600/ 4873]\n",
      "loss: 0.017874  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.667     0.533    105\n",
      " disgust     0.561     0.587     0.587    109\n",
      "    fear     0.561     0.500     0.463    80\n",
      "   happy     0.561     0.537     0.630    81\n",
      " neutral     0.561     0.578     0.702    84\n",
      "     sad     0.561     0.494     0.448    87\n",
      "surprise     0.561     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.557     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.166896 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 1.048641  [ 1200/ 4873]\n",
      "loss: 0.403455  [ 2400/ 4873]\n",
      "loss: 0.035509  [ 3600/ 4873]\n",
      "loss: 0.026248  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.646     0.486    105\n",
      " disgust     0.548     0.508     0.569    109\n",
      "    fear     0.548     0.487     0.475    80\n",
      "   happy     0.548     0.566     0.580    81\n",
      " neutral     0.548     0.648     0.679    84\n",
      "     sad     0.548     0.495     0.540    87\n",
      "surprise     0.548     0.492     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.549     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.186739 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.166558  [ 1200/ 4873]\n",
      "loss: 0.030237  [ 2400/ 4873]\n",
      "loss: 0.248816  [ 3600/ 4873]\n",
      "loss: 0.007119  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.609     0.533    105\n",
      " disgust     0.554     0.566     0.550    109\n",
      "    fear     0.554     0.521     0.475    80\n",
      "   happy     0.554     0.547     0.580    81\n",
      " neutral     0.554     0.667     0.690    84\n",
      "     sad     0.554     0.431     0.506    87\n",
      "surprise     0.554     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.555     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.186074 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.044861  [ 1200/ 4873]\n",
      "loss: 0.434174  [ 2400/ 4873]\n",
      "loss: 0.035446  [ 3600/ 4873]\n",
      "loss: 0.058846  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.608     0.457    105\n",
      " disgust     0.544     0.547     0.532    109\n",
      "    fear     0.544     0.463     0.475    80\n",
      "   happy     0.544     0.520     0.642    81\n",
      " neutral     0.544     0.655     0.655    84\n",
      "     sad     0.544     0.465     0.529    87\n",
      "surprise     0.544     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.549     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.211410 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.068916  [ 1200/ 4873]\n",
      "loss: 0.069409  [ 2400/ 4873]\n",
      "loss: 0.040106  [ 3600/ 4873]\n",
      "loss: 0.010360  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.641     0.562    105\n",
      " disgust     0.541     0.579     0.505    109\n",
      "    fear     0.541     0.457     0.463    80\n",
      "   happy     0.541     0.536     0.556    81\n",
      " neutral     0.541     0.611     0.690    84\n",
      "     sad     0.541     0.417     0.460    87\n",
      "surprise     0.541     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.540     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 3.084757 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.169711  [ 1200/ 4873]\n",
      "loss: 0.057793  [ 2400/ 4873]\n",
      "loss: 0.040221  [ 3600/ 4873]\n",
      "loss: 0.156414  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.533     0.457    105\n",
      " disgust     0.536     0.526     0.550    109\n",
      "    fear     0.536     0.446     0.512    80\n",
      "   happy     0.536     0.558     0.593    81\n",
      " neutral     0.536     0.671     0.631    84\n",
      "     sad     0.536     0.477     0.483    87\n",
      "surprise     0.536     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.541     0.539    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 3.192065 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.261013  [ 1200/ 4873]\n",
      "loss: 0.110867  [ 2400/ 4873]\n",
      "loss: 0.033219  [ 3600/ 4873]\n",
      "loss: 0.165926  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.593     0.457    105\n",
      " disgust     0.559     0.564     0.569    109\n",
      "    fear     0.559     0.526     0.500    80\n",
      "   happy     0.559     0.542     0.642    81\n",
      " neutral     0.559     0.608     0.702    84\n",
      "     sad     0.559     0.512     0.471    87\n",
      "surprise     0.559     0.557     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.557     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.067897 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.043846  [ 1200/ 4873]\n",
      "loss: 0.048771  [ 2400/ 4873]\n",
      "loss: 0.108295  [ 3600/ 4873]\n",
      "loss: 0.071351  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.662     0.467    105\n",
      " disgust     0.557     0.598     0.587    109\n",
      "    fear     0.557     0.494     0.487    80\n",
      "   happy     0.557     0.481     0.617    81\n",
      " neutral     0.557     0.695     0.679    84\n",
      "     sad     0.557     0.467     0.483    87\n",
      "surprise     0.557     0.527     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.561     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.102035 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.043571  [ 1200/ 4873]\n",
      "loss: 0.013479  [ 2400/ 4873]\n",
      "loss: 0.021899  [ 3600/ 4873]\n",
      "loss: 0.070251  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.617     0.552    105\n",
      " disgust     0.561     0.545     0.560    109\n",
      "    fear     0.561     0.524     0.537    80\n",
      "   happy     0.561     0.530     0.543    81\n",
      " neutral     0.561     0.600     0.714    84\n",
      "     sad     0.561     0.558     0.494    87\n",
      "surprise     0.561     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.558     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.107363 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.007635  [ 1200/ 4873]\n",
      "loss: 0.230613  [ 2400/ 4873]\n",
      "loss: 0.027127  [ 3600/ 4873]\n",
      "loss: 0.299747  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.531     0.486    105\n",
      " disgust     0.549     0.538     0.587    109\n",
      "    fear     0.549     0.436     0.512    80\n",
      "   happy     0.549     0.552     0.593    81\n",
      " neutral     0.549     0.700     0.667    84\n",
      "     sad     0.549     0.488     0.483    87\n",
      "surprise     0.549     0.688     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.562     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.045104 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.524622  [ 1200/ 4873]\n",
      "loss: 0.170804  [ 2400/ 4873]\n",
      "loss: 0.052261  [ 3600/ 4873]\n",
      "loss: 0.124207  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.621     0.514    105\n",
      " disgust     0.557     0.592     0.532    109\n",
      "    fear     0.557     0.446     0.463    80\n",
      "   happy     0.557     0.536     0.642    81\n",
      " neutral     0.557     0.629     0.726    84\n",
      "     sad     0.557     0.506     0.471    87\n",
      "surprise     0.557     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.555     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.140219 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.839315  [ 1200/ 4873]\n",
      "loss: 0.082683  [ 2400/ 4873]\n",
      "loss: 0.513431  [ 3600/ 4873]\n",
      "loss: 0.049326  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.610     0.476    105\n",
      " disgust     0.554     0.586     0.532    109\n",
      "    fear     0.554     0.478     0.537    80\n",
      "   happy     0.554     0.538     0.617    81\n",
      " neutral     0.554     0.574     0.690    84\n",
      "     sad     0.554     0.530     0.506    87\n",
      "surprise     0.554     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.554     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.041586 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.138721  [ 1200/ 4873]\n",
      "loss: 0.036609  [ 2400/ 4873]\n",
      "loss: 1.227967  [ 3600/ 4873]\n",
      "loss: 0.025699  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.642     0.495    105\n",
      " disgust     0.538     0.509     0.495    109\n",
      "    fear     0.538     0.480     0.450    80\n",
      "   happy     0.538     0.486     0.630    81\n",
      " neutral     0.538     0.617     0.690    84\n",
      "     sad     0.538     0.506     0.460    87\n",
      "surprise     0.538     0.529     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.538     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.088941 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.110297  [ 1200/ 4873]\n",
      "loss: 0.183853  [ 2400/ 4873]\n",
      "loss: 0.066559  [ 3600/ 4873]\n",
      "loss: 0.011361  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.611     0.524    105\n",
      " disgust     0.556     0.543     0.523    109\n",
      "    fear     0.556     0.477     0.525    80\n",
      "   happy     0.556     0.573     0.580    81\n",
      " neutral     0.556     0.686     0.702    84\n",
      "     sad     0.556     0.439     0.494    87\n",
      "surprise     0.556     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.560     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.261494 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.031577  [ 1200/ 4873]\n",
      "loss: 1.868831  [ 2400/ 4873]\n",
      "loss: 0.023245  [ 3600/ 4873]\n",
      "loss: 0.115933  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.591     0.524    105\n",
      " disgust     0.557     0.592     0.560    109\n",
      "    fear     0.557     0.507     0.463    80\n",
      "   happy     0.557     0.495     0.593    81\n",
      " neutral     0.557     0.671     0.679    84\n",
      "     sad     0.557     0.480     0.552    87\n",
      "surprise     0.557     0.576     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.559     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.150641 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.032591  [ 1200/ 4873]\n",
      "loss: 0.202860  [ 2400/ 4873]\n",
      "loss: 0.162862  [ 3600/ 4873]\n",
      "loss: 0.376373  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.667     0.533    105\n",
      " disgust     0.556     0.534     0.505    109\n",
      "    fear     0.556     0.458     0.550    80\n",
      "   happy     0.556     0.527     0.605    81\n",
      " neutral     0.556     0.636     0.667    84\n",
      "     sad     0.556     0.471     0.471    87\n",
      "surprise     0.556     0.644     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.563     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.013919 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.011918  [ 1200/ 4873]\n",
      "loss: 0.013206  [ 2400/ 4873]\n",
      "loss: 0.179360  [ 3600/ 4873]\n",
      "loss: 0.021580  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.686     0.562    105\n",
      " disgust     0.566     0.530     0.569    109\n",
      "    fear     0.566     0.526     0.500    80\n",
      "   happy     0.566     0.522     0.580    81\n",
      " neutral     0.566     0.652     0.690    84\n",
      "     sad     0.566     0.512     0.483    87\n",
      "surprise     0.566     0.529     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.565     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.148030 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.304636  [ 1200/ 4873]\n",
      "loss: 0.260758  [ 2400/ 4873]\n",
      "loss: 0.258643  [ 3600/ 4873]\n",
      "loss: 0.273115  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.645     0.467    105\n",
      " disgust     0.536     0.532     0.541    109\n",
      "    fear     0.536     0.494     0.487    80\n",
      "   happy     0.536     0.536     0.556    81\n",
      " neutral     0.536     0.659     0.690    84\n",
      "     sad     0.536     0.429     0.448    87\n",
      "surprise     0.536     0.469     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.537     0.541    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 3.293874 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.131256  [ 1200/ 4873]\n",
      "loss: 0.020672  [ 2400/ 4873]\n",
      "loss: 0.296202  [ 3600/ 4873]\n",
      "loss: 0.010426  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.521     0.551     0.514    105\n",
      " disgust     0.521     0.479     0.514    109\n",
      "    fear     0.521     0.438     0.400    80\n",
      "   happy     0.521     0.535     0.568    81\n",
      " neutral     0.521     0.602     0.667    84\n",
      "     sad     0.521     0.506     0.506    87\n",
      "surprise     0.521     0.536     0.469    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.521     0.521     0.520    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 3.137113 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.049137  [ 1200/ 4873]\n",
      "loss: 0.123820  [ 2400/ 4873]\n",
      "loss: 0.193898  [ 3600/ 4873]\n",
      "loss: 0.217109  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.663     0.524    105\n",
      " disgust     0.544     0.565     0.477    109\n",
      "    fear     0.544     0.487     0.475    80\n",
      "   happy     0.544     0.489     0.543    81\n",
      " neutral     0.544     0.630     0.690    84\n",
      "     sad     0.544     0.444     0.552    87\n",
      "surprise     0.544     0.552     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.547     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.053778 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.205084  [ 1200/ 4873]\n",
      "loss: 0.183218  [ 2400/ 4873]\n",
      "loss: 0.143895  [ 3600/ 4873]\n",
      "loss: 0.287268  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.676     0.476    105\n",
      " disgust     0.549     0.496     0.541    109\n",
      "    fear     0.549     0.444     0.500    80\n",
      "   happy     0.549     0.586     0.630    81\n",
      " neutral     0.549     0.695     0.679    84\n",
      "     sad     0.549     0.478     0.494    87\n",
      "surprise     0.549     0.515     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.556     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.100439 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.670841  [ 1200/ 4873]\n",
      "loss: 0.031691  [ 2400/ 4873]\n",
      "loss: 0.141348  [ 3600/ 4873]\n",
      "loss: 0.232050  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.618     0.524    105\n",
      " disgust     0.566     0.578     0.541    109\n",
      "    fear     0.566     0.556     0.500    80\n",
      "   happy     0.566     0.521     0.617    81\n",
      " neutral     0.566     0.583     0.750    84\n",
      "     sad     0.566     0.563     0.460    87\n",
      "surprise     0.566     0.528     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.564     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.959242 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.010722  [ 1200/ 4873]\n",
      "loss: 0.043201  [ 2400/ 4873]\n",
      "loss: 0.077098  [ 3600/ 4873]\n",
      "loss: 0.247428  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.638     0.571    105\n",
      " disgust     0.570     0.544     0.569    109\n",
      "    fear     0.570     0.535     0.475    80\n",
      "   happy     0.570     0.561     0.568    81\n",
      " neutral     0.570     0.652     0.690    84\n",
      "     sad     0.570     0.505     0.529    87\n",
      "surprise     0.570     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.569     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 3.222528 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.109782  [ 1200/ 4873]\n",
      "loss: 0.105712  [ 2400/ 4873]\n",
      "loss: 0.126615  [ 3600/ 4873]\n",
      "loss: 0.041506  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.679     0.505    105\n",
      " disgust     0.556     0.556     0.505    109\n",
      "    fear     0.556     0.603     0.475    80\n",
      "   happy     0.556     0.495     0.679    81\n",
      " neutral     0.556     0.637     0.690    84\n",
      "     sad     0.556     0.443     0.540    87\n",
      "surprise     0.556     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.564     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.057306 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.006553  [ 1200/ 4873]\n",
      "loss: 0.134409  [ 2400/ 4873]\n",
      "loss: 0.081947  [ 3600/ 4873]\n",
      "loss: 0.097093  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.678     0.562    105\n",
      " disgust     0.559     0.596     0.514    109\n",
      "    fear     0.559     0.565     0.487    80\n",
      "   happy     0.559     0.475     0.593    81\n",
      " neutral     0.559     0.619     0.714    84\n",
      "     sad     0.559     0.443     0.494    87\n",
      "surprise     0.559     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.561     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.968796 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.208958  [ 1200/ 4873]\n",
      "loss: 0.259721  [ 2400/ 4873]\n",
      "loss: 0.087992  [ 3600/ 4873]\n",
      "loss: 0.019871  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.612     0.495    105\n",
      " disgust     0.539     0.538     0.523    109\n",
      "    fear     0.539     0.437     0.475    80\n",
      "   happy     0.539     0.571     0.593    81\n",
      " neutral     0.539     0.625     0.714    84\n",
      "     sad     0.539     0.474     0.425    87\n",
      "surprise     0.539     0.500     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.537     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 3.159515 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.075639  [ 1200/ 4873]\n",
      "loss: 0.177357  [ 2400/ 4873]\n",
      "loss: 0.021164  [ 3600/ 4873]\n",
      "loss: 0.410787  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.604     0.552    105\n",
      " disgust     0.556     0.537     0.532    109\n",
      "    fear     0.556     0.479     0.425    80\n",
      "   happy     0.556     0.575     0.568    81\n",
      " neutral     0.556     0.626     0.738    84\n",
      "     sad     0.556     0.523     0.517    87\n",
      "surprise     0.556     0.514     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.551     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.229950 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.048908  [ 1200/ 4873]\n",
      "loss: 0.015243  [ 2400/ 4873]\n",
      "loss: 0.016657  [ 3600/ 4873]\n",
      "loss: 0.052652  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.613     0.467    105\n",
      " disgust     0.559     0.549     0.569    109\n",
      "    fear     0.559     0.488     0.512    80\n",
      "   happy     0.559     0.571     0.593    81\n",
      " neutral     0.559     0.646     0.738    84\n",
      "     sad     0.559     0.467     0.494    87\n",
      "surprise     0.559     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.561     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.013438 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.087250  [ 1200/ 4873]\n",
      "loss: 0.139696  [ 2400/ 4873]\n",
      "loss: 0.371691  [ 3600/ 4873]\n",
      "loss: 0.541924  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.528     0.649     0.476    105\n",
      " disgust     0.528     0.551     0.495    109\n",
      "    fear     0.528     0.463     0.475    80\n",
      "   happy     0.528     0.522     0.580    81\n",
      " neutral     0.528     0.625     0.655    84\n",
      "     sad     0.528     0.404     0.483    87\n",
      "surprise     0.528     0.507     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.528     0.532     0.532    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.248958 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.218648  [ 1200/ 4873]\n",
      "loss: 0.159644  [ 2400/ 4873]\n",
      "loss: 0.378890  [ 3600/ 4873]\n",
      "loss: 0.314358  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.588     0.476    105\n",
      " disgust     0.546     0.533     0.596    109\n",
      "    fear     0.546     0.486     0.450    80\n",
      "   happy     0.546     0.558     0.593    81\n",
      " neutral     0.546     0.659     0.714    84\n",
      "     sad     0.546     0.486     0.402    87\n",
      "surprise     0.546     0.487     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.543     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.273383 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.014045  [ 1200/ 4873]\n",
      "loss: 0.610775  [ 2400/ 4873]\n",
      "loss: 0.034821  [ 3600/ 4873]\n",
      "loss: 0.048082  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.544     0.583     0.533    105\n",
      " disgust     0.544     0.514     0.523    109\n",
      "    fear     0.544     0.481     0.475    80\n",
      "   happy     0.544     0.511     0.580    81\n",
      " neutral     0.544     0.698     0.714    84\n",
      "     sad     0.544     0.469     0.437    87\n",
      "surprise     0.544     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.544     0.544     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 3.154105 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.113090  [ 1200/ 4873]\n",
      "loss: 0.258593  [ 2400/ 4873]\n",
      "loss: 0.627334  [ 3600/ 4873]\n",
      "loss: 0.269473  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.624     0.505    105\n",
      " disgust     0.549     0.553     0.523    109\n",
      "    fear     0.549     0.468     0.463    80\n",
      "   happy     0.549     0.545     0.593    81\n",
      " neutral     0.549     0.690     0.714    84\n",
      "     sad     0.549     0.478     0.494    87\n",
      "surprise     0.549     0.474     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.548     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.323563 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.035681  [ 1200/ 4873]\n",
      "loss: 0.373163  [ 2400/ 4873]\n",
      "loss: 0.443514  [ 3600/ 4873]\n",
      "loss: 1.770484  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.607     0.514    105\n",
      " disgust     0.557     0.571     0.624    109\n",
      "    fear     0.557     0.556     0.438    80\n",
      "   happy     0.557     0.495     0.617    81\n",
      " neutral     0.557     0.647     0.655    84\n",
      "     sad     0.557     0.562     0.471    87\n",
      "surprise     0.557     0.463     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.557     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.347114 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.495527  [ 1200/ 4873]\n",
      "loss: 0.012469  [ 2400/ 4873]\n",
      "loss: 0.026989  [ 3600/ 4873]\n",
      "loss: 0.262309  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.646     0.505    105\n",
      " disgust     0.556     0.525     0.587    109\n",
      "    fear     0.556     0.520     0.487    80\n",
      "   happy     0.556     0.610     0.580    81\n",
      " neutral     0.556     0.576     0.679    84\n",
      "     sad     0.556     0.506     0.483    87\n",
      "surprise     0.556     0.514     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.557     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.128098 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.461904  [ 1200/ 4873]\n",
      "loss: 0.441858  [ 2400/ 4873]\n",
      "loss: 0.288399  [ 3600/ 4873]\n",
      "loss: 0.039866  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.646     0.505    105\n",
      " disgust     0.562     0.555     0.606    109\n",
      "    fear     0.562     0.494     0.475    80\n",
      "   happy     0.562     0.516     0.593    81\n",
      " neutral     0.562     0.696     0.655    84\n",
      "     sad     0.562     0.457     0.552    87\n",
      "surprise     0.562     0.636     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.571     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.103394 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.831926  [ 1200/ 4873]\n",
      "loss: 0.196399  [ 2400/ 4873]\n",
      "loss: 0.055352  [ 3600/ 4873]\n",
      "loss: 0.029075  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.655     0.543    105\n",
      " disgust     0.566     0.541     0.550    109\n",
      "    fear     0.566     0.529     0.463    80\n",
      "   happy     0.566     0.525     0.642    81\n",
      " neutral     0.566     0.624     0.690    84\n",
      "     sad     0.566     0.531     0.494    87\n",
      "surprise     0.566     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.565     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.064433 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.085839  [ 1200/ 4873]\n",
      "loss: 0.071098  [ 2400/ 4873]\n",
      "loss: 0.876223  [ 3600/ 4873]\n",
      "loss: 0.017117  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.671     0.505    105\n",
      " disgust     0.546     0.534     0.505    109\n",
      "    fear     0.546     0.481     0.487    80\n",
      "   happy     0.546     0.471     0.593    81\n",
      " neutral     0.546     0.633     0.679    84\n",
      "     sad     0.546     0.500     0.494    87\n",
      "surprise     0.546     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.549     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.074966 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.110491  [ 1200/ 4873]\n",
      "loss: 0.005494  [ 2400/ 4873]\n",
      "loss: 0.170411  [ 3600/ 4873]\n",
      "loss: 0.396676  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.621     0.514    105\n",
      " disgust     0.552     0.604     0.560    109\n",
      "    fear     0.552     0.525     0.525    80\n",
      "   happy     0.552     0.500     0.630    81\n",
      " neutral     0.552     0.588     0.679    84\n",
      "     sad     0.552     0.519     0.460    87\n",
      "surprise     0.552     0.485     0.500    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.549     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.237814 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.080687  [ 1200/ 4873]\n",
      "loss: 0.345714  [ 2400/ 4873]\n",
      "loss: 0.065451  [ 3600/ 4873]\n",
      "loss: 0.030257  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.687     0.543    105\n",
      " disgust     0.557     0.544     0.569    109\n",
      "    fear     0.557     0.442     0.475    80\n",
      "   happy     0.557     0.595     0.580    81\n",
      " neutral     0.557     0.683     0.667    84\n",
      "     sad     0.557     0.462     0.483    87\n",
      "surprise     0.557     0.507     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.120998 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.620131  [ 1200/ 4873]\n",
      "loss: 0.051174  [ 2400/ 4873]\n",
      "loss: 0.303190  [ 3600/ 4873]\n",
      "loss: 0.040727  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.602     0.476    105\n",
      " disgust     0.543     0.523     0.514    109\n",
      "    fear     0.543     0.443     0.487    80\n",
      "   happy     0.543     0.521     0.605    81\n",
      " neutral     0.543     0.706     0.714    84\n",
      "     sad     0.543     0.489     0.506    87\n",
      "surprise     0.543     0.524     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.544     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.082100 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.039753  [ 1200/ 4873]\n",
      "loss: 0.026358  [ 2400/ 4873]\n",
      "loss: 0.158482  [ 3600/ 4873]\n",
      "loss: 0.027372  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.591     0.524    105\n",
      " disgust     0.552     0.528     0.523    109\n",
      "    fear     0.552     0.500     0.475    80\n",
      "   happy     0.552     0.529     0.568    81\n",
      " neutral     0.552     0.646     0.738    84\n",
      "     sad     0.552     0.506     0.506    87\n",
      "surprise     0.552     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.551     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.086200 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.061090  [ 1200/ 4873]\n",
      "loss: 0.017683  [ 2400/ 4873]\n",
      "loss: 0.023842  [ 3600/ 4873]\n",
      "loss: 0.428601  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.709     0.533    105\n",
      " disgust     0.531     0.486     0.468    109\n",
      "    fear     0.531     0.507     0.450    80\n",
      "   happy     0.531     0.480     0.605    81\n",
      " neutral     0.531     0.618     0.655    84\n",
      "     sad     0.531     0.424     0.483    87\n",
      "surprise     0.531     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.538     0.534    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 3.155152 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.763767  [ 1200/ 4873]\n",
      "loss: 0.089014  [ 2400/ 4873]\n",
      "loss: 0.156669  [ 3600/ 4873]\n",
      "loss: 0.011143  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.637     0.486    105\n",
      " disgust     0.551     0.564     0.569    109\n",
      "    fear     0.551     0.471     0.500    80\n",
      "   happy     0.551     0.485     0.593    81\n",
      " neutral     0.551     0.659     0.690    84\n",
      "     sad     0.551     0.512     0.506    87\n",
      "surprise     0.551     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.551     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.217740 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.028777  [ 1200/ 4873]\n",
      "loss: 0.181541  [ 2400/ 4873]\n",
      "loss: 0.070363  [ 3600/ 4873]\n",
      "loss: 0.186287  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.573     0.524    105\n",
      " disgust     0.566     0.608     0.569    109\n",
      "    fear     0.566     0.466     0.512    80\n",
      "   happy     0.566     0.561     0.568    81\n",
      " neutral     0.566     0.682     0.690    84\n",
      "     sad     0.566     0.490     0.540    87\n",
      "surprise     0.566     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.567     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.118114 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.245390  [ 1200/ 4873]\n",
      "loss: 0.064961  [ 2400/ 4873]\n",
      "loss: 0.074611  [ 3600/ 4873]\n",
      "loss: 0.017946  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.602     0.505    105\n",
      " disgust     0.561     0.588     0.550    109\n",
      "    fear     0.561     0.435     0.500    80\n",
      "   happy     0.561     0.558     0.593    81\n",
      " neutral     0.561     0.698     0.714    84\n",
      "     sad     0.561     0.464     0.517    87\n",
      "surprise     0.561     0.610     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.565     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.147816 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.121656  [ 1200/ 4873]\n",
      "loss: 0.107252  [ 2400/ 4873]\n",
      "loss: 0.146152  [ 3600/ 4873]\n",
      "loss: 0.029341  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.641     0.476    105\n",
      " disgust     0.549     0.568     0.578    109\n",
      "    fear     0.549     0.536     0.463    80\n",
      "   happy     0.549     0.505     0.617    81\n",
      " neutral     0.549     0.584     0.702    84\n",
      "     sad     0.549     0.463     0.437    87\n",
      "surprise     0.549     0.543     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.549     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.225752 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.328033  [ 1200/ 4873]\n",
      "loss: 0.033010  [ 2400/ 4873]\n",
      "loss: 0.036379  [ 3600/ 4873]\n",
      "loss: 0.015913  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.554     0.533    105\n",
      " disgust     0.549     0.588     0.615    109\n",
      "    fear     0.549     0.486     0.450    80\n",
      "   happy     0.549     0.505     0.593    81\n",
      " neutral     0.549     0.636     0.667    84\n",
      "     sad     0.549     0.487     0.437    87\n",
      "surprise     0.549     0.567     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.546     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.106470 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.722684  [ 1200/ 4873]\n",
      "loss: 0.040452  [ 2400/ 4873]\n",
      "loss: 0.272292  [ 3600/ 4873]\n",
      "loss: 0.108095  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.539     0.646     0.505    105\n",
      " disgust     0.539     0.514     0.514    109\n",
      "    fear     0.539     0.452     0.475    80\n",
      "   happy     0.539     0.517     0.568    81\n",
      " neutral     0.539     0.722     0.679    84\n",
      "     sad     0.539     0.447     0.483    87\n",
      "surprise     0.539     0.507     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.539     0.544     0.543    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 3.261827 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.168035  [ 1200/ 4873]\n",
      "loss: 0.058398  [ 2400/ 4873]\n",
      "loss: 0.035578  [ 3600/ 4873]\n",
      "loss: 0.088069  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.600     0.486    105\n",
      " disgust     0.557     0.608     0.569    109\n",
      "    fear     0.557     0.543     0.475    80\n",
      "   happy     0.557     0.471     0.691    81\n",
      " neutral     0.557     0.632     0.714    84\n",
      "     sad     0.557     0.514     0.437    87\n",
      "surprise     0.557     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.558     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.096307 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.007621  [ 1200/ 4873]\n",
      "loss: 0.137836  [ 2400/ 4873]\n",
      "loss: 0.183387  [ 3600/ 4873]\n",
      "loss: 0.064664  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.591     0.524    105\n",
      " disgust     0.561     0.612     0.578    109\n",
      "    fear     0.561     0.500     0.525    80\n",
      "   happy     0.561     0.545     0.593    81\n",
      " neutral     0.561     0.615     0.667    84\n",
      "     sad     0.561     0.506     0.483    87\n",
      "surprise     0.561     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.557     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.282344 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.017971  [ 1200/ 4873]\n",
      "loss: 0.102488  [ 2400/ 4873]\n",
      "loss: 0.345250  [ 3600/ 4873]\n",
      "loss: 0.080696  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.611     0.552    105\n",
      " disgust     0.569     0.629     0.606    109\n",
      "    fear     0.569     0.461     0.512    80\n",
      "   happy     0.569     0.558     0.593    81\n",
      " neutral     0.569     0.682     0.714    84\n",
      "     sad     0.569     0.506     0.471    87\n",
      "surprise     0.569     0.500     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.564     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 3.141801 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.036163  [ 1200/ 4873]\n",
      "loss: 0.007351  [ 2400/ 4873]\n",
      "loss: 0.120280  [ 3600/ 4873]\n",
      "loss: 0.016722  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.636     0.600    105\n",
      " disgust     0.579     0.573     0.505    109\n",
      "    fear     0.579     0.483     0.537    80\n",
      "   happy     0.579     0.543     0.617    81\n",
      " neutral     0.579     0.714     0.714    84\n",
      "     sad     0.579     0.511     0.552    87\n",
      "surprise     0.579     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.581     0.580    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 3.061900 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.020082  [ 1200/ 4873]\n",
      "loss: 0.096546  [ 2400/ 4873]\n",
      "loss: 0.069720  [ 3600/ 4873]\n",
      "loss: 0.021507  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.588     0.476    105\n",
      " disgust     0.546     0.578     0.541    109\n",
      "    fear     0.546     0.441     0.512    80\n",
      "   happy     0.546     0.560     0.630    81\n",
      " neutral     0.546     0.620     0.679    84\n",
      "     sad     0.546     0.526     0.471    87\n",
      "surprise     0.546     0.493     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.544     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.259197 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.262520  [ 1200/ 4873]\n",
      "loss: 0.007580  [ 2400/ 4873]\n",
      "loss: 0.016513  [ 3600/ 4873]\n",
      "loss: 0.268916  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.604     0.524    105\n",
      " disgust     0.551     0.528     0.523    109\n",
      "    fear     0.551     0.480     0.450    80\n",
      "   happy     0.551     0.583     0.605    81\n",
      " neutral     0.551     0.700     0.667    84\n",
      "     sad     0.551     0.457     0.483    87\n",
      "surprise     0.551     0.512     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.552     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.114719 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.435201  [ 1200/ 4873]\n",
      "loss: 0.257398  [ 2400/ 4873]\n",
      "loss: 0.050587  [ 3600/ 4873]\n",
      "loss: 0.052002  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.630     0.486    105\n",
      " disgust     0.552     0.582     0.587    109\n",
      "    fear     0.552     0.415     0.487    80\n",
      "   happy     0.552     0.565     0.593    81\n",
      " neutral     0.552     0.644     0.667    84\n",
      "     sad     0.552     0.506     0.494    87\n",
      "surprise     0.552     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.553     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.098361 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.020428  [ 1200/ 4873]\n",
      "loss: 0.104106  [ 2400/ 4873]\n",
      "loss: 0.060989  [ 3600/ 4873]\n",
      "loss: 0.037486  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.531     0.662     0.486    105\n",
      " disgust     0.531     0.604     0.505    109\n",
      "    fear     0.531     0.467     0.438    80\n",
      "   happy     0.531     0.421     0.630    81\n",
      " neutral     0.531     0.631     0.631    84\n",
      "     sad     0.531     0.519     0.483    87\n",
      "surprise     0.531     0.457     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.531     0.537     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 3.294562 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.040756  [ 1200/ 4873]\n",
      "loss: 0.005728  [ 2400/ 4873]\n",
      "loss: 0.016881  [ 3600/ 4873]\n",
      "loss: 0.112974  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.658     0.476    105\n",
      " disgust     0.536     0.535     0.495    109\n",
      "    fear     0.536     0.494     0.500    80\n",
      "   happy     0.536     0.476     0.617    81\n",
      " neutral     0.536     0.700     0.667    84\n",
      "     sad     0.536     0.430     0.529    87\n",
      "surprise     0.536     0.517     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.544     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 3.219748 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.613844  [ 1200/ 4873]\n",
      "loss: 0.020589  [ 2400/ 4873]\n",
      "loss: 0.095522  [ 3600/ 4873]\n",
      "loss: 0.008113  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.579     0.524    105\n",
      " disgust     0.533     0.546     0.486    109\n",
      "    fear     0.533     0.451     0.463    80\n",
      "   happy     0.533     0.511     0.580    81\n",
      " neutral     0.533     0.556     0.714    84\n",
      "     sad     0.533     0.549     0.448    87\n",
      "surprise     0.533     0.523     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.531     0.535    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 3.320232 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.807996  [ 1200/ 4873]\n",
      "loss: 0.149109  [ 2400/ 4873]\n",
      "loss: 0.019533  [ 3600/ 4873]\n",
      "loss: 0.447200  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.611     0.552    105\n",
      " disgust     0.570     0.528     0.606    109\n",
      "    fear     0.570     0.449     0.500    80\n",
      "   happy     0.570     0.608     0.593    81\n",
      " neutral     0.570     0.741     0.714    84\n",
      "     sad     0.570     0.519     0.483    87\n",
      "surprise     0.570     0.567     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.574     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 3.110281 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.035558  [ 1200/ 4873]\n",
      "loss: 0.141308  [ 2400/ 4873]\n",
      "loss: 0.170316  [ 3600/ 4873]\n",
      "loss: 0.057484  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.618     0.524    105\n",
      " disgust     0.536     0.535     0.495    109\n",
      "    fear     0.536     0.463     0.463    80\n",
      "   happy     0.536     0.449     0.593    81\n",
      " neutral     0.536     0.641     0.702    84\n",
      "     sad     0.536     0.500     0.437    87\n",
      "surprise     0.536     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.537     0.539    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 3.060985 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.038822  [ 1200/ 4873]\n",
      "loss: 0.077983  [ 2400/ 4873]\n",
      "loss: 0.036364  [ 3600/ 4873]\n",
      "loss: 0.007778  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.614     0.486    105\n",
      " disgust     0.551     0.518     0.532    109\n",
      "    fear     0.551     0.479     0.575    80\n",
      "   happy     0.551     0.588     0.580    81\n",
      " neutral     0.551     0.667     0.690    84\n",
      "     sad     0.551     0.451     0.471    87\n",
      "surprise     0.551     0.574     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.556     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.228272 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.070127  [ 1200/ 4873]\n",
      "loss: 0.022733  [ 2400/ 4873]\n",
      "loss: 0.569533  [ 3600/ 4873]\n",
      "loss: 0.045051  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.695     0.543    105\n",
      " disgust     0.570     0.567     0.624    109\n",
      "    fear     0.570     0.521     0.475    80\n",
      "   happy     0.570     0.549     0.617    81\n",
      " neutral     0.570     0.679     0.679    84\n",
      "     sad     0.570     0.447     0.483    87\n",
      "surprise     0.570     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.572     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 3.040636 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.083015  [ 1200/ 4873]\n",
      "loss: 0.114156  [ 2400/ 4873]\n",
      "loss: 0.046740  [ 3600/ 4873]\n",
      "loss: 0.265488  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.612     0.600    105\n",
      " disgust     0.575     0.583     0.578    109\n",
      "    fear     0.575     0.482     0.500    80\n",
      "   happy     0.575     0.528     0.580    81\n",
      " neutral     0.575     0.682     0.714    84\n",
      "     sad     0.575     0.519     0.483    87\n",
      "surprise     0.575     0.621     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.575     0.574    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 3.001500 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.114577  [ 1200/ 4873]\n",
      "loss: 0.180399  [ 2400/ 4873]\n",
      "loss: 0.531390  [ 3600/ 4873]\n",
      "loss: 0.023433  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.671     0.524    105\n",
      " disgust     0.562     0.523     0.532    109\n",
      "    fear     0.562     0.487     0.463    80\n",
      "   happy     0.562     0.531     0.642    81\n",
      " neutral     0.562     0.671     0.679    84\n",
      "     sad     0.562     0.475     0.552    87\n",
      "surprise     0.562     0.632     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.570     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.083952 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.025522  [ 1200/ 4873]\n",
      "loss: 0.174989  [ 2400/ 4873]\n",
      "loss: 0.056076  [ 3600/ 4873]\n",
      "loss: 0.298027  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.679     0.505    105\n",
      " disgust     0.575     0.569     0.569    109\n",
      "    fear     0.575     0.451     0.512    80\n",
      "   happy     0.575     0.600     0.667    81\n",
      " neutral     0.575     0.655     0.655    84\n",
      "     sad     0.575     0.505     0.529    87\n",
      "surprise     0.575     0.597     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.579     0.580    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 3.128130 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.040606  [ 1200/ 4873]\n",
      "loss: 0.587601  [ 2400/ 4873]\n",
      "loss: 0.284980  [ 3600/ 4873]\n",
      "loss: 0.065302  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.584     0.646     0.590    105\n",
      " disgust     0.584     0.592     0.532    109\n",
      "    fear     0.584     0.519     0.525    80\n",
      "   happy     0.584     0.549     0.617    81\n",
      " neutral     0.584     0.721     0.738    84\n",
      "     sad     0.584     0.556     0.517    87\n",
      "surprise     0.584     0.481     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.584     0.580     0.585    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 3.178923 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.062479  [ 1200/ 4873]\n",
      "loss: 0.335592  [ 2400/ 4873]\n",
      "loss: 0.010195  [ 3600/ 4873]\n",
      "loss: 0.394648  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.631     0.505    105\n",
      " disgust     0.552     0.565     0.560    109\n",
      "    fear     0.552     0.464     0.487    80\n",
      "   happy     0.552     0.521     0.617    81\n",
      " neutral     0.552     0.600     0.714    84\n",
      "     sad     0.552     0.500     0.448    87\n",
      "surprise     0.552     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.552     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.099319 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.013131  [ 1200/ 4873]\n",
      "loss: 0.309447  [ 2400/ 4873]\n",
      "loss: 0.173594  [ 3600/ 4873]\n",
      "loss: 0.160125  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.686     0.562    105\n",
      " disgust     0.562     0.576     0.523    109\n",
      "    fear     0.562     0.489     0.550    80\n",
      "   happy     0.562     0.505     0.617    81\n",
      " neutral     0.562     0.629     0.667    84\n",
      "     sad     0.562     0.500     0.471    87\n",
      "surprise     0.562     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.563     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.265960 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.048505  [ 1200/ 4873]\n",
      "loss: 0.018154  [ 2400/ 4873]\n",
      "loss: 0.126236  [ 3600/ 4873]\n",
      "loss: 0.379245  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.596     0.590    105\n",
      " disgust     0.567     0.530     0.569    109\n",
      "    fear     0.567     0.521     0.463    80\n",
      "   happy     0.567     0.590     0.568    81\n",
      " neutral     0.567     0.615     0.702    84\n",
      "     sad     0.567     0.560     0.483    87\n",
      "surprise     0.567     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.566     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.187036 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.178830  [ 1200/ 4873]\n",
      "loss: 0.024118  [ 2400/ 4873]\n",
      "loss: 0.095579  [ 3600/ 4873]\n",
      "loss: 0.067433  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.647     0.524    105\n",
      " disgust     0.569     0.524     0.606    109\n",
      "    fear     0.569     0.535     0.475    80\n",
      "   happy     0.569     0.520     0.630    81\n",
      " neutral     0.569     0.700     0.667    84\n",
      "     sad     0.569     0.524     0.506    87\n",
      "surprise     0.569     0.561     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.573     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 3.205492 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 1.154528  [ 1200/ 4873]\n",
      "loss: 0.727533  [ 2400/ 4873]\n",
      "loss: 1.726140  [ 3600/ 4873]\n",
      "loss: 0.033618  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.598     0.495    105\n",
      " disgust     0.566     0.508     0.550    109\n",
      "    fear     0.566     0.500     0.525    80\n",
      "   happy     0.566     0.558     0.593    81\n",
      " neutral     0.566     0.728     0.702    84\n",
      "     sad     0.566     0.516     0.552    87\n",
      "surprise     0.566     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.571     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.060718 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.189482  [ 1200/ 4873]\n",
      "loss: 0.010475  [ 2400/ 4873]\n",
      "loss: 0.497660  [ 3600/ 4873]\n",
      "loss: 0.337781  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.582     0.674     0.552    105\n",
      " disgust     0.582     0.596     0.624    109\n",
      "    fear     0.582     0.470     0.487    80\n",
      "   happy     0.582     0.538     0.617    81\n",
      " neutral     0.582     0.671     0.679    84\n",
      "     sad     0.582     0.540     0.540    87\n",
      "surprise     0.582     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.582     0.581     0.580    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 3.161489 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.029190  [ 1200/ 4873]\n",
      "loss: 0.192438  [ 2400/ 4873]\n",
      "loss: 0.018455  [ 3600/ 4873]\n",
      "loss: 0.419398  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.632     0.524    105\n",
      " disgust     0.554     0.562     0.541    109\n",
      "    fear     0.554     0.465     0.500    80\n",
      "   happy     0.554     0.545     0.593    81\n",
      " neutral     0.554     0.617     0.690    84\n",
      "     sad     0.554     0.512     0.483    87\n",
      "surprise     0.554     0.529     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.552     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.210847 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.232897  [ 1200/ 4873]\n",
      "loss: 0.154293  [ 2400/ 4873]\n",
      "loss: 0.023215  [ 3600/ 4873]\n",
      "loss: 0.044190  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.652     0.552    105\n",
      " disgust     0.572     0.632     0.615    109\n",
      "    fear     0.572     0.458     0.475    80\n",
      "   happy     0.572     0.527     0.605    81\n",
      " neutral     0.572     0.690     0.714    84\n",
      "     sad     0.572     0.494     0.471    87\n",
      "surprise     0.572     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.568     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 3.083311 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.161763  [ 1200/ 4873]\n",
      "loss: 0.500622  [ 2400/ 4873]\n",
      "loss: 0.358134  [ 3600/ 4873]\n",
      "loss: 0.067534  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.651     0.514    105\n",
      " disgust     0.570     0.607     0.495    109\n",
      "    fear     0.570     0.468     0.550    80\n",
      "   happy     0.570     0.519     0.667    81\n",
      " neutral     0.570     0.659     0.714    84\n",
      "     sad     0.570     0.523     0.529    87\n",
      "surprise     0.570     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.570     0.574     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 3.078599 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.093488  [ 1200/ 4873]\n",
      "loss: 0.205767  [ 2400/ 4873]\n",
      "loss: 0.186902  [ 3600/ 4873]\n",
      "loss: 0.049268  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.650     0.495    105\n",
      " disgust     0.557     0.541     0.606    109\n",
      "    fear     0.557     0.442     0.475    80\n",
      "   happy     0.557     0.543     0.617    81\n",
      " neutral     0.557     0.644     0.690    84\n",
      "     sad     0.557     0.494     0.471    87\n",
      "surprise     0.557     0.614     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.561     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.151212 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.158844  [ 1200/ 4873]\n",
      "loss: 0.017248  [ 2400/ 4873]\n",
      "loss: 0.059895  [ 3600/ 4873]\n",
      "loss: 0.143806  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.609     0.533    105\n",
      " disgust     0.564     0.584     0.606    109\n",
      "    fear     0.564     0.451     0.463    80\n",
      "   happy     0.564     0.580     0.580    81\n",
      " neutral     0.564     0.685     0.726    84\n",
      "     sad     0.564     0.471     0.471    87\n",
      "surprise     0.564     0.545     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.561     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.278230 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.092359  [ 1200/ 4873]\n",
      "loss: 0.084834  [ 2400/ 4873]\n",
      "loss: 0.023973  [ 3600/ 4873]\n",
      "loss: 0.176583  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.612     0.495    105\n",
      " disgust     0.561     0.500     0.606    109\n",
      "    fear     0.561     0.455     0.500    80\n",
      "   happy     0.561     0.610     0.580    81\n",
      " neutral     0.561     0.695     0.679    84\n",
      "     sad     0.561     0.519     0.483    87\n",
      "surprise     0.561     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.568     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.116168 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.081199  [ 1200/ 4873]\n",
      "loss: 0.448675  [ 2400/ 4873]\n",
      "loss: 0.029817  [ 3600/ 4873]\n",
      "loss: 0.458277  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.610     0.448    105\n",
      " disgust     0.534     0.548     0.523    109\n",
      "    fear     0.534     0.440     0.500    80\n",
      "   happy     0.534     0.475     0.593    81\n",
      " neutral     0.534     0.695     0.679    84\n",
      "     sad     0.534     0.442     0.483    87\n",
      "surprise     0.534     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.534     0.542     0.539    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.173281 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.368244  [ 1200/ 4873]\n",
      "loss: 0.056610  [ 2400/ 4873]\n",
      "loss: 0.012015  [ 3600/ 4873]\n",
      "loss: 0.114663  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.598     0.552    105\n",
      " disgust     0.566     0.581     0.624    109\n",
      "    fear     0.566     0.526     0.500    80\n",
      "   happy     0.566     0.590     0.568    81\n",
      " neutral     0.566     0.645     0.714    84\n",
      "     sad     0.566     0.514     0.437    87\n",
      "surprise     0.566     0.467     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.560     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.378954 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.019054  [ 1200/ 4873]\n",
      "loss: 0.039432  [ 2400/ 4873]\n",
      "loss: 0.157402  [ 3600/ 4873]\n",
      "loss: 0.028255  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.600     0.486    105\n",
      " disgust     0.564     0.575     0.560    109\n",
      "    fear     0.564     0.494     0.525    80\n",
      "   happy     0.564     0.515     0.617    81\n",
      " neutral     0.564     0.638     0.714    84\n",
      "     sad     0.564     0.540     0.540    87\n",
      "surprise     0.564     0.589     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.565     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.212652 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.058895  [ 1200/ 4873]\n",
      "loss: 0.054702  [ 2400/ 4873]\n",
      "loss: 0.608534  [ 3600/ 4873]\n",
      "loss: 0.107987  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.644     0.552    105\n",
      " disgust     0.575     0.534     0.569    109\n",
      "    fear     0.575     0.500     0.525    80\n",
      "   happy     0.575     0.608     0.593    81\n",
      " neutral     0.575     0.674     0.714    84\n",
      "     sad     0.575     0.539     0.471    87\n",
      "surprise     0.575     0.526     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.575     0.578    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 3.282857 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.205647  [ 1200/ 4873]\n",
      "loss: 0.034756  [ 2400/ 4873]\n",
      "loss: 0.142467  [ 3600/ 4873]\n",
      "loss: 0.083804  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.628     0.514    105\n",
      " disgust     0.562     0.537     0.606    109\n",
      "    fear     0.562     0.456     0.450    80\n",
      "   happy     0.562     0.573     0.630    81\n",
      " neutral     0.562     0.655     0.679    84\n",
      "     sad     0.562     0.526     0.471    87\n",
      "surprise     0.562     0.559     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.562     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.219082 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.038325  [ 1200/ 4873]\n",
      "loss: 0.025091  [ 2400/ 4873]\n",
      "loss: 0.104027  [ 3600/ 4873]\n",
      "loss: 0.201689  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.630     0.486    105\n",
      " disgust     0.552     0.532     0.532    109\n",
      "    fear     0.552     0.487     0.463    80\n",
      "   happy     0.552     0.515     0.654    81\n",
      " neutral     0.552     0.725     0.690    84\n",
      "     sad     0.552     0.448     0.494    87\n",
      "surprise     0.552     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.558     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.220916 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.239019  [ 1200/ 4873]\n",
      "loss: 0.016031  [ 2400/ 4873]\n",
      "loss: 0.060033  [ 3600/ 4873]\n",
      "loss: 0.060060  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.574     0.552    105\n",
      " disgust     0.579     0.594     0.578    109\n",
      "    fear     0.579     0.488     0.525    80\n",
      "   happy     0.579     0.580     0.580    81\n",
      " neutral     0.579     0.702     0.702    84\n",
      "     sad     0.579     0.529     0.529    87\n",
      "surprise     0.579     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.579     0.580    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 3.114607 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.011169  [ 1200/ 4873]\n",
      "loss: 0.039946  [ 2400/ 4873]\n",
      "loss: 0.057550  [ 3600/ 4873]\n",
      "loss: 0.091410  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.675     0.533    105\n",
      " disgust     0.552     0.545     0.505    109\n",
      "    fear     0.552     0.463     0.475    80\n",
      "   happy     0.552     0.538     0.605    81\n",
      " neutral     0.552     0.656     0.726    84\n",
      "     sad     0.552     0.422     0.494    87\n",
      "surprise     0.552     0.603     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.557     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.135473 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.089919  [ 1200/ 4873]\n",
      "loss: 0.202224  [ 2400/ 4873]\n",
      "loss: 0.031933  [ 3600/ 4873]\n",
      "loss: 0.056585  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.600     0.486    105\n",
      " disgust     0.536     0.496     0.560    109\n",
      "    fear     0.536     0.506     0.487    80\n",
      "   happy     0.536     0.489     0.556    81\n",
      " neutral     0.536     0.621     0.702    84\n",
      "     sad     0.536     0.493     0.425    87\n",
      "surprise     0.536     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.537     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 3.239989 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.572035  [ 1200/ 4873]\n",
      "loss: 0.025088  [ 2400/ 4873]\n",
      "loss: 0.085807  [ 3600/ 4873]\n",
      "loss: 0.169235  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.628     0.467    105\n",
      " disgust     0.554     0.633     0.569    109\n",
      "    fear     0.554     0.473     0.438    80\n",
      "   happy     0.554     0.465     0.654    81\n",
      " neutral     0.554     0.626     0.679    84\n",
      "     sad     0.554     0.485     0.552    87\n",
      "surprise     0.554     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.560     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.052945 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.083508  [ 1200/ 4873]\n",
      "loss: 0.060507  [ 2400/ 4873]\n",
      "loss: 0.029675  [ 3600/ 4873]\n",
      "loss: 0.317579  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.579     0.644     0.552    105\n",
      " disgust     0.579     0.615     0.587    109\n",
      "    fear     0.579     0.554     0.450    80\n",
      "   happy     0.579     0.515     0.654    81\n",
      " neutral     0.579     0.653     0.738    84\n",
      "     sad     0.579     0.489     0.494    87\n",
      "surprise     0.579     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.579     0.577     0.579    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 3.106975 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.080347  [ 1200/ 4873]\n",
      "loss: 0.052619  [ 2400/ 4873]\n",
      "loss: 0.026575  [ 3600/ 4873]\n",
      "loss: 0.129601  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.647     0.524    105\n",
      " disgust     0.562     0.569     0.532    109\n",
      "    fear     0.562     0.582     0.487    80\n",
      "   happy     0.562     0.500     0.605    81\n",
      " neutral     0.562     0.604     0.726    84\n",
      "     sad     0.562     0.511     0.529    87\n",
      "surprise     0.562     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.562     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.147711 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.069816  [ 1200/ 4873]\n",
      "loss: 0.065902  [ 2400/ 4873]\n",
      "loss: 0.024628  [ 3600/ 4873]\n",
      "loss: 0.116628  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.533     0.568     0.476    105\n",
      " disgust     0.533     0.625     0.505    109\n",
      "    fear     0.533     0.406     0.487    80\n",
      "   happy     0.533     0.481     0.617    81\n",
      " neutral     0.533     0.644     0.667    84\n",
      "     sad     0.533     0.488     0.471    87\n",
      "surprise     0.533     0.540     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.533     0.536     0.536    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 3.312091 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.013910  [ 1200/ 4873]\n",
      "loss: 0.052368  [ 2400/ 4873]\n",
      "loss: 0.016828  [ 3600/ 4873]\n",
      "loss: 1.074659  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.602     0.476    105\n",
      " disgust     0.546     0.575     0.560    109\n",
      "    fear     0.546     0.493     0.450    80\n",
      "   happy     0.546     0.467     0.617    81\n",
      " neutral     0.546     0.598     0.690    84\n",
      "     sad     0.546     0.506     0.494    87\n",
      "surprise     0.546     0.593     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.548     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.240414 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.049428  [ 1200/ 4873]\n",
      "loss: 0.205424  [ 2400/ 4873]\n",
      "loss: 0.054049  [ 3600/ 4873]\n",
      "loss: 0.004530  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.624     0.552    105\n",
      " disgust     0.559     0.625     0.550    109\n",
      "    fear     0.559     0.493     0.438    80\n",
      "   happy     0.559     0.510     0.630    81\n",
      " neutral     0.559     0.614     0.738    84\n",
      "     sad     0.559     0.476     0.460    87\n",
      "surprise     0.559     0.538     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.554     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.105948 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.036976  [ 1200/ 4873]\n",
      "loss: 0.027841  [ 2400/ 4873]\n",
      "loss: 0.177173  [ 3600/ 4873]\n",
      "loss: 0.109072  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.635     0.448    105\n",
      " disgust     0.546     0.523     0.523    109\n",
      "    fear     0.546     0.506     0.487    80\n",
      "   happy     0.546     0.526     0.630    81\n",
      " neutral     0.546     0.625     0.655    84\n",
      "     sad     0.546     0.460     0.529    87\n",
      "surprise     0.546     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.551     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.292563 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.104860  [ 1200/ 4873]\n",
      "loss: 0.119773  [ 2400/ 4873]\n",
      "loss: 0.133122  [ 3600/ 4873]\n",
      "loss: 0.009779  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.630     0.552    105\n",
      " disgust     0.564     0.549     0.569    109\n",
      "    fear     0.564     0.493     0.463    80\n",
      "   happy     0.564     0.538     0.605    81\n",
      " neutral     0.564     0.659     0.690    84\n",
      "     sad     0.564     0.512     0.506    87\n",
      "surprise     0.564     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.562     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.215339 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.057193  [ 1200/ 4873]\n",
      "loss: 0.066191  [ 2400/ 4873]\n",
      "loss: 0.219031  [ 3600/ 4873]\n",
      "loss: 0.170652  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.648     0.543    105\n",
      " disgust     0.546     0.589     0.514    109\n",
      "    fear     0.546     0.416     0.463    80\n",
      "   happy     0.546     0.515     0.630    81\n",
      " neutral     0.546     0.644     0.667    84\n",
      "     sad     0.546     0.460     0.460    87\n",
      "surprise     0.546     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.546     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.306593 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.006865  [ 1200/ 4873]\n",
      "loss: 0.235866  [ 2400/ 4873]\n",
      "loss: 0.024315  [ 3600/ 4873]\n",
      "loss: 0.039003  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.632     0.457    105\n",
      " disgust     0.557     0.586     0.596    109\n",
      "    fear     0.557     0.462     0.525    80\n",
      "   happy     0.557     0.544     0.605    81\n",
      " neutral     0.557     0.659     0.667    84\n",
      "     sad     0.557     0.450     0.517    87\n",
      "surprise     0.557     0.614     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.564     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.103109 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.321899  [ 1200/ 4873]\n",
      "loss: 0.077243  [ 2400/ 4873]\n",
      "loss: 0.016914  [ 3600/ 4873]\n",
      "loss: 0.006474  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.574     0.514    105\n",
      " disgust     0.554     0.556     0.596    109\n",
      "    fear     0.554     0.447     0.475    80\n",
      "   happy     0.554     0.588     0.580    81\n",
      " neutral     0.554     0.674     0.690    84\n",
      "     sad     0.554     0.500     0.494    87\n",
      "surprise     0.554     0.532     0.516    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.553     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.149696 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.014000  [ 1200/ 4873]\n",
      "loss: 0.047076  [ 2400/ 4873]\n",
      "loss: 0.029622  [ 3600/ 4873]\n",
      "loss: 0.065930  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.735     0.476    105\n",
      " disgust     0.548     0.565     0.477    109\n",
      "    fear     0.548     0.521     0.475    80\n",
      "   happy     0.548     0.471     0.691    81\n",
      " neutral     0.548     0.633     0.679    84\n",
      "     sad     0.548     0.422     0.494    87\n",
      "surprise     0.548     0.576     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.560     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.150856 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.068183  [ 1200/ 4873]\n",
      "loss: 0.699624  [ 2400/ 4873]\n",
      "loss: 0.171255  [ 3600/ 4873]\n",
      "loss: 0.016875  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.585     0.524    105\n",
      " disgust     0.541     0.570     0.486    109\n",
      "    fear     0.541     0.471     0.500    80\n",
      "   happy     0.541     0.545     0.593    81\n",
      " neutral     0.541     0.602     0.667    84\n",
      "     sad     0.541     0.512     0.471    87\n",
      "surprise     0.541     0.481     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.538     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 3.207987 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.108453  [ 1200/ 4873]\n",
      "loss: 0.099087  [ 2400/ 4873]\n",
      "loss: 0.151239  [ 3600/ 4873]\n",
      "loss: 0.078450  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.626     0.543    105\n",
      " disgust     0.551     0.628     0.541    109\n",
      "    fear     0.551     0.500     0.487    80\n",
      "   happy     0.551     0.444     0.593    81\n",
      " neutral     0.551     0.606     0.679    84\n",
      "     sad     0.551     0.483     0.483    87\n",
      "surprise     0.551     0.586     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.553     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.078189 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.121230  [ 1200/ 4873]\n",
      "loss: 0.060006  [ 2400/ 4873]\n",
      "loss: 0.011653  [ 3600/ 4873]\n",
      "loss: 0.052538  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.538     0.634     0.495    105\n",
      " disgust     0.538     0.504     0.523    109\n",
      "    fear     0.538     0.444     0.450    80\n",
      "   happy     0.538     0.517     0.568    81\n",
      " neutral     0.538     0.656     0.702    84\n",
      "     sad     0.538     0.460     0.460    87\n",
      "surprise     0.538     0.559     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.538     0.539     0.542    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.298989 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.042246  [ 1200/ 4873]\n",
      "loss: 0.109788  [ 2400/ 4873]\n",
      "loss: 0.320717  [ 3600/ 4873]\n",
      "loss: 0.211689  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.615     0.562    105\n",
      " disgust     0.574     0.523     0.624    109\n",
      "    fear     0.574     0.500     0.487    80\n",
      "   happy     0.574     0.554     0.568    81\n",
      " neutral     0.574     0.656     0.702    84\n",
      "     sad     0.574     0.558     0.494    87\n",
      "surprise     0.574     0.643     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.578     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 3.107857 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.130884  [ 1200/ 4873]\n",
      "loss: 0.283622  [ 2400/ 4873]\n",
      "loss: 0.034182  [ 3600/ 4873]\n",
      "loss: 0.011885  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.537     0.486    105\n",
      " disgust     0.543     0.543     0.523    109\n",
      "    fear     0.543     0.465     0.500    80\n",
      "   happy     0.543     0.490     0.593    81\n",
      " neutral     0.543     0.690     0.690    84\n",
      "     sad     0.543     0.500     0.471    87\n",
      "surprise     0.543     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.546     0.546    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.156675 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.098863  [ 1200/ 4873]\n",
      "loss: 0.238545  [ 2400/ 4873]\n",
      "loss: 0.101414  [ 3600/ 4873]\n",
      "loss: 0.071826  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.625     0.476    105\n",
      " disgust     0.548     0.587     0.495    109\n",
      "    fear     0.548     0.461     0.512    80\n",
      "   happy     0.548     0.491     0.642    81\n",
      " neutral     0.548     0.667     0.667    84\n",
      "     sad     0.548     0.468     0.506    87\n",
      "surprise     0.548     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.552     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.202761 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.028004  [ 1200/ 4873]\n",
      "loss: 0.012800  [ 2400/ 4873]\n",
      "loss: 0.389466  [ 3600/ 4873]\n",
      "loss: 0.198460  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.624     0.552    105\n",
      " disgust     0.548     0.482     0.505    109\n",
      "    fear     0.548     0.500     0.475    80\n",
      "   happy     0.548     0.544     0.605    81\n",
      " neutral     0.548     0.647     0.655    84\n",
      "     sad     0.548     0.473     0.494    87\n",
      "surprise     0.548     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.551     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.227399 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.007796  [ 1200/ 4873]\n",
      "loss: 0.366014  [ 2400/ 4873]\n",
      "loss: 0.085903  [ 3600/ 4873]\n",
      "loss: 0.032922  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.617     0.552    105\n",
      " disgust     0.554     0.495     0.505    109\n",
      "    fear     0.554     0.458     0.475    80\n",
      "   happy     0.554     0.536     0.642    81\n",
      " neutral     0.554     0.714     0.655    84\n",
      "     sad     0.554     0.484     0.506    87\n",
      "surprise     0.554     0.632     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.562     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.124689 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.511828  [ 1200/ 4873]\n",
      "loss: 0.014346  [ 2400/ 4873]\n",
      "loss: 0.025271  [ 3600/ 4873]\n",
      "loss: 0.054082  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.641     0.562    105\n",
      " disgust     0.564     0.560     0.560    109\n",
      "    fear     0.564     0.526     0.512    80\n",
      "   happy     0.564     0.506     0.543    81\n",
      " neutral     0.564     0.585     0.738    84\n",
      "     sad     0.564     0.576     0.437    87\n",
      "surprise     0.564     0.542     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.562     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.289575 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.057213  [ 1200/ 4873]\n",
      "loss: 0.239878  [ 2400/ 4873]\n",
      "loss: 0.291571  [ 3600/ 4873]\n",
      "loss: 0.290271  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.634     0.495    105\n",
      " disgust     0.567     0.565     0.596    109\n",
      "    fear     0.567     0.477     0.512    80\n",
      "   happy     0.567     0.538     0.617    81\n",
      " neutral     0.567     0.663     0.702    84\n",
      "     sad     0.567     0.525     0.483    87\n",
      "surprise     0.567     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.567     0.569    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.148542 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.121857  [ 1200/ 4873]\n",
      "loss: 0.021863  [ 2400/ 4873]\n",
      "loss: 0.056288  [ 3600/ 4873]\n",
      "loss: 0.064528  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.655     0.524    105\n",
      " disgust     0.543     0.513     0.541    109\n",
      "    fear     0.543     0.481     0.463    80\n",
      "   happy     0.543     0.506     0.543    81\n",
      " neutral     0.543     0.620     0.679    84\n",
      "     sad     0.543     0.512     0.471    87\n",
      "surprise     0.543     0.507     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.542     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.293521 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.013747  [ 1200/ 4873]\n",
      "loss: 0.193017  [ 2400/ 4873]\n",
      "loss: 0.175406  [ 3600/ 4873]\n",
      "loss: 0.086239  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.675     0.533    105\n",
      " disgust     0.546     0.567     0.468    109\n",
      "    fear     0.546     0.441     0.512    80\n",
      "   happy     0.546     0.505     0.580    81\n",
      " neutral     0.546     0.641     0.702    84\n",
      "     sad     0.546     0.471     0.460    87\n",
      "surprise     0.546     0.527     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.547     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.119724 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.026386  [ 1200/ 4873]\n",
      "loss: 0.011214  [ 2400/ 4873]\n",
      "loss: 0.037291  [ 3600/ 4873]\n",
      "loss: 0.253033  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.622     0.533    105\n",
      " disgust     0.562     0.569     0.532    109\n",
      "    fear     0.562     0.494     0.525    80\n",
      "   happy     0.562     0.544     0.605    81\n",
      " neutral     0.562     0.682     0.690    84\n",
      "     sad     0.562     0.471     0.471    87\n",
      "surprise     0.562     0.549     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.562     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.205119 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.164670  [ 1200/ 4873]\n",
      "loss: 0.049117  [ 2400/ 4873]\n",
      "loss: 0.040868  [ 3600/ 4873]\n",
      "loss: 0.039645  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.602     0.476    105\n",
      " disgust     0.554     0.598     0.587    109\n",
      "    fear     0.554     0.434     0.450    80\n",
      "   happy     0.554     0.515     0.617    81\n",
      " neutral     0.554     0.656     0.750    84\n",
      "     sad     0.554     0.463     0.425    87\n",
      "surprise     0.554     0.594     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.552     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.309311 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.084889  [ 1200/ 4873]\n",
      "loss: 0.073922  [ 2400/ 4873]\n",
      "loss: 0.072029  [ 3600/ 4873]\n",
      "loss: 0.098327  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.621     0.562    105\n",
      " disgust     0.559     0.564     0.569    109\n",
      "    fear     0.559     0.507     0.450    80\n",
      "   happy     0.559     0.481     0.642    81\n",
      " neutral     0.559     0.637     0.690    84\n",
      "     sad     0.559     0.556     0.460    87\n",
      "surprise     0.559     0.540     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.558     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.078350 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.069241  [ 1200/ 4873]\n",
      "loss: 0.208579  [ 2400/ 4873]\n",
      "loss: 0.057717  [ 3600/ 4873]\n",
      "loss: 0.016558  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.671     0.467    105\n",
      " disgust     0.548     0.533     0.523    109\n",
      "    fear     0.548     0.535     0.475    80\n",
      "   happy     0.548     0.450     0.617    81\n",
      " neutral     0.548     0.773     0.690    84\n",
      "     sad     0.548     0.442     0.529    87\n",
      "surprise     0.548     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.561     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.322709 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.050954  [ 1200/ 4873]\n",
      "loss: 0.487585  [ 2400/ 4873]\n",
      "loss: 0.113518  [ 3600/ 4873]\n",
      "loss: 0.120160  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.589     0.533    105\n",
      " disgust     0.543     0.488     0.560    109\n",
      "    fear     0.543     0.481     0.475    80\n",
      "   happy     0.543     0.543     0.543    81\n",
      " neutral     0.543     0.690     0.690    84\n",
      "     sad     0.543     0.489     0.494    87\n",
      "surprise     0.543     0.534     0.484    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.545     0.540    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.445757 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.012284  [ 1200/ 4873]\n",
      "loss: 0.825508  [ 2400/ 4873]\n",
      "loss: 0.599286  [ 3600/ 4873]\n",
      "loss: 0.186093  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.548     0.486    105\n",
      " disgust     0.557     0.522     0.550    109\n",
      "    fear     0.557     0.519     0.525    80\n",
      "   happy     0.557     0.573     0.630    81\n",
      " neutral     0.557     0.674     0.690    84\n",
      "     sad     0.557     0.526     0.471    87\n",
      "surprise     0.557     0.544     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.558     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.327588 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.165794  [ 1200/ 4873]\n",
      "loss: 0.189101  [ 2400/ 4873]\n",
      "loss: 0.025863  [ 3600/ 4873]\n",
      "loss: 0.089449  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.618     0.524    105\n",
      " disgust     0.574     0.594     0.578    109\n",
      "    fear     0.574     0.505     0.588    80\n",
      "   happy     0.574     0.500     0.593    81\n",
      " neutral     0.574     0.725     0.690    84\n",
      "     sad     0.574     0.512     0.494    87\n",
      "surprise     0.574     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.576     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 3.248753 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.030027  [ 1200/ 4873]\n",
      "loss: 0.247792  [ 2400/ 4873]\n",
      "loss: 0.036321  [ 3600/ 4873]\n",
      "loss: 0.103832  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.651     0.533    105\n",
      " disgust     0.546     0.568     0.495    109\n",
      "    fear     0.546     0.456     0.450    80\n",
      "   happy     0.546     0.495     0.630    81\n",
      " neutral     0.546     0.692     0.643    84\n",
      "     sad     0.546     0.431     0.506    87\n",
      "surprise     0.546     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.552     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.230208 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.018517  [ 1200/ 4873]\n",
      "loss: 0.075260  [ 2400/ 4873]\n",
      "loss: 0.041913  [ 3600/ 4873]\n",
      "loss: 0.014584  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.628     0.514    105\n",
      " disgust     0.561     0.568     0.578    109\n",
      "    fear     0.561     0.465     0.500    80\n",
      "   happy     0.561     0.462     0.605    81\n",
      " neutral     0.561     0.707     0.690    84\n",
      "     sad     0.561     0.554     0.471    87\n",
      "surprise     0.561     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.565     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.172895 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.064969  [ 1200/ 4873]\n",
      "loss: 0.082781  [ 2400/ 4873]\n",
      "loss: 0.090789  [ 3600/ 4873]\n",
      "loss: 0.128482  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.644     0.533    105\n",
      " disgust     0.564     0.574     0.569    109\n",
      "    fear     0.564     0.476     0.500    80\n",
      "   happy     0.564     0.541     0.568    81\n",
      " neutral     0.564     0.711     0.702    84\n",
      "     sad     0.564     0.479     0.517    87\n",
      "surprise     0.564     0.522     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.564     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.192137 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.111715  [ 1200/ 4873]\n",
      "loss: 0.045611  [ 2400/ 4873]\n",
      "loss: 0.049200  [ 3600/ 4873]\n",
      "loss: 0.041731  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.614     0.514    105\n",
      " disgust     0.559     0.608     0.569    109\n",
      "    fear     0.559     0.500     0.463    80\n",
      "   happy     0.559     0.552     0.593    81\n",
      " neutral     0.559     0.602     0.702    84\n",
      "     sad     0.559     0.500     0.529    87\n",
      "surprise     0.559     0.507     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.555     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.279210 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.075074  [ 1200/ 4873]\n",
      "loss: 0.090873  [ 2400/ 4873]\n",
      "loss: 0.069749  [ 3600/ 4873]\n",
      "loss: 0.346184  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.634     0.495    105\n",
      " disgust     0.559     0.578     0.578    109\n",
      "    fear     0.559     0.494     0.500    80\n",
      "   happy     0.559     0.511     0.568    81\n",
      " neutral     0.559     0.628     0.702    84\n",
      "     sad     0.559     0.494     0.494    87\n",
      "surprise     0.559     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.558     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.200730 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.077165  [ 1200/ 4873]\n",
      "loss: 0.293030  [ 2400/ 4873]\n",
      "loss: 0.009407  [ 3600/ 4873]\n",
      "loss: 0.076321  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.589     0.533    105\n",
      " disgust     0.548     0.533     0.523    109\n",
      "    fear     0.548     0.458     0.475    80\n",
      "   happy     0.548     0.552     0.593    81\n",
      " neutral     0.548     0.596     0.702    84\n",
      "     sad     0.548     0.521     0.437    87\n",
      "surprise     0.548     0.576     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.546     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.240164 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.145945  [ 1200/ 4873]\n",
      "loss: 0.456467  [ 2400/ 4873]\n",
      "loss: 0.032312  [ 3600/ 4873]\n",
      "loss: 0.027965  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.602     0.505    105\n",
      " disgust     0.552     0.553     0.578    109\n",
      "    fear     0.552     0.444     0.500    80\n",
      "   happy     0.552     0.548     0.568    81\n",
      " neutral     0.552     0.644     0.667    84\n",
      "     sad     0.552     0.488     0.483    87\n",
      "surprise     0.552     0.607     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.555     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.192404 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.187247  [ 1200/ 4873]\n",
      "loss: 0.060149  [ 2400/ 4873]\n",
      "loss: 0.183272  [ 3600/ 4873]\n",
      "loss: 0.018364  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.648     0.562    105\n",
      " disgust     0.559     0.515     0.615    109\n",
      "    fear     0.559     0.479     0.438    80\n",
      "   happy     0.559     0.506     0.556    81\n",
      " neutral     0.559     0.750     0.679    84\n",
      "     sad     0.559     0.524     0.494    87\n",
      "surprise     0.559     0.507     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.561     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.178216 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.190733  [ 1200/ 4873]\n",
      "loss: 0.070440  [ 2400/ 4873]\n",
      "loss: 0.035787  [ 3600/ 4873]\n",
      "loss: 0.177408  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.667     0.457    105\n",
      " disgust     0.543     0.552     0.486    109\n",
      "    fear     0.543     0.467     0.537    80\n",
      "   happy     0.543     0.427     0.580    81\n",
      " neutral     0.543     0.770     0.679    84\n",
      "     sad     0.543     0.448     0.540    87\n",
      "surprise     0.543     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.560     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.290773 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.045091  [ 1200/ 4873]\n",
      "loss: 0.531021  [ 2400/ 4873]\n",
      "loss: 0.048186  [ 3600/ 4873]\n",
      "loss: 0.073152  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.644     0.533    105\n",
      " disgust     0.557     0.600     0.550    109\n",
      "    fear     0.557     0.576     0.475    80\n",
      "   happy     0.557     0.453     0.593    81\n",
      " neutral     0.557     0.625     0.714    84\n",
      "     sad     0.557     0.467     0.483    87\n",
      "surprise     0.557     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.560     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.178233 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.032169  [ 1200/ 4873]\n",
      "loss: 0.021115  [ 2400/ 4873]\n",
      "loss: 0.040904  [ 3600/ 4873]\n",
      "loss: 0.040573  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.552     0.505    105\n",
      " disgust     0.559     0.558     0.578    109\n",
      "    fear     0.559     0.469     0.475    80\n",
      "   happy     0.559     0.576     0.654    81\n",
      " neutral     0.559     0.667     0.714    84\n",
      "     sad     0.559     0.541     0.460    87\n",
      "surprise     0.559     0.531     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.556     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.263113 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.046590  [ 1200/ 4873]\n",
      "loss: 0.013489  [ 2400/ 4873]\n",
      "loss: 0.018304  [ 3600/ 4873]\n",
      "loss: 0.682249  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.580     0.713     0.543    105\n",
      " disgust     0.580     0.564     0.606    109\n",
      "    fear     0.580     0.548     0.500    80\n",
      "   happy     0.580     0.486     0.630    81\n",
      " neutral     0.580     0.667     0.690    84\n",
      "     sad     0.580     0.506     0.460    87\n",
      "surprise     0.580     0.609     0.656    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.580     0.585     0.583    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 3.127636 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.189904  [ 1200/ 4873]\n",
      "loss: 0.218167  [ 2400/ 4873]\n",
      "loss: 0.185489  [ 3600/ 4873]\n",
      "loss: 0.024844  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.636     0.533    105\n",
      " disgust     0.564     0.582     0.523    109\n",
      "    fear     0.564     0.506     0.487    80\n",
      "   happy     0.564     0.557     0.605    81\n",
      " neutral     0.564     0.638     0.714    84\n",
      "     sad     0.564     0.523     0.529    87\n",
      "surprise     0.564     0.481     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.560     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.195621 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.265713  [ 1200/ 4873]\n",
      "loss: 0.144251  [ 2400/ 4873]\n",
      "loss: 0.260573  [ 3600/ 4873]\n",
      "loss: 0.336649  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.568     0.514    105\n",
      " disgust     0.552     0.546     0.541    109\n",
      "    fear     0.552     0.484     0.550    80\n",
      "   happy     0.552     0.516     0.593    81\n",
      " neutral     0.552     0.671     0.679    84\n",
      "     sad     0.552     0.556     0.460    87\n",
      "surprise     0.552     0.530     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.553     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.147246 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.182106  [ 1200/ 4873]\n",
      "loss: 0.268974  [ 2400/ 4873]\n",
      "loss: 0.033092  [ 3600/ 4873]\n",
      "loss: 0.546558  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.630     0.552    105\n",
      " disgust     0.567     0.575     0.560    109\n",
      "    fear     0.567     0.526     0.500    80\n",
      "   happy     0.567     0.511     0.593    81\n",
      " neutral     0.567     0.682     0.690    84\n",
      "     sad     0.567     0.512     0.506    87\n",
      "surprise     0.567     0.521     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.565     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.126331 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.668033  [ 1200/ 4873]\n",
      "loss: 0.211521  [ 2400/ 4873]\n",
      "loss: 0.382656  [ 3600/ 4873]\n",
      "loss: 0.012457  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.662     0.505    105\n",
      " disgust     0.549     0.487     0.505    109\n",
      "    fear     0.549     0.494     0.512    80\n",
      "   happy     0.549     0.495     0.617    81\n",
      " neutral     0.549     0.756     0.702    84\n",
      "     sad     0.549     0.439     0.494    87\n",
      "surprise     0.549     0.596     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.561     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.223670 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.202680  [ 1200/ 4873]\n",
      "loss: 0.393546  [ 2400/ 4873]\n",
      "loss: 0.353509  [ 3600/ 4873]\n",
      "loss: 0.021920  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.618     0.524    105\n",
      " disgust     0.543     0.575     0.459    109\n",
      "    fear     0.543     0.472     0.525    80\n",
      "   happy     0.543     0.500     0.580    81\n",
      " neutral     0.543     0.600     0.714    84\n",
      "     sad     0.543     0.489     0.494    87\n",
      "surprise     0.543     0.540     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.542     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.235532 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.522239  [ 1200/ 4873]\n",
      "loss: 0.009097  [ 2400/ 4873]\n",
      "loss: 0.057469  [ 3600/ 4873]\n",
      "loss: 0.167207  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.629     0.533    105\n",
      " disgust     0.552     0.579     0.505    109\n",
      "    fear     0.552     0.513     0.487    80\n",
      "   happy     0.552     0.490     0.630    81\n",
      " neutral     0.552     0.641     0.702    84\n",
      "     sad     0.552     0.475     0.437    87\n",
      "surprise     0.552     0.527     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.551     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.126048 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.064128  [ 1200/ 4873]\n",
      "loss: 0.021913  [ 2400/ 4873]\n",
      "loss: 0.114804  [ 3600/ 4873]\n",
      "loss: 0.264242  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.624     0.552    105\n",
      " disgust     0.566     0.585     0.569    109\n",
      "    fear     0.566     0.438     0.487    80\n",
      "   happy     0.566     0.615     0.593    81\n",
      " neutral     0.566     0.626     0.679    84\n",
      "     sad     0.566     0.489     0.517    87\n",
      "surprise     0.566     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.567     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.130031 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.058239  [ 1200/ 4873]\n",
      "loss: 0.114448  [ 2400/ 4873]\n",
      "loss: 0.741565  [ 3600/ 4873]\n",
      "loss: 0.029169  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.592     0.552    105\n",
      " disgust     0.564     0.564     0.569    109\n",
      "    fear     0.564     0.520     0.487    80\n",
      "   happy     0.564     0.510     0.605    81\n",
      " neutral     0.564     0.702     0.702    84\n",
      "     sad     0.564     0.477     0.471    87\n",
      "surprise     0.564     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.565     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.119444 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.065193  [ 1200/ 4873]\n",
      "loss: 0.418639  [ 2400/ 4873]\n",
      "loss: 0.921129  [ 3600/ 4873]\n",
      "loss: 0.202960  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.575     0.659     0.552    105\n",
      " disgust     0.575     0.573     0.578    109\n",
      "    fear     0.575     0.449     0.500    80\n",
      "   happy     0.575     0.556     0.617    81\n",
      " neutral     0.575     0.686     0.702    84\n",
      "     sad     0.575     0.523     0.517    87\n",
      "surprise     0.575     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.575     0.577     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 3.217245 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.026133  [ 1200/ 4873]\n",
      "loss: 0.014366  [ 2400/ 4873]\n",
      "loss: 0.246073  [ 3600/ 4873]\n",
      "loss: 0.027871  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.612     0.495    105\n",
      " disgust     0.561     0.577     0.514    109\n",
      "    fear     0.561     0.494     0.500    80\n",
      "   happy     0.561     0.552     0.654    81\n",
      " neutral     0.561     0.625     0.714    84\n",
      "     sad     0.561     0.524     0.494    87\n",
      "surprise     0.561     0.521     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.558     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.272410 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.021834  [ 1200/ 4873]\n",
      "loss: 0.033883  [ 2400/ 4873]\n",
      "loss: 0.074661  [ 3600/ 4873]\n",
      "loss: 0.073075  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.574     0.514    105\n",
      " disgust     0.567     0.555     0.606    109\n",
      "    fear     0.567     0.455     0.575    80\n",
      "   happy     0.567     0.608     0.556    81\n",
      " neutral     0.567     0.718     0.667    84\n",
      "     sad     0.567     0.518     0.494    87\n",
      "surprise     0.567     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.574     0.568    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.212658 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.032855  [ 1200/ 4873]\n",
      "loss: 0.029474  [ 2400/ 4873]\n",
      "loss: 0.073620  [ 3600/ 4873]\n",
      "loss: 0.020810  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.591     0.524    105\n",
      " disgust     0.556     0.561     0.550    109\n",
      "    fear     0.556     0.446     0.463    80\n",
      "   happy     0.556     0.553     0.642    81\n",
      " neutral     0.556     0.667     0.714    84\n",
      "     sad     0.556     0.494     0.437    87\n",
      "surprise     0.556     0.561     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.553     0.558    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.125193 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.012461  [ 1200/ 4873]\n",
      "loss: 0.285120  [ 2400/ 4873]\n",
      "loss: 0.039874  [ 3600/ 4873]\n",
      "loss: 0.020075  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.579     0.524    105\n",
      " disgust     0.554     0.546     0.541    109\n",
      "    fear     0.554     0.442     0.475    80\n",
      "   happy     0.554     0.545     0.593    81\n",
      " neutral     0.554     0.700     0.667    84\n",
      "     sad     0.554     0.511     0.517    87\n",
      "surprise     0.554     0.569     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.556     0.556    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.234692 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.034386  [ 1200/ 4873]\n",
      "loss: 0.156878  [ 2400/ 4873]\n",
      "loss: 0.227617  [ 3600/ 4873]\n",
      "loss: 0.436881  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.596     0.505    105\n",
      " disgust     0.561     0.571     0.550    109\n",
      "    fear     0.561     0.473     0.438    80\n",
      "   happy     0.561     0.516     0.593    81\n",
      " neutral     0.561     0.621     0.762    84\n",
      "     sad     0.561     0.518     0.494    87\n",
      "surprise     0.561     0.619     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.559     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.175832 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.173536  [ 1200/ 4873]\n",
      "loss: 0.228141  [ 2400/ 4873]\n",
      "loss: 0.143049  [ 3600/ 4873]\n",
      "loss: 0.051905  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.625     0.571    105\n",
      " disgust     0.572     0.570     0.596    109\n",
      "    fear     0.572     0.483     0.537    80\n",
      "   happy     0.572     0.556     0.556    81\n",
      " neutral     0.572     0.609     0.667    84\n",
      "     sad     0.572     0.592     0.483    87\n",
      "surprise     0.572     0.567     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.572     0.572    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 3.217690 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.164150  [ 1200/ 4873]\n",
      "loss: 0.069016  [ 2400/ 4873]\n",
      "loss: 0.077251  [ 3600/ 4873]\n",
      "loss: 0.082254  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.586     0.486    105\n",
      " disgust     0.559     0.588     0.550    109\n",
      "    fear     0.559     0.488     0.525    80\n",
      "   happy     0.559     0.532     0.617    81\n",
      " neutral     0.559     0.724     0.655    84\n",
      "     sad     0.559     0.442     0.529    87\n",
      "surprise     0.559     0.607     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.567     0.563    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.224613 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.088360  [ 1200/ 4873]\n",
      "loss: 0.020248  [ 2400/ 4873]\n",
      "loss: 0.121424  [ 3600/ 4873]\n",
      "loss: 0.013423  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.646     0.505    105\n",
      " disgust     0.556     0.545     0.550    109\n",
      "    fear     0.556     0.476     0.487    80\n",
      "   happy     0.556     0.552     0.593    81\n",
      " neutral     0.556     0.634     0.702    84\n",
      "     sad     0.556     0.524     0.494    87\n",
      "surprise     0.556     0.500     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.554     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.370562 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.084372  [ 1200/ 4873]\n",
      "loss: 0.051996  [ 2400/ 4873]\n",
      "loss: 0.243660  [ 3600/ 4873]\n",
      "loss: 0.019330  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.659     0.533    105\n",
      " disgust     0.541     0.538     0.523    109\n",
      "    fear     0.541     0.543     0.475    80\n",
      "   happy     0.541     0.495     0.568    81\n",
      " neutral     0.541     0.648     0.679    84\n",
      "     sad     0.541     0.413     0.437    87\n",
      "surprise     0.541     0.500     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.542     0.544    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 3.396552 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.591792  [ 1200/ 4873]\n",
      "loss: 0.334834  [ 2400/ 4873]\n",
      "loss: 0.017228  [ 3600/ 4873]\n",
      "loss: 0.082443  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.600     0.486    105\n",
      " disgust     0.551     0.559     0.606    109\n",
      "    fear     0.551     0.515     0.438    80\n",
      "   happy     0.551     0.535     0.568    81\n",
      " neutral     0.551     0.606     0.714    84\n",
      "     sad     0.551     0.506     0.483    87\n",
      "surprise     0.551     0.507     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.547     0.551    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.359728 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.196329  [ 1200/ 4873]\n",
      "loss: 0.152667  [ 2400/ 4873]\n",
      "loss: 0.059585  [ 3600/ 4873]\n",
      "loss: 0.441822  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.630     0.552    105\n",
      " disgust     0.566     0.562     0.578    109\n",
      "    fear     0.566     0.452     0.525    80\n",
      "   happy     0.566     0.523     0.568    81\n",
      " neutral     0.566     0.678     0.702    84\n",
      "     sad     0.566     0.500     0.460    87\n",
      "surprise     0.566     0.638     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.569     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.963874 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.073857  [ 1200/ 4873]\n",
      "loss: 0.253314  [ 2400/ 4873]\n",
      "loss: 0.030108  [ 3600/ 4873]\n",
      "loss: 0.029510  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.570     0.543    105\n",
      " disgust     0.564     0.594     0.550    109\n",
      "    fear     0.564     0.500     0.537    80\n",
      "   happy     0.564     0.568     0.617    81\n",
      " neutral     0.564     0.602     0.667    84\n",
      "     sad     0.564     0.594     0.471    87\n",
      "surprise     0.564     0.507     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.562     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.221973 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.025633  [ 1200/ 4873]\n",
      "loss: 0.019684  [ 2400/ 4873]\n",
      "loss: 0.025830  [ 3600/ 4873]\n",
      "loss: 0.280394  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.642     0.495    105\n",
      " disgust     0.559     0.519     0.514    109\n",
      "    fear     0.559     0.532     0.512    80\n",
      "   happy     0.559     0.527     0.605    81\n",
      " neutral     0.559     0.619     0.714    84\n",
      "     sad     0.559     0.500     0.529    87\n",
      "surprise     0.559     0.597     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.562     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.200063 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.011078  [ 1200/ 4873]\n",
      "loss: 0.037210  [ 2400/ 4873]\n",
      "loss: 0.044617  [ 3600/ 4873]\n",
      "loss: 0.066080  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.536     0.627     0.495    105\n",
      " disgust     0.536     0.571     0.514    109\n",
      "    fear     0.536     0.422     0.475    80\n",
      "   happy     0.536     0.490     0.605    81\n",
      " neutral     0.536     0.679     0.655    84\n",
      "     sad     0.536     0.447     0.483    87\n",
      "surprise     0.536     0.547     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.536     0.540     0.539    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 3.329074 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.015383  [ 1200/ 4873]\n",
      "loss: 0.034004  [ 2400/ 4873]\n",
      "loss: 0.062185  [ 3600/ 4873]\n",
      "loss: 0.047612  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.671     0.543    105\n",
      " disgust     0.557     0.484     0.560    109\n",
      "    fear     0.557     0.453     0.537    80\n",
      "   happy     0.557     0.605     0.568    81\n",
      " neutral     0.557     0.696     0.655    84\n",
      "     sad     0.557     0.473     0.506    87\n",
      "surprise     0.557     0.607     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.570     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.355566 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.008968  [ 1200/ 4873]\n",
      "loss: 0.052249  [ 2400/ 4873]\n",
      "loss: 0.012171  [ 3600/ 4873]\n",
      "loss: 0.146708  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.543     0.588     0.448    105\n",
      " disgust     0.543     0.590     0.541    109\n",
      "    fear     0.543     0.432     0.475    80\n",
      "   happy     0.543     0.500     0.593    81\n",
      " neutral     0.543     0.598     0.690    84\n",
      "     sad     0.543     0.511     0.517    87\n",
      "surprise     0.543     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.543     0.544     0.547    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.303689 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.008791  [ 1200/ 4873]\n",
      "loss: 0.009634  [ 2400/ 4873]\n",
      "loss: 0.020704  [ 3600/ 4873]\n",
      "loss: 0.037116  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.638     0.571    105\n",
      " disgust     0.564     0.538     0.523    109\n",
      "    fear     0.564     0.512     0.525    80\n",
      "   happy     0.564     0.533     0.593    81\n",
      " neutral     0.564     0.679     0.679    84\n",
      "     sad     0.564     0.506     0.483    87\n",
      "surprise     0.564     0.535     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.563     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.178249 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.221673  [ 1200/ 4873]\n",
      "loss: 0.249639  [ 2400/ 4873]\n",
      "loss: 0.008567  [ 3600/ 4873]\n",
      "loss: 0.106466  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.611     0.524    105\n",
      " disgust     0.561     0.537     0.532    109\n",
      "    fear     0.561     0.471     0.500    80\n",
      "   happy     0.561     0.603     0.580    81\n",
      " neutral     0.561     0.711     0.702    84\n",
      "     sad     0.561     0.485     0.552    87\n",
      "surprise     0.561     0.522     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.563     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.203514 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 1.456315  [ 1200/ 4873]\n",
      "loss: 0.036025  [ 2400/ 4873]\n",
      "loss: 0.127771  [ 3600/ 4873]\n",
      "loss: 0.019181  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.549     0.629     0.533    105\n",
      " disgust     0.549     0.568     0.495    109\n",
      "    fear     0.549     0.542     0.487    80\n",
      "   happy     0.549     0.482     0.654    81\n",
      " neutral     0.549     0.741     0.714    84\n",
      "     sad     0.549     0.413     0.437    87\n",
      "surprise     0.549     0.493     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.549     0.553     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 3.258797 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.051899  [ 1200/ 4873]\n",
      "loss: 0.048215  [ 2400/ 4873]\n",
      "loss: 0.009602  [ 3600/ 4873]\n",
      "loss: 0.132763  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.626     0.590    105\n",
      " disgust     0.562     0.519     0.514    109\n",
      "    fear     0.562     0.530     0.438    80\n",
      "   happy     0.562     0.543     0.630    81\n",
      " neutral     0.562     0.644     0.667    84\n",
      "     sad     0.562     0.523     0.529    87\n",
      "surprise     0.562     0.544     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.561     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.262619 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.157474  [ 1200/ 4873]\n",
      "loss: 0.190871  [ 2400/ 4873]\n",
      "loss: 0.038172  [ 3600/ 4873]\n",
      "loss: 0.057178  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.637     0.552    105\n",
      " disgust     0.548     0.500     0.495    109\n",
      "    fear     0.548     0.500     0.463    80\n",
      "   happy     0.548     0.510     0.642    81\n",
      " neutral     0.548     0.621     0.702    84\n",
      "     sad     0.548     0.513     0.460    87\n",
      "surprise     0.548     0.548     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.547     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.274746 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.093081  [ 1200/ 4873]\n",
      "loss: 0.007490  [ 2400/ 4873]\n",
      "loss: 0.660490  [ 3600/ 4873]\n",
      "loss: 0.216056  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.640     0.543    105\n",
      " disgust     0.548     0.514     0.523    109\n",
      "    fear     0.548     0.479     0.438    80\n",
      "   happy     0.548     0.470     0.580    81\n",
      " neutral     0.548     0.693     0.726    84\n",
      "     sad     0.548     0.483     0.483    87\n",
      "surprise     0.548     0.565     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.549     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.336879 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.103548  [ 1200/ 4873]\n",
      "loss: 0.017575  [ 2400/ 4873]\n",
      "loss: 0.008115  [ 3600/ 4873]\n",
      "loss: 0.152320  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.596     0.505    105\n",
      " disgust     0.559     0.525     0.587    109\n",
      "    fear     0.559     0.451     0.512    80\n",
      "   happy     0.559     0.563     0.605    81\n",
      " neutral     0.559     0.698     0.714    84\n",
      "     sad     0.559     0.533     0.460    87\n",
      "surprise     0.559     0.567     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.562     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.458222 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.188568  [ 1200/ 4873]\n",
      "loss: 0.207779  [ 2400/ 4873]\n",
      "loss: 0.049387  [ 3600/ 4873]\n",
      "loss: 0.024206  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.617     0.552    105\n",
      " disgust     0.557     0.549     0.514    109\n",
      "    fear     0.557     0.476     0.487    80\n",
      "   happy     0.557     0.549     0.617    81\n",
      " neutral     0.557     0.616     0.726    84\n",
      "     sad     0.557     0.549     0.448    87\n",
      "surprise     0.557     0.521     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.554     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.316078 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.232457  [ 1200/ 4873]\n",
      "loss: 0.006613  [ 2400/ 4873]\n",
      "loss: 0.014004  [ 3600/ 4873]\n",
      "loss: 0.009370  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.619     0.495    105\n",
      " disgust     0.552     0.567     0.505    109\n",
      "    fear     0.552     0.440     0.500    80\n",
      "   happy     0.552     0.515     0.630    81\n",
      " neutral     0.552     0.648     0.702    84\n",
      "     sad     0.552     0.500     0.506    87\n",
      "surprise     0.552     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.556     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.252368 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.050865  [ 1200/ 4873]\n",
      "loss: 0.342352  [ 2400/ 4873]\n",
      "loss: 0.189583  [ 3600/ 4873]\n",
      "loss: 0.727143  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.578     0.562    105\n",
      " disgust     0.552     0.566     0.514    109\n",
      "    fear     0.552     0.427     0.512    80\n",
      "   happy     0.552     0.545     0.593    81\n",
      " neutral     0.552     0.711     0.702    84\n",
      "     sad     0.552     0.482     0.460    87\n",
      "surprise     0.552     0.576     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.555     0.553    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.242731 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.276568  [ 1200/ 4873]\n",
      "loss: 0.141645  [ 2400/ 4873]\n",
      "loss: 0.393615  [ 3600/ 4873]\n",
      "loss: 0.009788  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.640     0.524    105\n",
      " disgust     0.552     0.581     0.495    109\n",
      "    fear     0.552     0.426     0.500    80\n",
      "   happy     0.552     0.563     0.605    81\n",
      " neutral     0.552     0.633     0.679    84\n",
      "     sad     0.552     0.471     0.471    87\n",
      "surprise     0.552     0.562     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.554     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.226925 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.220605  [ 1200/ 4873]\n",
      "loss: 0.174075  [ 2400/ 4873]\n",
      "loss: 0.203569  [ 3600/ 4873]\n",
      "loss: 0.680458  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.567     0.524    105\n",
      " disgust     0.564     0.545     0.670    109\n",
      "    fear     0.564     0.481     0.463    80\n",
      "   happy     0.564     0.576     0.605    81\n",
      " neutral     0.564     0.655     0.679    84\n",
      "     sad     0.564     0.544     0.425    87\n",
      "surprise     0.564     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.564     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.212650 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.053422  [ 1200/ 4873]\n",
      "loss: 0.044427  [ 2400/ 4873]\n",
      "loss: 0.070798  [ 3600/ 4873]\n",
      "loss: 0.060906  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.552     0.583     0.533    105\n",
      " disgust     0.552     0.609     0.514    109\n",
      "    fear     0.552     0.432     0.475    80\n",
      "   happy     0.552     0.566     0.580    81\n",
      " neutral     0.552     0.625     0.714    84\n",
      "     sad     0.552     0.526     0.460    87\n",
      "surprise     0.552     0.506     0.625    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.552     0.550     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 3.227825 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.141751  [ 1200/ 4873]\n",
      "loss: 0.080140  [ 2400/ 4873]\n",
      "loss: 0.028530  [ 3600/ 4873]\n",
      "loss: 0.009499  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.564     0.596     0.533    105\n",
      " disgust     0.564     0.541     0.541    109\n",
      "    fear     0.564     0.446     0.512    80\n",
      "   happy     0.564     0.671     0.580    81\n",
      " neutral     0.564     0.655     0.655    84\n",
      "     sad     0.564     0.490     0.575    87\n",
      "surprise     0.564     0.610     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.564     0.573     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 3.247672 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.038678  [ 1200/ 4873]\n",
      "loss: 0.026346  [ 2400/ 4873]\n",
      "loss: 0.171869  [ 3600/ 4873]\n",
      "loss: 0.459550  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.626     0.543    105\n",
      " disgust     0.546     0.478     0.495    109\n",
      "    fear     0.546     0.500     0.475    80\n",
      "   happy     0.546     0.558     0.593    81\n",
      " neutral     0.546     0.652     0.714    84\n",
      "     sad     0.546     0.494     0.471    87\n",
      "surprise     0.546     0.507     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.545     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.316516 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.089551  [ 1200/ 4873]\n",
      "loss: 0.151851  [ 2400/ 4873]\n",
      "loss: 0.176890  [ 3600/ 4873]\n",
      "loss: 0.006411  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.556     0.670     0.581    105\n",
      " disgust     0.556     0.569     0.532    109\n",
      "    fear     0.556     0.468     0.463    80\n",
      "   happy     0.556     0.490     0.593    81\n",
      " neutral     0.556     0.648     0.702    84\n",
      "     sad     0.556     0.500     0.483    87\n",
      "surprise     0.556     0.523     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.556     0.553     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 3.328585 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.210241  [ 1200/ 4873]\n",
      "loss: 0.244615  [ 2400/ 4873]\n",
      "loss: 0.032715  [ 3600/ 4873]\n",
      "loss: 0.499635  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.598     0.524    105\n",
      " disgust     0.557     0.548     0.578    109\n",
      "    fear     0.557     0.487     0.463    80\n",
      "   happy     0.557     0.556     0.556    81\n",
      " neutral     0.557     0.632     0.655    84\n",
      "     sad     0.557     0.506     0.506    87\n",
      "surprise     0.557     0.569     0.641    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.556     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.300603 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.282722  [ 1200/ 4873]\n",
      "loss: 0.102972  [ 2400/ 4873]\n",
      "loss: 0.018901  [ 3600/ 4873]\n",
      "loss: 0.935149  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.566     0.588     0.543    105\n",
      " disgust     0.566     0.563     0.615    109\n",
      "    fear     0.566     0.561     0.463    80\n",
      "   happy     0.566     0.558     0.593    81\n",
      " neutral     0.566     0.639     0.631    84\n",
      "     sad     0.566     0.542     0.517    87\n",
      "surprise     0.566     0.500     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.566     0.564     0.565    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 3.338546 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.432258  [ 1200/ 4873]\n",
      "loss: 0.120500  [ 2400/ 4873]\n",
      "loss: 0.142355  [ 3600/ 4873]\n",
      "loss: 0.056570  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.640     0.524    105\n",
      " disgust     0.554     0.541     0.550    109\n",
      "    fear     0.554     0.444     0.500    80\n",
      "   happy     0.554     0.505     0.630    81\n",
      " neutral     0.554     0.696     0.655    84\n",
      "     sad     0.554     0.500     0.483    87\n",
      "surprise     0.554     0.593     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.560     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.306785 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.006183  [ 1200/ 4873]\n",
      "loss: 0.101622  [ 2400/ 4873]\n",
      "loss: 0.201840  [ 3600/ 4873]\n",
      "loss: 0.093876  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.636     0.533    105\n",
      " disgust     0.548     0.617     0.532    109\n",
      "    fear     0.548     0.440     0.463    80\n",
      "   happy     0.548     0.425     0.556    81\n",
      " neutral     0.548     0.608     0.702    84\n",
      "     sad     0.548     0.566     0.494    87\n",
      "surprise     0.548     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.549     0.549    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.241662 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.055544  [ 1200/ 4873]\n",
      "loss: 0.176374  [ 2400/ 4873]\n",
      "loss: 0.060465  [ 3600/ 4873]\n",
      "loss: 0.049913  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.611     0.552    105\n",
      " disgust     0.572     0.544     0.569    109\n",
      "    fear     0.572     0.469     0.475    80\n",
      "   happy     0.572     0.548     0.630    81\n",
      " neutral     0.572     0.744     0.690    84\n",
      "     sad     0.572     0.535     0.529    87\n",
      "surprise     0.572     0.571     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.575     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 3.191021 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.082478  [ 1200/ 4873]\n",
      "loss: 0.241945  [ 2400/ 4873]\n",
      "loss: 0.007680  [ 3600/ 4873]\n",
      "loss: 0.195248  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.620     0.590    105\n",
      " disgust     0.567     0.512     0.578    109\n",
      "    fear     0.567     0.526     0.500    80\n",
      "   happy     0.567     0.547     0.580    81\n",
      " neutral     0.567     0.679     0.679    84\n",
      "     sad     0.567     0.488     0.471    87\n",
      "surprise     0.567     0.632     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.572     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.275522 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.091220  [ 1200/ 4873]\n",
      "loss: 0.377050  [ 2400/ 4873]\n",
      "loss: 0.029430  [ 3600/ 4873]\n",
      "loss: 0.460107  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.629     0.581    105\n",
      " disgust     0.562     0.535     0.486    109\n",
      "    fear     0.562     0.536     0.562    80\n",
      "   happy     0.562     0.522     0.580    81\n",
      " neutral     0.562     0.632     0.655    84\n",
      "     sad     0.562     0.550     0.506    87\n",
      "surprise     0.562     0.521     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.561     0.566    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.232088 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.015227  [ 1200/ 4873]\n",
      "loss: 0.112114  [ 2400/ 4873]\n",
      "loss: 0.116027  [ 3600/ 4873]\n",
      "loss: 0.070901  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.562     0.618     0.524    105\n",
      " disgust     0.562     0.577     0.550    109\n",
      "    fear     0.562     0.543     0.475    80\n",
      "   happy     0.562     0.441     0.642    81\n",
      " neutral     0.562     0.747     0.702    84\n",
      "     sad     0.562     0.489     0.506    87\n",
      "surprise     0.562     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.562     0.571     0.564    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 3.337291 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.054595  [ 1200/ 4873]\n",
      "loss: 0.013605  [ 2400/ 4873]\n",
      "loss: 0.028410  [ 3600/ 4873]\n",
      "loss: 0.097771  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.678     0.562    105\n",
      " disgust     0.551     0.529     0.505    109\n",
      "    fear     0.551     0.562     0.450    80\n",
      "   happy     0.551     0.429     0.630    81\n",
      " neutral     0.551     0.590     0.702    84\n",
      "     sad     0.551     0.560     0.483    87\n",
      "surprise     0.551     0.557     0.531    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.558     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.271968 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.022970  [ 1200/ 4873]\n",
      "loss: 0.014053  [ 2400/ 4873]\n",
      "loss: 0.024884  [ 3600/ 4873]\n",
      "loss: 0.166430  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.610     0.581    105\n",
      " disgust     0.572     0.524     0.596    109\n",
      "    fear     0.572     0.460     0.500    80\n",
      "   happy     0.572     0.595     0.580    81\n",
      " neutral     0.572     0.716     0.690    84\n",
      "     sad     0.572     0.532     0.483    87\n",
      "surprise     0.572     0.600     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.577     0.570    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 3.220865 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.006113  [ 1200/ 4873]\n",
      "loss: 0.055225  [ 2400/ 4873]\n",
      "loss: 0.010644  [ 3600/ 4873]\n",
      "loss: 0.019209  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.651     0.533    105\n",
      " disgust     0.551     0.525     0.477    109\n",
      "    fear     0.551     0.477     0.512    80\n",
      "   happy     0.551     0.515     0.630    81\n",
      " neutral     0.551     0.699     0.690    84\n",
      "     sad     0.551     0.457     0.494    87\n",
      "surprise     0.551     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.554     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.310940 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.015410  [ 1200/ 4873]\n",
      "loss: 0.033391  [ 2400/ 4873]\n",
      "loss: 0.217709  [ 3600/ 4873]\n",
      "loss: 0.212835  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.559     0.654     0.505    105\n",
      " disgust     0.559     0.565     0.560    109\n",
      "    fear     0.559     0.487     0.463    80\n",
      "   happy     0.559     0.510     0.630    81\n",
      " neutral     0.559     0.655     0.679    84\n",
      "     sad     0.559     0.479     0.529    87\n",
      "surprise     0.559     0.581     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.559     0.562     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.126365 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.043536  [ 1200/ 4873]\n",
      "loss: 0.385936  [ 2400/ 4873]\n",
      "loss: 0.012051  [ 3600/ 4873]\n",
      "loss: 0.096583  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.567     0.615     0.533    105\n",
      " disgust     0.567     0.588     0.615    109\n",
      "    fear     0.567     0.470     0.487    80\n",
      "   happy     0.567     0.529     0.568    81\n",
      " neutral     0.567     0.656     0.702    84\n",
      "     sad     0.567     0.532     0.483    87\n",
      "surprise     0.567     0.561     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.567     0.564     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 3.225170 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.016056  [ 1200/ 4873]\n",
      "loss: 0.031620  [ 2400/ 4873]\n",
      "loss: 0.091544  [ 3600/ 4873]\n",
      "loss: 0.090894  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.577     0.735     0.581    105\n",
      " disgust     0.577     0.573     0.578    109\n",
      "    fear     0.577     0.514     0.450    80\n",
      "   happy     0.577     0.500     0.642    81\n",
      " neutral     0.577     0.663     0.702    84\n",
      "     sad     0.577     0.483     0.494    87\n",
      "surprise     0.577     0.585     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.577     0.579     0.577    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 3.124855 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.051435  [ 1200/ 4873]\n",
      "loss: 0.030010  [ 2400/ 4873]\n",
      "loss: 0.021112  [ 3600/ 4873]\n",
      "loss: 0.309098  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.701     0.514    105\n",
      " disgust     0.554     0.550     0.550    109\n",
      "    fear     0.554     0.521     0.475    80\n",
      "   happy     0.554     0.505     0.630    81\n",
      " neutral     0.554     0.671     0.655    84\n",
      "     sad     0.554     0.473     0.494    87\n",
      "surprise     0.554     0.481     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.554     0.557     0.557    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.394877 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.116242  [ 1200/ 4873]\n",
      "loss: 0.289616  [ 2400/ 4873]\n",
      "loss: 0.038937  [ 3600/ 4873]\n",
      "loss: 0.012886  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.541     0.631     0.505    105\n",
      " disgust     0.541     0.560     0.514    109\n",
      "    fear     0.541     0.444     0.450    80\n",
      "   happy     0.541     0.490     0.605    81\n",
      " neutral     0.541     0.590     0.702    84\n",
      "     sad     0.541     0.519     0.460    87\n",
      "surprise     0.541     0.544     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.541     0.540     0.545    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 3.270987 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.016776  [ 1200/ 4873]\n",
      "loss: 0.168153  [ 2400/ 4873]\n",
      "loss: 0.038302  [ 3600/ 4873]\n",
      "loss: 0.080681  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.639     0.505    105\n",
      " disgust     0.548     0.554     0.514    109\n",
      "    fear     0.548     0.477     0.512    80\n",
      "   happy     0.548     0.563     0.605    81\n",
      " neutral     0.548     0.600     0.714    84\n",
      "     sad     0.548     0.513     0.448    87\n",
      "surprise     0.548     0.468     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.548     0.545     0.552    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 3.171553 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.031059  [ 1200/ 4873]\n",
      "loss: 0.088472  [ 2400/ 4873]\n",
      "loss: 0.025037  [ 3600/ 4873]\n",
      "loss: 0.319869  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.678     0.562    105\n",
      " disgust     0.551     0.509     0.514    109\n",
      "    fear     0.551     0.487     0.487    80\n",
      "   happy     0.551     0.495     0.593    81\n",
      " neutral     0.551     0.734     0.690    84\n",
      "     sad     0.551     0.432     0.437    87\n",
      "surprise     0.551     0.551     0.594    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.555     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.243618 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.082420  [ 1200/ 4873]\n",
      "loss: 0.012774  [ 2400/ 4873]\n",
      "loss: 0.076994  [ 3600/ 4873]\n",
      "loss: 0.120987  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.580     0.660     0.590    105\n",
      " disgust     0.580     0.548     0.624    109\n",
      "    fear     0.580     0.486     0.450    80\n",
      "   happy     0.580     0.570     0.605    81\n",
      " neutral     0.580     0.704     0.679    84\n",
      "     sad     0.580     0.495     0.517    87\n",
      "surprise     0.580     0.617     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.580     0.583     0.578    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 3.352638 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.052146  [ 1200/ 4873]\n",
      "loss: 0.005857  [ 2400/ 4873]\n",
      "loss: 0.243730  [ 3600/ 4873]\n",
      "loss: 0.303255  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.588     0.543    105\n",
      " disgust     0.561     0.543     0.578    109\n",
      "    fear     0.561     0.448     0.487    80\n",
      "   happy     0.561     0.540     0.580    81\n",
      " neutral     0.561     0.648     0.702    84\n",
      "     sad     0.561     0.583     0.483    87\n",
      "surprise     0.561     0.583     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.562     0.560    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.295323 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.084052  [ 1200/ 4873]\n",
      "loss: 0.207592  [ 2400/ 4873]\n",
      "loss: 0.226369  [ 3600/ 4873]\n",
      "loss: 0.137801  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.546     0.634     0.495    105\n",
      " disgust     0.546     0.486     0.495    109\n",
      "    fear     0.546     0.442     0.475    80\n",
      "   happy     0.546     0.520     0.630    81\n",
      " neutral     0.546     0.707     0.690    84\n",
      "     sad     0.546     0.511     0.517    87\n",
      "surprise     0.546     0.556     0.547    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.546     0.551     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.144538 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.087162  [ 1200/ 4873]\n",
      "loss: 0.034633  [ 2400/ 4873]\n",
      "loss: 0.006360  [ 3600/ 4873]\n",
      "loss: 0.026135  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.687     0.543    105\n",
      " disgust     0.574     0.555     0.560    109\n",
      "    fear     0.574     0.531     0.537    80\n",
      "   happy     0.574     0.543     0.617    81\n",
      " neutral     0.574     0.663     0.702    84\n",
      "     sad     0.574     0.518     0.494    87\n",
      "surprise     0.574     0.514     0.578    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.574     0.573     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 3.253530 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.119783  [ 1200/ 4873]\n",
      "loss: 0.392159  [ 2400/ 4873]\n",
      "loss: 0.378734  [ 3600/ 4873]\n",
      "loss: 0.477945  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.572     0.628     0.562    105\n",
      " disgust     0.572     0.532     0.606    109\n",
      "    fear     0.572     0.549     0.487    80\n",
      "   happy     0.572     0.557     0.605    81\n",
      " neutral     0.572     0.687     0.679    84\n",
      "     sad     0.572     0.558     0.494    87\n",
      "surprise     0.572     0.493     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.572     0.572     0.571    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 3.272659 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.034024  [ 1200/ 4873]\n",
      "loss: 0.027662  [ 2400/ 4873]\n",
      "loss: 0.035067  [ 3600/ 4873]\n",
      "loss: 0.009616  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.569     0.651     0.514    105\n",
      " disgust     0.569     0.545     0.550    109\n",
      "    fear     0.569     0.438     0.487    80\n",
      "   happy     0.569     0.584     0.642    81\n",
      " neutral     0.569     0.690     0.690    84\n",
      "     sad     0.569     0.489     0.517    87\n",
      "surprise     0.569     0.619     0.609    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.569     0.574     0.573    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 3.182644 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.028254  [ 1200/ 4873]\n",
      "loss: 0.437650  [ 2400/ 4873]\n",
      "loss: 0.068688  [ 3600/ 4873]\n",
      "loss: 0.036399  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.561     0.624     0.552    105\n",
      " disgust     0.561     0.541     0.550    109\n",
      "    fear     0.561     0.466     0.512    80\n",
      "   happy     0.561     0.517     0.568    81\n",
      " neutral     0.561     0.688     0.655    84\n",
      "     sad     0.561     0.548     0.529    87\n",
      "surprise     0.561     0.554     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.561     0.562     0.561    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 3.224587 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.215962  [ 1200/ 4873]\n",
      "loss: 0.008166  [ 2400/ 4873]\n",
      "loss: 0.090101  [ 3600/ 4873]\n",
      "loss: 0.474082  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.551     0.684     0.514    105\n",
      " disgust     0.551     0.535     0.495    109\n",
      "    fear     0.551     0.513     0.500    80\n",
      "   happy     0.551     0.505     0.630    81\n",
      " neutral     0.551     0.641     0.702    84\n",
      "     sad     0.551     0.457     0.483    87\n",
      "surprise     0.551     0.537     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.551     0.553     0.555    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.154488 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.112848  [ 1200/ 4873]\n",
      "loss: 0.342144  [ 2400/ 4873]\n",
      "loss: 0.151745  [ 3600/ 4873]\n",
      "loss: 0.018125  [ 4800/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.557     0.549     0.533    105\n",
      " disgust     0.557     0.556     0.550    109\n",
      "    fear     0.557     0.494     0.512    80\n",
      "   happy     0.557     0.542     0.556    81\n",
      " neutral     0.557     0.652     0.690    84\n",
      "     sad     0.557     0.524     0.506    87\n",
      "surprise     0.557     0.590     0.562    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.557     0.558     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 3.176032 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.5885245901639344,\n 631,\n [3,\n  3,\n  6,\n  3,\n  4,\n  5,\n  5,\n  4,\n  1,\n  3,\n  5,\n  5,\n  5,\n  4,\n  4,\n  6,\n  3,\n  3,\n  1,\n  6,\n  1,\n  1,\n  4,\n  4,\n  5,\n  1,\n  5,\n  3,\n  6,\n  4,\n  4,\n  0,\n  6,\n  2,\n  2,\n  0,\n  2,\n  3,\n  6,\n  0,\n  0,\n  1,\n  1,\n  5,\n  0,\n  6,\n  1,\n  6,\n  4,\n  2,\n  4,\n  2,\n  0,\n  0,\n  4,\n  4,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  5,\n  3,\n  0,\n  5,\n  2,\n  5,\n  0,\n  5,\n  2,\n  1,\n  2,\n  0,\n  4,\n  0,\n  0,\n  1,\n  2,\n  0,\n  5,\n  3,\n  4,\n  0,\n  2,\n  1,\n  0,\n  2,\n  5,\n  2,\n  0,\n  5,\n  4,\n  3,\n  4,\n  3,\n  4,\n  3,\n  6,\n  4,\n  0,\n  3,\n  5,\n  0,\n  0,\n  4,\n  3,\n  1,\n  0,\n  3,\n  1,\n  1,\n  2,\n  3,\n  2,\n  2,\n  5,\n  5,\n  3,\n  1,\n  6,\n  1,\n  3,\n  1,\n  1,\n  6,\n  2,\n  3,\n  0,\n  0,\n  0,\n  1,\n  4,\n  6,\n  2,\n  6,\n  1,\n  1,\n  1,\n  2,\n  0,\n  1,\n  4,\n  4,\n  4,\n  6,\n  1,\n  0,\n  4,\n  3,\n  1,\n  0,\n  1,\n  0,\n  6,\n  5,\n  4,\n  2,\n  1,\n  5,\n  2,\n  5,\n  4,\n  3,\n  6,\n  5,\n  1,\n  5,\n  4,\n  4,\n  3,\n  3,\n  1,\n  5,\n  0,\n  4,\n  1,\n  5,\n  2,\n  6,\n  2,\n  5,\n  4,\n  0,\n  0,\n  6,\n  6,\n  2,\n  5,\n  6,\n  6,\n  1,\n  5,\n  4,\n  3,\n  3,\n  1,\n  4,\n  5,\n  6,\n  1,\n  4,\n  3,\n  6,\n  0,\n  2,\n  0,\n  0,\n  4,\n  1,\n  2,\n  0,\n  4,\n  4,\n  3,\n  6,\n  2,\n  0,\n  2,\n  1,\n  6,\n  5,\n  1,\n  6,\n  4,\n  3,\n  4,\n  5,\n  0,\n  5,\n  5,\n  1,\n  0,\n  1,\n  4,\n  0,\n  2,\n  2,\n  1,\n  2,\n  5,\n  1,\n  3,\n  5,\n  0,\n  2,\n  6,\n  3,\n  0,\n  1,\n  6,\n  0,\n  3,\n  1,\n  0,\n  5,\n  5,\n  1,\n  4,\n  3,\n  0,\n  5,\n  4,\n  4,\n  0,\n  4,\n  4,\n  3,\n  1,\n  4,\n  6,\n  4,\n  4,\n  1,\n  5,\n  2,\n  1,\n  0,\n  1,\n  6,\n  1,\n  3,\n  0,\n  0,\n  2,\n  3,\n  0,\n  0,\n  1,\n  2,\n  1,\n  5,\n  1,\n  3,\n  5,\n  0,\n  6,\n  2,\n  5,\n  0,\n  4,\n  0,\n  5,\n  4,\n  6,\n  0,\n  3,\n  3,\n  2,\n  5,\n  2,\n  3,\n  3,\n  0,\n  0,\n  5,\n  5,\n  6,\n  6,\n  2,\n  6,\n  3,\n  0,\n  3,\n  0,\n  5,\n  3,\n  2,\n  1,\n  1,\n  1,\n  0,\n  1,\n  5,\n  4,\n  6,\n  2,\n  6,\n  0,\n  6,\n  6,\n  4,\n  4,\n  1,\n  0,\n  2,\n  3,\n  1,\n  0,\n  3,\n  5,\n  3,\n  2,\n  3,\n  0,\n  6,\n  5,\n  5,\n  5,\n  6,\n  1,\n  0,\n  5,\n  3,\n  5,\n  3,\n  0,\n  1,\n  2,\n  0,\n  0,\n  3,\n  5,\n  3,\n  1,\n  3,\n  2,\n  1,\n  5,\n  5,\n  6,\n  6,\n  0,\n  2,\n  5,\n  4,\n  4,\n  4,\n  1,\n  0,\n  0,\n  2,\n  2,\n  5,\n  2,\n  5,\n  0,\n  2,\n  3,\n  4,\n  4,\n  0,\n  2,\n  5,\n  1,\n  5,\n  0,\n  2,\n  0,\n  1,\n  4,\n  3,\n  3,\n  2,\n  1,\n  0,\n  0,\n  5,\n  1,\n  6,\n  1,\n  0,\n  5,\n  0,\n  3,\n  4,\n  1,\n  4,\n  1,\n  3,\n  0,\n  3,\n  4,\n  1,\n  0,\n  3,\n  1,\n  5,\n  0,\n  5,\n  1,\n  3,\n  0,\n  1,\n  1,\n  1,\n  5,\n  3,\n  0,\n  1,\n  3,\n  6,\n  4,\n  5,\n  1,\n  6,\n  6,\n  2,\n  1,\n  2,\n  3,\n  0,\n  6,\n  5,\n  1,\n  1,\n  3,\n  5,\n  1,\n  3,\n  4,\n  4,\n  1,\n  3,\n  5,\n  1,\n  1,\n  6,\n  1,\n  1,\n  3,\n  4,\n  5,\n  4,\n  0,\n  0,\n  1,\n  2,\n  3,\n  4,\n  4,\n  3,\n  1,\n  4,\n  5,\n  6,\n  1,\n  4,\n  1,\n  0,\n  6,\n  5,\n  1,\n  0,\n  6,\n  6,\n  0,\n  1,\n  3,\n  0,\n  1,\n  0,\n  0,\n  5,\n  2,\n  2,\n  6,\n  5,\n  3,\n  5,\n  2,\n  0,\n  3,\n  2,\n  4,\n  5,\n  4,\n  1,\n  1,\n  4,\n  2,\n  1,\n  4,\n  1,\n  6,\n  6,\n  4,\n  0,\n  5,\n  4,\n  2,\n  5,\n  1,\n  4,\n  2,\n  5,\n  5,\n  3,\n  2,\n  3,\n  1,\n  2,\n  0,\n  6,\n  5,\n  4,\n  2,\n  6,\n  1,\n  4,\n  2,\n  0,\n  2,\n  5,\n  0,\n  1,\n  0,\n  2,\n  6,\n  1,\n  2,\n  5,\n  0,\n  2,\n  3,\n  1,\n  2,\n  4,\n  0,\n  2,\n  3,\n  2,\n  4,\n  6,\n  2,\n  0,\n  4,\n  1,\n  3,\n  2,\n  3,\n  2,\n  6,\n  1,\n  2,\n  6,\n  4,\n  1,\n  1,\n  2,\n  2,\n  5,\n  6,\n  4,\n  3,\n  1,\n  6,\n  1,\n  2,\n  5],\n [3,\n  2,\n  2,\n  3,\n  2,\n  5,\n  5,\n  4,\n  1,\n  0,\n  5,\n  6,\n  1,\n  1,\n  4,\n  6,\n  3,\n  5,\n  0,\n  6,\n  1,\n  1,\n  4,\n  2,\n  5,\n  1,\n  1,\n  3,\n  0,\n  2,\n  2,\n  1,\n  6,\n  2,\n  5,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0,\n  0,\n  5,\n  5,\n  0,\n  6,\n  1,\n  6,\n  4,\n  5,\n  4,\n  4,\n  0,\n  1,\n  2,\n  2,\n  1,\n  0,\n  3,\n  4,\n  0,\n  5,\n  3,\n  3,\n  1,\n  5,\n  2,\n  5,\n  2,\n  5,\n  2,\n  1,\n  2,\n  0,\n  4,\n  2,\n  4,\n  2,\n  2,\n  0,\n  1,\n  0,\n  4,\n  6,\n  1,\n  2,\n  0,\n  1,\n  2,\n  2,\n  0,\n  6,\n  5,\n  3,\n  4,\n  3,\n  4,\n  3,\n  0,\n  1,\n  5,\n  3,\n  0,\n  0,\n  0,\n  4,\n  3,\n  1,\n  0,\n  5,\n  1,\n  5,\n  2,\n  1,\n  2,\n  2,\n  1,\n  2,\n  3,\n  5,\n  5,\n  1,\n  5,\n  1,\n  1,\n  0,\n  2,\n  3,\n  0,\n  0,\n  0,\n  1,\n  4,\n  6,\n  2,\n  1,\n  1,\n  1,\n  1,\n  2,\n  0,\n  2,\n  4,\n  4,\n  4,\n  0,\n  2,\n  3,\n  4,\n  3,\n  1,\n  0,\n  1,\n  0,\n  6,\n  3,\n  4,\n  0,\n  1,\n  5,\n  2,\n  5,\n  4,\n  2,\n  6,\n  5,\n  5,\n  5,\n  4,\n  4,\n  6,\n  5,\n  1,\n  5,\n  6,\n  4,\n  1,\n  5,\n  2,\n  6,\n  2,\n  5,\n  4,\n  1,\n  2,\n  4,\n  2,\n  4,\n  6,\n  1,\n  6,\n  2,\n  1,\n  4,\n  3,\n  3,\n  2,\n  4,\n  5,\n  1,\n  1,\n  4,\n  3,\n  6,\n  6,\n  1,\n  0,\n  0,\n  4,\n  1,\n  0,\n  4,\n  4,\n  1,\n  3,\n  1,\n  1,\n  0,\n  2,\n  3,\n  6,\n  2,\n  1,\n  6,\n  4,\n  3,\n  2,\n  2,\n  0,\n  5,\n  3,\n  1,\n  4,\n  5,\n  4,\n  0,\n  2,\n  4,\n  3,\n  0,\n  5,\n  1,\n  1,\n  2,\n  0,\n  3,\n  6,\n  3,\n  0,\n  5,\n  3,\n  0,\n  3,\n  1,\n  0,\n  5,\n  6,\n  1,\n  4,\n  4,\n  6,\n  1,\n  4,\n  4,\n  0,\n  4,\n  4,\n  1,\n  0,\n  4,\n  1,\n  4,\n  4,\n  1,\n  2,\n  2,\n  1,\n  0,\n  1,\n  3,\n  5,\n  3,\n  0,\n  0,\n  4,\n  3,\n  2,\n  6,\n  1,\n  2,\n  1,\n  1,\n  0,\n  3,\n  5,\n  4,\n  1,\n  1,\n  5,\n  0,\n  4,\n  0,\n  5,\n  4,\n  6,\n  1,\n  2,\n  1,\n  4,\n  6,\n  3,\n  6,\n  3,\n  1,\n  1,\n  0,\n  1,\n  6,\n  6,\n  5,\n  6,\n  3,\n  0,\n  3,\n  0,\n  5,\n  2,\n  6,\n  1,\n  1,\n  1,\n  0,\n  1,\n  6,\n  5,\n  5,\n  3,\n  0,\n  0,\n  5,\n  3,\n  4,\n  4,\n  1,\n  2,\n  2,\n  3,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0,\n  1,\n  5,\n  5,\n  6,\n  1,\n  0,\n  5,\n  4,\n  0,\n  1,\n  5,\n  1,\n  4,\n  0,\n  0,\n  5,\n  3,\n  3,\n  3,\n  3,\n  2,\n  3,\n  1,\n  5,\n  0,\n  6,\n  0,\n  5,\n  1,\n  3,\n  4,\n  4,\n  2,\n  0,\n  3,\n  5,\n  0,\n  5,\n  2,\n  2,\n  0,\n  0,\n  6,\n  4,\n  2,\n  0,\n  6,\n  5,\n  1,\n  2,\n  0,\n  4,\n  0,\n  0,\n  2,\n  2,\n  3,\n  2,\n  1,\n  0,\n  0,\n  5,\n  3,\n  6,\n  0,\n  3,\n  3,\n  0,\n  3,\n  0,\n  1,\n  4,\n  1,\n  3,\n  6,\n  3,\n  4,\n  1,\n  5,\n  3,\n  1,\n  5,\n  4,\n  5,\n  1,\n  6,\n  0,\n  1,\n  1,\n  1,\n  0,\n  3,\n  0,\n  1,\n  6,\n  4,\n  4,\n  1,\n  5,\n  0,\n  6,\n  2,\n  1,\n  6,\n  6,\n  1,\n  6,\n  5,\n  3,\n  1,\n  3,\n  3,\n  1,\n  6,\n  4,\n  4,\n  0,\n  3,\n  2,\n  1,\n  3,\n  6,\n  1,\n  1,\n  3,\n  6,\n  5,\n  4,\n  3,\n  0,\n  1,\n  2,\n  3,\n  4,\n  4,\n  3,\n  6,\n  4,\n  5,\n  6,\n  1,\n  4,\n  1,\n  0,\n  6,\n  5,\n  0,\n  0,\n  6,\n  6,\n  6,\n  5,\n  6,\n  5,\n  1,\n  0,\n  0,\n  5,\n  5,\n  2,\n  5,\n  5,\n  3,\n  5,\n  1,\n  1,\n  1,\n  5,\n  1,\n  5,\n  2,\n  1,\n  1,\n  4,\n  2,\n  2,\n  0,\n  1,\n  6,\n  1,\n  5,\n  0,\n  5,\n  5,\n  2,\n  2,\n  1,\n  4,\n  2,\n  5,\n  5,\n  3,\n  0,\n  1,\n  1,\n  2,\n  0,\n  6,\n  5,\n  4,\n  4,\n  6,\n  5,\n  4,\n  1,\n  0,\n  3,\n  4,\n  0,\n  1,\n  5,\n  2,\n  6,\n  5,\n  0,\n  0,\n  4,\n  2,\n  2,\n  1,\n  6,\n  4,\n  0,\n  4,\n  5,\n  5,\n  4,\n  6,\n  2,\n  4,\n  4,\n  1,\n  6,\n  2,\n  1,\n  6,\n  0,\n  1,\n  2,\n  6,\n  4,\n  1,\n  1,\n  2,\n  1,\n  3,\n  5,\n  4,\n  3,\n  3,\n  6,\n  1,\n  2,\n  4])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import SSDimRedModel, SmallDimRed\n",
    "model = SmallDimRed(x_size=110)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module.parameters of SmallDimRed(\n  (base_linear1): Linear(in_features=300, out_features=100, bias=True)\n  (base_linear2): Linear(in_features=100, out_features=4, bias=True)\n  (base_linear3): Linear(in_features=4, out_features=4, bias=True)\n  (base_linear4): Linear(in_features=4, out_features=7, bias=True)\n  (dropouts): Dropout(p=0.2, inplace=False)\n  (linear1): Linear(in_features=110, out_features=500, bias=True)\n  (linear2): Linear(in_features=500, out_features=300, bias=True)\n)>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

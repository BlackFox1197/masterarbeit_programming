{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 18:02:51.986568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 18:02:52.719213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-08 18:02:52.719380: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-08 18:02:52.719387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import SSDimRedModel\n",
    "from network_models.soundsream_models_and_utils.ss_model_conv import SSConvModel3Sec, SmallConvModel\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from network_models.soundsream_models_and_utils.ss_complex_conv_net import SSComplexConvModel3Sec\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "#data_set= ss_encoded_dataset_full(\n",
    "#    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncs_betterSS_12_1_relwrap_music.pkl\", device=\"cuda\")\n",
    "#data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks_clip/content/datasets/mfcc/mfcc_dataset_3_5_sec_induced.pkl\", device=\"cuda\")\n",
    "data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks_clip/content/datasets/soundstream_encoded/allEncodings_noInducednoStimuli_3_5_sec_v12_1_basic.pkl\", device=\"cuda\")\n",
    "\n",
    "modelDimRed = SSDimRedModel(eval_mode= True).cuda()\n",
    "modelConv = SSConvModel3Sec(xSize=512, ySize=175, eval_mode= True).cuda()\n",
    "#modelComplexConv = SSComplexConvModel3Sec(eval_mode=True).to(\"cuda\")\n",
    "#smalConfModel = SmallConvModel(xSize=110, ySize=40).cuda()\n",
    "\n",
    "# trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "# trainDS, valDs = train_val_dataset(trainDS, val_split=0.1, seed=100)\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.2, seed=100)\n",
    "valDs, testDs = train_val_dataset(testDs, val_split=0.5, seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "#modelConv.load_state_dict(torch.load(\"../content/soundstream/experiments/experiment_v_12_1_NR3_relu/Run_Nr_0/conv/emo_reco_best_ep852_acc_75.pth\"))\n",
    "#modelDimRed.load_state_dict(torch.load(\"../content/soundstream/experiments/experiment_v_12_1_NR3_relu/Run_Nr_0/dimred/emo_reco_best_ep824_acc_70.pth\"))\n",
    "#modelDimRed.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep105_acc_96.pth\"))\n",
    "modelConv.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments_final/Run_Nr_0/conv/emo_reco_best_ep149_acc_73.pth\"))\n",
    "modelDimRed.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments_final/Run_Nr_0/dimred/emo_reco_best_ep563_acc_69.pth\"))\n",
    "#modelComplexConv.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/conv_complex/Nr2_tess/emo_reco_best_ep92_acc_100.pth\"))\n",
    "#modelComplexConv.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/conv_complex/Nr4/emo_reco_best_ep95_acc_69.pth\"))\n",
    "#modelComplexConv.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/conv_complex/Nr2_tess/emo_reco_best_ep92_acc_100.pth\"))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module.parameters of SSConvModel3Sec(\n  (base_linear1): Linear(in_features=300, out_features=100, bias=True)\n  (base_linear2): Linear(in_features=100, out_features=4, bias=True)\n  (base_linear3): Linear(in_features=4, out_features=4, bias=True)\n  (base_linear4): Linear(in_features=4, out_features=7, bias=True)\n  (dropouts): Dropout(p=0, inplace=False)\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (linear1): Linear(in_features=80000, out_features=300, bias=True)\n  (linear2): Linear(in_features=300, out_features=300, bias=True)\n)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelConv.parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from utils.utils__evalutation import evaluate\n",
    "import gc\n",
    "\n",
    "\n",
    "def evaluateLoc(device, model, dataset):\n",
    "\n",
    "    return evaluate(device, model, dataset, batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 609\n",
      "60 of 609\n",
      "120 of 609\n",
      "180 of 609\n",
      "240 of 609\n",
      "300 of 609\n",
      "360 of 609\n",
      "420 of 609\n",
      "480 of 609\n",
      "540 of 609\n",
      "600 of 609\n",
      "------------------ Conv: ----------------\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.673     0.802     0.714    91\n",
      " disgust     0.673     0.810     0.750    108\n",
      "    fear     0.673     0.568     0.622    74\n",
      "   happy     0.673     0.435     0.602    83\n",
      " neutral     0.673     0.833     0.674    89\n",
      "     sad     0.673     0.710     0.676    105\n",
      "surprise     0.673     0.617     0.627    59\n",
      "                                          609\n",
      "\n",
      " \n",
      "     avg     0.673     0.682     0.667    \n",
      "\n",
      "                   angry     disgust        fear       happy     neutral         sad    surprise    support\n",
      "       angry       0.714       0.011       0.055       0.121       0.000       0.022       0.077         91\n",
      "     disgust       0.037       0.750       0.019       0.111       0.028       0.009       0.046        108\n",
      "        fear       0.014       0.054       0.622       0.176       0.000       0.122       0.014         74\n",
      "       happy       0.048       0.048       0.133       0.602       0.036       0.036       0.096         83\n",
      "     neutral       0.011       0.022       0.022       0.112       0.674       0.157       0.000         89\n",
      "         sad       0.038       0.076       0.105       0.048       0.038       0.676       0.019        105\n",
      "    surprise       0.034       0.000       0.068       0.237       0.034       0.000       0.627         59\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.eval_utils import classificationReport, confusion_matrix\n",
    "trueConv, predsConv = evaluateLoc(\"cuda\", modelDimRed, valDs)\n",
    "print(\"------------------ Conv: ----------------\")\n",
    "classificationReport(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "confusion_matrix(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 610\n",
      "60 of 610\n",
      "120 of 610\n",
      "180 of 610\n",
      "240 of 610\n",
      "300 of 610\n",
      "360 of 610\n",
      "420 of 610\n",
      "480 of 610\n",
      "540 of 610\n",
      "600 of 610\n",
      "0 of 610\n",
      "60 of 610\n",
      "120 of 610\n",
      "180 of 610\n",
      "240 of 610\n",
      "300 of 610\n",
      "360 of 610\n",
      "420 of 610\n",
      "480 of 610\n",
      "540 of 610\n",
      "600 of 610\n",
      "------------------ Conv: ----------------\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.746     0.705     0.798    99\n",
      " disgust     0.746     0.826     0.710    107\n",
      "    fear     0.746     0.756     0.775    80\n",
      "   happy     0.746     0.611     0.714    77\n",
      " neutral     0.746     0.787     0.779    95\n",
      "     sad     0.746     0.833     0.714    91\n",
      "surprise     0.746     0.710     0.721    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.746     0.747     0.745    \n",
      "\n",
      "                   angry     disgust        fear       happy     neutral         sad    surprise    support\n",
      "       angry       0.798       0.040       0.030       0.061       0.020       0.010       0.040         99\n",
      "     disgust       0.112       0.710       0.009       0.037       0.112       0.009       0.009        107\n",
      "        fear       0.037       0.000       0.775       0.087       0.000       0.050       0.050         80\n",
      "       happy       0.091       0.065       0.052       0.714       0.000       0.013       0.065         77\n",
      "     neutral       0.053       0.032       0.021       0.053       0.779       0.042       0.021         95\n",
      "         sad       0.022       0.022       0.088       0.066       0.066       0.714       0.022         91\n",
      "    surprise       0.066       0.033       0.033       0.115       0.000       0.033       0.721         61\n",
      "\n",
      "------------------ DimRed: ----------------\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.773     0.687    99\n",
      " disgust     0.705     0.806     0.738    107\n",
      "    fear     0.705     0.622     0.575    80\n",
      "   happy     0.705     0.690     0.636    77\n",
      " neutral     0.705     0.813     0.779    95\n",
      "     sad     0.705     0.630     0.747    91\n",
      "surprise     0.705     0.575     0.754    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.705     0.701     0.702    \n",
      "\n",
      "                   angry     disgust        fear       happy     neutral         sad    surprise    support\n",
      "       angry       0.687       0.040       0.061       0.061       0.010       0.040       0.101         99\n",
      "     disgust       0.065       0.738       0.028       0.028       0.019       0.112       0.009        107\n",
      "        fear       0.062       0.037       0.575       0.087       0.025       0.113       0.100         80\n",
      "       happy       0.039       0.026       0.065       0.636       0.065       0.026       0.143         77\n",
      "     neutral       0.032       0.021       0.021       0.011       0.779       0.126       0.011         95\n",
      "         sad       0.022       0.077       0.055       0.022       0.044       0.747       0.033         91\n",
      "    surprise       0.000       0.016       0.115       0.049       0.049       0.016       0.754         61\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.eval_utils import classificationReport, confusion_matrix\n",
    "\n",
    "trueConv, predsConv = evaluateLoc(\"cuda\", modelConv, testDs)\n",
    "trueDimRed, predsDimRed = evaluateLoc(\"cuda\", modelDimRed, testDs)\n",
    "\n",
    "print(\"------------------ Conv: ----------------\")\n",
    "classificationReport(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "confusion_matrix(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "print(\"------------------ DimRed: ----------------\")\n",
    "classificationReport(trueDimRed, predsDimRed, data_set.encoded_dataset.label_list)\n",
    "confusion_matrix(trueDimRed, predsDimRed, data_set.encoded_dataset.label_list)\n",
    "\n",
    "\n",
    "print(\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

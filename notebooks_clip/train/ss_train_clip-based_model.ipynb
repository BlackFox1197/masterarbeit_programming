{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 14:08:21.962049: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 14:08:22.486783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-28 14:08:22.486836: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-28 14:08:22.486841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from network_models.clip.models.ss_encoderbased_model import SSClipBasedModel, SSClipModelNoBaseClass\n",
    "from network_models.soundsream_models_and_utils.clip_like.encoder.ss_dims_class_model import SS_Enc_Class_Dims\n",
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "import gc\n",
    "\n",
    "from network_models.soundsream_models_and_utils.ss_wrapper_trainer_experiments import ExperimentsTrainer\n",
    "import torch\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 8\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/\"\n",
    "safe_model_every = 500\n",
    "epochs = 15001\n",
    "save_highest_acc_min_acc = 0.5\n",
    "lr = 1e-5\n",
    "gc.collect()\n",
    "\n",
    "# data_set= ss_encoded_dataset_full(\n",
    "#     csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings_clip_like.pkl\", device=\"cuda\")\n",
    "# trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "#\n",
    "# torch.manual_seed(300)\n",
    "# model = SSClipBasedModel(dropout=0.3).to(device)\n",
    "\n",
    "\n",
    "# data_set= ss_encoded_dataset_full(\n",
    "#     csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/encoder_datasets/encodings_noCafe.pkl\", device=\"cuda\")\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/encoder_datasets/full_encodings_with_umap.pkl\", device=\"cuda\", umap=True)\n",
    "trainDS, valDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "trainDS, testDs = train_val_dataset(trainDS, val_split=0.1, seed=100)\n",
    "torch.manual_seed(33333)\n",
    "#model = SS_Enc_Class_Dims().to(device)\n",
    "model = SSClipModelNoBaseClass(input_size=4).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.922280  [    0/ 4933]\n",
      "loss: 2.079230  [  800/ 4933]\n",
      "loss: 1.917735  [ 1600/ 4933]\n",
      "loss: 1.987685  [ 2400/ 4933]\n",
      "loss: 2.042836  [ 3200/ 4933]\n",
      "loss: 1.898008  [ 4000/ 4933]\n",
      "loss: 1.819652  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.200     0.273     0.951    82\n",
      " disgust     0.200     0.000     0.000    87\n",
      "    fear     0.200     0.136     0.364    88\n",
      "   happy     0.200     0.000     0.000    89\n",
      " neutral     0.200     0.000     0.000    52\n",
      "     sad     0.200     0.000     0.000    90\n",
      "surprise     0.200     0.000     0.000    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.200     0.058     0.188    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 20.0%, Avg loss: 1.918462 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.806484  [    0/ 4933]\n",
      "loss: 1.963436  [  800/ 4933]\n",
      "loss: 2.168400  [ 1600/ 4933]\n",
      "loss: 1.732465  [ 2400/ 4933]\n",
      "loss: 2.118508  [ 3200/ 4933]\n",
      "loss: 1.945118  [ 4000/ 4933]\n",
      "loss: 1.931546  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.275     0.317     0.951    82\n",
      " disgust     0.275     0.000     0.000    87\n",
      "    fear     0.275     0.264     0.830    88\n",
      "   happy     0.275     0.000     0.000    89\n",
      " neutral     0.275     0.000     0.000    52\n",
      "     sad     0.275     0.000     0.000    90\n",
      "surprise     0.275     0.000     0.000    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.275     0.083     0.254    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 27.5%, Avg loss: 1.869058 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.908540  [    0/ 4933]\n",
      "loss: 1.830959  [  800/ 4933]\n",
      "loss: 1.801259  [ 1600/ 4933]\n",
      "loss: 1.686026  [ 2400/ 4933]\n",
      "loss: 1.871335  [ 3200/ 4933]\n",
      "loss: 1.764143  [ 4000/ 4933]\n",
      "loss: 1.844469  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.281     0.313     0.951    82\n",
      " disgust     0.281     0.000     0.000    87\n",
      "    fear     0.281     0.271     0.841    88\n",
      "   happy     0.281     0.000     0.000    89\n",
      " neutral     0.281     1.000     0.038    52\n",
      "     sad     0.281     0.000     0.000    90\n",
      "surprise     0.281     0.000     0.000    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.281     0.226     0.262    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 28.1%, Avg loss: 1.821993 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.702643  [    0/ 4933]\n",
      "loss: 1.909742  [  800/ 4933]\n",
      "loss: 1.870232  [ 1600/ 4933]\n",
      "loss: 1.898291  [ 2400/ 4933]\n",
      "loss: 1.716098  [ 3200/ 4933]\n",
      "loss: 1.747228  [ 4000/ 4933]\n",
      "loss: 1.712157  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.366     0.312     0.963    82\n",
      " disgust     0.366     1.000     0.276    87\n",
      "    fear     0.366     0.314     0.875    88\n",
      "   happy     0.366     0.000     0.000    89\n",
      " neutral     0.366     1.000     0.404    52\n",
      "     sad     0.366     0.000     0.000    90\n",
      "surprise     0.366     0.000     0.000    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.366     0.375     0.360    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 1.777385 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.949180  [    0/ 4933]\n",
      "loss: 1.789720  [  800/ 4933]\n",
      "loss: 1.798396  [ 1600/ 4933]\n",
      "loss: 1.680298  [ 2400/ 4933]\n",
      "loss: 1.705227  [ 3200/ 4933]\n",
      "loss: 1.812647  [ 4000/ 4933]\n",
      "loss: 1.610797  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.408     0.299     0.963    82\n",
      " disgust     0.408     1.000     0.471    87\n",
      "    fear     0.408     0.364     0.898    88\n",
      "   happy     0.408     0.000     0.000    89\n",
      " neutral     0.408     1.000     0.481    52\n",
      "     sad     0.408     0.000     0.000    90\n",
      "surprise     0.408     0.000     0.000    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.408     0.380     0.402    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.734205 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.675147  [    0/ 4933]\n",
      "loss: 1.950707  [  800/ 4933]\n",
      "loss: 1.716204  [ 1600/ 4933]\n",
      "loss: 1.685954  [ 2400/ 4933]\n",
      "loss: 1.906554  [ 3200/ 4933]\n",
      "loss: 1.828822  [ 4000/ 4933]\n",
      "loss: 1.708037  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.437     0.300     0.963    82\n",
      " disgust     0.437     1.000     0.621    87\n",
      "    fear     0.437     0.390     0.909    88\n",
      "   happy     0.437     0.000     0.000    89\n",
      " neutral     0.437     1.000     0.519    52\n",
      "     sad     0.437     0.000     0.000    90\n",
      "surprise     0.437     0.000     0.000    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.437     0.384     0.430    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.693088 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.819238  [    0/ 4933]\n",
      "loss: 1.839130  [  800/ 4933]\n",
      "loss: 1.692852  [ 1600/ 4933]\n",
      "loss: 1.588445  [ 2400/ 4933]\n",
      "loss: 1.622578  [ 3200/ 4933]\n",
      "loss: 1.599635  [ 4000/ 4933]\n",
      "loss: 1.557361  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.448     0.304     0.963    82\n",
      " disgust     0.448     1.000     0.678    87\n",
      "    fear     0.448     0.399     0.920    88\n",
      "   happy     0.448     0.000     0.000    89\n",
      " neutral     0.448     1.000     0.519    52\n",
      "     sad     0.448     0.000     0.000    90\n",
      "surprise     0.448     0.000     0.000    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.448     0.386     0.440    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.653915 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.642085  [    0/ 4933]\n",
      "loss: 1.658098  [  800/ 4933]\n",
      "loss: 1.650460  [ 1600/ 4933]\n",
      "loss: 1.756468  [ 2400/ 4933]\n",
      "loss: 1.662415  [ 3200/ 4933]\n",
      "loss: 1.584514  [ 4000/ 4933]\n",
      "loss: 1.548213  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.521     0.360     0.976    82\n",
      " disgust     0.521     0.986     0.805    87\n",
      "    fear     0.521     0.400     0.909    88\n",
      "   happy     0.521     0.000     0.000    89\n",
      " neutral     0.521     1.000     0.519    52\n",
      "     sad     0.521     0.000     0.000    90\n",
      "surprise     0.521     1.000     0.475    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.521     0.535     0.526    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 1.615770 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep7_acc_52.md \n",
      "\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep7_acc_52\"!  new accuracy: 52.1\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.549984  [    0/ 4933]\n",
      "loss: 1.735037  [  800/ 4933]\n",
      "loss: 1.732583  [ 1600/ 4933]\n",
      "loss: 1.591836  [ 2400/ 4933]\n",
      "loss: 1.463098  [ 3200/ 4933]\n",
      "loss: 1.647629  [ 4000/ 4933]\n",
      "loss: 1.688656  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.548     0.392     0.976    82\n",
      " disgust     0.548     0.973     0.828    87\n",
      "    fear     0.548     0.399     0.920    88\n",
      "   happy     0.548     0.000     0.000    89\n",
      " neutral     0.548     1.000     0.519    52\n",
      "     sad     0.548     0.000     0.000    90\n",
      "surprise     0.548     1.000     0.672    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.548     0.538     0.559    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 1.578892 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep8_acc_55.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep7_acc_52\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep8_acc_55\"! Old accuracy: 52.1, new accuracy: 54.8\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.551858  [    0/ 4933]\n",
      "loss: 1.443863  [  800/ 4933]\n",
      "loss: 1.498841  [ 1600/ 4933]\n",
      "loss: 1.526070  [ 2400/ 4933]\n",
      "loss: 1.657224  [ 3200/ 4933]\n",
      "loss: 1.565025  [ 4000/ 4933]\n",
      "loss: 1.623336  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.570     0.416     0.963    82\n",
      " disgust     0.570     0.974     0.874    87\n",
      "    fear     0.570     0.397     0.920    88\n",
      "   happy     0.570     0.000     0.000    89\n",
      " neutral     0.570     1.000     0.519    52\n",
      "     sad     0.570     0.000     0.000    90\n",
      "surprise     0.570     1.000     0.820    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.570     0.541     0.585    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 1.543572 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep9_acc_57.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep8_acc_55\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep9_acc_57\"! Old accuracy: 54.8, new accuracy: 57.0\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.432097  [    0/ 4933]\n",
      "loss: 1.692122  [  800/ 4933]\n",
      "loss: 1.515800  [ 1600/ 4933]\n",
      "loss: 1.618261  [ 2400/ 4933]\n",
      "loss: 1.649930  [ 3200/ 4933]\n",
      "loss: 1.406378  [ 4000/ 4933]\n",
      "loss: 1.400755  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.627     0.465     0.963    82\n",
      " disgust     0.627     0.975     0.885    87\n",
      "    fear     0.627     0.420     0.920    88\n",
      "   happy     0.627     1.000     0.191    89\n",
      " neutral     0.627     1.000     0.519    52\n",
      "     sad     0.627     1.000     0.089    90\n",
      "surprise     0.627     1.000     0.902    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.627     0.837     0.639    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.509456 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep10_acc_63.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep9_acc_57\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep10_acc_63\"! Old accuracy: 57.0, new accuracy: 62.7\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.496596  [    0/ 4933]\n",
      "loss: 1.500880  [  800/ 4933]\n",
      "loss: 1.481274  [ 1600/ 4933]\n",
      "loss: 1.713638  [ 2400/ 4933]\n",
      "loss: 1.427410  [ 3200/ 4933]\n",
      "loss: 1.567312  [ 4000/ 4933]\n",
      "loss: 1.515564  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.703     0.503     0.963    82\n",
      " disgust     0.703     0.975     0.897    87\n",
      "    fear     0.703     0.494     0.920    88\n",
      "   happy     0.703     1.000     0.326    89\n",
      " neutral     0.703     1.000     0.538    52\n",
      "     sad     0.703     1.000     0.367    90\n",
      "surprise     0.703     1.000     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.703     0.853     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 1.476832 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep11_acc_70.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep10_acc_63\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep11_acc_70\"! Old accuracy: 62.7, new accuracy: 70.3\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.420866  [    0/ 4933]\n",
      "loss: 1.401951  [  800/ 4933]\n",
      "loss: 1.459471  [ 1600/ 4933]\n",
      "loss: 1.367010  [ 2400/ 4933]\n",
      "loss: 1.656652  [ 3200/ 4933]\n",
      "loss: 1.397087  [ 4000/ 4933]\n",
      "loss: 1.235744  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.719     0.527     0.963    82\n",
      " disgust     0.719     0.963     0.897    87\n",
      "    fear     0.719     0.509     0.932    88\n",
      "   happy     0.719     1.000     0.382    89\n",
      " neutral     0.719     1.000     0.558    52\n",
      "     sad     0.719     1.000     0.389    90\n",
      "surprise     0.719     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.719     0.855     0.724    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 1.444990 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep12_acc_72.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep11_acc_70\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep12_acc_72\"! Old accuracy: 70.3, new accuracy: 71.9\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.338833  [    0/ 4933]\n",
      "loss: 1.452514  [  800/ 4933]\n",
      "loss: 1.476386  [ 1600/ 4933]\n",
      "loss: 1.352519  [ 2400/ 4933]\n",
      "loss: 1.466095  [ 3200/ 4933]\n",
      "loss: 1.359233  [ 4000/ 4933]\n",
      "loss: 1.342838  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.765     0.568     0.963    82\n",
      " disgust     0.765     0.963     0.897    87\n",
      "    fear     0.765     0.562     0.932    88\n",
      "   happy     0.765     1.000     0.506    89\n",
      " neutral     0.765     0.967     0.558    52\n",
      "     sad     0.765     1.000     0.544    90\n",
      "surprise     0.765     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.765     0.863     0.764    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 1.414491 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep13_acc_77.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep12_acc_72\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep13_acc_77\"! Old accuracy: 71.9, new accuracy: 76.5\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.476461  [    0/ 4933]\n",
      "loss: 1.380526  [  800/ 4933]\n",
      "loss: 1.266399  [ 1600/ 4933]\n",
      "loss: 1.538650  [ 2400/ 4933]\n",
      "loss: 1.143784  [ 3200/ 4933]\n",
      "loss: 1.356031  [ 4000/ 4933]\n",
      "loss: 1.419803  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.796     0.608     0.963    82\n",
      " disgust     0.796     0.951     0.897    87\n",
      "    fear     0.796     0.599     0.932    88\n",
      "   happy     0.796     1.000     0.607    89\n",
      " neutral     0.796     0.967     0.558    52\n",
      "     sad     0.796     1.000     0.633    90\n",
      "surprise     0.796     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.796     0.872     0.791    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 1.384749 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep14_acc_80.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep13_acc_77\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep14_acc_80\"! Old accuracy: 76.5, new accuracy: 79.6\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.333731  [    0/ 4933]\n",
      "loss: 1.393778  [  800/ 4933]\n",
      "loss: 1.333934  [ 1600/ 4933]\n",
      "loss: 1.369419  [ 2400/ 4933]\n",
      "loss: 1.292303  [ 3200/ 4933]\n",
      "loss: 1.511734  [ 4000/ 4933]\n",
      "loss: 1.333755  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.818     0.639     0.951    82\n",
      " disgust     0.818     0.929     0.897    87\n",
      "    fear     0.818     0.636     0.932    88\n",
      "   happy     0.818     1.000     0.685    89\n",
      " neutral     0.818     0.967     0.558    52\n",
      "     sad     0.818     0.984     0.700    90\n",
      "surprise     0.818     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.818     0.877     0.810    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 1.356000 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep15_acc_82.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep14_acc_80\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep15_acc_82\"! Old accuracy: 79.6, new accuracy: 81.8\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.585983  [    0/ 4933]\n",
      "loss: 1.253566  [  800/ 4933]\n",
      "loss: 1.162815  [ 1600/ 4933]\n",
      "loss: 1.403127  [ 2400/ 4933]\n",
      "loss: 1.315722  [ 3200/ 4933]\n",
      "loss: 1.068330  [ 4000/ 4933]\n",
      "loss: 1.408795  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.847     0.709     0.951    82\n",
      " disgust     0.847     0.929     0.908    87\n",
      "    fear     0.847     0.667     0.932    88\n",
      "   happy     0.847     0.972     0.775    89\n",
      " neutral     0.847     0.967     0.558    52\n",
      "     sad     0.847     0.986     0.778    90\n",
      "surprise     0.847     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.847     0.888     0.836    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 1.327989 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep16_acc_85.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep15_acc_82\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep16_acc_85\"! Old accuracy: 81.8, new accuracy: 84.7\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.321663  [    0/ 4933]\n",
      "loss: 1.210487  [  800/ 4933]\n",
      "loss: 1.370325  [ 1600/ 4933]\n",
      "loss: 1.148952  [ 2400/ 4933]\n",
      "loss: 1.298532  [ 3200/ 4933]\n",
      "loss: 1.149196  [ 4000/ 4933]\n",
      "loss: 1.441914  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.863     0.757     0.951    82\n",
      " disgust     0.863     0.888     0.908    87\n",
      "    fear     0.863     0.709     0.943    88\n",
      "   happy     0.863     0.961     0.820    89\n",
      " neutral     0.863     0.967     0.558    52\n",
      "     sad     0.863     0.987     0.822    90\n",
      "surprise     0.863     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.863     0.893     0.850    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 1.300719 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep17_acc_86.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep16_acc_85\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep17_acc_86\"! Old accuracy: 84.7, new accuracy: 86.3\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.539178  [    0/ 4933]\n",
      "loss: 1.213531  [  800/ 4933]\n",
      "loss: 1.325636  [ 1600/ 4933]\n",
      "loss: 1.464213  [ 2400/ 4933]\n",
      "loss: 1.063945  [ 3200/ 4933]\n",
      "loss: 1.219148  [ 4000/ 4933]\n",
      "loss: 1.313044  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.869     0.772     0.951    82\n",
      " disgust     0.869     0.876     0.897    87\n",
      "    fear     0.869     0.739     0.932    88\n",
      "   happy     0.869     0.962     0.843    89\n",
      " neutral     0.869     0.967     0.558    52\n",
      "     sad     0.869     0.951     0.856    90\n",
      "surprise     0.869     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.869     0.893     0.855    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 1.274521 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep18_acc_87.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep17_acc_86\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep18_acc_87\"! Old accuracy: 86.3, new accuracy: 86.9\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.169375  [    0/ 4933]\n",
      "loss: 1.339731  [  800/ 4933]\n",
      "loss: 1.359952  [ 1600/ 4933]\n",
      "loss: 1.177083  [ 2400/ 4933]\n",
      "loss: 1.373655  [ 3200/ 4933]\n",
      "loss: 1.254709  [ 4000/ 4933]\n",
      "loss: 1.153680  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.876     0.788     0.951    82\n",
      " disgust     0.876     0.888     0.908    87\n",
      "    fear     0.876     0.745     0.932    88\n",
      "   happy     0.876     0.963     0.865    89\n",
      " neutral     0.876     0.967     0.558    52\n",
      "     sad     0.876     0.951     0.867    90\n",
      "surprise     0.876     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.876     0.898     0.862    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 1.248956 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep19_acc_88.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep18_acc_87\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep19_acc_88\"! Old accuracy: 86.9, new accuracy: 87.6\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.031853  [    0/ 4933]\n",
      "loss: 1.068196  [  800/ 4933]\n",
      "loss: 1.382937  [ 1600/ 4933]\n",
      "loss: 1.292233  [ 2400/ 4933]\n",
      "loss: 1.068196  [ 3200/ 4933]\n",
      "loss: 1.271512  [ 4000/ 4933]\n",
      "loss: 1.189810  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.878     0.804     0.951    82\n",
      " disgust     0.878     0.889     0.920    87\n",
      "    fear     0.878     0.745     0.932    88\n",
      "   happy     0.878     0.963     0.865    89\n",
      " neutral     0.878     0.967     0.558    52\n",
      "     sad     0.878     0.940     0.867    90\n",
      "surprise     0.878     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.878     0.899     0.863    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 1.224396 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep20_acc_88.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep19_acc_88\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep20_acc_88\"! Old accuracy: 87.6, new accuracy: 87.8\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.288478  [    0/ 4933]\n",
      "loss: 1.182126  [  800/ 4933]\n",
      "loss: 1.440909  [ 1600/ 4933]\n",
      "loss: 1.392937  [ 2400/ 4933]\n",
      "loss: 1.300551  [ 3200/ 4933]\n",
      "loss: 1.210986  [ 4000/ 4933]\n",
      "loss: 1.328701  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.878     0.804     0.951    82\n",
      " disgust     0.878     0.870     0.920    87\n",
      "    fear     0.878     0.759     0.932    88\n",
      "   happy     0.878     0.963     0.865    89\n",
      " neutral     0.878     0.967     0.558    52\n",
      "     sad     0.878     0.940     0.867    90\n",
      "surprise     0.878     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.878     0.898     0.863    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 1.200045 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.022939  [    0/ 4933]\n",
      "loss: 1.178255  [  800/ 4933]\n",
      "loss: 1.134005  [ 1600/ 4933]\n",
      "loss: 1.196931  [ 2400/ 4933]\n",
      "loss: 1.244129  [ 3200/ 4933]\n",
      "loss: 1.062636  [ 4000/ 4933]\n",
      "loss: 1.212680  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.885     0.830     0.951    82\n",
      " disgust     0.885     0.879     0.920    87\n",
      "    fear     0.885     0.779     0.920    88\n",
      "   happy     0.885     0.940     0.888    89\n",
      " neutral     0.885     0.967     0.558    52\n",
      "     sad     0.885     0.931     0.900    90\n",
      "surprise     0.885     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.885     0.901     0.870    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 1.176528 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep22_acc_89.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep20_acc_88\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep22_acc_89\"! Old accuracy: 87.8, new accuracy: 88.5\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.205413  [    0/ 4933]\n",
      "loss: 1.282980  [  800/ 4933]\n",
      "loss: 1.265459  [ 1600/ 4933]\n",
      "loss: 1.219191  [ 2400/ 4933]\n",
      "loss: 1.202389  [ 3200/ 4933]\n",
      "loss: 1.051611  [ 4000/ 4933]\n",
      "loss: 0.852613  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.887     0.848     0.951    82\n",
      " disgust     0.887     0.889     0.920    87\n",
      "    fear     0.887     0.784     0.909    88\n",
      "   happy     0.887     0.919     0.888    89\n",
      " neutral     0.887     0.969     0.596    52\n",
      "     sad     0.887     0.920     0.900    90\n",
      "surprise     0.887     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.887     0.902     0.873    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 1.153700 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep23_acc_89.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep22_acc_89\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep23_acc_89\"! Old accuracy: 88.5, new accuracy: 88.7\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.231944  [    0/ 4933]\n",
      "loss: 1.096684  [  800/ 4933]\n",
      "loss: 0.988609  [ 1600/ 4933]\n",
      "loss: 1.133676  [ 2400/ 4933]\n",
      "loss: 1.058493  [ 3200/ 4933]\n",
      "loss: 0.923087  [ 4000/ 4933]\n",
      "loss: 1.106974  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.867     0.951    82\n",
      " disgust     0.891     0.889     0.920    87\n",
      "    fear     0.891     0.792     0.909    88\n",
      "   happy     0.891     0.910     0.910    89\n",
      " neutral     0.891     0.969     0.596    52\n",
      "     sad     0.891     0.920     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.904     0.877    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 1.131616 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep24_acc_89.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep23_acc_89\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep24_acc_89\"! Old accuracy: 88.7, new accuracy: 89.1\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.142524  [    0/ 4933]\n",
      "loss: 1.362291  [  800/ 4933]\n",
      "loss: 0.750515  [ 1600/ 4933]\n",
      "loss: 0.986541  [ 2400/ 4933]\n",
      "loss: 0.817945  [ 3200/ 4933]\n",
      "loss: 1.336405  [ 4000/ 4933]\n",
      "loss: 1.079483  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.867     0.951    82\n",
      " disgust     0.891     0.879     0.920    87\n",
      "    fear     0.891     0.800     0.909    88\n",
      "   happy     0.891     0.910     0.910    89\n",
      " neutral     0.891     0.969     0.596    52\n",
      "     sad     0.891     0.920     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.904     0.877    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 1.110155 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.337733  [    0/ 4933]\n",
      "loss: 1.112340  [  800/ 4933]\n",
      "loss: 1.017394  [ 1600/ 4933]\n",
      "loss: 0.933882  [ 2400/ 4933]\n",
      "loss: 1.083035  [ 3200/ 4933]\n",
      "loss: 1.023077  [ 4000/ 4933]\n",
      "loss: 1.049278  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.889     0.865     0.939    82\n",
      " disgust     0.889     0.889     0.920    87\n",
      "    fear     0.889     0.800     0.909    88\n",
      "   happy     0.889     0.900     0.910    89\n",
      " neutral     0.889     0.969     0.596    52\n",
      "     sad     0.889     0.910     0.900    90\n",
      "surprise     0.889     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.889     0.902     0.875    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 1.089336 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.056471  [    0/ 4933]\n",
      "loss: 1.204151  [  800/ 4933]\n",
      "loss: 1.123812  [ 1600/ 4933]\n",
      "loss: 1.098736  [ 2400/ 4933]\n",
      "loss: 0.897623  [ 3200/ 4933]\n",
      "loss: 1.089385  [ 4000/ 4933]\n",
      "loss: 0.931104  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.865     0.939    82\n",
      " disgust     0.891     0.889     0.920    87\n",
      "    fear     0.891     0.808     0.909    88\n",
      "   happy     0.891     0.900     0.910    89\n",
      " neutral     0.891     0.970     0.615    52\n",
      "     sad     0.891     0.910     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.904     0.878    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 1.069207 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.300603  [    0/ 4933]\n",
      "loss: 0.811341  [  800/ 4933]\n",
      "loss: 0.859602  [ 1600/ 4933]\n",
      "loss: 1.038090  [ 2400/ 4933]\n",
      "loss: 1.162444  [ 3200/ 4933]\n",
      "loss: 1.270185  [ 4000/ 4933]\n",
      "loss: 0.924583  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.875     0.939    82\n",
      " disgust     0.891     0.889     0.920    87\n",
      "    fear     0.891     0.808     0.909    88\n",
      "   happy     0.891     0.890     0.910    89\n",
      " neutral     0.891     0.970     0.615    52\n",
      "     sad     0.891     0.910     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.904     0.878    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 1.049814 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.858400  [    0/ 4933]\n",
      "loss: 1.008710  [  800/ 4933]\n",
      "loss: 1.227295  [ 1600/ 4933]\n",
      "loss: 0.920871  [ 2400/ 4933]\n",
      "loss: 0.899958  [ 3200/ 4933]\n",
      "loss: 0.838790  [ 4000/ 4933]\n",
      "loss: 0.950441  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.874     0.927    82\n",
      " disgust     0.891     0.899     0.920    87\n",
      "    fear     0.891     0.816     0.909    88\n",
      "   happy     0.891     0.880     0.910    89\n",
      " neutral     0.891     0.943     0.635    52\n",
      "     sad     0.891     0.910     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.901     0.879    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 1.030700 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.095795  [    0/ 4933]\n",
      "loss: 0.956154  [  800/ 4933]\n",
      "loss: 0.827139  [ 1600/ 4933]\n",
      "loss: 1.259497  [ 2400/ 4933]\n",
      "loss: 0.803219  [ 3200/ 4933]\n",
      "loss: 1.042205  [ 4000/ 4933]\n",
      "loss: 1.144223  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.893     0.874     0.927    82\n",
      " disgust     0.893     0.909     0.920    87\n",
      "    fear     0.893     0.816     0.909    88\n",
      "   happy     0.893     0.880     0.910    89\n",
      " neutral     0.893     0.944     0.654    52\n",
      "     sad     0.893     0.910     0.900    90\n",
      "surprise     0.893     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.893     0.902     0.881    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 1.012071 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep30_acc_89.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep24_acc_89\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep30_acc_89\"! Old accuracy: 89.1, new accuracy: 89.3\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.889788  [    0/ 4933]\n",
      "loss: 0.984667  [  800/ 4933]\n",
      "loss: 0.926485  [ 1600/ 4933]\n",
      "loss: 1.225104  [ 2400/ 4933]\n",
      "loss: 1.122033  [ 3200/ 4933]\n",
      "loss: 0.907219  [ 4000/ 4933]\n",
      "loss: 1.081099  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.872     0.915    82\n",
      " disgust     0.891     0.909     0.920    87\n",
      "    fear     0.891     0.816     0.909    88\n",
      "   happy     0.891     0.871     0.910    89\n",
      " neutral     0.891     0.944     0.654    52\n",
      "     sad     0.891     0.910     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.901     0.880    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.993911 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.196173  [    0/ 4933]\n",
      "loss: 0.900454  [  800/ 4933]\n",
      "loss: 0.842202  [ 1600/ 4933]\n",
      "loss: 1.210779  [ 2400/ 4933]\n",
      "loss: 0.834875  [ 3200/ 4933]\n",
      "loss: 1.227055  [ 4000/ 4933]\n",
      "loss: 0.957418  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.872     0.915    82\n",
      " disgust     0.891     0.909     0.920    87\n",
      "    fear     0.891     0.816     0.909    88\n",
      "   happy     0.891     0.871     0.910    89\n",
      " neutral     0.891     0.944     0.654    52\n",
      "     sad     0.891     0.910     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.901     0.880    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.976339 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.801027  [    0/ 4933]\n",
      "loss: 0.870054  [  800/ 4933]\n",
      "loss: 1.410083  [ 1600/ 4933]\n",
      "loss: 0.844334  [ 2400/ 4933]\n",
      "loss: 1.129583  [ 3200/ 4933]\n",
      "loss: 1.459283  [ 4000/ 4933]\n",
      "loss: 0.929413  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.872     0.915    82\n",
      " disgust     0.891     0.909     0.920    87\n",
      "    fear     0.891     0.816     0.909    88\n",
      "   happy     0.891     0.871     0.910    89\n",
      " neutral     0.891     0.944     0.654    52\n",
      "     sad     0.891     0.910     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.901     0.880    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.959159 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.024116  [    0/ 4933]\n",
      "loss: 0.760439  [  800/ 4933]\n",
      "loss: 1.001997  [ 1600/ 4933]\n",
      "loss: 0.932450  [ 2400/ 4933]\n",
      "loss: 0.587207  [ 3200/ 4933]\n",
      "loss: 1.033601  [ 4000/ 4933]\n",
      "loss: 0.940268  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.891     0.872     0.915    82\n",
      " disgust     0.891     0.909     0.920    87\n",
      "    fear     0.891     0.816     0.909    88\n",
      "   happy     0.891     0.871     0.910    89\n",
      " neutral     0.891     0.944     0.654    52\n",
      "     sad     0.891     0.910     0.900    90\n",
      "surprise     0.891     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.891     0.901     0.880    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.942577 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.006679  [    0/ 4933]\n",
      "loss: 0.989507  [  800/ 4933]\n",
      "loss: 0.651778  [ 1600/ 4933]\n",
      "loss: 0.530104  [ 2400/ 4933]\n",
      "loss: 0.962105  [ 3200/ 4933]\n",
      "loss: 0.611189  [ 4000/ 4933]\n",
      "loss: 0.786371  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.893     0.872     0.915    82\n",
      " disgust     0.893     0.909     0.920    87\n",
      "    fear     0.893     0.827     0.920    88\n",
      "   happy     0.893     0.880     0.910    89\n",
      " neutral     0.893     0.919     0.654    52\n",
      "     sad     0.893     0.910     0.900    90\n",
      "surprise     0.893     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.893     0.900     0.881    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.926490 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.711903  [    0/ 4933]\n",
      "loss: 1.119242  [  800/ 4933]\n",
      "loss: 0.886520  [ 1600/ 4933]\n",
      "loss: 1.022278  [ 2400/ 4933]\n",
      "loss: 1.053604  [ 3200/ 4933]\n",
      "loss: 0.700938  [ 4000/ 4933]\n",
      "loss: 1.046874  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.893     0.872     0.915    82\n",
      " disgust     0.893     0.909     0.920    87\n",
      "    fear     0.893     0.827     0.920    88\n",
      "   happy     0.893     0.880     0.910    89\n",
      " neutral     0.893     0.919     0.654    52\n",
      "     sad     0.893     0.910     0.900    90\n",
      "surprise     0.893     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.893     0.900     0.881    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.910690 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.006108  [    0/ 4933]\n",
      "loss: 1.127333  [  800/ 4933]\n",
      "loss: 0.604943  [ 1600/ 4933]\n",
      "loss: 0.799340  [ 2400/ 4933]\n",
      "loss: 0.708020  [ 3200/ 4933]\n",
      "loss: 0.658546  [ 4000/ 4933]\n",
      "loss: 0.744608  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.893     0.872     0.915    82\n",
      " disgust     0.893     0.920     0.920    87\n",
      "    fear     0.893     0.835     0.920    88\n",
      "   happy     0.893     0.880     0.910    89\n",
      " neutral     0.893     0.919     0.654    52\n",
      "     sad     0.893     0.890     0.900    90\n",
      "surprise     0.893     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.893     0.900     0.881    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.895366 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.005907  [    0/ 4933]\n",
      "loss: 1.375666  [  800/ 4933]\n",
      "loss: 0.827787  [ 1600/ 4933]\n",
      "loss: 1.127546  [ 2400/ 4933]\n",
      "loss: 0.915243  [ 3200/ 4933]\n",
      "loss: 0.792551  [ 4000/ 4933]\n",
      "loss: 1.031599  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.894     0.872     0.915    82\n",
      " disgust     0.894     0.930     0.920    87\n",
      "    fear     0.894     0.835     0.920    88\n",
      "   happy     0.894     0.880     0.910    89\n",
      " neutral     0.894     0.921     0.673    52\n",
      "     sad     0.894     0.890     0.900    90\n",
      "surprise     0.894     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.894     0.902     0.884    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.880494 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep38_acc_89.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep30_acc_89\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep38_acc_89\"! Old accuracy: 89.3, new accuracy: 89.4\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.165414  [    0/ 4933]\n",
      "loss: 1.055516  [  800/ 4933]\n",
      "loss: 0.773267  [ 1600/ 4933]\n",
      "loss: 0.649819  [ 2400/ 4933]\n",
      "loss: 0.796339  [ 3200/ 4933]\n",
      "loss: 0.859059  [ 4000/ 4933]\n",
      "loss: 0.809735  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.898     0.872     0.915    82\n",
      " disgust     0.898     0.941     0.920    87\n",
      "    fear     0.898     0.844     0.920    88\n",
      "   happy     0.898     0.880     0.910    89\n",
      " neutral     0.898     0.925     0.712    52\n",
      "     sad     0.898     0.890     0.900    90\n",
      "surprise     0.898     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.898     0.905     0.890    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.865885 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep39_acc_90.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep38_acc_89\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep39_acc_90\"! Old accuracy: 89.4, new accuracy: 89.8\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.709168  [    0/ 4933]\n",
      "loss: 0.550098  [  800/ 4933]\n",
      "loss: 0.641825  [ 1600/ 4933]\n",
      "loss: 0.497980  [ 2400/ 4933]\n",
      "loss: 0.947491  [ 3200/ 4933]\n",
      "loss: 0.936957  [ 4000/ 4933]\n",
      "loss: 0.766754  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.898     0.872     0.915    82\n",
      " disgust     0.898     0.941     0.920    87\n",
      "    fear     0.898     0.844     0.920    88\n",
      "   happy     0.898     0.880     0.910    89\n",
      " neutral     0.898     0.925     0.712    52\n",
      "     sad     0.898     0.890     0.900    90\n",
      "surprise     0.898     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.898     0.905     0.890    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.851834 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.887715  [    0/ 4933]\n",
      "loss: 0.814407  [  800/ 4933]\n",
      "loss: 0.434833  [ 1600/ 4933]\n",
      "loss: 0.901995  [ 2400/ 4933]\n",
      "loss: 0.647734  [ 3200/ 4933]\n",
      "loss: 0.978558  [ 4000/ 4933]\n",
      "loss: 0.992670  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.896     0.872     0.915    82\n",
      " disgust     0.896     0.941     0.920    87\n",
      "    fear     0.896     0.844     0.920    88\n",
      "   happy     0.896     0.879     0.899    89\n",
      " neutral     0.896     0.902     0.712    52\n",
      "     sad     0.896     0.890     0.900    90\n",
      "surprise     0.896     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.896     0.902     0.888    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.838065 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.793614  [    0/ 4933]\n",
      "loss: 0.914828  [  800/ 4933]\n",
      "loss: 0.528473  [ 1600/ 4933]\n",
      "loss: 0.557651  [ 2400/ 4933]\n",
      "loss: 0.761297  [ 3200/ 4933]\n",
      "loss: 0.617018  [ 4000/ 4933]\n",
      "loss: 0.854695  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.902     0.882     0.915    82\n",
      " disgust     0.902     0.952     0.920    87\n",
      "    fear     0.902     0.853     0.920    88\n",
      "   happy     0.902     0.880     0.910    89\n",
      " neutral     0.902     0.907     0.750    52\n",
      "     sad     0.902     0.890     0.900    90\n",
      "surprise     0.902     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.902     0.907     0.895    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.824742 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep42_acc_90.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep39_acc_90\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep42_acc_90\"! Old accuracy: 89.8, new accuracy: 90.2\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.528159  [    0/ 4933]\n",
      "loss: 0.547812  [  800/ 4933]\n",
      "loss: 0.786694  [ 1600/ 4933]\n",
      "loss: 0.582826  [ 2400/ 4933]\n",
      "loss: 1.314409  [ 3200/ 4933]\n",
      "loss: 0.540901  [ 4000/ 4933]\n",
      "loss: 0.884999  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.902     0.882     0.915    82\n",
      " disgust     0.902     0.952     0.920    87\n",
      "    fear     0.902     0.853     0.920    88\n",
      "   happy     0.902     0.880     0.910    89\n",
      " neutral     0.902     0.907     0.750    52\n",
      "     sad     0.902     0.890     0.900    90\n",
      "surprise     0.902     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.902     0.907     0.895    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.811665 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.873703  [    0/ 4933]\n",
      "loss: 0.852782  [  800/ 4933]\n",
      "loss: 0.706763  [ 1600/ 4933]\n",
      "loss: 0.843165  [ 2400/ 4933]\n",
      "loss: 0.799601  [ 3200/ 4933]\n",
      "loss: 0.827662  [ 4000/ 4933]\n",
      "loss: 0.957706  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.902     0.882     0.915    82\n",
      " disgust     0.902     0.952     0.920    87\n",
      "    fear     0.902     0.853     0.920    88\n",
      "   happy     0.902     0.880     0.910    89\n",
      " neutral     0.902     0.907     0.750    52\n",
      "     sad     0.902     0.890     0.900    90\n",
      "surprise     0.902     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.902     0.907     0.895    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.799015 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.655186  [    0/ 4933]\n",
      "loss: 0.684518  [  800/ 4933]\n",
      "loss: 0.690513  [ 1600/ 4933]\n",
      "loss: 0.708746  [ 2400/ 4933]\n",
      "loss: 0.513878  [ 3200/ 4933]\n",
      "loss: 0.927649  [ 4000/ 4933]\n",
      "loss: 0.612526  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.907     0.882     0.915    82\n",
      " disgust     0.907     0.964     0.920    87\n",
      "    fear     0.907     0.871     0.920    88\n",
      "   happy     0.907     0.890     0.910    89\n",
      " neutral     0.907     0.911     0.788    52\n",
      "     sad     0.907     0.882     0.911    90\n",
      "surprise     0.907     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.907     0.912     0.902    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.786776 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep45_acc_91.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep42_acc_90\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep45_acc_91\"! Old accuracy: 90.2, new accuracy: 90.7\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.506578  [    0/ 4933]\n",
      "loss: 0.873403  [  800/ 4933]\n",
      "loss: 0.795932  [ 1600/ 4933]\n",
      "loss: 0.687273  [ 2400/ 4933]\n",
      "loss: 0.824146  [ 3200/ 4933]\n",
      "loss: 0.426205  [ 4000/ 4933]\n",
      "loss: 0.660338  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.907     0.893     0.915    82\n",
      " disgust     0.907     0.964     0.920    87\n",
      "    fear     0.907     0.871     0.920    88\n",
      "   happy     0.907     0.880     0.910    89\n",
      " neutral     0.907     0.911     0.788    52\n",
      "     sad     0.907     0.882     0.911    90\n",
      "surprise     0.907     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.907     0.912     0.902    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.774891 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.886607  [    0/ 4933]\n",
      "loss: 0.791281  [  800/ 4933]\n",
      "loss: 0.815420  [ 1600/ 4933]\n",
      "loss: 1.136951  [ 2400/ 4933]\n",
      "loss: 0.518555  [ 3200/ 4933]\n",
      "loss: 1.150599  [ 4000/ 4933]\n",
      "loss: 0.736294  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.909     0.904     0.915    82\n",
      " disgust     0.909     0.964     0.920    87\n",
      "    fear     0.909     0.871     0.920    88\n",
      "   happy     0.909     0.882     0.921    89\n",
      " neutral     0.909     0.911     0.788    52\n",
      "     sad     0.909     0.882     0.911    90\n",
      "surprise     0.909     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.909     0.914     0.904    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.763261 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep47_acc_91.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep45_acc_91\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep47_acc_91\"! Old accuracy: 90.7, new accuracy: 90.9\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.393169  [    0/ 4933]\n",
      "loss: 1.074759  [  800/ 4933]\n",
      "loss: 0.848033  [ 1600/ 4933]\n",
      "loss: 0.978131  [ 2400/ 4933]\n",
      "loss: 0.847086  [ 3200/ 4933]\n",
      "loss: 0.598540  [ 4000/ 4933]\n",
      "loss: 1.077600  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.909     0.904     0.915    82\n",
      " disgust     0.909     0.964     0.920    87\n",
      "    fear     0.909     0.871     0.920    88\n",
      "   happy     0.909     0.882     0.921    89\n",
      " neutral     0.909     0.911     0.788    52\n",
      "     sad     0.909     0.882     0.911    90\n",
      "surprise     0.909     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.909     0.914     0.904    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.751906 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.683834  [    0/ 4933]\n",
      "loss: 0.775828  [  800/ 4933]\n",
      "loss: 0.653391  [ 1600/ 4933]\n",
      "loss: 0.587370  [ 2400/ 4933]\n",
      "loss: 1.535186  [ 3200/ 4933]\n",
      "loss: 0.746009  [ 4000/ 4933]\n",
      "loss: 0.857559  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.909     0.904     0.915    82\n",
      " disgust     0.909     0.964     0.920    87\n",
      "    fear     0.909     0.871     0.920    88\n",
      "   happy     0.909     0.882     0.921    89\n",
      " neutral     0.909     0.911     0.788    52\n",
      "     sad     0.909     0.882     0.911    90\n",
      "surprise     0.909     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.909     0.914     0.904    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.740918 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.754199  [    0/ 4933]\n",
      "loss: 0.653141  [  800/ 4933]\n",
      "loss: 0.783774  [ 1600/ 4933]\n",
      "loss: 0.648554  [ 2400/ 4933]\n",
      "loss: 0.654157  [ 3200/ 4933]\n",
      "loss: 0.687377  [ 4000/ 4933]\n",
      "loss: 0.606219  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.909     0.904     0.915    82\n",
      " disgust     0.909     0.964     0.920    87\n",
      "    fear     0.909     0.871     0.920    88\n",
      "   happy     0.909     0.882     0.921    89\n",
      " neutral     0.909     0.911     0.788    52\n",
      "     sad     0.909     0.882     0.911    90\n",
      "surprise     0.909     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.909     0.914     0.904    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.730258 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.545999  [    0/ 4933]\n",
      "loss: 0.652681  [  800/ 4933]\n",
      "loss: 0.579668  [ 1600/ 4933]\n",
      "loss: 0.826086  [ 2400/ 4933]\n",
      "loss: 0.688433  [ 3200/ 4933]\n",
      "loss: 0.751725  [ 4000/ 4933]\n",
      "loss: 0.861449  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.909     0.904     0.915    82\n",
      " disgust     0.909     0.964     0.920    87\n",
      "    fear     0.909     0.871     0.920    88\n",
      "   happy     0.909     0.882     0.921    89\n",
      " neutral     0.909     0.911     0.788    52\n",
      "     sad     0.909     0.882     0.911    90\n",
      "surprise     0.909     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.909     0.914     0.904    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.719785 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.941110  [    0/ 4933]\n",
      "loss: 0.468468  [  800/ 4933]\n",
      "loss: 0.885466  [ 1600/ 4933]\n",
      "loss: 0.451476  [ 2400/ 4933]\n",
      "loss: 0.359589  [ 3200/ 4933]\n",
      "loss: 0.752931  [ 4000/ 4933]\n",
      "loss: 0.964499  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.909     0.904     0.915    82\n",
      " disgust     0.909     0.964     0.920    87\n",
      "    fear     0.909     0.871     0.920    88\n",
      "   happy     0.909     0.882     0.921    89\n",
      " neutral     0.909     0.911     0.788    52\n",
      "     sad     0.909     0.882     0.911    90\n",
      "surprise     0.909     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.909     0.914     0.904    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.709626 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.631286  [    0/ 4933]\n",
      "loss: 0.643085  [  800/ 4933]\n",
      "loss: 0.774971  [ 1600/ 4933]\n",
      "loss: 0.859921  [ 2400/ 4933]\n",
      "loss: 0.624760  [ 3200/ 4933]\n",
      "loss: 0.506583  [ 4000/ 4933]\n",
      "loss: 0.708544  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.911     0.904     0.915    82\n",
      " disgust     0.911     0.964     0.920    87\n",
      "    fear     0.911     0.871     0.920    88\n",
      "   happy     0.911     0.882     0.921    89\n",
      " neutral     0.911     0.913     0.808    52\n",
      "     sad     0.911     0.891     0.911    90\n",
      "surprise     0.911     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.911     0.915     0.907    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.699891 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep53_acc_91.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep47_acc_91\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep53_acc_91\"! Old accuracy: 90.9, new accuracy: 91.1\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.662362  [    0/ 4933]\n",
      "loss: 0.588892  [  800/ 4933]\n",
      "loss: 0.372176  [ 1600/ 4933]\n",
      "loss: 0.751409  [ 2400/ 4933]\n",
      "loss: 0.803463  [ 3200/ 4933]\n",
      "loss: 0.693030  [ 4000/ 4933]\n",
      "loss: 0.924037  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.911     0.904     0.915    82\n",
      " disgust     0.911     0.964     0.920    87\n",
      "    fear     0.911     0.871     0.920    88\n",
      "   happy     0.911     0.882     0.921    89\n",
      " neutral     0.911     0.913     0.808    52\n",
      "     sad     0.911     0.891     0.911    90\n",
      "surprise     0.911     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.911     0.915     0.907    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.690332 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.408161  [    0/ 4933]\n",
      "loss: 0.627633  [  800/ 4933]\n",
      "loss: 0.674200  [ 1600/ 4933]\n",
      "loss: 0.606849  [ 2400/ 4933]\n",
      "loss: 0.484885  [ 3200/ 4933]\n",
      "loss: 0.512810  [ 4000/ 4933]\n",
      "loss: 0.505344  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.911     0.904     0.915    82\n",
      " disgust     0.911     0.964     0.920    87\n",
      "    fear     0.911     0.871     0.920    88\n",
      "   happy     0.911     0.882     0.921    89\n",
      " neutral     0.911     0.913     0.808    52\n",
      "     sad     0.911     0.891     0.911    90\n",
      "surprise     0.911     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.911     0.915     0.907    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.680934 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.582558  [    0/ 4933]\n",
      "loss: 0.721951  [  800/ 4933]\n",
      "loss: 0.733721  [ 1600/ 4933]\n",
      "loss: 0.762506  [ 2400/ 4933]\n",
      "loss: 0.411478  [ 3200/ 4933]\n",
      "loss: 0.655156  [ 4000/ 4933]\n",
      "loss: 0.470301  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.911     0.904     0.915    82\n",
      " disgust     0.911     0.964     0.920    87\n",
      "    fear     0.911     0.871     0.920    88\n",
      "   happy     0.911     0.882     0.921    89\n",
      " neutral     0.911     0.913     0.808    52\n",
      "     sad     0.911     0.891     0.911    90\n",
      "surprise     0.911     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.911     0.915     0.907    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.671829 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.714566  [    0/ 4933]\n",
      "loss: 0.658298  [  800/ 4933]\n",
      "loss: 0.814476  [ 1600/ 4933]\n",
      "loss: 0.536250  [ 2400/ 4933]\n",
      "loss: 1.001433  [ 3200/ 4933]\n",
      "loss: 0.566482  [ 4000/ 4933]\n",
      "loss: 0.740760  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.913     0.904     0.915    82\n",
      " disgust     0.913     0.964     0.920    87\n",
      "    fear     0.913     0.880     0.920    88\n",
      "   happy     0.913     0.882     0.921    89\n",
      " neutral     0.913     0.915     0.827    52\n",
      "     sad     0.913     0.891     0.911    90\n",
      "surprise     0.913     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.913     0.917     0.909    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.663032 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep57_acc_91.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep53_acc_91\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep57_acc_91\"! Old accuracy: 91.1, new accuracy: 91.3\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.668794  [    0/ 4933]\n",
      "loss: 0.454908  [  800/ 4933]\n",
      "loss: 0.591602  [ 1600/ 4933]\n",
      "loss: 0.717566  [ 2400/ 4933]\n",
      "loss: 0.700930  [ 3200/ 4933]\n",
      "loss: 0.484462  [ 4000/ 4933]\n",
      "loss: 0.602289  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.913     0.904     0.915    82\n",
      " disgust     0.913     0.964     0.920    87\n",
      "    fear     0.913     0.880     0.920    88\n",
      "   happy     0.913     0.882     0.921    89\n",
      " neutral     0.913     0.915     0.827    52\n",
      "     sad     0.913     0.891     0.911    90\n",
      "surprise     0.913     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.913     0.917     0.909    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.654513 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.951605  [    0/ 4933]\n",
      "loss: 0.817320  [  800/ 4933]\n",
      "loss: 0.501287  [ 1600/ 4933]\n",
      "loss: 0.657034  [ 2400/ 4933]\n",
      "loss: 0.808523  [ 3200/ 4933]\n",
      "loss: 0.509755  [ 4000/ 4933]\n",
      "loss: 0.624024  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.913     0.904     0.915    82\n",
      " disgust     0.913     0.964     0.920    87\n",
      "    fear     0.913     0.880     0.920    88\n",
      "   happy     0.913     0.882     0.921    89\n",
      " neutral     0.913     0.915     0.827    52\n",
      "     sad     0.913     0.891     0.911    90\n",
      "surprise     0.913     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.913     0.917     0.909    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.646102 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.535186  [    0/ 4933]\n",
      "loss: 0.407446  [  800/ 4933]\n",
      "loss: 0.661954  [ 1600/ 4933]\n",
      "loss: 0.756025  [ 2400/ 4933]\n",
      "loss: 0.854116  [ 3200/ 4933]\n",
      "loss: 0.661465  [ 4000/ 4933]\n",
      "loss: 0.407470  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.913     0.904     0.915    82\n",
      " disgust     0.913     0.964     0.920    87\n",
      "    fear     0.913     0.880     0.920    88\n",
      "   happy     0.913     0.882     0.921    89\n",
      " neutral     0.913     0.915     0.827    52\n",
      "     sad     0.913     0.891     0.911    90\n",
      "surprise     0.913     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.913     0.917     0.909    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.637919 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.893976  [    0/ 4933]\n",
      "loss: 0.780187  [  800/ 4933]\n",
      "loss: 0.584467  [ 1600/ 4933]\n",
      "loss: 0.544654  [ 2400/ 4933]\n",
      "loss: 0.548472  [ 3200/ 4933]\n",
      "loss: 0.403815  [ 4000/ 4933]\n",
      "loss: 0.815540  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.914     0.904     0.915    82\n",
      " disgust     0.914     0.964     0.920    87\n",
      "    fear     0.914     0.871     0.920    88\n",
      "   happy     0.914     0.901     0.921    89\n",
      " neutral     0.914     0.917     0.846    52\n",
      "     sad     0.914     0.891     0.911    90\n",
      "surprise     0.914     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.914     0.919     0.912    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.629965 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep61_acc_91.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep57_acc_91\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep61_acc_91\"! Old accuracy: 91.3, new accuracy: 91.4\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.956104  [    0/ 4933]\n",
      "loss: 0.829778  [  800/ 4933]\n",
      "loss: 0.798377  [ 1600/ 4933]\n",
      "loss: 0.604173  [ 2400/ 4933]\n",
      "loss: 1.107488  [ 3200/ 4933]\n",
      "loss: 1.077297  [ 4000/ 4933]\n",
      "loss: 0.534672  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.916     0.904     0.915    82\n",
      " disgust     0.916     0.976     0.920    87\n",
      "    fear     0.916     0.871     0.920    88\n",
      "   happy     0.916     0.901     0.921    89\n",
      " neutral     0.916     0.918     0.865    52\n",
      "     sad     0.916     0.891     0.911    90\n",
      "surprise     0.916     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.916     0.921     0.915    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.622220 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep62_acc_92.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep61_acc_91\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep62_acc_92\"! Old accuracy: 91.4, new accuracy: 91.6\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.379967  [    0/ 4933]\n",
      "loss: 0.582954  [  800/ 4933]\n",
      "loss: 0.682886  [ 1600/ 4933]\n",
      "loss: 0.561605  [ 2400/ 4933]\n",
      "loss: 0.376591  [ 3200/ 4933]\n",
      "loss: 1.385627  [ 4000/ 4933]\n",
      "loss: 0.548631  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.916     0.904     0.915    82\n",
      " disgust     0.916     0.976     0.920    87\n",
      "    fear     0.916     0.871     0.920    88\n",
      "   happy     0.916     0.901     0.921    89\n",
      " neutral     0.916     0.918     0.865    52\n",
      "     sad     0.916     0.891     0.911    90\n",
      "surprise     0.916     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.916     0.921     0.915    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.614654 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.502449  [    0/ 4933]\n",
      "loss: 0.581417  [  800/ 4933]\n",
      "loss: 0.671071  [ 1600/ 4933]\n",
      "loss: 0.624952  [ 2400/ 4933]\n",
      "loss: 0.538932  [ 3200/ 4933]\n",
      "loss: 0.828587  [ 4000/ 4933]\n",
      "loss: 0.607336  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.916     0.904     0.915    82\n",
      " disgust     0.916     0.976     0.920    87\n",
      "    fear     0.916     0.871     0.920    88\n",
      "   happy     0.916     0.901     0.921    89\n",
      " neutral     0.916     0.918     0.865    52\n",
      "     sad     0.916     0.891     0.911    90\n",
      "surprise     0.916     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.916     0.921     0.915    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.607349 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.948891  [    0/ 4933]\n",
      "loss: 0.384144  [  800/ 4933]\n",
      "loss: 0.851816  [ 1600/ 4933]\n",
      "loss: 0.396178  [ 2400/ 4933]\n",
      "loss: 0.325201  [ 3200/ 4933]\n",
      "loss: 0.669899  [ 4000/ 4933]\n",
      "loss: 0.516647  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.916     0.904     0.915    82\n",
      " disgust     0.916     0.976     0.920    87\n",
      "    fear     0.916     0.871     0.920    88\n",
      "   happy     0.916     0.901     0.921    89\n",
      " neutral     0.916     0.918     0.865    52\n",
      "     sad     0.916     0.891     0.911    90\n",
      "surprise     0.916     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.916     0.921     0.915    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.600289 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.431602  [    0/ 4933]\n",
      "loss: 0.284613  [  800/ 4933]\n",
      "loss: 0.536686  [ 1600/ 4933]\n",
      "loss: 0.637808  [ 2400/ 4933]\n",
      "loss: 0.741960  [ 3200/ 4933]\n",
      "loss: 0.685100  [ 4000/ 4933]\n",
      "loss: 0.441062  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.916     0.904     0.915    82\n",
      " disgust     0.916     0.976     0.920    87\n",
      "    fear     0.916     0.871     0.920    88\n",
      "   happy     0.916     0.901     0.921    89\n",
      " neutral     0.916     0.918     0.865    52\n",
      "     sad     0.916     0.891     0.911    90\n",
      "surprise     0.916     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.916     0.921     0.915    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.593367 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.724404  [    0/ 4933]\n",
      "loss: 0.523021  [  800/ 4933]\n",
      "loss: 0.558983  [ 1600/ 4933]\n",
      "loss: 0.445233  [ 2400/ 4933]\n",
      "loss: 0.375762  [ 3200/ 4933]\n",
      "loss: 0.444132  [ 4000/ 4933]\n",
      "loss: 0.898257  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.916     0.904     0.915    82\n",
      " disgust     0.916     0.976     0.920    87\n",
      "    fear     0.916     0.871     0.920    88\n",
      "   happy     0.916     0.901     0.921    89\n",
      " neutral     0.916     0.918     0.865    52\n",
      "     sad     0.916     0.891     0.911    90\n",
      "surprise     0.916     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.916     0.921     0.915    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.586616 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.343611  [    0/ 4933]\n",
      "loss: 0.433257  [  800/ 4933]\n",
      "loss: 0.979580  [ 1600/ 4933]\n",
      "loss: 0.969881  [ 2400/ 4933]\n",
      "loss: 0.313020  [ 3200/ 4933]\n",
      "loss: 0.473486  [ 4000/ 4933]\n",
      "loss: 0.651367  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.916     0.904     0.915    82\n",
      " disgust     0.916     0.976     0.920    87\n",
      "    fear     0.916     0.871     0.920    88\n",
      "   happy     0.916     0.901     0.921    89\n",
      " neutral     0.916     0.918     0.865    52\n",
      "     sad     0.916     0.891     0.911    90\n",
      "surprise     0.916     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.916     0.921     0.915    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.580007 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.560695  [    0/ 4933]\n",
      "loss: 0.670128  [  800/ 4933]\n",
      "loss: 0.472223  [ 1600/ 4933]\n",
      "loss: 0.599922  [ 2400/ 4933]\n",
      "loss: 0.409522  [ 3200/ 4933]\n",
      "loss: 0.721129  [ 4000/ 4933]\n",
      "loss: 0.834685  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.920     0.904     0.915    82\n",
      " disgust     0.920     0.976     0.920    87\n",
      "    fear     0.920     0.880     0.920    88\n",
      "   happy     0.920     0.901     0.921    89\n",
      " neutral     0.920     0.920     0.885    52\n",
      "     sad     0.920     0.902     0.922    90\n",
      "surprise     0.920     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.920     0.924     0.919    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.573563 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep69_acc_92.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep62_acc_92\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep69_acc_92\"! Old accuracy: 91.6, new accuracy: 92.0\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.764451  [    0/ 4933]\n",
      "loss: 0.431058  [  800/ 4933]\n",
      "loss: 0.505370  [ 1600/ 4933]\n",
      "loss: 0.582030  [ 2400/ 4933]\n",
      "loss: 0.762607  [ 3200/ 4933]\n",
      "loss: 0.448789  [ 4000/ 4933]\n",
      "loss: 0.485452  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.920     0.904     0.915    82\n",
      " disgust     0.920     0.976     0.920    87\n",
      "    fear     0.920     0.880     0.920    88\n",
      "   happy     0.920     0.901     0.921    89\n",
      " neutral     0.920     0.920     0.885    52\n",
      "     sad     0.920     0.902     0.922    90\n",
      "surprise     0.920     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.920     0.924     0.919    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.567338 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.647868  [    0/ 4933]\n",
      "loss: 0.371854  [  800/ 4933]\n",
      "loss: 0.401209  [ 1600/ 4933]\n",
      "loss: 0.396898  [ 2400/ 4933]\n",
      "loss: 0.254232  [ 3200/ 4933]\n",
      "loss: 0.274874  [ 4000/ 4933]\n",
      "loss: 0.586347  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.920     0.904     0.915    82\n",
      " disgust     0.920     0.976     0.920    87\n",
      "    fear     0.920     0.880     0.920    88\n",
      "   happy     0.920     0.901     0.921    89\n",
      " neutral     0.920     0.920     0.885    52\n",
      "     sad     0.920     0.902     0.922    90\n",
      "surprise     0.920     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.920     0.924     0.919    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.561272 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.768224  [    0/ 4933]\n",
      "loss: 0.247451  [  800/ 4933]\n",
      "loss: 0.393666  [ 1600/ 4933]\n",
      "loss: 0.559199  [ 2400/ 4933]\n",
      "loss: 0.594902  [ 3200/ 4933]\n",
      "loss: 0.273144  [ 4000/ 4933]\n",
      "loss: 0.365494  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.922     0.904     0.915    82\n",
      " disgust     0.922     0.976     0.920    87\n",
      "    fear     0.922     0.880     0.920    88\n",
      "   happy     0.922     0.901     0.921    89\n",
      " neutral     0.922     0.922     0.904    52\n",
      "     sad     0.922     0.912     0.922    90\n",
      "surprise     0.922     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.922     0.925     0.922    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.555330 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep72_acc_92.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep69_acc_92\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep72_acc_92\"! Old accuracy: 92.0, new accuracy: 92.2\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.802502  [    0/ 4933]\n",
      "loss: 0.598901  [  800/ 4933]\n",
      "loss: 0.423343  [ 1600/ 4933]\n",
      "loss: 0.376129  [ 2400/ 4933]\n",
      "loss: 0.397366  [ 3200/ 4933]\n",
      "loss: 0.803515  [ 4000/ 4933]\n",
      "loss: 0.811506  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.922     0.904     0.915    82\n",
      " disgust     0.922     0.976     0.920    87\n",
      "    fear     0.922     0.880     0.920    88\n",
      "   happy     0.922     0.901     0.921    89\n",
      " neutral     0.922     0.922     0.904    52\n",
      "     sad     0.922     0.912     0.922    90\n",
      "surprise     0.922     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.922     0.925     0.922    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.549449 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.953845  [    0/ 4933]\n",
      "loss: 0.291786  [  800/ 4933]\n",
      "loss: 0.323367  [ 1600/ 4933]\n",
      "loss: 0.425789  [ 2400/ 4933]\n",
      "loss: 0.531320  [ 3200/ 4933]\n",
      "loss: 0.622034  [ 4000/ 4933]\n",
      "loss: 0.256507  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.922     0.904     0.915    82\n",
      " disgust     0.922     0.976     0.920    87\n",
      "    fear     0.922     0.880     0.920    88\n",
      "   happy     0.922     0.901     0.921    89\n",
      " neutral     0.922     0.922     0.904    52\n",
      "     sad     0.922     0.912     0.922    90\n",
      "surprise     0.922     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.922     0.925     0.922    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.543827 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.378384  [    0/ 4933]\n",
      "loss: 0.635037  [  800/ 4933]\n",
      "loss: 0.643263  [ 1600/ 4933]\n",
      "loss: 0.709421  [ 2400/ 4933]\n",
      "loss: 0.495817  [ 3200/ 4933]\n",
      "loss: 0.491584  [ 4000/ 4933]\n",
      "loss: 0.492511  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.922     0.904     0.915    82\n",
      " disgust     0.922     0.976     0.920    87\n",
      "    fear     0.922     0.871     0.920    88\n",
      "   happy     0.922     0.911     0.921    89\n",
      " neutral     0.922     0.922     0.904    52\n",
      "     sad     0.922     0.912     0.922    90\n",
      "surprise     0.922     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.922     0.925     0.922    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.538316 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.346239  [    0/ 4933]\n",
      "loss: 0.965751  [  800/ 4933]\n",
      "loss: 0.530283  [ 1600/ 4933]\n",
      "loss: 0.648203  [ 2400/ 4933]\n",
      "loss: 0.402537  [ 3200/ 4933]\n",
      "loss: 0.431915  [ 4000/ 4933]\n",
      "loss: 1.167857  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.923     0.904     0.915    82\n",
      " disgust     0.923     0.976     0.920    87\n",
      "    fear     0.923     0.871     0.920    88\n",
      "   happy     0.923     0.911     0.921    89\n",
      " neutral     0.923     0.923     0.923    52\n",
      "     sad     0.923     0.922     0.922    90\n",
      "surprise     0.923     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.923     0.927     0.925    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.532963 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep76_acc_92.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep72_acc_92\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep76_acc_92\"! Old accuracy: 92.2, new accuracy: 92.3\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.308337  [    0/ 4933]\n",
      "loss: 0.731411  [  800/ 4933]\n",
      "loss: 0.202980  [ 1600/ 4933]\n",
      "loss: 0.464746  [ 2400/ 4933]\n",
      "loss: 0.360502  [ 3200/ 4933]\n",
      "loss: 0.745773  [ 4000/ 4933]\n",
      "loss: 0.346760  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.923     0.904     0.915    82\n",
      " disgust     0.923     0.976     0.920    87\n",
      "    fear     0.923     0.871     0.920    88\n",
      "   happy     0.923     0.911     0.921    89\n",
      " neutral     0.923     0.923     0.923    52\n",
      "     sad     0.923     0.922     0.922    90\n",
      "surprise     0.923     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.923     0.927     0.925    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.527781 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.278958  [    0/ 4933]\n",
      "loss: 0.400000  [  800/ 4933]\n",
      "loss: 0.428683  [ 1600/ 4933]\n",
      "loss: 0.375938  [ 2400/ 4933]\n",
      "loss: 0.542955  [ 3200/ 4933]\n",
      "loss: 0.590630  [ 4000/ 4933]\n",
      "loss: 0.364929  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.923     0.904     0.915    82\n",
      " disgust     0.923     0.976     0.920    87\n",
      "    fear     0.923     0.871     0.920    88\n",
      "   happy     0.923     0.911     0.921    89\n",
      " neutral     0.923     0.923     0.923    52\n",
      "     sad     0.923     0.922     0.922    90\n",
      "surprise     0.923     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.923     0.927     0.925    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.522698 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.460365  [    0/ 4933]\n",
      "loss: 0.700805  [  800/ 4933]\n",
      "loss: 0.623806  [ 1600/ 4933]\n",
      "loss: 0.510277  [ 2400/ 4933]\n",
      "loss: 0.358913  [ 3200/ 4933]\n",
      "loss: 0.814324  [ 4000/ 4933]\n",
      "loss: 0.276165  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.923     0.904     0.915    82\n",
      " disgust     0.923     0.976     0.920    87\n",
      "    fear     0.923     0.871     0.920    88\n",
      "   happy     0.923     0.911     0.921    89\n",
      " neutral     0.923     0.923     0.923    52\n",
      "     sad     0.923     0.922     0.922    90\n",
      "surprise     0.923     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.923     0.927     0.925    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.517681 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.158386  [    0/ 4933]\n",
      "loss: 0.439016  [  800/ 4933]\n",
      "loss: 0.656969  [ 1600/ 4933]\n",
      "loss: 0.816471  [ 2400/ 4933]\n",
      "loss: 0.259513  [ 3200/ 4933]\n",
      "loss: 0.597890  [ 4000/ 4933]\n",
      "loss: 0.504335  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.923     0.904     0.915    82\n",
      " disgust     0.923     0.976     0.920    87\n",
      "    fear     0.923     0.871     0.920    88\n",
      "   happy     0.923     0.911     0.921    89\n",
      " neutral     0.923     0.923     0.923    52\n",
      "     sad     0.923     0.922     0.922    90\n",
      "surprise     0.923     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.923     0.927     0.925    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.512858 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.636321  [    0/ 4933]\n",
      "loss: 0.340070  [  800/ 4933]\n",
      "loss: 0.640792  [ 1600/ 4933]\n",
      "loss: 0.577975  [ 2400/ 4933]\n",
      "loss: 0.330789  [ 3200/ 4933]\n",
      "loss: 0.345140  [ 4000/ 4933]\n",
      "loss: 1.090898  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.923     0.904     0.915    82\n",
      " disgust     0.923     0.976     0.920    87\n",
      "    fear     0.923     0.871     0.920    88\n",
      "   happy     0.923     0.911     0.921    89\n",
      " neutral     0.923     0.923     0.923    52\n",
      "     sad     0.923     0.922     0.922    90\n",
      "surprise     0.923     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.923     0.927     0.925    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.508119 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.552733  [    0/ 4933]\n",
      "loss: 0.466254  [  800/ 4933]\n",
      "loss: 0.847754  [ 1600/ 4933]\n",
      "loss: 0.342531  [ 2400/ 4933]\n",
      "loss: 0.366215  [ 3200/ 4933]\n",
      "loss: 0.408342  [ 4000/ 4933]\n",
      "loss: 0.278202  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.923     0.904     0.915    82\n",
      " disgust     0.923     0.976     0.920    87\n",
      "    fear     0.923     0.871     0.920    88\n",
      "   happy     0.923     0.911     0.921    89\n",
      " neutral     0.923     0.923     0.923    52\n",
      "     sad     0.923     0.922     0.922    90\n",
      "surprise     0.923     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.923     0.927     0.925    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.503522 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.340935  [    0/ 4933]\n",
      "loss: 0.188210  [  800/ 4933]\n",
      "loss: 0.683537  [ 1600/ 4933]\n",
      "loss: 0.377350  [ 2400/ 4933]\n",
      "loss: 0.682317  [ 3200/ 4933]\n",
      "loss: 0.711179  [ 4000/ 4933]\n",
      "loss: 0.636525  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.923     0.904     0.915    82\n",
      " disgust     0.923     0.976     0.920    87\n",
      "    fear     0.923     0.871     0.920    88\n",
      "   happy     0.923     0.911     0.921    89\n",
      " neutral     0.923     0.923     0.923    52\n",
      "     sad     0.923     0.922     0.922    90\n",
      "surprise     0.923     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.923     0.927     0.925    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.499091 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.618311  [    0/ 4933]\n",
      "loss: 0.692664  [  800/ 4933]\n",
      "loss: 0.353356  [ 1600/ 4933]\n",
      "loss: 0.355246  [ 2400/ 4933]\n",
      "loss: 0.305177  [ 3200/ 4933]\n",
      "loss: 0.316798  [ 4000/ 4933]\n",
      "loss: 0.386608  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.925     0.904     0.915    82\n",
      " disgust     0.925     0.976     0.920    87\n",
      "    fear     0.925     0.871     0.920    88\n",
      "   happy     0.925     0.911     0.921    89\n",
      " neutral     0.925     0.925     0.942    52\n",
      "     sad     0.925     0.933     0.922    90\n",
      "surprise     0.925     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.925     0.929     0.927    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.494718 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep84_acc_93.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep76_acc_92\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep84_acc_93\"! Old accuracy: 92.3, new accuracy: 92.5\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.360367  [    0/ 4933]\n",
      "loss: 0.626948  [  800/ 4933]\n",
      "loss: 0.553941  [ 1600/ 4933]\n",
      "loss: 0.842684  [ 2400/ 4933]\n",
      "loss: 0.738772  [ 3200/ 4933]\n",
      "loss: 0.495380  [ 4000/ 4933]\n",
      "loss: 0.287064  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.490431 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep85_acc_93.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep84_acc_93\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip_smallModel/UMAP_Nr1/emo_reco_best_ep85_acc_93\"! Old accuracy: 92.5, new accuracy: 92.7\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.450065  [    0/ 4933]\n",
      "loss: 0.226149  [  800/ 4933]\n",
      "loss: 0.288565  [ 1600/ 4933]\n",
      "loss: 0.273190  [ 2400/ 4933]\n",
      "loss: 0.492789  [ 3200/ 4933]\n",
      "loss: 0.393348  [ 4000/ 4933]\n",
      "loss: 0.453713  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.486267 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.412586  [    0/ 4933]\n",
      "loss: 0.371547  [  800/ 4933]\n",
      "loss: 0.650600  [ 1600/ 4933]\n",
      "loss: 0.584025  [ 2400/ 4933]\n",
      "loss: 0.430032  [ 3200/ 4933]\n",
      "loss: 0.467315  [ 4000/ 4933]\n",
      "loss: 0.631730  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.482221 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.313873  [    0/ 4933]\n",
      "loss: 0.699985  [  800/ 4933]\n",
      "loss: 0.729870  [ 1600/ 4933]\n",
      "loss: 0.248971  [ 2400/ 4933]\n",
      "loss: 0.272105  [ 3200/ 4933]\n",
      "loss: 0.221133  [ 4000/ 4933]\n",
      "loss: 0.392605  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.478224 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.310432  [    0/ 4933]\n",
      "loss: 0.525379  [  800/ 4933]\n",
      "loss: 0.337227  [ 1600/ 4933]\n",
      "loss: 0.220544  [ 2400/ 4933]\n",
      "loss: 0.458488  [ 3200/ 4933]\n",
      "loss: 0.573668  [ 4000/ 4933]\n",
      "loss: 0.303941  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.474342 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.807399  [    0/ 4933]\n",
      "loss: 0.570644  [  800/ 4933]\n",
      "loss: 0.791390  [ 1600/ 4933]\n",
      "loss: 0.440782  [ 2400/ 4933]\n",
      "loss: 0.152594  [ 3200/ 4933]\n",
      "loss: 0.518905  [ 4000/ 4933]\n",
      "loss: 0.520038  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.470502 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.361003  [    0/ 4933]\n",
      "loss: 1.209903  [  800/ 4933]\n",
      "loss: 0.627754  [ 1600/ 4933]\n",
      "loss: 0.514220  [ 2400/ 4933]\n",
      "loss: 0.222004  [ 3200/ 4933]\n",
      "loss: 0.536977  [ 4000/ 4933]\n",
      "loss: 0.354890  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.466833 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.525807  [    0/ 4933]\n",
      "loss: 0.458262  [  800/ 4933]\n",
      "loss: 0.520985  [ 1600/ 4933]\n",
      "loss: 0.425578  [ 2400/ 4933]\n",
      "loss: 0.340907  [ 3200/ 4933]\n",
      "loss: 0.582097  [ 4000/ 4933]\n",
      "loss: 0.419877  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.463204 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.237961  [    0/ 4933]\n",
      "loss: 0.306208  [  800/ 4933]\n",
      "loss: 0.385033  [ 1600/ 4933]\n",
      "loss: 0.122152  [ 2400/ 4933]\n",
      "loss: 0.204677  [ 3200/ 4933]\n",
      "loss: 0.409162  [ 4000/ 4933]\n",
      "loss: 0.482143  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.459641 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.470057  [    0/ 4933]\n",
      "loss: 0.284949  [  800/ 4933]\n",
      "loss: 0.229374  [ 1600/ 4933]\n",
      "loss: 0.336892  [ 2400/ 4933]\n",
      "loss: 0.517537  [ 3200/ 4933]\n",
      "loss: 1.220792  [ 4000/ 4933]\n",
      "loss: 1.199130  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.456200 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.529284  [    0/ 4933]\n",
      "loss: 0.397168  [  800/ 4933]\n",
      "loss: 0.377374  [ 1600/ 4933]\n",
      "loss: 0.487052  [ 2400/ 4933]\n",
      "loss: 0.334131  [ 3200/ 4933]\n",
      "loss: 0.462622  [ 4000/ 4933]\n",
      "loss: 0.362500  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.452833 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.553929  [    0/ 4933]\n",
      "loss: 0.198909  [  800/ 4933]\n",
      "loss: 0.904113  [ 1600/ 4933]\n",
      "loss: 0.258495  [ 2400/ 4933]\n",
      "loss: 1.022839  [ 3200/ 4933]\n",
      "loss: 0.111096  [ 4000/ 4933]\n",
      "loss: 0.465730  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.449524 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.277865  [    0/ 4933]\n",
      "loss: 0.698148  [  800/ 4933]\n",
      "loss: 0.700211  [ 1600/ 4933]\n",
      "loss: 0.454057  [ 2400/ 4933]\n",
      "loss: 0.353965  [ 3200/ 4933]\n",
      "loss: 0.660065  [ 4000/ 4933]\n",
      "loss: 0.276400  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.446290 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.330003  [    0/ 4933]\n",
      "loss: 0.729827  [  800/ 4933]\n",
      "loss: 0.228619  [ 1600/ 4933]\n",
      "loss: 0.921181  [ 2400/ 4933]\n",
      "loss: 0.658907  [ 3200/ 4933]\n",
      "loss: 0.469624  [ 4000/ 4933]\n",
      "loss: 0.723084  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.872     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.925     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.930     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.443153 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.270050  [    0/ 4933]\n",
      "loss: 0.246278  [  800/ 4933]\n",
      "loss: 0.419708  [ 1600/ 4933]\n",
      "loss: 0.948227  [ 2400/ 4933]\n",
      "loss: 0.433084  [ 3200/ 4933]\n",
      "loss: 0.468098  [ 4000/ 4933]\n",
      "loss: 0.453203  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.440068 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.750809  [    0/ 4933]\n",
      "loss: 0.263721  [  800/ 4933]\n",
      "loss: 0.379857  [ 1600/ 4933]\n",
      "loss: 0.575498  [ 2400/ 4933]\n",
      "loss: 0.732807  [ 3200/ 4933]\n",
      "loss: 0.455759  [ 4000/ 4933]\n",
      "loss: 0.196212  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.437072 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.195106  [    0/ 4933]\n",
      "loss: 0.529034  [  800/ 4933]\n",
      "loss: 0.708757  [ 1600/ 4933]\n",
      "loss: 0.437264  [ 2400/ 4933]\n",
      "loss: 0.212830  [ 3200/ 4933]\n",
      "loss: 0.487458  [ 4000/ 4933]\n",
      "loss: 0.388277  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.434174 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.411885  [    0/ 4933]\n",
      "loss: 0.381072  [  800/ 4933]\n",
      "loss: 0.411113  [ 1600/ 4933]\n",
      "loss: 0.862744  [ 2400/ 4933]\n",
      "loss: 0.511501  [ 3200/ 4933]\n",
      "loss: 0.302031  [ 4000/ 4933]\n",
      "loss: 0.275237  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.431341 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.300608  [    0/ 4933]\n",
      "loss: 0.253120  [  800/ 4933]\n",
      "loss: 0.511739  [ 1600/ 4933]\n",
      "loss: 0.708053  [ 2400/ 4933]\n",
      "loss: 0.288807  [ 3200/ 4933]\n",
      "loss: 0.554134  [ 4000/ 4933]\n",
      "loss: 0.144583  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.428535 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.112379  [    0/ 4933]\n",
      "loss: 0.279960  [  800/ 4933]\n",
      "loss: 0.388677  [ 1600/ 4933]\n",
      "loss: 0.294336  [ 2400/ 4933]\n",
      "loss: 0.664021  [ 3200/ 4933]\n",
      "loss: 0.143133  [ 4000/ 4933]\n",
      "loss: 0.334828  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.425773 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.215120  [    0/ 4933]\n",
      "loss: 0.417883  [  800/ 4933]\n",
      "loss: 0.363865  [ 1600/ 4933]\n",
      "loss: 0.487287  [ 2400/ 4933]\n",
      "loss: 0.635958  [ 3200/ 4933]\n",
      "loss: 0.408967  [ 4000/ 4933]\n",
      "loss: 0.588671  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.423136 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.505755  [    0/ 4933]\n",
      "loss: 0.183559  [  800/ 4933]\n",
      "loss: 0.471104  [ 1600/ 4933]\n",
      "loss: 0.607988  [ 2400/ 4933]\n",
      "loss: 0.397989  [ 3200/ 4933]\n",
      "loss: 0.307232  [ 4000/ 4933]\n",
      "loss: 0.334087  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.420485 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.416938  [    0/ 4933]\n",
      "loss: 0.073443  [  800/ 4933]\n",
      "loss: 0.483532  [ 1600/ 4933]\n",
      "loss: 0.262245  [ 2400/ 4933]\n",
      "loss: 0.411001  [ 3200/ 4933]\n",
      "loss: 0.292768  [ 4000/ 4933]\n",
      "loss: 0.345604  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.417944 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.364343  [    0/ 4933]\n",
      "loss: 0.333822  [  800/ 4933]\n",
      "loss: 0.345633  [ 1600/ 4933]\n",
      "loss: 0.197755  [ 2400/ 4933]\n",
      "loss: 0.259028  [ 3200/ 4933]\n",
      "loss: 0.514356  [ 4000/ 4933]\n",
      "loss: 0.302266  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.415424 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.535707  [    0/ 4933]\n",
      "loss: 0.343001  [  800/ 4933]\n",
      "loss: 0.078608  [ 1600/ 4933]\n",
      "loss: 0.298824  [ 2400/ 4933]\n",
      "loss: 0.208634  [ 3200/ 4933]\n",
      "loss: 0.658943  [ 4000/ 4933]\n",
      "loss: 0.391866  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.927     0.904     0.915    82\n",
      " disgust     0.927     0.976     0.920    87\n",
      "    fear     0.927     0.882     0.932    88\n",
      "   happy     0.927     0.921     0.921    89\n",
      " neutral     0.927     0.907     0.942    52\n",
      "     sad     0.927     0.933     0.922    90\n",
      "surprise     0.927     0.983     0.951    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.927     0.929     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.412993 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.155038  [    0/ 4933]\n",
      "loss: 0.353422  [  800/ 4933]\n",
      "loss: 0.170563  [ 1600/ 4933]\n",
      "loss: 0.843516  [ 2400/ 4933]\n",
      "loss: 0.660213  [ 3200/ 4933]\n",
      "loss: 0.241915  [ 4000/ 4933]\n",
      "loss: 0.431408  [ 4800/ 4933]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 19\u001B[0m\n\u001B[1;32m     11\u001B[0m lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-4\u001B[39m\n\u001B[1;32m     12\u001B[0m trainer \u001B[38;5;241m=\u001B[39m sset\u001B[38;5;241m.\u001B[39mSSGenModelTrainer(lr\u001B[38;5;241m=\u001B[39mlr, num_epochs\u001B[38;5;241m=\u001B[39mepochs, model\u001B[38;5;241m=\u001B[39mmodel, train_dataset\u001B[38;5;241m=\u001B[39mtrainDS,\n\u001B[1;32m     13\u001B[0m                             eval_dataset\u001B[38;5;241m=\u001B[39mtestDs,\n\u001B[1;32m     14\u001B[0m                             device\u001B[38;5;241m=\u001B[39mdevice, labelList\u001B[38;5;241m=\u001B[39mdata_set\u001B[38;5;241m.\u001B[39mencoded_dataset\u001B[38;5;241m.\u001B[39mlabel_list,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m                             save_highest_acc_min_acc\u001B[38;5;241m=\u001B[39msave_highest_acc_min_acc,\n\u001B[1;32m     18\u001B[0m                             model_path \u001B[38;5;241m=\u001B[39m models_dir)\n\u001B[0;32m---> 19\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:77\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loop(train_dataloader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn, optimizer, t)\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# --------------------- testloop and evaluation- ---------------\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m acc, true, preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(acc \u001B[38;5;241m>\u001B[39m highest_acc):\n\u001B[1;32m     80\u001B[0m     old_acc \u001B[38;5;241m=\u001B[39m highest_acc\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:151\u001B[0m, in \u001B[0;36mSSGenModelTrainer.test_loop\u001B[0;34m(self, dataloader, model, loss_fn)\u001B[0m\n\u001B[1;32m    148\u001B[0m batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 151\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m X, labels \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[1;32m    152\u001B[0m         X \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    153\u001B[0m         labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1315\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1316\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1317\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1318\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1319\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1279\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1281\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1282\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1283\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1284\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[1;32m   1108\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[1;32m   1109\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1117\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[1;32m   1118\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[1;32m   1119\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1120\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1121\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[1;32m   1122\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1123\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[1;32m   1124\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[1;32m   1125\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 424\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    928\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    933\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m/usr/lib/python3.10/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_models_and_utils/encoder\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import network_models.soundsream_models_and_utils.ss_trainer_gen_models as sset\n",
    "importlib.reload(sset)\n",
    "\n",
    "lr = 1e-4\n",
    "trainer = sset.SSGenModelTrainer(lr=lr, num_epochs=epochs, model=model, train_dataset=trainDS,\n",
    "                            eval_dataset=testDs,\n",
    "                            device=device, labelList=data_set.encoded_dataset.label_list,\n",
    "                            batch_size=batch_size,\n",
    "                            save_model_every=safe_model_every,\n",
    "                            save_highest_acc_min_acc=save_highest_acc_min_acc,\n",
    "                            model_path = models_dir)\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

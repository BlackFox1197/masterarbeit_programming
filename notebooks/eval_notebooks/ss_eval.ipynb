{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 14:19:42 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2023-02-09 14:19:42.840181: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 14:19:43.263268: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 14:19:43.263326: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 14:19:43.263331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import SSDimRedModel\n",
    "from network_models.soundsream_models_and_utils.ss_model_conv import SSConvModel3Sec\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings.pkl\", device=\"cuda\")\n",
    "\n",
    "\n",
    "modelDimRed = SSDimRedModel().cuda()\n",
    "modelConv = SSConvModel3Sec(xSize=512, ySize=175).cuda()\n",
    "\n",
    "\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelConv.load_state_dict(torch.load(\"../content/soundstream/experiments/nr2Run_Nr_0_conv/emo_reco_best_ep216_acc_62\"))\n",
    "modelDimRed.load_state_dict(torch.load(\"../content/soundstream/experiments/nr2Run_Nr_0_dimred/emo_reco_500.pth\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "def evaluate(device, model, dataset):\n",
    "    loader = DataLoader(dataset, shuffle=False, batch_size=batch_size)\n",
    "    true, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, z) in enumerate(loader):\n",
    "            X, z = X.to(device),  z.to(device)\n",
    "            pred = model(X)\n",
    "            labels = [torch.squeeze(a.nonzero()).item() for a in z]\n",
    "            true = true + labels\n",
    "\n",
    "            preds = preds + pred.argmax(1).cpu().numpy().tolist()\n",
    "            #preds.append(pred.argmax(1))\n",
    "            if batch % 10 == 0:\n",
    "                print(f\"{batch*batch_size} of {len(dataset)}\")\n",
    "\n",
    "    return true, preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 610\n",
      "60 of 610\n",
      "120 of 610\n",
      "180 of 610\n",
      "240 of 610\n",
      "300 of 610\n",
      "360 of 610\n",
      "420 of 610\n",
      "480 of 610\n",
      "540 of 610\n",
      "600 of 610\n",
      "0 of 610\n",
      "60 of 610\n",
      "120 of 610\n",
      "180 of 610\n",
      "240 of 610\n",
      "300 of 610\n",
      "360 of 610\n",
      "420 of 610\n",
      "480 of 610\n",
      "540 of 610\n",
      "600 of 610\n",
      "------------------ Conv: ----------------\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.595     0.640     0.576    99\n",
      " disgust     0.595     0.582     0.729    107\n",
      "    fear     0.595     0.557     0.487    80\n",
      "   happy     0.595     0.500     0.481    77\n",
      " neutral     0.595     0.758     0.726    95\n",
      "     sad     0.595     0.697     0.582    91\n",
      "surprise     0.595     0.395     0.492    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.595     0.590     0.582    \n",
      "\n",
      "                   angry     disgust        fear       happy     neutral         sad    surprise    support\n",
      "       angry       0.576       0.141       0.040       0.121       0.030       0.030       0.061         99\n",
      "     disgust       0.065       0.729       0.028       0.037       0.037       0.065       0.037        107\n",
      "        fear       0.075       0.100       0.487       0.113       0.025       0.025       0.175         80\n",
      "       happy       0.104       0.143       0.065       0.481       0.039       0.039       0.130         77\n",
      "     neutral       0.032       0.063       0.063       0.021       0.726       0.021       0.074         95\n",
      "         sad       0.044       0.121       0.055       0.055       0.088       0.582       0.055         91\n",
      "    surprise       0.066       0.098       0.131       0.082       0.033       0.098       0.492         61\n",
      "\n",
      "------------------ DimRed: ----------------\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.502     0.570     0.535    99\n",
      " disgust     0.502     0.496     0.523    107\n",
      "    fear     0.502     0.439     0.362    80\n",
      "   happy     0.502     0.406     0.364    77\n",
      " neutral     0.502     0.843     0.621    95\n",
      "     sad     0.502     0.446     0.593    91\n",
      "surprise     0.502     0.346     0.443    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.502     0.507     0.492    \n",
      "\n",
      "                   angry     disgust        fear       happy     neutral         sad    surprise    support\n",
      "       angry       0.535       0.101       0.091       0.111       0.010       0.081       0.071         99\n",
      "     disgust       0.056       0.523       0.028       0.131       0.009       0.140       0.112        107\n",
      "        fear       0.150       0.125       0.362       0.075       0.013       0.113       0.163         80\n",
      "       happy       0.156       0.156       0.091       0.364       0.026       0.130       0.078         77\n",
      "     neutral       0.011       0.063       0.053       0.032       0.621       0.147       0.074         95\n",
      "         sad       0.033       0.154       0.066       0.022       0.066       0.593       0.066         91\n",
      "    surprise       0.098       0.082       0.115       0.082       0.000       0.180       0.443         61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.eval_utils import classificationReport, confusion_matrix\n",
    "\n",
    "trueConv, predsConv = evaluate(\"cuda\", modelConv, testDs)\n",
    "trueDimRed, predsDimRed = evaluate(\"cuda\", modelDimRed, testDs)\n",
    "\n",
    "print(\"------------------ Conv: ----------------\")\n",
    "classificationReport(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "confusion_matrix(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "print(\"------------------ DimRed: ----------------\")\n",
    "classificationReport(trueDimRed, predsDimRed, data_set.encoded_dataset.label_list)\n",
    "confusion_matrix(trueDimRed, predsDimRed, data_set.encoded_dataset.label_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

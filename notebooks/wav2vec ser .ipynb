{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.6\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "#from PIL import Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions defined"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\ndef scale_minmax(X, min=0.0, max=1.0):\\n    X_std = (X - X.min()) / (X.max() - X.min())\\n    X_scaled = X_std * (max - min) + min\\n    return X_scaled\\n\\ndef spectrogram_image(y, sr, out, hop_length, n_mels):\\n    # use log-melspectrogram\\n    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\\n                                            n_fft=hop_length*2, hop_length=hop_length)\\n    mels = numpy.log(mels + 1e-9) # add small number to avoid log(0)\\n\\n    # min-max scale to fit inside 8-bit range\\n    img = scale_minmax(mels, 0, 255).astype(numpy.uint8)\\n    img = numpy.flip(img, axis=0) # put low frequencies at the bottom in image\\n    img = 255-img # invert. make black==more energy\\n\\n    # save as PNG\\n    #plt.axis(\\'off\\')\\n    plt.imsave(\"spec.png\",img)\\n    plt.imshow(img)\\n\\ndef createSpectrogramm(path, label):\\n    data, sr = librosa.load(path)\\n    fourier = librosa.stft(data)\\n    fourierdb = librosa.amplitude_to_db(abs(fourier))\\n    librosa.display.specshow(fourierdb, sr=sr, x_axis=\\'time\\', y_axis=\\'hz\\')\\n\\ndef createMelSpectrogramm(path, label):\\n    data, sr = librosa.load(path, sr=22050, offset=0, duration=1)\\n    melSpec = librosa.feature.melspectrogram(data, sr, n_mels=192, n_fft=1024, hop_length=260)\\n\\n    # plt.figure(figsize=(10, 4))\\n    # plt.title(label, size=20)\\n    librosa.display.specshow(melSpec, sr=sr, x_axis=\\'time\\', y_axis=\\'hz\\')\\n    # plt.colorbar()\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def load_custom_dataset():\n",
    "    paths = []\n",
    "    testpaths = []\n",
    "    testlabels = []\n",
    "    terminator = 'D:/Uni/19.Master/Daten/terminator.wav'\n",
    "    print(sys.executable)\n",
    "    labels = []\n",
    "    # for dirname, _, filenames in os.walk('Daten/TESS Toronto emotional speech set data'):\n",
    "    # D:\\Uni\\19.Master\\DATEN\n",
    "    for dirname, _, filenames in os.walk('../tess'):\n",
    "        for filename in filenames:\n",
    "            label = filename.split('_')[-1]\n",
    "            label = label.split('.')[0]\n",
    "            if (label != 'neutral'):\n",
    "                labels.append(label.lower())\n",
    "                paths.append(os.path.join(dirname, filename))\n",
    "    for dirname, _, filenames in os.walk('../stimuli_intensitätsmorphs'):\n",
    "        for filename in filenames:\n",
    "\n",
    "            intens = filename.split('_')[-2]\n",
    "            emot = filename.split('_')[1]\n",
    "            label = emot\n",
    "            match label:\n",
    "                case 'ang':\n",
    "                    label = 'angry'\n",
    "                case 'dis':\n",
    "                    label = 'disgust'\n",
    "                case 'fea':\n",
    "                    label = 'fear'\n",
    "                case 'hap':\n",
    "                    label = 'happy'\n",
    "                case 'sad':\n",
    "                    label = 'sad'\n",
    "                case 'sur':\n",
    "                    label = 'ps'\n",
    "            if (emot != 'ple'):\n",
    "                testpaths.append(os.path.join(dirname, filename))\n",
    "                testlabels.append(label.lower())\n",
    "    com_labels = testlabels + labels\n",
    "    com_paths = testpaths + paths\n",
    "    print(testlabels)\n",
    "    print(testpaths)\n",
    "    print('Dataset is loaded')\n",
    "    return paths, labels, testpaths, testlabels\n",
    "\"\"\"\n",
    "def scale_minmax(X, min=0.0, max=1.0):\n",
    "    X_std = (X - X.min()) / (X.max() - X.min())\n",
    "    X_scaled = X_std * (max - min) + min\n",
    "    return X_scaled\n",
    "\n",
    "def spectrogram_image(y, sr, out, hop_length, n_mels):\n",
    "    # use log-melspectrogram\n",
    "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\n",
    "                                            n_fft=hop_length*2, hop_length=hop_length)\n",
    "    mels = numpy.log(mels + 1e-9) # add small number to avoid log(0)\n",
    "\n",
    "    # min-max scale to fit inside 8-bit range\n",
    "    img = scale_minmax(mels, 0, 255).astype(numpy.uint8)\n",
    "    img = numpy.flip(img, axis=0) # put low frequencies at the bottom in image\n",
    "    img = 255-img # invert. make black==more energy\n",
    "\n",
    "    # save as PNG\n",
    "    #plt.axis('off')\n",
    "    plt.imsave(\"spec.png\",img)\n",
    "    plt.imshow(img)\n",
    "\n",
    "def createSpectrogramm(path, label):\n",
    "    data, sr = librosa.load(path)\n",
    "    fourier = librosa.stft(data)\n",
    "    fourierdb = librosa.amplitude_to_db(abs(fourier))\n",
    "    librosa.display.specshow(fourierdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "\n",
    "def createMelSpectrogramm(path, label):\n",
    "    data, sr = librosa.load(path, sr=22050, offset=0, duration=1)\n",
    "    melSpec = librosa.feature.melspectrogram(data, sr, n_mels=192, n_fft=1024, hop_length=260)\n",
    "\n",
    "    # plt.figure(figsize=(10, 4))\n",
    "    # plt.title(label, size=20)\n",
    "    librosa.display.specshow(melSpec, sr=sr, x_axis='time', y_axis='hz')\n",
    "    # plt.colorbar()\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\\masterarbeit_programming\\venv\\Scripts\\python.exe\n",
      "['angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps', 'ps']\n",
      "['../stimuli_intensitätsmorphs\\\\nf01_ang_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_ang_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_dis_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_fea_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_hap_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sad_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf01_sur_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_ang_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_dis_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_fea_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_hap_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sad_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf02_sur_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_ang_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_dis_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_fea_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_hap_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sad_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf03_sur_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_ang_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_dis_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_fea_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_hap_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sad_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nf04_sur_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_ang_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_dis_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_fea_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_hap_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sad_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm01_sur_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_ang_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_dis_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_fea_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_hap_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sad_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm02_sur_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_ang_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_dis_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_fea_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_hap_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sad_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm03_sur_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_ang_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_dis_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_fea_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w01_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w01_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w01_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w01_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_hap_w05_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w02_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w02_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w02_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w02_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w03_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w03_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w03_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w03_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w05_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w05_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w05_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sad_w05_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w01_c_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w01_c_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w01_c_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w01_c_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w02_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w02_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w02_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w02_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w03_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w03_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w03_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w03_o_75_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w05_o_100_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w05_o_25_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w05_o_50_70dB.wav', '../stimuli_intensitätsmorphs\\\\nm04_sur_w05_o_75_70dB.wav']\n",
      "Dataset is loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                  path  label\n0    ../stimuli_intensitätsmorphs\\nf01_ang_w01_o_10...  angry\n1    ../stimuli_intensitätsmorphs\\nf01_ang_w01_o_25...  angry\n2    ../stimuli_intensitätsmorphs\\nf01_ang_w01_o_50...  angry\n3    ../stimuli_intensitätsmorphs\\nf01_ang_w01_o_75...  angry\n4    ../stimuli_intensitätsmorphs\\nf01_ang_w02_o_10...  angry\n..                                                 ...    ...\n763  ../stimuli_intensitätsmorphs\\nm04_sur_w03_o_75...     ps\n764  ../stimuli_intensitätsmorphs\\nm04_sur_w05_o_10...     ps\n765  ../stimuli_intensitätsmorphs\\nm04_sur_w05_o_25...     ps\n766  ../stimuli_intensitätsmorphs\\nm04_sur_w05_o_50...     ps\n767  ../stimuli_intensitätsmorphs\\nm04_sur_w05_o_75...     ps\n\n[768 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../stimuli_intensitätsmorphs\\nf01_ang_w01_o_10...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../stimuli_intensitätsmorphs\\nf01_ang_w01_o_25...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../stimuli_intensitätsmorphs\\nf01_ang_w01_o_50...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../stimuli_intensitätsmorphs\\nf01_ang_w01_o_75...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../stimuli_intensitätsmorphs\\nf01_ang_w02_o_10...</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>../stimuli_intensitätsmorphs\\nm04_sur_w03_o_75...</td>\n      <td>ps</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>../stimuli_intensitätsmorphs\\nm04_sur_w05_o_10...</td>\n      <td>ps</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>../stimuli_intensitätsmorphs\\nm04_sur_w05_o_25...</td>\n      <td>ps</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>../stimuli_intensitätsmorphs\\nm04_sur_w05_o_50...</td>\n      <td>ps</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>../stimuli_intensitätsmorphs\\nm04_sur_w05_o_75...</td>\n      <td>ps</td>\n    </tr>\n  </tbody>\n</table>\n<p>768 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainpaths, trainlabels, testpaths, testlabels = load_custom_dataset()\n",
    "\n",
    "###create dataframes for training and testing###\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF[\"path\"] = trainpaths\n",
    "trainDF[\"label\"] = trainlabels\n",
    "\n",
    "testDF = pd.DataFrame()\n",
    "testDF[\"path\"] = testpaths\n",
    "testDF[\"label\"] = testlabels\n",
    "\n",
    "\n",
    "testDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\npath = trainDF[\"speech\"][0]\\n# settings\\nhop_length = 302 # number of samples per time-step in spectrogram\\nn_mels = 192 # number of bins in spectrogram. Height of image\\ntime_steps = 192 # number of time-steps. Width of image\\n\\n# load audio. Using example from librosa\\ny, sr = librosa.load(path, offset=0.1, duration=1, sr=99100)\\nout = \\'out.png\\'\\n\\n# extract a fixed length window\\nstart_sample = 0 # starting at beginning\\nlength_samples = time_steps*hop_length\\nwindow = y[start_sample:start_sample+length_samples]\\n\\n# convert to PNG\\nspectrogram_image(window, sr=sr, out=out, hop_length=hop_length, n_mels=n_mels)\\n\\n#train_spectros = trainDF[\"speech\"].apply(lambda x: spectrogram_image(x))\\n'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "path = trainDF[\"speech\"][0]\n",
    "# settings\n",
    "hop_length = 302 # number of samples per time-step in spectrogram\n",
    "n_mels = 192 # number of bins in spectrogram. Height of image\n",
    "time_steps = 192 # number of time-steps. Width of image\n",
    "\n",
    "# load audio. Using example from librosa\n",
    "y, sr = librosa.load(path, offset=0.1, duration=1, sr=99100)\n",
    "out = 'out.png'\n",
    "\n",
    "# extract a fixed length window\n",
    "start_sample = 0 # starting at beginning\n",
    "length_samples = time_steps*hop_length\n",
    "window = y[start_sample:start_sample+length_samples]\n",
    "\n",
    "# convert to PNG\n",
    "spectrogram_image(window, sr=sr, out=out, hop_length=hop_length, n_mels=n_mels)\n",
    "\n",
    "#train_spectros = trainDF[\"speech\"].apply(lambda x: spectrogram_image(x))\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\\nmodel = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torchvision.models import AlexNet_Weights\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\"\"\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# load dummy dataset and read soundfiles\\nds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\\n# tokenize\\ninput_values = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\\n\\n# retrieve logits\\nlogits = model(input_values).logits\\n\\n# take argmax and decode\\npredicted_ids = torch.argmax(logits, dim=-1)\\ntranscription = processor.batch_decode(predicted_ids)\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import wer\n",
    "import torch\n",
    "\"\"\"\n",
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "# tokenize\n",
    "input_values = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    "\n",
    "# retrieve logits\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\ny = librosa.load(sr=16000, path=testDF[\"speech\"][0])\\n\\n\\ninput_values = processor(y[0], return_tensors=\"pt\",  sampling_rate=16000).input_values  # Batch size 1\\n\\n# retrieve logits\\nlogits = model(input_values).logits\\n\\n# take argmax and decode\\npredicted_ids = torch.argmax(logits, dim=-1)\\ntranscription = processor.batch_decode(predicted_ids)\\n'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "y = librosa.load(sr=16000, path=testDF[\"speech\"][0])\n",
    "\n",
    "\n",
    "input_values = processor(y[0], return_tensors=\"pt\",  sampling_rate=16000).input_values  # Batch size 1\n",
    "\n",
    "# retrieve logits\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\ntrain_audios=[]\\nfor x in testDF[\"speech\"]:\\n    audio=librosa.load(path=x, sr=16000)\\n    train_audios.append(audio[0])\\ntrain_audios\\n'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_audios=[]\n",
    "for x in testDF[\"speech\"]:\n",
    "    audio=librosa.load(path=x, sr=16000)\n",
    "    train_audios.append(audio[0])\n",
    "train_audios\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "save_path=\"/masterarbeit_programming/notebooks/content/data\"\n",
    "train_df, test_df=train_test_split(trainDF, test_size=0.2, random_state=101, stratify=trainDF[\"label\"])\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv(f\"{save_path}/train.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "test_df.to_csv(f\"{save_path}/test.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 2)\n",
      "(480, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-84799cbb514f4b9f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/tonib/.cache/huggingface/datasets/csv/default-84799cbb514f4b9f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "975f6508ab02465db8262b410c6bcd53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b961f7fa21c460db6b367484f578a51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\download\\streaming_download_manager.py:714: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating validation split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d4bd110f02c4b6aa962dd29e30e29a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/tonib/.cache/huggingface/datasets/csv/default-84799cbb514f4b9f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\download\\streaming_download_manager.py:714: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21aa1fb32927486a91bb982bb78588d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['path', 'label'],\n",
      "    num_rows: 1920\n",
      "})\n",
      "Dataset({\n",
      "    features: ['path', 'label'],\n",
      "    num_rows: 480\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Loading the created dataset using datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"/masterarbeit_programming/notebooks/content/data/train.csv\",\n",
    "    \"validation\": \"/masterarbeit_programming/notebooks/content/data/test.csv\",\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\", )\n",
    "train_df = dataset[\"train\"]\n",
    "test_df = dataset[\"validation\"]\n",
    "\n",
    "print(train_df)\n",
    "print(test_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# specifiy input and output column\n",
    "input_colum=\"path\"\n",
    "output_column=\"label\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Classes: ['angry', 'disgust', 'fear', 'happy', 'ps', 'sad']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#distinguish labels\n",
    "class_list = train_df.unique(output_column)\n",
    "class_list.sort()\n",
    "num_class = len(class_list)\n",
    "\n",
    "print(f\"{num_class} Classes: {class_list}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "\n",
    "model_name_path =  \"facebook/wav2vec2-base-960h\"\n",
    "pooling_mode = \"mean\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "### config\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_path,\n",
    "    num_labels=num_class,\n",
    "    label2id={label: i for i, label in enumerate(class_list)},\n",
    "    id2label={i: label for i, label in enumerate(class_list)},\n",
    "    finetuning_task=\"wav2vec2_clf\"\n",
    ")\n",
    "setattr(config, 'pooling_mode', pooling_mode)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sample rate: 16000\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(model_name_path)\n",
    "target_sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(f\"Target sample rate: {target_sampling_rate}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import soundfile\n",
    "\n",
    "def speech_file_to_array(speech_path):\n",
    "    speech_array, sampling_rate = torchaudio.load(speech_path)\n",
    "    resampler = librosa.resample(speech_array, orig_sr=sampling_rate, target_sr=target_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "\n",
    "def speech_file_to_array_librosa(speech_path):\n",
    "    speech_array, sampling_rate = librosa.load(speech_path)\n",
    "    resampler = librosa.resample(speech_array, orig_sr=sampling_rate, target_sr=target_sampling_rate)\n",
    "    return speech_array\n",
    "\n",
    "def label_to_id(label, label_list):\n",
    "\n",
    "    if len(label_list) > 0:\n",
    "        return label_list.index(label) if label in label_list else -1\n",
    "    return label\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    speech_list=[]\n",
    "    speech_list = [ speech_file_to_array_librosa(speech_path) for speech_path in examples[input_colum]]\n",
    "    target_list = [ label_to_id(label, class_list) for label in examples[output_column]]\n",
    "\n",
    "    result = processor(speech_list, sampling_rate=target_sampling_rate)\n",
    "    result[\"labels\"] = list(target_list)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "### resample\n",
    "#from datasets import Audio\n",
    "#train_df = train_df.cast_column(\"path\", Audio(sampling_rate=target_sampling_rate))\n",
    "\n",
    "#test_df = test_df.cast_column(\"path\", Audio(sampling_rate=target_sampling_rate))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/192 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0470965e74d34d85af4c6ca9070cd5ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\masterarbeit_programming\\venv\\lib\\site-packages\\transformers\\feature_extraction_utils.py:164: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/48 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1155ea7abc444108ae40e88d7142d21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = train_df.map(\n",
    "    preprocess_function,\n",
    "    batch_size=10,\n",
    "    batched=True,\n",
    "    # num_proc=4\n",
    ")\n",
    "test_df = test_df.map(\n",
    "    preprocess_function,\n",
    "    batch_size=10,\n",
    "    batched=True,\n",
    "    # num_proc=4\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'path': '../tess\\\\OAF_Fear\\\\OAF_choice_fear.wav',\n 'label': 'fear',\n 'input_values': [0.005347009282559156,\n  -7.528260175604373e-05,\n  0.00019006124057341367,\n  0.0011511975899338722,\n  -7.297880802070722e-05,\n  -0.002332984237000346,\n  -0.0027273274026811123,\n  -0.0007437366875819862,\n  -0.0034132860600948334,\n  -0.005155489780008793,\n  -0.0022231556940823793,\n  -0.003020818345248699,\n  -0.007137116510421038,\n  -0.007239627186208963,\n  -0.007200169377028942,\n  -0.005426994990557432,\n  -0.007078962400555611,\n  -0.012079843319952488,\n  -0.009139073081314564,\n  -0.01059677917510271,\n  -0.01161156129091978,\n  -0.008673600852489471,\n  -0.009095572866499424,\n  -0.00934215635061264,\n  -0.01163135189563036,\n  -0.01184934563934803,\n  -0.013085247948765755,\n  -0.013547476381063461,\n  -0.012033736333251,\n  -0.011728492565453053,\n  -0.012789004482328892,\n  -0.0141847999766469,\n  -0.012567385099828243,\n  -0.014910061843693256,\n  -0.01439056545495987,\n  -0.016309164464473724,\n  -0.018531007692217827,\n  -0.018635498359799385,\n  -0.020213710144162178,\n  -0.017976028844714165,\n  -0.022646835073828697,\n  -0.021242275834083557,\n  -0.01951524056494236,\n  -0.02127530798316002,\n  -0.02151043526828289,\n  -0.023723144084215164,\n  -0.023958932608366013,\n  -0.023451928049325943,\n  -0.022668614983558655,\n  -0.021707816049456596,\n  -0.024089746177196503,\n  -0.026851145550608635,\n  -0.023667337372899055,\n  -0.02607182040810585,\n  -0.025598889216780663,\n  -0.027882706373929977,\n  -0.029352456331253052,\n  -0.027608059346675873,\n  -0.030620915815234184,\n  -0.02830434776842594,\n  -0.027278302237391472,\n  -0.02826009877026081,\n  -0.0301347766071558,\n  -0.028584128245711327,\n  -0.029199955984950066,\n  -0.03141048178076744,\n  -0.03279034420847893,\n  -0.03573068603873253,\n  -0.031382862478494644,\n  -0.02975788153707981,\n  -0.033312197774648666,\n  -0.03236908093094826,\n  -0.0329926535487175,\n  -0.03237873688340187,\n  -0.03313979133963585,\n  -0.03642917051911354,\n  -0.034545231610536575,\n  -0.03134406358003616,\n  -0.03364281728863716,\n  -0.03649059310555458,\n  -0.0340711772441864,\n  -0.03650952875614166,\n  -0.03597807139158249,\n  -0.03697953000664711,\n  -0.03975094109773636,\n  -0.03903840854763985,\n  -0.037748757749795914,\n  -0.03865578770637512,\n  -0.041217319667339325,\n  -0.037296924740076065,\n  -0.042197320610284805,\n  -0.041074346750974655,\n  -0.03978899493813515,\n  -0.04285493120551109,\n  -0.04031037911772728,\n  -0.04151604697108269,\n  -0.039792876690626144,\n  -0.04418560117483139,\n  -0.047724660485982895,\n  -0.04390135779976845,\n  -0.042669627815485,\n  -0.04469012841582298,\n  -0.04402008280158043,\n  -0.04712050408124924,\n  -0.04721155762672424,\n  -0.04230722039937973,\n  -0.04461022838950157,\n  -0.04847142472863197,\n  -0.045544032007455826,\n  -0.04404142498970032,\n  -0.050150804221630096,\n  -0.04922415688633919,\n  -0.05046914145350456,\n  -0.05181894451379776,\n  -0.05056541785597801,\n  -0.049793541431427,\n  -0.05004620552062988,\n  -0.05288445204496384,\n  -0.055363427847623825,\n  -0.05676973983645439,\n  -0.055086586624383926,\n  -0.05878915265202522,\n  -0.056677624583244324,\n  -0.05456624552607536,\n  -0.05753297358751297,\n  -0.05738149210810661,\n  -0.05912036448717117,\n  -0.0584263876080513,\n  -0.05769548565149307,\n  -0.061248235404491425,\n  -0.06056543439626694,\n  -0.05677906796336174,\n  -0.06169453263282776,\n  -0.06542026251554489,\n  -0.06304341554641724,\n  -0.06215743348002434,\n  -0.06318928301334381,\n  -0.06414484232664108,\n  -0.06153558939695358,\n  -0.06406714767217636,\n  -0.06631997227668762,\n  -0.06065190210938454,\n  -0.0638326108455658,\n  -0.06855978816747665,\n  -0.06565103679895401,\n  -0.06594006717205048,\n  -0.06798005104064941,\n  -0.06819800287485123,\n  -0.07070647925138474,\n  -0.0688636302947998,\n  -0.06796720623970032,\n  -0.07214673608541489,\n  -0.06735453754663467,\n  -0.06689336150884628,\n  -0.06673049181699753,\n  -0.06664057821035385,\n  -0.06977763772010803,\n  -0.06865425407886505,\n  -0.07169222086668015,\n  -0.07081956416368484,\n  -0.07009257376194,\n  -0.07127097994089127,\n  -0.07142983376979828,\n  -0.07025903463363647,\n  -0.07200880348682404,\n  -0.07336340844631195,\n  -0.06999937444925308,\n  -0.07115687429904938,\n  -0.06982484459877014,\n  -0.07486323267221451,\n  -0.0745893269777298,\n  -0.06885895878076553,\n  -0.07431479543447495,\n  -0.07318353652954102,\n  -0.07337356358766556,\n  -0.07658766955137253,\n  -0.07520008832216263,\n  -0.07730913907289505,\n  -0.07863728702068329,\n  -0.07477553188800812,\n  -0.0778944119811058,\n  -0.07788123935461044,\n  -0.0747329443693161,\n  -0.07819579541683197,\n  -0.07474648207426071,\n  -0.07496875524520874,\n  -0.08018936961889267,\n  -0.08105842024087906,\n  -0.07731121778488159,\n  -0.0767759308218956,\n  -0.07818810641765594,\n  -0.07759695500135422,\n  -0.07899449020624161,\n  -0.07851375639438629,\n  -0.07774323970079422,\n  -0.07795147597789764,\n  -0.07940756529569626,\n  -0.07741690427064896,\n  -0.07726385444402695,\n  -0.07892841845750809,\n  -0.07904801517724991,\n  -0.0800020843744278,\n  -0.07711268216371536,\n  -0.07834825664758682,\n  -0.07885212451219559,\n  -0.077033631503582,\n  -0.0793093591928482,\n  -0.08103495091199875,\n  -0.08103751391172409,\n  -0.079989954829216,\n  -0.08051768690347672,\n  -0.07805933058261871,\n  -0.07911088317632675,\n  -0.07723028212785721,\n  -0.07238370925188065,\n  -0.07889531552791595,\n  -0.07848048955202103,\n  -0.07889188081026077,\n  -0.0808689296245575,\n  -0.07800407707691193,\n  -0.07987599074840546,\n  -0.07981257140636444,\n  -0.08274756371974945,\n  -0.08051107078790665,\n  -0.07750420272350311,\n  -0.0797305554151535,\n  -0.07702989131212234,\n  -0.07746684551239014,\n  -0.07911309599876404,\n  -0.07881229370832443,\n  -0.08104008436203003,\n  -0.07931685447692871,\n  -0.07982827723026276,\n  -0.08279173821210861,\n  -0.08189412951469421,\n  -0.08110731840133667,\n  -0.07778101414442062,\n  -0.07803061604499817,\n  -0.077072374522686,\n  -0.07783068716526031,\n  -0.08006034791469574,\n  -0.0789889544248581,\n  -0.07844851166009903,\n  -0.08055377006530762,\n  -0.08278621733188629,\n  -0.07965653389692307,\n  -0.08079494535923004,\n  -0.07772213965654373,\n  -0.07741241157054901,\n  -0.08132597804069519,\n  -0.07931321859359741,\n  -0.07963370531797409,\n  -0.07924196869134903,\n  -0.08113276213407516,\n  -0.08069863170385361,\n  -0.08123618364334106,\n  -0.08305077254772186,\n  -0.08014698326587677,\n  -0.0821366235613823,\n  -0.08326736837625504,\n  -0.0832265317440033,\n  -0.08138125389814377,\n  -0.08080773055553436,\n  -0.08248887956142426,\n  -0.08274264633655548,\n  -0.08364302664995193,\n  -0.08173301815986633,\n  -0.08441212028265,\n  -0.08382465690374374,\n  -0.08140034973621368,\n  -0.08343060314655304,\n  -0.08080048114061356,\n  -0.07990509271621704,\n  -0.08468078821897507,\n  -0.08499284088611603,\n  -0.08368627727031708,\n  -0.08743955940008163,\n  -0.08229381591081619,\n  -0.08271826058626175,\n  -0.0879507064819336,\n  -0.08439541608095169,\n  -0.0848015546798706,\n  -0.08433312177658081,\n  -0.08523108065128326,\n  -0.08572616428136826,\n  -0.08353248983621597,\n  -0.08362272381782532,\n  -0.08730310201644897,\n  -0.08392981439828873,\n  -0.08284198492765427,\n  -0.08777020126581192,\n  -0.07942961901426315,\n  -0.07971478998661041,\n  -0.08706632256507874,\n  -0.08594062924385071,\n  -0.08419309556484222,\n  -0.08585995435714722,\n  -0.08491311222314835,\n  -0.08333370834589005,\n  -0.0824904516339302,\n  -0.0792730525135994,\n  -0.08342865109443665,\n  -0.08328726887702942,\n  -0.08187979459762573,\n  -0.08451970666646957,\n  -0.08176764845848083,\n  -0.08043356239795685,\n  -0.0825326144695282,\n  -0.08490120619535446,\n  -0.08586295694112778,\n  -0.08421161025762558,\n  -0.0831807479262352,\n  -0.08537857979536057,\n  -0.0824754610657692,\n  -0.08329185843467712,\n  -0.08425945788621902,\n  -0.07992446422576904,\n  -0.08205185830593109,\n  -0.08231018483638763,\n  -0.0808461382985115,\n  -0.08066181093454361,\n  -0.08175937086343765,\n  -0.08156611770391464,\n  -0.08106662333011627,\n  -0.07863624393939972,\n  -0.07889463007450104,\n  -0.08087018877267838,\n  -0.07785387337207794,\n  -0.0763995423913002,\n  -0.07879342138767242,\n  -0.08119016885757446,\n  -0.07698888331651688,\n  -0.07937256991863251,\n  -0.07743290066719055,\n  -0.07502318173646927,\n  -0.07843188941478729,\n  -0.07628156989812851,\n  -0.07780531793832779,\n  -0.07457435131072998,\n  -0.07489616423845291,\n  -0.07195285707712173,\n  -0.07114548236131668,\n  -0.07588484138250351,\n  -0.07168718427419662,\n  -0.07300793379545212,\n  -0.07312541455030441,\n  -0.07268442213535309,\n  -0.06867191940546036,\n  -0.0696197897195816,\n  -0.07108746469020844,\n  -0.07145831733942032,\n  -0.07210114598274231,\n  -0.06894776970148087,\n  -0.07252737134695053,\n  -0.07001198828220367,\n  -0.07153265923261642,\n  -0.06788859516382217,\n  -0.0636264830827713,\n  -0.06531824916601181,\n  -0.06761662662029266,\n  -0.06778336316347122,\n  -0.06470552831888199,\n  -0.06529895216226578,\n  -0.06579495221376419,\n  -0.06435208767652512,\n  -0.0654681846499443,\n  -0.06641267985105515,\n  -0.06035752594470978,\n  -0.06491363793611526,\n  -0.06484920531511307,\n  -0.0640273466706276,\n  -0.0662236139178276,\n  -0.06342140585184097,\n  -0.06418784707784653,\n  -0.06201217696070671,\n  -0.0604887381196022,\n  -0.059983450919389725,\n  -0.06322063505649567,\n  -0.06431177258491516,\n  -0.06160224974155426,\n  -0.06295410543680191,\n  -0.060731541365385056,\n  -0.06111924350261688,\n  -0.06211327388882637,\n  -0.060814328491687775,\n  -0.0634407103061676,\n  -0.06210717558860779,\n  -0.06331215053796768,\n  -0.06223742291331291,\n  -0.06145661696791649,\n  -0.06166013702750206,\n  -0.058122120797634125,\n  -0.05891736224293709,\n  -0.058702751994132996,\n  -0.06043757125735283,\n  -0.06195132061839104,\n  -0.057707589119672775,\n  -0.06041509285569191,\n  -0.06313750147819519,\n  -0.0577840618789196,\n  -0.05930265411734581,\n  -0.059377241879701614,\n  -0.06135951355099678,\n  -0.0651642382144928,\n  -0.059393830597400665,\n  -0.0603150837123394,\n  -0.06101495027542114,\n  -0.059084270149469376,\n  -0.05942492559552193,\n  -0.060461100190877914,\n  -0.06248123571276665,\n  -0.058971647173166275,\n  -0.060455985367298126,\n  -0.06109006330370903,\n  -0.05802295729517937,\n  -0.06002609059214592,\n  -0.06227763742208481,\n  -0.06097733974456787,\n  -0.061354879289865494,\n  -0.05881865695118904,\n  -0.0591985285282135,\n  -0.06411407142877579,\n  -0.05943533033132553,\n  -0.05874626338481903,\n  -0.057490915060043335,\n  -0.05570077896118164,\n  -0.05867185443639755,\n  -0.0595364011824131,\n  -0.05924176797270775,\n  -0.05968031287193298,\n  -0.05863278731703758,\n  -0.05515439808368683,\n  -0.05643797665834427,\n  -0.05662462115287781,\n  -0.056088171899318695,\n  -0.05683194473385811,\n  -0.0567193329334259,\n  -0.061193108558654785,\n  -0.058817118406295776,\n  -0.054278574883937836,\n  -0.055899728089571,\n  -0.05506320297718048,\n  -0.054883163422346115,\n  -0.05436404421925545,\n  -0.053326837718486786,\n  -0.05236108973622322,\n  -0.05426615849137306,\n  -0.051270678639411926,\n  -0.05046791583299637,\n  -0.0550282821059227,\n  -0.053334616124629974,\n  -0.052976805716753006,\n  -0.05199027061462402,\n  -0.05104643851518631,\n  -0.05131854861974716,\n  -0.052151601761579514,\n  -0.05196046829223633,\n  -0.050528209656476974,\n  -0.050548553466796875,\n  -0.04821477085351944,\n  -0.049051254987716675,\n  -0.05459287390112877,\n  -0.051694028079509735,\n  -0.048559267073869705,\n  -0.04819313809275627,\n  -0.04718161001801491,\n  -0.049141477793455124,\n  -0.04558735713362694,\n  -0.04738693684339523,\n  -0.048971183598041534,\n  -0.045295123010873795,\n  -0.04945957660675049,\n  -0.04697008058428764,\n  -0.044868484139442444,\n  -0.045729998499155045,\n  -0.04224357381463051,\n  -0.044441498816013336,\n  -0.044031258672475815,\n  -0.044238340109586716,\n  -0.04462176933884621,\n  -0.04530055448412895,\n  -0.04483950510621071,\n  -0.04153318703174591,\n  -0.043665703386068344,\n  -0.04296954721212387,\n  -0.04005492851138115,\n  -0.04086035490036011,\n  -0.04213801398873329,\n  -0.04113627225160599,\n  -0.0421745628118515,\n  -0.03968951106071472,\n  -0.04077481850981712,\n  -0.04345910623669624,\n  -0.03779594600200653,\n  -0.04000552371144295,\n  -0.04259072244167328,\n  -0.04065724089741707,\n  -0.040590181946754456,\n  -0.03915678709745407,\n  -0.03974676504731178,\n  -0.04307302460074425,\n  -0.04207070544362068,\n  -0.039292287081480026,\n  -0.041861869394779205,\n  -0.03991269692778587,\n  -0.03867635130882263,\n  -0.040651097893714905,\n  -0.038790781050920486,\n  -0.03718656301498413,\n  -0.03665771707892418,\n  -0.039510831236839294,\n  -0.03896588087081909,\n  -0.037628427147865295,\n  -0.03640038147568703,\n  -0.03526483476161957,\n  -0.03817791864275932,\n  -0.039845842868089676,\n  -0.038388870656490326,\n  -0.03855818882584572,\n  -0.0404561311006546,\n  -0.03995541110634804,\n  -0.04134411737322807,\n  -0.039146535098552704,\n  -0.03973104804754257,\n  -0.03855552896857262,\n  -0.036983828991651535,\n  -0.03955667465925217,\n  -0.036868005990982056,\n  -0.04094361141324043,\n  -0.04174822196364403,\n  -0.03940305486321449,\n  -0.03932573273777962,\n  -0.03669553995132446,\n  -0.03763536363840103,\n  -0.03866250440478325,\n  -0.038363017141819,\n  -0.040454670786857605,\n  -0.043830931186676025,\n  -0.04275844991207123,\n  -0.041265521198511124,\n  -0.0405745767056942,\n  -0.04122120887041092,\n  -0.04179368540644646,\n  -0.039800968021154404,\n  -0.045382339507341385,\n  -0.04276266321539879,\n  -0.03960438072681427,\n  -0.044738274067640305,\n  -0.04084031656384468,\n  -0.041419923305511475,\n  -0.04261656478047371,\n  -0.04398616775870323,\n  -0.047024231404066086,\n  -0.04633825272321701,\n  -0.045571524649858475,\n  -0.04663892462849617,\n  -0.04484965279698372,\n  -0.04358058050274849,\n  -0.0461360327899456,\n  -0.043348655104637146,\n  -0.047608524560928345,\n  -0.04831906408071518,\n  -0.04496612027287483,\n  -0.04734017699956894,\n  -0.046685006469488144,\n  -0.045702021569013596,\n  -0.048875633627176285,\n  -0.05109647661447525,\n  -0.049034345895051956,\n  -0.04739445820450783,\n  -0.04661022871732712,\n  -0.048337120562791824,\n  -0.04669103026390076,\n  -0.04918816685676575,\n  -0.05020806938409805,\n  -0.046697523444890976,\n  -0.04793420061469078,\n  -0.050526440143585205,\n  -0.048011261969804764,\n  -0.045312512665987015,\n  -0.049339067190885544,\n  -0.04567256569862366,\n  -0.04727577418088913,\n  -0.049042437225580215,\n  -0.05077086016535759,\n  -0.051384054124355316,\n  -0.048990923911333084,\n  -0.053943898528814316,\n  -0.048462774604558945,\n  -0.046571534126996994,\n  -0.04906853288412094,\n  -0.049630049616098404,\n  -0.04972485452890396,\n  -0.05118422582745552,\n  -0.05254664272069931,\n  -0.04943358153104782,\n  -0.05122276023030281,\n  -0.05133316293358803,\n  -0.05084416642785072,\n  -0.05242956429719925,\n  -0.05272166430950165,\n  -0.05012883245944977,\n  -0.050456006079912186,\n  -0.050908252596855164,\n  -0.048694416880607605,\n  -0.05433584749698639,\n  -0.05334227532148361,\n  -0.05263705924153328,\n  -0.05227552726864815,\n  -0.052157528698444366,\n  -0.0564647875726223,\n  -0.0504138357937336,\n  -0.050378937274217606,\n  -0.05251713842153549,\n  -0.05376763641834259,\n  -0.0556882843375206,\n  -0.054260723292827606,\n  -0.05393040552735329,\n  -0.05270010232925415,\n  -0.05279197171330452,\n  -0.05573036149144173,\n  -0.05299264192581177,\n  -0.05177714303135872,\n  -0.0520939826965332,\n  -0.05182570964097977,\n  -0.054933954030275345,\n  -0.05148715525865555,\n  -0.052894651889801025,\n  -0.05266096442937851,\n  -0.0556432344019413,\n  -0.05391470342874527,\n  -0.05237176641821861,\n  -0.055887963622808456,\n  -0.05322230979800224,\n  -0.058995407074689865,\n  -0.05623602122068405,\n  -0.05571072921156883,\n  -0.059005267918109894,\n  -0.05666426196694374,\n  -0.05646692216396332,\n  -0.05811107158660889,\n  -0.05782785266637802,\n  -0.05701049789786339,\n  -0.059402015060186386,\n  -0.05841577425599098,\n  -0.05826707184314728,\n  -0.057885851711034775,\n  -0.057539939880371094,\n  -0.059123966842889786,\n  -0.058149248361587524,\n  -0.05898473411798477,\n  -0.06320104002952576,\n  -0.06586592644453049,\n  -0.061445996165275574,\n  -0.06250432878732681,\n  -0.06351377069950104,\n  -0.059984419494867325,\n  -0.06327557563781738,\n  -0.06386027485132217,\n  -0.06481128185987473,\n  -0.06344936043024063,\n  -0.06194884702563286,\n  -0.06376469880342484,\n  -0.06572110950946808,\n  -0.06230849772691727,\n  -0.06304003298282623,\n  -0.06586243212223053,\n  -0.06432375311851501,\n  -0.06521400809288025,\n  -0.06745269149541855,\n  -0.06856068223714828,\n  -0.06432878226041794,\n  -0.06657755374908447,\n  -0.06681294739246368,\n  -0.06958901137113571,\n  -0.0695718303322792,\n  -0.06825441867113113,\n  -0.07074861228466034,\n  -0.06645489484071732,\n  -0.06596089899539948,\n  -0.06628323346376419,\n  -0.06702860444784164,\n  -0.06849109381437302,\n  -0.06959285587072372,\n  -0.06798727810382843,\n  -0.06894484162330627,\n  -0.06956494599580765,\n  -0.06590793281793594,\n  -0.06707990914583206,\n  -0.0712999552488327,\n  -0.0721835047006607,\n  -0.07050199061632156,\n  -0.0721903070807457,\n  -0.07162921875715256,\n  -0.07015980780124664,\n  -0.07078881561756134,\n  -0.07087825983762741,\n  -0.07279231399297714,\n  -0.07117202877998352,\n  -0.07169058173894882,\n  -0.07050040364265442,\n  -0.07093007117509842,\n  -0.07366511970758438,\n  -0.07077237218618393,\n  -0.07172010093927383,\n  -0.06986086070537567,\n  -0.07269071787595749,\n  -0.07460734248161316,\n  -0.07535767555236816,\n  -0.0756111666560173,\n  -0.07295820116996765,\n  -0.07600568979978561,\n  -0.07547981292009354,\n  -0.07633725553750992,\n  -0.07730607688426971,\n  -0.0780324637889862,\n  -0.07704830914735794,\n  -0.07373525202274323,\n  -0.07478152960538864,\n  -0.07824863493442535,\n  -0.0771404579281807,\n  -0.07515187561511993,\n  -0.077002614736557,\n  -0.07895367592573166,\n  -0.07864031195640564,\n  -0.07754600048065186,\n  -0.08040116727352142,\n  -0.079766646027565,\n  -0.07778047770261765,\n  -0.07980597019195557,\n  -0.08091087639331818,\n  -0.07778031378984451,\n  -0.07819347828626633,\n  -0.08088485151529312,\n  -0.07959090173244476,\n  -0.08062149584293365,\n  -0.07969281077384949,\n  -0.08068089932203293,\n  -0.08268801867961884,\n  -0.07968100905418396,\n  -0.08186465501785278,\n  -0.0871683806180954,\n  -0.08435668796300888,\n  -0.08083360642194748,\n  -0.08308843523263931,\n  -0.08296345919370651,\n  -0.0807228684425354,\n  -0.08100510388612747,\n  -0.08283986151218414,\n  -0.08367551863193512,\n  -0.08441830426454544,\n  -0.08178815990686417,\n  -0.08329836279153824,\n  -0.08599238097667694,\n  -0.08496062457561493,\n  -0.08560732752084732,\n  -0.08662677556276321,\n  -0.08865223824977875,\n  -0.08556918054819107,\n  -0.08724895119667053,\n  -0.08935092389583588,\n  -0.08890864998102188,\n  -0.08914642035961151,\n  -0.08792652934789658,\n  -0.088559091091156,\n  -0.08798126876354218,\n  -0.08720161020755768,\n  -0.08800680190324783,\n  -0.08935476094484329,\n  -0.08791723847389221,\n  -0.08997883647680283,\n  -0.09070775657892227,\n  -0.08954306691884995,\n  -0.08851918578147888,\n  -0.09128763526678085,\n  -0.0935346782207489,\n  -0.08849217742681503,\n  -0.09194004535675049,\n  -0.0927196592092514,\n  -0.09011226147413254,\n  -0.09410814940929413,\n  -0.0916483998298645,\n  -0.09163147211074829,\n  -0.09308148175477982,\n  -0.09126436710357666,\n  -0.09491804242134094,\n  -0.09701031446456909,\n  -0.0959646925330162,\n  -0.09675639867782593,\n  -0.09710176289081573,\n  -0.09629372507333755,\n  -0.09864846616983414,\n  -0.09618016332387924,\n  -0.09699937701225281,\n  -0.10046179592609406,\n  -0.10011933743953705,\n  -0.09911485016345978,\n  -0.09495488554239273,\n  -0.10038629174232483,\n  -0.10114385187625885,\n  -0.09659510850906372,\n  -0.09883343428373337,\n  -0.10247854143381119,\n  -0.10362307727336884,\n  -0.10062649846076965,\n  -0.10364478081464767,\n  -0.10155104845762253,\n  -0.09749993681907654,\n  -0.10196875780820847,\n  -0.10128920525312424,\n  -0.1028820052742958,\n  -0.10587092489004135,\n  -0.10315405577421188,\n  -0.10508905351161957,\n  -0.10577071458101273,\n  -0.10419078171253204,\n  -0.10655268281698227,\n  -0.1091822013258934,\n  -0.10670701414346695,\n  -0.10712394118309021,\n  -0.10896102339029312,\n  -0.10767152160406113,\n  -0.11105307191610336,\n  -0.1090097576379776,\n  -0.10716640949249268,\n  -0.10763150453567505,\n  -0.10888227075338364,\n  -0.11176301538944244,\n  -0.11332084238529205,\n  -0.11203699558973312,\n  -0.11130564659833908,\n  -0.11357295513153076,\n  -0.11060778796672821,\n  -0.11399554461240768,\n  -0.11346250772476196,\n  -0.1130150705575943,\n  -0.11602823436260223,\n  -0.1121060848236084,\n  -0.11367560923099518,\n  -0.11278972029685974,\n  -0.11496912688016891,\n  -0.11781271547079086,\n  -0.1168590560555458,\n  -0.11733373999595642,\n  -0.11766257137060165,\n  -0.11965127289295197,\n  -0.12135063111782074,\n  -0.11966410279273987,\n  -0.11804382503032684,\n  -0.11939934641122818,\n  -0.11588486284017563,\n  -0.11794370412826538,\n  -0.12040579319000244,\n  -0.12020272761583328,\n  -0.11993180215358734,\n  -0.12122828513383865,\n  -0.12271536141633987,\n  -0.12115879356861115,\n  -0.12197341024875641,\n  -0.12142272293567657,\n  -0.1239556148648262,\n  -0.12395133078098297,\n  -0.12676604092121124,\n  -0.12380558252334595,\n  -0.1216006726026535,\n  -0.12597712874412537,\n  -0.12366270273923874,\n  -0.12549029290676117,\n  -0.12655429542064667,\n  -0.12563441693782806,\n  -0.1268165111541748,\n  -0.12747369706630707,\n  -0.1277841031551361,\n  -0.12673738598823547,\n  -0.1265036016702652,\n  -0.1296227127313614,\n  -0.1256474107503891,\n  -0.12451067566871643,\n  -0.12936857342720032,\n  -0.13098609447479248,\n  -0.12931190431118011,\n  -0.12718290090560913,\n  -0.12452501058578491,\n  -0.12812791764736176,\n  -0.13383172452449799,\n  -0.12706150114536285,\n  -0.12734535336494446,\n  -0.13058175146579742,\n  -0.1307530254125595,\n  -0.12748722732067108,\n  -0.1307217925786972,\n  -0.1309807151556015,\n  -0.12802651524543762,\n  -0.13370029628276825,\n  -0.13206635415554047,\n  -0.13083729147911072,\n  -0.1288071870803833,\n  -0.13333027064800262,\n  -0.13352294266223907,\n  -0.13105209171772003,\n  -0.1310829371213913,\n  -0.13299015164375305,\n  -0.13479793071746826,\n  -0.12974518537521362,\n  -0.13108006119728088,\n  -0.1330575942993164,\n  -0.13572590053081512,\n  -0.1355431228876114,\n  -0.13402387499809265,\n  -0.13406270742416382,\n  -0.13663047552108765,\n  -0.13761278986930847,\n  -0.13582280278205872,\n  -0.1381060779094696,\n  -0.1405322253704071,\n  -0.14116564393043518,\n  -0.13849948346614838,\n  -0.13700631260871887,\n  -0.14012393355369568,\n  -0.13890698552131653,\n  -0.14058658480644226,\n  -0.1410498172044754,\n  -0.14061668515205383,\n  -0.14653630554676056,\n  -0.13752013444900513,\n  -0.13960854709148407,\n  -0.1424749195575714,\n  -0.13818596303462982,\n  -0.14175528287887573,\n  -0.14036139845848083,\n  -0.14233547449111938,\n  -0.1400918811559677,\n  -0.14170172810554504,\n  -0.14126041531562805,\n  -0.1393938958644867,\n  -0.1430346518754959,\n  -0.14193172752857208,\n  -0.14326760172843933,\n  -0.1434599757194519,\n  -0.14161020517349243,\n  -0.145217165350914,\n  -0.1449873000383377,\n  -0.14606085419654846,\n  -0.14570283889770508,\n  -0.14119194447994232,\n  -0.14240750670433044,\n  -0.14307811856269836,\n  -0.14794522523880005,\n  -0.14459577202796936,\n  -0.14461760222911835,\n  -0.14907214045524597,\n  -0.14529232680797577,\n  -0.14680631458759308,\n  -0.14740397036075592,\n  -0.1500559002161026,\n  -0.15277670323848724,\n  -0.15411676466464996,\n  -0.15547916293144226,\n  -0.15461131930351257,\n  -0.15342403948307037,\n  -0.1508660614490509,\n  -0.15351763367652893,\n  -0.15512430667877197,\n  -0.15687361359596252,\n  -0.15558497607707977,\n  -0.15257352590560913,\n  -0.1567288041114807,\n  -0.15426182746887207,\n  -0.15551331639289856,\n  -0.15566283464431763,\n  -0.1534697711467743,\n  -0.15808573365211487,\n  -0.1560550332069397,\n  -0.1551084816455841,\n  -0.16087059676647186,\n  -0.15982912480831146,\n  -0.15411344170570374,\n  -0.15129810571670532,\n  -0.15257301926612854,\n  -0.15284410119056702,\n  -0.15284855663776398,\n  -0.15627890825271606,\n  -0.1552513986825943,\n  -0.16299636662006378,\n  -0.16238220036029816,\n  -0.15717653930187225,\n  -0.16262872517108917,\n  -0.15985238552093506,\n  -0.16054309904575348,\n  -0.15993821620941162,\n  -0.160519078373909,\n  -0.16162937879562378,\n  -0.15952615439891815,\n  -0.16157427430152893,\n  -0.15966446697711945,\n  -0.1605106145143509,\n  -0.16097761690616608,\n  -0.15987101197242737,\n  -0.16173967719078064,\n  -0.16340754926204681,\n  ...],\n 'labels': 2}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#from datasets import ClassLabel\n",
    "\n",
    "### label 2 id\n",
    "\n",
    "#train_df = train_df.cast_column(output_column, ClassLabel(num_classes=num_class,names=class_list))\n",
    "\n",
    "#test_df = test_df.cast_column(output_column, ClassLabel(num_classes=num_class,names=class_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'path': '../tess\\\\OAF_Fear\\\\OAF_choice_fear.wav',\n 'label': 'fear',\n 'input_values': [0.005347009282559156,\n  -7.528260175604373e-05,\n  0.00019006124057341367,\n  0.0011511975899338722,\n  -7.297880802070722e-05,\n  -0.002332984237000346,\n  -0.0027273274026811123,\n  -0.0007437366875819862,\n  -0.0034132860600948334,\n  -0.005155489780008793,\n  -0.0022231556940823793,\n  -0.003020818345248699,\n  -0.007137116510421038,\n  -0.007239627186208963,\n  -0.007200169377028942,\n  -0.005426994990557432,\n  -0.007078962400555611,\n  -0.012079843319952488,\n  -0.009139073081314564,\n  -0.01059677917510271,\n  -0.01161156129091978,\n  -0.008673600852489471,\n  -0.009095572866499424,\n  -0.00934215635061264,\n  -0.01163135189563036,\n  -0.01184934563934803,\n  -0.013085247948765755,\n  -0.013547476381063461,\n  -0.012033736333251,\n  -0.011728492565453053,\n  -0.012789004482328892,\n  -0.0141847999766469,\n  -0.012567385099828243,\n  -0.014910061843693256,\n  -0.01439056545495987,\n  -0.016309164464473724,\n  -0.018531007692217827,\n  -0.018635498359799385,\n  -0.020213710144162178,\n  -0.017976028844714165,\n  -0.022646835073828697,\n  -0.021242275834083557,\n  -0.01951524056494236,\n  -0.02127530798316002,\n  -0.02151043526828289,\n  -0.023723144084215164,\n  -0.023958932608366013,\n  -0.023451928049325943,\n  -0.022668614983558655,\n  -0.021707816049456596,\n  -0.024089746177196503,\n  -0.026851145550608635,\n  -0.023667337372899055,\n  -0.02607182040810585,\n  -0.025598889216780663,\n  -0.027882706373929977,\n  -0.029352456331253052,\n  -0.027608059346675873,\n  -0.030620915815234184,\n  -0.02830434776842594,\n  -0.027278302237391472,\n  -0.02826009877026081,\n  -0.0301347766071558,\n  -0.028584128245711327,\n  -0.029199955984950066,\n  -0.03141048178076744,\n  -0.03279034420847893,\n  -0.03573068603873253,\n  -0.031382862478494644,\n  -0.02975788153707981,\n  -0.033312197774648666,\n  -0.03236908093094826,\n  -0.0329926535487175,\n  -0.03237873688340187,\n  -0.03313979133963585,\n  -0.03642917051911354,\n  -0.034545231610536575,\n  -0.03134406358003616,\n  -0.03364281728863716,\n  -0.03649059310555458,\n  -0.0340711772441864,\n  -0.03650952875614166,\n  -0.03597807139158249,\n  -0.03697953000664711,\n  -0.03975094109773636,\n  -0.03903840854763985,\n  -0.037748757749795914,\n  -0.03865578770637512,\n  -0.041217319667339325,\n  -0.037296924740076065,\n  -0.042197320610284805,\n  -0.041074346750974655,\n  -0.03978899493813515,\n  -0.04285493120551109,\n  -0.04031037911772728,\n  -0.04151604697108269,\n  -0.039792876690626144,\n  -0.04418560117483139,\n  -0.047724660485982895,\n  -0.04390135779976845,\n  -0.042669627815485,\n  -0.04469012841582298,\n  -0.04402008280158043,\n  -0.04712050408124924,\n  -0.04721155762672424,\n  -0.04230722039937973,\n  -0.04461022838950157,\n  -0.04847142472863197,\n  -0.045544032007455826,\n  -0.04404142498970032,\n  -0.050150804221630096,\n  -0.04922415688633919,\n  -0.05046914145350456,\n  -0.05181894451379776,\n  -0.05056541785597801,\n  -0.049793541431427,\n  -0.05004620552062988,\n  -0.05288445204496384,\n  -0.055363427847623825,\n  -0.05676973983645439,\n  -0.055086586624383926,\n  -0.05878915265202522,\n  -0.056677624583244324,\n  -0.05456624552607536,\n  -0.05753297358751297,\n  -0.05738149210810661,\n  -0.05912036448717117,\n  -0.0584263876080513,\n  -0.05769548565149307,\n  -0.061248235404491425,\n  -0.06056543439626694,\n  -0.05677906796336174,\n  -0.06169453263282776,\n  -0.06542026251554489,\n  -0.06304341554641724,\n  -0.06215743348002434,\n  -0.06318928301334381,\n  -0.06414484232664108,\n  -0.06153558939695358,\n  -0.06406714767217636,\n  -0.06631997227668762,\n  -0.06065190210938454,\n  -0.0638326108455658,\n  -0.06855978816747665,\n  -0.06565103679895401,\n  -0.06594006717205048,\n  -0.06798005104064941,\n  -0.06819800287485123,\n  -0.07070647925138474,\n  -0.0688636302947998,\n  -0.06796720623970032,\n  -0.07214673608541489,\n  -0.06735453754663467,\n  -0.06689336150884628,\n  -0.06673049181699753,\n  -0.06664057821035385,\n  -0.06977763772010803,\n  -0.06865425407886505,\n  -0.07169222086668015,\n  -0.07081956416368484,\n  -0.07009257376194,\n  -0.07127097994089127,\n  -0.07142983376979828,\n  -0.07025903463363647,\n  -0.07200880348682404,\n  -0.07336340844631195,\n  -0.06999937444925308,\n  -0.07115687429904938,\n  -0.06982484459877014,\n  -0.07486323267221451,\n  -0.0745893269777298,\n  -0.06885895878076553,\n  -0.07431479543447495,\n  -0.07318353652954102,\n  -0.07337356358766556,\n  -0.07658766955137253,\n  -0.07520008832216263,\n  -0.07730913907289505,\n  -0.07863728702068329,\n  -0.07477553188800812,\n  -0.0778944119811058,\n  -0.07788123935461044,\n  -0.0747329443693161,\n  -0.07819579541683197,\n  -0.07474648207426071,\n  -0.07496875524520874,\n  -0.08018936961889267,\n  -0.08105842024087906,\n  -0.07731121778488159,\n  -0.0767759308218956,\n  -0.07818810641765594,\n  -0.07759695500135422,\n  -0.07899449020624161,\n  -0.07851375639438629,\n  -0.07774323970079422,\n  -0.07795147597789764,\n  -0.07940756529569626,\n  -0.07741690427064896,\n  -0.07726385444402695,\n  -0.07892841845750809,\n  -0.07904801517724991,\n  -0.0800020843744278,\n  -0.07711268216371536,\n  -0.07834825664758682,\n  -0.07885212451219559,\n  -0.077033631503582,\n  -0.0793093591928482,\n  -0.08103495091199875,\n  -0.08103751391172409,\n  -0.079989954829216,\n  -0.08051768690347672,\n  -0.07805933058261871,\n  -0.07911088317632675,\n  -0.07723028212785721,\n  -0.07238370925188065,\n  -0.07889531552791595,\n  -0.07848048955202103,\n  -0.07889188081026077,\n  -0.0808689296245575,\n  -0.07800407707691193,\n  -0.07987599074840546,\n  -0.07981257140636444,\n  -0.08274756371974945,\n  -0.08051107078790665,\n  -0.07750420272350311,\n  -0.0797305554151535,\n  -0.07702989131212234,\n  -0.07746684551239014,\n  -0.07911309599876404,\n  -0.07881229370832443,\n  -0.08104008436203003,\n  -0.07931685447692871,\n  -0.07982827723026276,\n  -0.08279173821210861,\n  -0.08189412951469421,\n  -0.08110731840133667,\n  -0.07778101414442062,\n  -0.07803061604499817,\n  -0.077072374522686,\n  -0.07783068716526031,\n  -0.08006034791469574,\n  -0.0789889544248581,\n  -0.07844851166009903,\n  -0.08055377006530762,\n  -0.08278621733188629,\n  -0.07965653389692307,\n  -0.08079494535923004,\n  -0.07772213965654373,\n  -0.07741241157054901,\n  -0.08132597804069519,\n  -0.07931321859359741,\n  -0.07963370531797409,\n  -0.07924196869134903,\n  -0.08113276213407516,\n  -0.08069863170385361,\n  -0.08123618364334106,\n  -0.08305077254772186,\n  -0.08014698326587677,\n  -0.0821366235613823,\n  -0.08326736837625504,\n  -0.0832265317440033,\n  -0.08138125389814377,\n  -0.08080773055553436,\n  -0.08248887956142426,\n  -0.08274264633655548,\n  -0.08364302664995193,\n  -0.08173301815986633,\n  -0.08441212028265,\n  -0.08382465690374374,\n  -0.08140034973621368,\n  -0.08343060314655304,\n  -0.08080048114061356,\n  -0.07990509271621704,\n  -0.08468078821897507,\n  -0.08499284088611603,\n  -0.08368627727031708,\n  -0.08743955940008163,\n  -0.08229381591081619,\n  -0.08271826058626175,\n  -0.0879507064819336,\n  -0.08439541608095169,\n  -0.0848015546798706,\n  -0.08433312177658081,\n  -0.08523108065128326,\n  -0.08572616428136826,\n  -0.08353248983621597,\n  -0.08362272381782532,\n  -0.08730310201644897,\n  -0.08392981439828873,\n  -0.08284198492765427,\n  -0.08777020126581192,\n  -0.07942961901426315,\n  -0.07971478998661041,\n  -0.08706632256507874,\n  -0.08594062924385071,\n  -0.08419309556484222,\n  -0.08585995435714722,\n  -0.08491311222314835,\n  -0.08333370834589005,\n  -0.0824904516339302,\n  -0.0792730525135994,\n  -0.08342865109443665,\n  -0.08328726887702942,\n  -0.08187979459762573,\n  -0.08451970666646957,\n  -0.08176764845848083,\n  -0.08043356239795685,\n  -0.0825326144695282,\n  -0.08490120619535446,\n  -0.08586295694112778,\n  -0.08421161025762558,\n  -0.0831807479262352,\n  -0.08537857979536057,\n  -0.0824754610657692,\n  -0.08329185843467712,\n  -0.08425945788621902,\n  -0.07992446422576904,\n  -0.08205185830593109,\n  -0.08231018483638763,\n  -0.0808461382985115,\n  -0.08066181093454361,\n  -0.08175937086343765,\n  -0.08156611770391464,\n  -0.08106662333011627,\n  -0.07863624393939972,\n  -0.07889463007450104,\n  -0.08087018877267838,\n  -0.07785387337207794,\n  -0.0763995423913002,\n  -0.07879342138767242,\n  -0.08119016885757446,\n  -0.07698888331651688,\n  -0.07937256991863251,\n  -0.07743290066719055,\n  -0.07502318173646927,\n  -0.07843188941478729,\n  -0.07628156989812851,\n  -0.07780531793832779,\n  -0.07457435131072998,\n  -0.07489616423845291,\n  -0.07195285707712173,\n  -0.07114548236131668,\n  -0.07588484138250351,\n  -0.07168718427419662,\n  -0.07300793379545212,\n  -0.07312541455030441,\n  -0.07268442213535309,\n  -0.06867191940546036,\n  -0.0696197897195816,\n  -0.07108746469020844,\n  -0.07145831733942032,\n  -0.07210114598274231,\n  -0.06894776970148087,\n  -0.07252737134695053,\n  -0.07001198828220367,\n  -0.07153265923261642,\n  -0.06788859516382217,\n  -0.0636264830827713,\n  -0.06531824916601181,\n  -0.06761662662029266,\n  -0.06778336316347122,\n  -0.06470552831888199,\n  -0.06529895216226578,\n  -0.06579495221376419,\n  -0.06435208767652512,\n  -0.0654681846499443,\n  -0.06641267985105515,\n  -0.06035752594470978,\n  -0.06491363793611526,\n  -0.06484920531511307,\n  -0.0640273466706276,\n  -0.0662236139178276,\n  -0.06342140585184097,\n  -0.06418784707784653,\n  -0.06201217696070671,\n  -0.0604887381196022,\n  -0.059983450919389725,\n  -0.06322063505649567,\n  -0.06431177258491516,\n  -0.06160224974155426,\n  -0.06295410543680191,\n  -0.060731541365385056,\n  -0.06111924350261688,\n  -0.06211327388882637,\n  -0.060814328491687775,\n  -0.0634407103061676,\n  -0.06210717558860779,\n  -0.06331215053796768,\n  -0.06223742291331291,\n  -0.06145661696791649,\n  -0.06166013702750206,\n  -0.058122120797634125,\n  -0.05891736224293709,\n  -0.058702751994132996,\n  -0.06043757125735283,\n  -0.06195132061839104,\n  -0.057707589119672775,\n  -0.06041509285569191,\n  -0.06313750147819519,\n  -0.0577840618789196,\n  -0.05930265411734581,\n  -0.059377241879701614,\n  -0.06135951355099678,\n  -0.0651642382144928,\n  -0.059393830597400665,\n  -0.0603150837123394,\n  -0.06101495027542114,\n  -0.059084270149469376,\n  -0.05942492559552193,\n  -0.060461100190877914,\n  -0.06248123571276665,\n  -0.058971647173166275,\n  -0.060455985367298126,\n  -0.06109006330370903,\n  -0.05802295729517937,\n  -0.06002609059214592,\n  -0.06227763742208481,\n  -0.06097733974456787,\n  -0.061354879289865494,\n  -0.05881865695118904,\n  -0.0591985285282135,\n  -0.06411407142877579,\n  -0.05943533033132553,\n  -0.05874626338481903,\n  -0.057490915060043335,\n  -0.05570077896118164,\n  -0.05867185443639755,\n  -0.0595364011824131,\n  -0.05924176797270775,\n  -0.05968031287193298,\n  -0.05863278731703758,\n  -0.05515439808368683,\n  -0.05643797665834427,\n  -0.05662462115287781,\n  -0.056088171899318695,\n  -0.05683194473385811,\n  -0.0567193329334259,\n  -0.061193108558654785,\n  -0.058817118406295776,\n  -0.054278574883937836,\n  -0.055899728089571,\n  -0.05506320297718048,\n  -0.054883163422346115,\n  -0.05436404421925545,\n  -0.053326837718486786,\n  -0.05236108973622322,\n  -0.05426615849137306,\n  -0.051270678639411926,\n  -0.05046791583299637,\n  -0.0550282821059227,\n  -0.053334616124629974,\n  -0.052976805716753006,\n  -0.05199027061462402,\n  -0.05104643851518631,\n  -0.05131854861974716,\n  -0.052151601761579514,\n  -0.05196046829223633,\n  -0.050528209656476974,\n  -0.050548553466796875,\n  -0.04821477085351944,\n  -0.049051254987716675,\n  -0.05459287390112877,\n  -0.051694028079509735,\n  -0.048559267073869705,\n  -0.04819313809275627,\n  -0.04718161001801491,\n  -0.049141477793455124,\n  -0.04558735713362694,\n  -0.04738693684339523,\n  -0.048971183598041534,\n  -0.045295123010873795,\n  -0.04945957660675049,\n  -0.04697008058428764,\n  -0.044868484139442444,\n  -0.045729998499155045,\n  -0.04224357381463051,\n  -0.044441498816013336,\n  -0.044031258672475815,\n  -0.044238340109586716,\n  -0.04462176933884621,\n  -0.04530055448412895,\n  -0.04483950510621071,\n  -0.04153318703174591,\n  -0.043665703386068344,\n  -0.04296954721212387,\n  -0.04005492851138115,\n  -0.04086035490036011,\n  -0.04213801398873329,\n  -0.04113627225160599,\n  -0.0421745628118515,\n  -0.03968951106071472,\n  -0.04077481850981712,\n  -0.04345910623669624,\n  -0.03779594600200653,\n  -0.04000552371144295,\n  -0.04259072244167328,\n  -0.04065724089741707,\n  -0.040590181946754456,\n  -0.03915678709745407,\n  -0.03974676504731178,\n  -0.04307302460074425,\n  -0.04207070544362068,\n  -0.039292287081480026,\n  -0.041861869394779205,\n  -0.03991269692778587,\n  -0.03867635130882263,\n  -0.040651097893714905,\n  -0.038790781050920486,\n  -0.03718656301498413,\n  -0.03665771707892418,\n  -0.039510831236839294,\n  -0.03896588087081909,\n  -0.037628427147865295,\n  -0.03640038147568703,\n  -0.03526483476161957,\n  -0.03817791864275932,\n  -0.039845842868089676,\n  -0.038388870656490326,\n  -0.03855818882584572,\n  -0.0404561311006546,\n  -0.03995541110634804,\n  -0.04134411737322807,\n  -0.039146535098552704,\n  -0.03973104804754257,\n  -0.03855552896857262,\n  -0.036983828991651535,\n  -0.03955667465925217,\n  -0.036868005990982056,\n  -0.04094361141324043,\n  -0.04174822196364403,\n  -0.03940305486321449,\n  -0.03932573273777962,\n  -0.03669553995132446,\n  -0.03763536363840103,\n  -0.03866250440478325,\n  -0.038363017141819,\n  -0.040454670786857605,\n  -0.043830931186676025,\n  -0.04275844991207123,\n  -0.041265521198511124,\n  -0.0405745767056942,\n  -0.04122120887041092,\n  -0.04179368540644646,\n  -0.039800968021154404,\n  -0.045382339507341385,\n  -0.04276266321539879,\n  -0.03960438072681427,\n  -0.044738274067640305,\n  -0.04084031656384468,\n  -0.041419923305511475,\n  -0.04261656478047371,\n  -0.04398616775870323,\n  -0.047024231404066086,\n  -0.04633825272321701,\n  -0.045571524649858475,\n  -0.04663892462849617,\n  -0.04484965279698372,\n  -0.04358058050274849,\n  -0.0461360327899456,\n  -0.043348655104637146,\n  -0.047608524560928345,\n  -0.04831906408071518,\n  -0.04496612027287483,\n  -0.04734017699956894,\n  -0.046685006469488144,\n  -0.045702021569013596,\n  -0.048875633627176285,\n  -0.05109647661447525,\n  -0.049034345895051956,\n  -0.04739445820450783,\n  -0.04661022871732712,\n  -0.048337120562791824,\n  -0.04669103026390076,\n  -0.04918816685676575,\n  -0.05020806938409805,\n  -0.046697523444890976,\n  -0.04793420061469078,\n  -0.050526440143585205,\n  -0.048011261969804764,\n  -0.045312512665987015,\n  -0.049339067190885544,\n  -0.04567256569862366,\n  -0.04727577418088913,\n  -0.049042437225580215,\n  -0.05077086016535759,\n  -0.051384054124355316,\n  -0.048990923911333084,\n  -0.053943898528814316,\n  -0.048462774604558945,\n  -0.046571534126996994,\n  -0.04906853288412094,\n  -0.049630049616098404,\n  -0.04972485452890396,\n  -0.05118422582745552,\n  -0.05254664272069931,\n  -0.04943358153104782,\n  -0.05122276023030281,\n  -0.05133316293358803,\n  -0.05084416642785072,\n  -0.05242956429719925,\n  -0.05272166430950165,\n  -0.05012883245944977,\n  -0.050456006079912186,\n  -0.050908252596855164,\n  -0.048694416880607605,\n  -0.05433584749698639,\n  -0.05334227532148361,\n  -0.05263705924153328,\n  -0.05227552726864815,\n  -0.052157528698444366,\n  -0.0564647875726223,\n  -0.0504138357937336,\n  -0.050378937274217606,\n  -0.05251713842153549,\n  -0.05376763641834259,\n  -0.0556882843375206,\n  -0.054260723292827606,\n  -0.05393040552735329,\n  -0.05270010232925415,\n  -0.05279197171330452,\n  -0.05573036149144173,\n  -0.05299264192581177,\n  -0.05177714303135872,\n  -0.0520939826965332,\n  -0.05182570964097977,\n  -0.054933954030275345,\n  -0.05148715525865555,\n  -0.052894651889801025,\n  -0.05266096442937851,\n  -0.0556432344019413,\n  -0.05391470342874527,\n  -0.05237176641821861,\n  -0.055887963622808456,\n  -0.05322230979800224,\n  -0.058995407074689865,\n  -0.05623602122068405,\n  -0.05571072921156883,\n  -0.059005267918109894,\n  -0.05666426196694374,\n  -0.05646692216396332,\n  -0.05811107158660889,\n  -0.05782785266637802,\n  -0.05701049789786339,\n  -0.059402015060186386,\n  -0.05841577425599098,\n  -0.05826707184314728,\n  -0.057885851711034775,\n  -0.057539939880371094,\n  -0.059123966842889786,\n  -0.058149248361587524,\n  -0.05898473411798477,\n  -0.06320104002952576,\n  -0.06586592644453049,\n  -0.061445996165275574,\n  -0.06250432878732681,\n  -0.06351377069950104,\n  -0.059984419494867325,\n  -0.06327557563781738,\n  -0.06386027485132217,\n  -0.06481128185987473,\n  -0.06344936043024063,\n  -0.06194884702563286,\n  -0.06376469880342484,\n  -0.06572110950946808,\n  -0.06230849772691727,\n  -0.06304003298282623,\n  -0.06586243212223053,\n  -0.06432375311851501,\n  -0.06521400809288025,\n  -0.06745269149541855,\n  -0.06856068223714828,\n  -0.06432878226041794,\n  -0.06657755374908447,\n  -0.06681294739246368,\n  -0.06958901137113571,\n  -0.0695718303322792,\n  -0.06825441867113113,\n  -0.07074861228466034,\n  -0.06645489484071732,\n  -0.06596089899539948,\n  -0.06628323346376419,\n  -0.06702860444784164,\n  -0.06849109381437302,\n  -0.06959285587072372,\n  -0.06798727810382843,\n  -0.06894484162330627,\n  -0.06956494599580765,\n  -0.06590793281793594,\n  -0.06707990914583206,\n  -0.0712999552488327,\n  -0.0721835047006607,\n  -0.07050199061632156,\n  -0.0721903070807457,\n  -0.07162921875715256,\n  -0.07015980780124664,\n  -0.07078881561756134,\n  -0.07087825983762741,\n  -0.07279231399297714,\n  -0.07117202877998352,\n  -0.07169058173894882,\n  -0.07050040364265442,\n  -0.07093007117509842,\n  -0.07366511970758438,\n  -0.07077237218618393,\n  -0.07172010093927383,\n  -0.06986086070537567,\n  -0.07269071787595749,\n  -0.07460734248161316,\n  -0.07535767555236816,\n  -0.0756111666560173,\n  -0.07295820116996765,\n  -0.07600568979978561,\n  -0.07547981292009354,\n  -0.07633725553750992,\n  -0.07730607688426971,\n  -0.0780324637889862,\n  -0.07704830914735794,\n  -0.07373525202274323,\n  -0.07478152960538864,\n  -0.07824863493442535,\n  -0.0771404579281807,\n  -0.07515187561511993,\n  -0.077002614736557,\n  -0.07895367592573166,\n  -0.07864031195640564,\n  -0.07754600048065186,\n  -0.08040116727352142,\n  -0.079766646027565,\n  -0.07778047770261765,\n  -0.07980597019195557,\n  -0.08091087639331818,\n  -0.07778031378984451,\n  -0.07819347828626633,\n  -0.08088485151529312,\n  -0.07959090173244476,\n  -0.08062149584293365,\n  -0.07969281077384949,\n  -0.08068089932203293,\n  -0.08268801867961884,\n  -0.07968100905418396,\n  -0.08186465501785278,\n  -0.0871683806180954,\n  -0.08435668796300888,\n  -0.08083360642194748,\n  -0.08308843523263931,\n  -0.08296345919370651,\n  -0.0807228684425354,\n  -0.08100510388612747,\n  -0.08283986151218414,\n  -0.08367551863193512,\n  -0.08441830426454544,\n  -0.08178815990686417,\n  -0.08329836279153824,\n  -0.08599238097667694,\n  -0.08496062457561493,\n  -0.08560732752084732,\n  -0.08662677556276321,\n  -0.08865223824977875,\n  -0.08556918054819107,\n  -0.08724895119667053,\n  -0.08935092389583588,\n  -0.08890864998102188,\n  -0.08914642035961151,\n  -0.08792652934789658,\n  -0.088559091091156,\n  -0.08798126876354218,\n  -0.08720161020755768,\n  -0.08800680190324783,\n  -0.08935476094484329,\n  -0.08791723847389221,\n  -0.08997883647680283,\n  -0.09070775657892227,\n  -0.08954306691884995,\n  -0.08851918578147888,\n  -0.09128763526678085,\n  -0.0935346782207489,\n  -0.08849217742681503,\n  -0.09194004535675049,\n  -0.0927196592092514,\n  -0.09011226147413254,\n  -0.09410814940929413,\n  -0.0916483998298645,\n  -0.09163147211074829,\n  -0.09308148175477982,\n  -0.09126436710357666,\n  -0.09491804242134094,\n  -0.09701031446456909,\n  -0.0959646925330162,\n  -0.09675639867782593,\n  -0.09710176289081573,\n  -0.09629372507333755,\n  -0.09864846616983414,\n  -0.09618016332387924,\n  -0.09699937701225281,\n  -0.10046179592609406,\n  -0.10011933743953705,\n  -0.09911485016345978,\n  -0.09495488554239273,\n  -0.10038629174232483,\n  -0.10114385187625885,\n  -0.09659510850906372,\n  -0.09883343428373337,\n  -0.10247854143381119,\n  -0.10362307727336884,\n  -0.10062649846076965,\n  -0.10364478081464767,\n  -0.10155104845762253,\n  -0.09749993681907654,\n  -0.10196875780820847,\n  -0.10128920525312424,\n  -0.1028820052742958,\n  -0.10587092489004135,\n  -0.10315405577421188,\n  -0.10508905351161957,\n  -0.10577071458101273,\n  -0.10419078171253204,\n  -0.10655268281698227,\n  -0.1091822013258934,\n  -0.10670701414346695,\n  -0.10712394118309021,\n  -0.10896102339029312,\n  -0.10767152160406113,\n  -0.11105307191610336,\n  -0.1090097576379776,\n  -0.10716640949249268,\n  -0.10763150453567505,\n  -0.10888227075338364,\n  -0.11176301538944244,\n  -0.11332084238529205,\n  -0.11203699558973312,\n  -0.11130564659833908,\n  -0.11357295513153076,\n  -0.11060778796672821,\n  -0.11399554461240768,\n  -0.11346250772476196,\n  -0.1130150705575943,\n  -0.11602823436260223,\n  -0.1121060848236084,\n  -0.11367560923099518,\n  -0.11278972029685974,\n  -0.11496912688016891,\n  -0.11781271547079086,\n  -0.1168590560555458,\n  -0.11733373999595642,\n  -0.11766257137060165,\n  -0.11965127289295197,\n  -0.12135063111782074,\n  -0.11966410279273987,\n  -0.11804382503032684,\n  -0.11939934641122818,\n  -0.11588486284017563,\n  -0.11794370412826538,\n  -0.12040579319000244,\n  -0.12020272761583328,\n  -0.11993180215358734,\n  -0.12122828513383865,\n  -0.12271536141633987,\n  -0.12115879356861115,\n  -0.12197341024875641,\n  -0.12142272293567657,\n  -0.1239556148648262,\n  -0.12395133078098297,\n  -0.12676604092121124,\n  -0.12380558252334595,\n  -0.1216006726026535,\n  -0.12597712874412537,\n  -0.12366270273923874,\n  -0.12549029290676117,\n  -0.12655429542064667,\n  -0.12563441693782806,\n  -0.1268165111541748,\n  -0.12747369706630707,\n  -0.1277841031551361,\n  -0.12673738598823547,\n  -0.1265036016702652,\n  -0.1296227127313614,\n  -0.1256474107503891,\n  -0.12451067566871643,\n  -0.12936857342720032,\n  -0.13098609447479248,\n  -0.12931190431118011,\n  -0.12718290090560913,\n  -0.12452501058578491,\n  -0.12812791764736176,\n  -0.13383172452449799,\n  -0.12706150114536285,\n  -0.12734535336494446,\n  -0.13058175146579742,\n  -0.1307530254125595,\n  -0.12748722732067108,\n  -0.1307217925786972,\n  -0.1309807151556015,\n  -0.12802651524543762,\n  -0.13370029628276825,\n  -0.13206635415554047,\n  -0.13083729147911072,\n  -0.1288071870803833,\n  -0.13333027064800262,\n  -0.13352294266223907,\n  -0.13105209171772003,\n  -0.1310829371213913,\n  -0.13299015164375305,\n  -0.13479793071746826,\n  -0.12974518537521362,\n  -0.13108006119728088,\n  -0.1330575942993164,\n  -0.13572590053081512,\n  -0.1355431228876114,\n  -0.13402387499809265,\n  -0.13406270742416382,\n  -0.13663047552108765,\n  -0.13761278986930847,\n  -0.13582280278205872,\n  -0.1381060779094696,\n  -0.1405322253704071,\n  -0.14116564393043518,\n  -0.13849948346614838,\n  -0.13700631260871887,\n  -0.14012393355369568,\n  -0.13890698552131653,\n  -0.14058658480644226,\n  -0.1410498172044754,\n  -0.14061668515205383,\n  -0.14653630554676056,\n  -0.13752013444900513,\n  -0.13960854709148407,\n  -0.1424749195575714,\n  -0.13818596303462982,\n  -0.14175528287887573,\n  -0.14036139845848083,\n  -0.14233547449111938,\n  -0.1400918811559677,\n  -0.14170172810554504,\n  -0.14126041531562805,\n  -0.1393938958644867,\n  -0.1430346518754959,\n  -0.14193172752857208,\n  -0.14326760172843933,\n  -0.1434599757194519,\n  -0.14161020517349243,\n  -0.145217165350914,\n  -0.1449873000383377,\n  -0.14606085419654846,\n  -0.14570283889770508,\n  -0.14119194447994232,\n  -0.14240750670433044,\n  -0.14307811856269836,\n  -0.14794522523880005,\n  -0.14459577202796936,\n  -0.14461760222911835,\n  -0.14907214045524597,\n  -0.14529232680797577,\n  -0.14680631458759308,\n  -0.14740397036075592,\n  -0.1500559002161026,\n  -0.15277670323848724,\n  -0.15411676466464996,\n  -0.15547916293144226,\n  -0.15461131930351257,\n  -0.15342403948307037,\n  -0.1508660614490509,\n  -0.15351763367652893,\n  -0.15512430667877197,\n  -0.15687361359596252,\n  -0.15558497607707977,\n  -0.15257352590560913,\n  -0.1567288041114807,\n  -0.15426182746887207,\n  -0.15551331639289856,\n  -0.15566283464431763,\n  -0.1534697711467743,\n  -0.15808573365211487,\n  -0.1560550332069397,\n  -0.1551084816455841,\n  -0.16087059676647186,\n  -0.15982912480831146,\n  -0.15411344170570374,\n  -0.15129810571670532,\n  -0.15257301926612854,\n  -0.15284410119056702,\n  -0.15284855663776398,\n  -0.15627890825271606,\n  -0.1552513986825943,\n  -0.16299636662006378,\n  -0.16238220036029816,\n  -0.15717653930187225,\n  -0.16262872517108917,\n  -0.15985238552093506,\n  -0.16054309904575348,\n  -0.15993821620941162,\n  -0.160519078373909,\n  -0.16162937879562378,\n  -0.15952615439891815,\n  -0.16157427430152893,\n  -0.15966446697711945,\n  -0.1605106145143509,\n  -0.16097761690616608,\n  -0.15987101197242737,\n  -0.16173967719078064,\n  -0.16340754926204681,\n  ...],\n 'labels': 2}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "from transformers.file_utils import ModelOutput\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SpeechClassifierOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2PreTrainedModel,\n",
    "    Wav2Vec2Model\n",
    ")\n",
    "\n",
    "\n",
    "class Wav2Vec2ClassificationHead(nn.Module):\n",
    "    \"\"\"Head for wav2vec classification task.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.final_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Wav2Vec2ForSpeechClassification(Wav2Vec2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pooling_mode = config.pooling_mode\n",
    "        self.config = config\n",
    "\n",
    "        self.wav2vec2 = Wav2Vec2Model(config)\n",
    "        self.classifier = Wav2Vec2ClassificationHead(config)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def freeze_feature_extractor(self):\n",
    "        self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "\n",
    "    def merged_strategy(\n",
    "            self,\n",
    "            hidden_states,\n",
    "            mode=\"mean\"\n",
    "    ):\n",
    "        if mode == \"mean\":\n",
    "            outputs = torch.mean(hidden_states, dim=1)\n",
    "        elif mode == \"sum\":\n",
    "            outputs = torch.sum(hidden_states, dim=1)\n",
    "        elif mode == \"max\":\n",
    "            outputs = torch.max(hidden_states, dim=1)[0]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_values,\n",
    "            attention_mask=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,\n",
    "            labels=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        outputs = self.wav2vec2(\n",
    "            input_values,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = outputs[0]\n",
    "        hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SpeechClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [feature[\"labels\"] for feature in features]\n",
    "\n",
    "        d_type = torch.long if isinstance(label_features[0], int) else torch.float\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = torch.tensor(label_features, dtype=d_type)\n",
    "\n",
    "        return batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "is_regression = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = numpy.squeeze(preds) if is_regression else numpy.argmax(preds, axis=1)\n",
    "\n",
    "    if is_regression:\n",
    "        return {\"mse\": ((preds - p.label_ids) ** 2).mean().item()}\n",
    "    else:\n",
    "        return {\"accuracy\": (preds == p.label_ids).astype(numpy.float32).mean().item()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForSpeechClassification: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSpeechClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'wav2vec2.masked_spec_embed', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForSpeechClassification.from_pretrained(\n",
    "    model_name_path,\n",
    "    config=config,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#print(is_apex_available())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "import apex\n",
    "from apex import amp\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/masterarbeit_programming/notebooks/content\",\n",
    "    # output_dir=\"/content/gdrive/MyDrive/wav2vec2-xlsr-greek-speech-emotion-recognition\"\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=1.0,\n",
    "    fp16=True,\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    save_total_limit=2,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "#install apex\n",
    "#!pip install -v --no-cache-dir   ../apex"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'experimental_functions_run_eagerly' from 'tensorflow.python.eager.def_function' (X:\\masterarbeit_programming\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [35], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m###import\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcuda\u001B[39;00m\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\tensorflow\\__init__.py:51\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograph\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m bitwise\n\u001B[1;32m---> 51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compat\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py:37\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Compatibility functions.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03mThe `tf.compat` module contains two sets of compatibility functions.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     32\u001B[0m \n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v1\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v2\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m forward_compatibility_horizon\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:30\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograph\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m bitwise\n\u001B[1;32m---> 30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compat\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py:37\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Compatibility functions.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03mThe `tf.compat` module contains two sets of compatibility functions.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     32\u001B[0m \n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v1\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m v2\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m forward_compatibility_horizon\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py:31\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograph\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m bitwise\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m debugging\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\config\\__init__.py:14\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LogicalDeviceConfiguration\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PhysicalDevice\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdef_function\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m experimental_functions_run_eagerly\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdef_function\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m experimental_run_functions_eagerly\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdef_function\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functions_run_eagerly\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'experimental_functions_run_eagerly' from 'tensorflow.python.eager.def_function' (X:\\masterarbeit_programming\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py)"
     ]
    }
   ],
   "source": [
    "###import\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import cuda\n",
    "import sys\n",
    "import numba\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Cuda version\", cuda.__version__)\n",
    "print(\"Numba version:\", numba.__version__)\n",
    "print(\"Numpy version:\", numpy.__version__)\n",
    "print(\"Torch version: \", torch.__version__)\n",
    "apex\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda True\n",
      "apex True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"cuda\",torch.cuda.is_available())\n",
    "print(\"apex\",is_apex_available())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Union\n",
    "\n",
    "\n",
    "import torch\n",
    "from packaging import version\n",
    "from torch import nn\n",
    "\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    is_apex_available,\n",
    ")\n",
    "\n",
    "if is_apex_available():\n",
    "    from apex import amp\n",
    "\n",
    "if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n",
    "    _is_native_amp_available = True\n",
    "    from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "class CTCTrainer(Trainer):\n",
    "    def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform a training step on a batch of inputs.\n",
    "\n",
    "        Subclass and override to inject custom behavior.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`nn.Module`):\n",
    "                The model to train.\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "\n",
    "        Return:\n",
    "            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n",
    "        \"\"\"\n",
    "\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        #if self.amp.use_amp:\n",
    "        if self.use_cuda_amp:\n",
    "            with autocast():\n",
    "                loss = self.compute_loss(model, inputs)\n",
    "        else:\n",
    "            loss = self.compute_loss(model, inputs)\n",
    "\n",
    "        if self.args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "        #if self.use_amp:\n",
    "        if self.use_cuda_amp:\n",
    "            self.scaler.scale(loss).backward()\n",
    "        #elif self.use_apex:\n",
    "        elif self.use_apex:\n",
    "            with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        elif self.deepspeed:\n",
    "            self.deepspeed.backward(loss)\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        return loss.detach()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = CTCTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_df,\n",
    "    eval_dataset=test_df,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "X:\\masterarbeit_programming\\venv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1920\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 240\n",
      "  Number of trainable parameters = 90766470\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/240 : < :, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-10\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-10\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-10\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-10\\preprocessor_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-20\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-20\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-20\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-20\\preprocessor_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-30\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-30\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-30\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-30\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-10] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-40\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-40\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-40\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-40\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-20] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-50\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-50\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-50\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-50\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-30] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-60\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-60\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-60\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-60\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-40] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-70\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-70\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-70\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-70\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-50] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-80\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-80\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-80\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-80\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-60] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-90\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-90\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-90\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-90\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-70] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-100\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-100\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-100\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-100\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-80] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-110\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-110\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-110\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-110\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-90] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-120\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-120\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-120\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-120\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-130\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-130\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-130\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-130\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-110] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-140\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-140\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-140\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-140\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-120] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-150\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-150\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-150\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-150\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-130] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-160\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-160\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-160\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-160\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-140] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-170\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-170\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-170\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-170\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-150] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-180\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-180\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-180\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-180\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-160] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-190\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-190\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-190\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-190\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-170] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-200\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-200\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-200\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-200\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-180] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-210\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-210\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-210\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-210\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-190] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-220\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-220\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-220\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-220\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-230\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-230\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-230\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-230\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-210] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path. If path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 480\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /masterarbeit_programming/notebooks/content\\checkpoint-240\n",
      "Configuration saved in /masterarbeit_programming/notebooks/content\\checkpoint-240\\config.json\n",
      "Model weights saved in /masterarbeit_programming/notebooks/content\\checkpoint-240\\pytorch_model.bin\n",
      "Feature extractor saved in /masterarbeit_programming/notebooks/content\\checkpoint-240\\preprocessor_config.json\n",
      "Deleting older checkpoint [\\masterarbeit_programming\\notebooks\\content\\checkpoint-220] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=240, training_loss=1.8036376953125, metrics={'train_runtime': 586.6198, 'train_samples_per_second': 3.273, 'train_steps_per_second': 0.409, 'total_flos': 5.819426334039211e+16, 'train_loss': 1.8036376953125, 'epoch': 1.0})"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import librosa\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "save_path=\"/masterarbeit_programming/notebooks/content/data\"\n",
    "trainReal_df, testReal_df=train_test_split(trainDF, test_size=0.2, random_state=101, stratify=trainDF[\"label\"])\n",
    "\n",
    "trainRealDf=trainReal_df.reset_index(drop=True)\n",
    "testRealDf=testReal_df.reset_index(drop=True)\n",
    "\n",
    "testRealDf.to_csv(f\"{save_path}/testReal.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-07c1e2ebfe30f97b\n",
      "Found cached dataset csv (C:/Users/tonib/.cache/huggingface/datasets/csv/default-07c1e2ebfe30f97b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bad3f5250964702b5afed47628cdd43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['path', 'label'],\n",
      "    num_rows: 480\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Loading the created dataset using datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "data_files = {\n",
    "    \"test\": \"/masterarbeit_programming/notebooks/content/data/testReal.csv\",\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\", )\n",
    "\n",
    "test_dfReal = dataset[\"test\"]\n",
    "\n",
    "\n",
    "print(test_dfReal)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device:{device}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"facebook/wav2vec2-base-960h\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading configuration file preprocessor_config.json from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"return_attention_mask\": false,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"facebook/wav2vec2-base-960h\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\vocab.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\tokenizer_config.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\special_tokens_map.json\n",
      "loading configuration file config.json from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"facebook/wav2vec2-base-960h\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"facebook/wav2vec2-base-960h\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\tonib/.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h\\snapshots\\22aad52d435eb6dbaf354bdad9b0da84ce7d6156\\pytorch_model.bin\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Wav2Vec2Config' object has no attribute 'pooling_mode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [54], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m config \u001B[38;5;241m=\u001B[39m AutoConfig\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name_path)\n\u001B[0;32m      2\u001B[0m processor\u001B[38;5;241m=\u001B[39m Wav2Vec2Processor\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name_path)\n\u001B[1;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mWav2Vec2ForSpeechClassification\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:2230\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   2227\u001B[0m     init_contexts\u001B[38;5;241m.\u001B[39mappend(init_empty_weights())\n\u001B[0;32m   2229\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(init_contexts):\n\u001B[1;32m-> 2230\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(config, \u001B[38;5;241m*\u001B[39mmodel_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[0;32m   2232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m load_in_8bit:\n\u001B[0;32m   2233\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbitsandbytes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_keys_to_not_convert, replace_8bit_linear\n",
      "Cell \u001B[1;32mIn [25], line 34\u001B[0m, in \u001B[0;36mWav2Vec2ForSpeechClassification.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(config)\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_labels \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mnum_labels\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooling_mode \u001B[38;5;241m=\u001B[39m \u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpooling_mode\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig \u001B[38;5;241m=\u001B[39m config\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwav2vec2 \u001B[38;5;241m=\u001B[39m Wav2Vec2Model(config)\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\transformers\\configuration_utils.py:254\u001B[0m, in \u001B[0;36mPretrainedConfig.__getattribute__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattribute_map\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattribute_map\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    253\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattribute_map\u001B[39m\u001B[38;5;124m\"\u001B[39m)[key]\n\u001B[1;32m--> 254\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Wav2Vec2Config' object has no attribute 'pooling_mode'"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name_path)\n",
    "processor= Wav2Vec2Processor.from_pretrained(model_name_path)\n",
    "model = Wav2Vec2ForSpeechClassification.from_pretrained(model_name_path).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def predict(batch):\n",
    "    features = processor(batch[\"speech\"], sampling_rate=processor.feature_extractor.sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = features.attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    batch[\"predicted\"] = pred_ids\n",
    "    return batch\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    speech_array = speech_array.squeeze().numpy()\n",
    "    speech_array = librosa.resample(numpy.asarray(speech_array), sampling_rate, processor.feature_extractor.sampling_rate)\n",
    "\n",
    "    batch[\"speech\"] = speech_array\n",
    "    return batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/480 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0196e631eaa24426a5f8cfcc80523d42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonib\\AppData\\Local\\Temp\\ipykernel_14392\\1160560738.py:17: FutureWarning: Pass orig_sr=24414, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  speech_array = librosa.resample(numpy.asarray(speech_array), sampling_rate, processor.feature_extractor.sampling_rate)\n"
     ]
    }
   ],
   "source": [
    "test_dfReal = test_dfReal.map(speech_file_to_array_fn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "#test_df[0]\n",
    "test_dfReal=test_dfReal.rename_column(\"input_values\", \"speech\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/60 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cf437e445b846bc94055985dbf66634"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\transformers\\feature_extraction_utils.py:89\u001B[0m, in \u001B[0;36mBatchFeature.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 89\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[1;31mKeyError\u001B[0m: 'attention_mask'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [82], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mtest_dfReal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:2585\u001B[0m, in \u001B[0;36mDataset.map\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[0;32m   2582\u001B[0m disable_tqdm \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mis_progress_bar_enabled()\n\u001B[0;32m   2584\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_proc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m num_proc \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m-> 2585\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_single\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2587\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2588\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2589\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2590\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2591\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2592\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2594\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2600\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2601\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnew_fingerprint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_fingerprint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2602\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable_tqdm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_tqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2603\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2604\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2605\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2607\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_cache_file_name\u001B[39m(cache_file_name, rank):\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:585\u001B[0m, in \u001B[0;36mtransmit_tasks.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    583\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    584\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 585\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    586\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    587\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[0;32m    588\u001B[0m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:552\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    545\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    546\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[0;32m    547\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[0;32m    548\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[0;32m    550\u001B[0m }\n\u001B[0;32m    551\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 552\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    553\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    554\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\fingerprint.py:480\u001B[0m, in \u001B[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    476\u001B[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001B[0;32m    478\u001B[0m \u001B[38;5;66;03m# Call actual function\u001B[39;00m\n\u001B[1;32m--> 480\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    482\u001B[0m \u001B[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001B[39;00m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:  \u001B[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001B[39;00m\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:2982\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001B[0m\n\u001B[0;32m   2978\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[0;32m   2979\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(input_dataset\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[0;32m   2980\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[0;32m   2981\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2982\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2983\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2984\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2985\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_same_num_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_indexes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2986\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2987\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2988\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[0;32m   2989\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[0;32m   2990\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2991\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:2865\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[1;34m(inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[0;32m   2863\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[0;32m   2864\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[1;32m-> 2865\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m function(\u001B[38;5;241m*\u001B[39mfn_args, \u001B[38;5;241m*\u001B[39madditional_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_kwargs)\n\u001B[0;32m   2866\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m update_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2867\u001B[0m     \u001B[38;5;66;03m# Check if the function returns updated examples\u001B[39;00m\n\u001B[0;32m   2868\u001B[0m     update_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, (Mapping, pa\u001B[38;5;241m.\u001B[39mTable))\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\datasets\\arrow_dataset.py:2545\u001B[0m, in \u001B[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001B[1;34m(item, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2541\u001B[0m decorated_item \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   2542\u001B[0m     Example(item, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m batched \u001B[38;5;28;01melse\u001B[39;00m Batch(item, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[0;32m   2543\u001B[0m )\n\u001B[0;32m   2544\u001B[0m \u001B[38;5;66;03m# Use the LazyDict internally, while mapping the function\u001B[39;00m\n\u001B[1;32m-> 2545\u001B[0m result \u001B[38;5;241m=\u001B[39m f(decorated_item, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2546\u001B[0m \u001B[38;5;66;03m# Return a standard dict\u001B[39;00m\n\u001B[0;32m   2547\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, LazyDict) \u001B[38;5;28;01melse\u001B[39;00m result\n",
      "Cell \u001B[1;32mIn [76], line 5\u001B[0m, in \u001B[0;36mpredict\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m      2\u001B[0m features \u001B[38;5;241m=\u001B[39m processor(batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspeech\u001B[39m\u001B[38;5;124m\"\u001B[39m], sampling_rate\u001B[38;5;241m=\u001B[39mprocessor\u001B[38;5;241m.\u001B[39mfeature_extractor\u001B[38;5;241m.\u001B[39msampling_rate, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      4\u001B[0m input_values \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39minput_values\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 5\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m \u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m      8\u001B[0m     logits \u001B[38;5;241m=\u001B[39m model(input_values, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask)\u001B[38;5;241m.\u001B[39mlogits\n",
      "File \u001B[1;32mX:\\masterarbeit_programming\\venv\\lib\\site-packages\\transformers\\feature_extraction_utils.py:91\u001B[0m, in \u001B[0;36mBatchFeature.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[item]\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m---> 91\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "result = test_dfReal.map(predict, batched=True, batch_size=8)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to content/mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/26421880 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21e4cdefe4b644c68b74cd60ead48592"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content/mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to content/mnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to content/mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29515 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa4eae7561f94cea94d67c7b8d498773"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content/mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to content/mnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to content/mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4422102 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2ff46a61634405593a1902a438151a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content/mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to content/mnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to content/mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5148 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7d160eef1c248fcab52c7580f18909b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content/mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to content/mnist/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"content/mnist\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"content/mnist\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"content/mnist\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([7], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[1.9682e-01, 0.0000e+00, 2.4959e-01, 3.7983e-04, 5.1515e-01, 0.0000e+00,\n",
      "         5.4102e-01, 1.3123e-01, 3.3201e-01, 0.0000e+00, 7.8645e-03, 3.4106e-01,\n",
      "         0.0000e+00, 1.8910e-01, 2.5196e-01, 0.0000e+00, 0.0000e+00, 3.3459e-01,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [5.6090e-01, 0.0000e+00, 8.5249e-02, 0.0000e+00, 4.7450e-01, 0.0000e+00,\n",
      "         2.9193e-01, 1.8693e-01, 5.5733e-01, 1.0912e-02, 0.0000e+00, 2.3032e-01,\n",
      "         0.0000e+00, 4.2638e-01, 2.6310e-01, 0.0000e+00, 0.0000e+00, 3.5820e-01,\n",
      "         0.0000e+00, 1.3286e-01],\n",
      "        [5.5051e-01, 0.0000e+00, 2.1652e-01, 0.0000e+00, 1.9552e-01, 0.0000e+00,\n",
      "         0.0000e+00, 1.3215e-01, 5.5015e-01, 1.8538e-02, 0.0000e+00, 1.2313e-01,\n",
      "         0.0000e+00, 6.4172e-02, 1.3936e-01, 0.0000e+00, 7.4892e-03, 3.8634e-01,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[1.9682e-01, 0.0000e+00, 2.4959e-01, 3.7983e-04, 5.1515e-01, 0.0000e+00,\n",
      "         5.4102e-01, 1.3123e-01, 3.3201e-01, 0.0000e+00, 7.8645e-03, 3.4106e-01,\n",
      "         0.0000e+00, 1.8910e-01, 2.5196e-01, 0.0000e+00, 0.0000e+00, 3.3459e-01,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [5.6090e-01, 0.0000e+00, 8.5249e-02, 0.0000e+00, 4.7450e-01, 0.0000e+00,\n",
      "         2.9193e-01, 1.8693e-01, 5.5733e-01, 1.0912e-02, 0.0000e+00, 2.3032e-01,\n",
      "         0.0000e+00, 4.2638e-01, 2.6310e-01, 0.0000e+00, 0.0000e+00, 3.5820e-01,\n",
      "         0.0000e+00, 1.3286e-01],\n",
      "        [5.5051e-01, 0.0000e+00, 2.1652e-01, 0.0000e+00, 1.9552e-01, 0.0000e+00,\n",
      "         0.0000e+00, 1.3215e-01, 5.5015e-01, 1.8538e-02, 0.0000e+00, 1.2313e-01,\n",
      "         0.0000e+00, 6.4172e-02, 1.3936e-01, 0.0000e+00, 7.4892e-03, 3.8634e-01,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0982, 0.0825, 0.1052, 0.1139, 0.1242, 0.0930, 0.1024, 0.0771, 0.1048,\n         0.0987],\n        [0.1094, 0.0782, 0.1099, 0.1153, 0.1109, 0.1042, 0.0993, 0.0778, 0.1039,\n         0.0911],\n        [0.1128, 0.0860, 0.1114, 0.1065, 0.0973, 0.0830, 0.1111, 0.0772, 0.1070,\n         0.1074]], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x7f7e9d267550>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f7ea83b7c40>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"content/mnist\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"content/mnist\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.795716  [    0/60000]\n",
      "loss: 0.877979  [ 6400/60000]\n",
      "loss: 0.636990  [12800/60000]\n",
      "loss: 0.834962  [19200/60000]\n",
      "loss: 0.745807  [25600/60000]\n",
      "loss: 0.731235  [32000/60000]\n",
      "loss: 0.818525  [38400/60000]\n",
      "loss: 0.792515  [44800/60000]\n",
      "loss: 0.796719  [51200/60000]\n",
      "loss: 0.770926  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.763758 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.757785  [    0/60000]\n",
      "loss: 0.848109  [ 6400/60000]\n",
      "loss: 0.605129  [12800/60000]\n",
      "loss: 0.809966  [19200/60000]\n",
      "loss: 0.723448  [25600/60000]\n",
      "loss: 0.705426  [32000/60000]\n",
      "loss: 0.792805  [38400/60000]\n",
      "loss: 0.776183  [44800/60000]\n",
      "loss: 0.774987  [51200/60000]\n",
      "loss: 0.749445  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.741270 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.724959  [    0/60000]\n",
      "loss: 0.821403  [ 6400/60000]\n",
      "loss: 0.578189  [12800/60000]\n",
      "loss: 0.788846  [19200/60000]\n",
      "loss: 0.704113  [25600/60000]\n",
      "loss: 0.684305  [32000/60000]\n",
      "loss: 0.769437  [38400/60000]\n",
      "loss: 0.761951  [44800/60000]\n",
      "loss: 0.756297  [51200/60000]\n",
      "loss: 0.730439  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.721442 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.695980  [    0/60000]\n",
      "loss: 0.796778  [ 6400/60000]\n",
      "loss: 0.554893  [12800/60000]\n",
      "loss: 0.770447  [19200/60000]\n",
      "loss: 0.687128  [25600/60000]\n",
      "loss: 0.666721  [32000/60000]\n",
      "loss: 0.747706  [38400/60000]\n",
      "loss: 0.749027  [44800/60000]\n",
      "loss: 0.739905  [51200/60000]\n",
      "loss: 0.713124  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.703510 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.670123  [    0/60000]\n",
      "loss: 0.773793  [ 6400/60000]\n",
      "loss: 0.534358  [12800/60000]\n",
      "loss: 0.754069  [19200/60000]\n",
      "loss: 0.672020  [25600/60000]\n",
      "loss: 0.651802  [32000/60000]\n",
      "loss: 0.727253  [38400/60000]\n",
      "loss: 0.737140  [44800/60000]\n",
      "loss: 0.725348  [51200/60000]\n",
      "loss: 0.697150  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.687064 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.646798  [    0/60000]\n",
      "loss: 0.752285  [ 6400/60000]\n",
      "loss: 0.516059  [12800/60000]\n",
      "loss: 0.739179  [19200/60000]\n",
      "loss: 0.658536  [25600/60000]\n",
      "loss: 0.638908  [32000/60000]\n",
      "loss: 0.707985  [38400/60000]\n",
      "loss: 0.726212  [44800/60000]\n",
      "loss: 0.712261  [51200/60000]\n",
      "loss: 0.682332  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.671893 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.625651  [    0/60000]\n",
      "loss: 0.732200  [ 6400/60000]\n",
      "loss: 0.499664  [12800/60000]\n",
      "loss: 0.725550  [19200/60000]\n",
      "loss: 0.646354  [25600/60000]\n",
      "loss: 0.627780  [32000/60000]\n",
      "loss: 0.689913  [38400/60000]\n",
      "loss: 0.716170  [44800/60000]\n",
      "loss: 0.700542  [51200/60000]\n",
      "loss: 0.668513  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.657864 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.606404  [    0/60000]\n",
      "loss: 0.713520  [ 6400/60000]\n",
      "loss: 0.484920  [12800/60000]\n",
      "loss: 0.713033  [19200/60000]\n",
      "loss: 0.635343  [25600/60000]\n",
      "loss: 0.618123  [32000/60000]\n",
      "loss: 0.673052  [38400/60000]\n",
      "loss: 0.707097  [44800/60000]\n",
      "loss: 0.690122  [51200/60000]\n",
      "loss: 0.655502  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.644890 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.588948  [    0/60000]\n",
      "loss: 0.696083  [ 6400/60000]\n",
      "loss: 0.471613  [12800/60000]\n",
      "loss: 0.701468  [19200/60000]\n",
      "loss: 0.625403  [25600/60000]\n",
      "loss: 0.609708  [32000/60000]\n",
      "loss: 0.657313  [38400/60000]\n",
      "loss: 0.698997  [44800/60000]\n",
      "loss: 0.680999  [51200/60000]\n",
      "loss: 0.643225  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.632888 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.572966  [    0/60000]\n",
      "loss: 0.679843  [ 6400/60000]\n",
      "loss: 0.459583  [12800/60000]\n",
      "loss: 0.690783  [19200/60000]\n",
      "loss: 0.616383  [25600/60000]\n",
      "loss: 0.602216  [32000/60000]\n",
      "loss: 0.642520  [38400/60000]\n",
      "loss: 0.691895  [44800/60000]\n",
      "loss: 0.672996  [51200/60000]\n",
      "loss: 0.631716  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.621788 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.558414  [    0/60000]\n",
      "loss: 0.664701  [ 6400/60000]\n",
      "loss: 0.448664  [12800/60000]\n",
      "loss: 0.680893  [19200/60000]\n",
      "loss: 0.608333  [25600/60000]\n",
      "loss: 0.595630  [32000/60000]\n",
      "loss: 0.628743  [38400/60000]\n",
      "loss: 0.685723  [44800/60000]\n",
      "loss: 0.666016  [51200/60000]\n",
      "loss: 0.620679  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.611582 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.545046  [    0/60000]\n",
      "loss: 0.650732  [ 6400/60000]\n",
      "loss: 0.438747  [12800/60000]\n",
      "loss: 0.671628  [19200/60000]\n",
      "loss: 0.600930  [25600/60000]\n",
      "loss: 0.589669  [32000/60000]\n",
      "loss: 0.616036  [38400/60000]\n",
      "loss: 0.680543  [44800/60000]\n",
      "loss: 0.660047  [51200/60000]\n",
      "loss: 0.610064  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.602175 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.532643  [    0/60000]\n",
      "loss: 0.637813  [ 6400/60000]\n",
      "loss: 0.429701  [12800/60000]\n",
      "loss: 0.662946  [19200/60000]\n",
      "loss: 0.593999  [25600/60000]\n",
      "loss: 0.584253  [32000/60000]\n",
      "loss: 0.604324  [38400/60000]\n",
      "loss: 0.676234  [44800/60000]\n",
      "loss: 0.654949  [51200/60000]\n",
      "loss: 0.599880  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.593496 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.521136  [    0/60000]\n",
      "loss: 0.625866  [ 6400/60000]\n",
      "loss: 0.421354  [12800/60000]\n",
      "loss: 0.654738  [19200/60000]\n",
      "loss: 0.587479  [25600/60000]\n",
      "loss: 0.579273  [32000/60000]\n",
      "loss: 0.593494  [38400/60000]\n",
      "loss: 0.672726  [44800/60000]\n",
      "loss: 0.650621  [51200/60000]\n",
      "loss: 0.590113  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.585478 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.510471  [    0/60000]\n",
      "loss: 0.614818  [ 6400/60000]\n",
      "loss: 0.413633  [12800/60000]\n",
      "loss: 0.647019  [19200/60000]\n",
      "loss: 0.581129  [25600/60000]\n",
      "loss: 0.574598  [32000/60000]\n",
      "loss: 0.583546  [38400/60000]\n",
      "loss: 0.669930  [44800/60000]\n",
      "loss: 0.646904  [51200/60000]\n",
      "loss: 0.580658  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.578059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.500454  [    0/60000]\n",
      "loss: 0.604598  [ 6400/60000]\n",
      "loss: 0.406433  [12800/60000]\n",
      "loss: 0.639694  [19200/60000]\n",
      "loss: 0.575021  [25600/60000]\n",
      "loss: 0.570172  [32000/60000]\n",
      "loss: 0.574346  [38400/60000]\n",
      "loss: 0.667741  [44800/60000]\n",
      "loss: 0.643663  [51200/60000]\n",
      "loss: 0.571519  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.571182 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.491068  [    0/60000]\n",
      "loss: 0.595101  [ 6400/60000]\n",
      "loss: 0.399762  [12800/60000]\n",
      "loss: 0.632691  [19200/60000]\n",
      "loss: 0.569093  [25600/60000]\n",
      "loss: 0.565903  [32000/60000]\n",
      "loss: 0.565821  [38400/60000]\n",
      "loss: 0.666050  [44800/60000]\n",
      "loss: 0.640889  [51200/60000]\n",
      "loss: 0.562737  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.564804 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.482159  [    0/60000]\n",
      "loss: 0.586213  [ 6400/60000]\n",
      "loss: 0.393548  [12800/60000]\n",
      "loss: 0.626010  [19200/60000]\n",
      "loss: 0.563356  [25600/60000]\n",
      "loss: 0.561787  [32000/60000]\n",
      "loss: 0.557936  [38400/60000]\n",
      "loss: 0.664915  [44800/60000]\n",
      "loss: 0.638441  [51200/60000]\n",
      "loss: 0.554220  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.558875 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.473743  [    0/60000]\n",
      "loss: 0.577929  [ 6400/60000]\n",
      "loss: 0.387708  [12800/60000]\n",
      "loss: 0.619606  [19200/60000]\n",
      "loss: 0.557756  [25600/60000]\n",
      "loss: 0.557708  [32000/60000]\n",
      "loss: 0.550688  [38400/60000]\n",
      "loss: 0.664177  [44800/60000]\n",
      "loss: 0.636208  [51200/60000]\n",
      "loss: 0.546024  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.553350 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.465815  [    0/60000]\n",
      "loss: 0.570224  [ 6400/60000]\n",
      "loss: 0.382150  [12800/60000]\n",
      "loss: 0.613503  [19200/60000]\n",
      "loss: 0.552185  [25600/60000]\n",
      "loss: 0.553572  [32000/60000]\n",
      "loss: 0.543984  [38400/60000]\n",
      "loss: 0.663693  [44800/60000]\n",
      "loss: 0.634186  [51200/60000]\n",
      "loss: 0.538099  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.548196 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.458247  [    0/60000]\n",
      "loss: 0.563073  [ 6400/60000]\n",
      "loss: 0.376966  [12800/60000]\n",
      "loss: 0.607665  [19200/60000]\n",
      "loss: 0.546646  [25600/60000]\n",
      "loss: 0.549444  [32000/60000]\n",
      "loss: 0.537836  [38400/60000]\n",
      "loss: 0.663480  [44800/60000]\n",
      "loss: 0.632302  [51200/60000]\n",
      "loss: 0.530426  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.543380 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.451066  [    0/60000]\n",
      "loss: 0.556472  [ 6400/60000]\n",
      "loss: 0.372083  [12800/60000]\n",
      "loss: 0.602049  [19200/60000]\n",
      "loss: 0.541206  [25600/60000]\n",
      "loss: 0.545298  [32000/60000]\n",
      "loss: 0.532168  [38400/60000]\n",
      "loss: 0.663448  [44800/60000]\n",
      "loss: 0.630522  [51200/60000]\n",
      "loss: 0.522987  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.538865 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.444223  [    0/60000]\n",
      "loss: 0.550307  [ 6400/60000]\n",
      "loss: 0.367399  [12800/60000]\n",
      "loss: 0.596640  [19200/60000]\n",
      "loss: 0.535872  [25600/60000]\n",
      "loss: 0.541203  [32000/60000]\n",
      "loss: 0.526959  [38400/60000]\n",
      "loss: 0.663549  [44800/60000]\n",
      "loss: 0.628821  [51200/60000]\n",
      "loss: 0.515830  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.534628 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.437694  [    0/60000]\n",
      "loss: 0.544578  [ 6400/60000]\n",
      "loss: 0.362895  [12800/60000]\n",
      "loss: 0.591449  [19200/60000]\n",
      "loss: 0.530636  [25600/60000]\n",
      "loss: 0.537161  [32000/60000]\n",
      "loss: 0.522142  [38400/60000]\n",
      "loss: 0.663726  [44800/60000]\n",
      "loss: 0.627118  [51200/60000]\n",
      "loss: 0.508976  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.530650 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.431489  [    0/60000]\n",
      "loss: 0.539255  [ 6400/60000]\n",
      "loss: 0.358633  [12800/60000]\n",
      "loss: 0.586451  [19200/60000]\n",
      "loss: 0.525437  [25600/60000]\n",
      "loss: 0.533211  [32000/60000]\n",
      "loss: 0.517728  [38400/60000]\n",
      "loss: 0.663932  [44800/60000]\n",
      "loss: 0.625488  [51200/60000]\n",
      "loss: 0.502359  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.526908 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.425584  [    0/60000]\n",
      "loss: 0.534291  [ 6400/60000]\n",
      "loss: 0.354624  [12800/60000]\n",
      "loss: 0.581640  [19200/60000]\n",
      "loss: 0.520342  [25600/60000]\n",
      "loss: 0.529313  [32000/60000]\n",
      "loss: 0.513618  [38400/60000]\n",
      "loss: 0.664145  [44800/60000]\n",
      "loss: 0.623831  [51200/60000]\n",
      "loss: 0.495972  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.523383 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.419927  [    0/60000]\n",
      "loss: 0.529699  [ 6400/60000]\n",
      "loss: 0.350811  [12800/60000]\n",
      "loss: 0.577014  [19200/60000]\n",
      "loss: 0.515350  [25600/60000]\n",
      "loss: 0.525555  [32000/60000]\n",
      "loss: 0.509788  [38400/60000]\n",
      "loss: 0.664339  [44800/60000]\n",
      "loss: 0.622202  [51200/60000]\n",
      "loss: 0.489872  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.520056 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.414487  [    0/60000]\n",
      "loss: 0.525383  [ 6400/60000]\n",
      "loss: 0.347201  [12800/60000]\n",
      "loss: 0.572586  [19200/60000]\n",
      "loss: 0.510508  [25600/60000]\n",
      "loss: 0.521880  [32000/60000]\n",
      "loss: 0.506187  [38400/60000]\n",
      "loss: 0.664433  [44800/60000]\n",
      "loss: 0.620534  [51200/60000]\n",
      "loss: 0.484072  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.516906 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.409303  [    0/60000]\n",
      "loss: 0.521348  [ 6400/60000]\n",
      "loss: 0.343761  [12800/60000]\n",
      "loss: 0.568319  [19200/60000]\n",
      "loss: 0.505761  [25600/60000]\n",
      "loss: 0.518176  [32000/60000]\n",
      "loss: 0.502827  [38400/60000]\n",
      "loss: 0.664469  [44800/60000]\n",
      "loss: 0.618826  [51200/60000]\n",
      "loss: 0.478539  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.513921 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.404313  [    0/60000]\n",
      "loss: 0.517524  [ 6400/60000]\n",
      "loss: 0.340435  [12800/60000]\n",
      "loss: 0.564184  [19200/60000]\n",
      "loss: 0.501173  [25600/60000]\n",
      "loss: 0.514530  [32000/60000]\n",
      "loss: 0.499645  [38400/60000]\n",
      "loss: 0.664315  [44800/60000]\n",
      "loss: 0.617098  [51200/60000]\n",
      "loss: 0.473336  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.511083 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.399519  [    0/60000]\n",
      "loss: 0.513947  [ 6400/60000]\n",
      "loss: 0.337265  [12800/60000]\n",
      "loss: 0.560201  [19200/60000]\n",
      "loss: 0.496702  [25600/60000]\n",
      "loss: 0.510978  [32000/60000]\n",
      "loss: 0.496667  [38400/60000]\n",
      "loss: 0.664001  [44800/60000]\n",
      "loss: 0.615315  [51200/60000]\n",
      "loss: 0.468404  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.508385 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.394868  [    0/60000]\n",
      "loss: 0.510593  [ 6400/60000]\n",
      "loss: 0.334247  [12800/60000]\n",
      "loss: 0.556350  [19200/60000]\n",
      "loss: 0.492357  [25600/60000]\n",
      "loss: 0.507526  [32000/60000]\n",
      "loss: 0.493817  [38400/60000]\n",
      "loss: 0.663498  [44800/60000]\n",
      "loss: 0.613599  [51200/60000]\n",
      "loss: 0.463762  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.505809 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.390356  [    0/60000]\n",
      "loss: 0.507415  [ 6400/60000]\n",
      "loss: 0.331387  [12800/60000]\n",
      "loss: 0.552609  [19200/60000]\n",
      "loss: 0.488148  [25600/60000]\n",
      "loss: 0.504063  [32000/60000]\n",
      "loss: 0.491110  [38400/60000]\n",
      "loss: 0.662892  [44800/60000]\n",
      "loss: 0.611826  [51200/60000]\n",
      "loss: 0.459359  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.503353 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.386013  [    0/60000]\n",
      "loss: 0.504493  [ 6400/60000]\n",
      "loss: 0.328658  [12800/60000]\n",
      "loss: 0.549003  [19200/60000]\n",
      "loss: 0.484020  [25600/60000]\n",
      "loss: 0.500715  [32000/60000]\n",
      "loss: 0.488540  [38400/60000]\n",
      "loss: 0.662149  [44800/60000]\n",
      "loss: 0.610043  [51200/60000]\n",
      "loss: 0.455241  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.501009 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.381842  [    0/60000]\n",
      "loss: 0.501715  [ 6400/60000]\n",
      "loss: 0.326027  [12800/60000]\n",
      "loss: 0.545543  [19200/60000]\n",
      "loss: 0.479979  [25600/60000]\n",
      "loss: 0.497448  [32000/60000]\n",
      "loss: 0.486097  [38400/60000]\n",
      "loss: 0.661309  [44800/60000]\n",
      "loss: 0.608318  [51200/60000]\n",
      "loss: 0.451358  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.498771 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.377787  [    0/60000]\n",
      "loss: 0.499066  [ 6400/60000]\n",
      "loss: 0.323444  [12800/60000]\n",
      "loss: 0.542229  [19200/60000]\n",
      "loss: 0.476060  [25600/60000]\n",
      "loss: 0.494365  [32000/60000]\n",
      "loss: 0.483752  [38400/60000]\n",
      "loss: 0.660306  [44800/60000]\n",
      "loss: 0.606601  [51200/60000]\n",
      "loss: 0.447713  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.496626 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.373898  [    0/60000]\n",
      "loss: 0.496571  [ 6400/60000]\n",
      "loss: 0.320949  [12800/60000]\n",
      "loss: 0.539035  [19200/60000]\n",
      "loss: 0.472304  [25600/60000]\n",
      "loss: 0.491480  [32000/60000]\n",
      "loss: 0.481488  [38400/60000]\n",
      "loss: 0.659199  [44800/60000]\n",
      "loss: 0.604943  [51200/60000]\n",
      "loss: 0.444254  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.494567 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.370169  [    0/60000]\n",
      "loss: 0.494220  [ 6400/60000]\n",
      "loss: 0.318567  [12800/60000]\n",
      "loss: 0.535951  [19200/60000]\n",
      "loss: 0.468662  [25600/60000]\n",
      "loss: 0.488707  [32000/60000]\n",
      "loss: 0.479300  [38400/60000]\n",
      "loss: 0.658028  [44800/60000]\n",
      "loss: 0.603210  [51200/60000]\n",
      "loss: 0.441034  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.492587 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.366541  [    0/60000]\n",
      "loss: 0.491969  [ 6400/60000]\n",
      "loss: 0.316229  [12800/60000]\n",
      "loss: 0.533015  [19200/60000]\n",
      "loss: 0.465062  [25600/60000]\n",
      "loss: 0.485979  [32000/60000]\n",
      "loss: 0.477166  [38400/60000]\n",
      "loss: 0.656742  [44800/60000]\n",
      "loss: 0.601440  [51200/60000]\n",
      "loss: 0.437999  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.490681 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.362966  [    0/60000]\n",
      "loss: 0.489835  [ 6400/60000]\n",
      "loss: 0.313985  [12800/60000]\n",
      "loss: 0.530205  [19200/60000]\n",
      "loss: 0.461612  [25600/60000]\n",
      "loss: 0.483376  [32000/60000]\n",
      "loss: 0.475141  [38400/60000]\n",
      "loss: 0.655354  [44800/60000]\n",
      "loss: 0.599708  [51200/60000]\n",
      "loss: 0.435114  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.488848 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.359513  [    0/60000]\n",
      "loss: 0.487784  [ 6400/60000]\n",
      "loss: 0.311834  [12800/60000]\n",
      "loss: 0.527531  [19200/60000]\n",
      "loss: 0.458236  [25600/60000]\n",
      "loss: 0.480835  [32000/60000]\n",
      "loss: 0.473184  [38400/60000]\n",
      "loss: 0.653850  [44800/60000]\n",
      "loss: 0.598006  [51200/60000]\n",
      "loss: 0.432369  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.487077 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.356191  [    0/60000]\n",
      "loss: 0.485788  [ 6400/60000]\n",
      "loss: 0.309778  [12800/60000]\n",
      "loss: 0.524972  [19200/60000]\n",
      "loss: 0.455031  [25600/60000]\n",
      "loss: 0.478378  [32000/60000]\n",
      "loss: 0.471333  [38400/60000]\n",
      "loss: 0.652287  [44800/60000]\n",
      "loss: 0.596352  [51200/60000]\n",
      "loss: 0.429811  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.485365 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.352971  [    0/60000]\n",
      "loss: 0.483812  [ 6400/60000]\n",
      "loss: 0.307765  [12800/60000]\n",
      "loss: 0.522521  [19200/60000]\n",
      "loss: 0.451921  [25600/60000]\n",
      "loss: 0.476083  [32000/60000]\n",
      "loss: 0.469551  [38400/60000]\n",
      "loss: 0.650677  [44800/60000]\n",
      "loss: 0.594708  [51200/60000]\n",
      "loss: 0.427344  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.483709 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.349842  [    0/60000]\n",
      "loss: 0.481893  [ 6400/60000]\n",
      "loss: 0.305756  [12800/60000]\n",
      "loss: 0.520130  [19200/60000]\n",
      "loss: 0.448928  [25600/60000]\n",
      "loss: 0.473916  [32000/60000]\n",
      "loss: 0.467825  [38400/60000]\n",
      "loss: 0.648983  [44800/60000]\n",
      "loss: 0.593079  [51200/60000]\n",
      "loss: 0.424989  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.482104 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.346794  [    0/60000]\n",
      "loss: 0.480033  [ 6400/60000]\n",
      "loss: 0.303802  [12800/60000]\n",
      "loss: 0.517815  [19200/60000]\n",
      "loss: 0.446024  [25600/60000]\n",
      "loss: 0.471815  [32000/60000]\n",
      "loss: 0.466178  [38400/60000]\n",
      "loss: 0.647296  [44800/60000]\n",
      "loss: 0.591477  [51200/60000]\n",
      "loss: 0.422792  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.480542 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.343835  [    0/60000]\n",
      "loss: 0.478256  [ 6400/60000]\n",
      "loss: 0.301929  [12800/60000]\n",
      "loss: 0.515575  [19200/60000]\n",
      "loss: 0.443205  [25600/60000]\n",
      "loss: 0.469793  [32000/60000]\n",
      "loss: 0.464505  [38400/60000]\n",
      "loss: 0.645611  [44800/60000]\n",
      "loss: 0.589917  [51200/60000]\n",
      "loss: 0.420744  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.479027 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.340929  [    0/60000]\n",
      "loss: 0.476518  [ 6400/60000]\n",
      "loss: 0.300123  [12800/60000]\n",
      "loss: 0.513431  [19200/60000]\n",
      "loss: 0.440468  [25600/60000]\n",
      "loss: 0.467779  [32000/60000]\n",
      "loss: 0.462909  [38400/60000]\n",
      "loss: 0.643894  [44800/60000]\n",
      "loss: 0.588345  [51200/60000]\n",
      "loss: 0.418747  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.477546 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.338077  [    0/60000]\n",
      "loss: 0.474812  [ 6400/60000]\n",
      "loss: 0.298356  [12800/60000]\n",
      "loss: 0.511376  [19200/60000]\n",
      "loss: 0.437832  [25600/60000]\n",
      "loss: 0.465846  [32000/60000]\n",
      "loss: 0.461371  [38400/60000]\n",
      "loss: 0.642196  [44800/60000]\n",
      "loss: 0.586819  [51200/60000]\n",
      "loss: 0.416890  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.476105 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.335256  [    0/60000]\n",
      "loss: 0.473165  [ 6400/60000]\n",
      "loss: 0.296625  [12800/60000]\n",
      "loss: 0.509363  [19200/60000]\n",
      "loss: 0.435274  [25600/60000]\n",
      "loss: 0.463988  [32000/60000]\n",
      "loss: 0.459826  [38400/60000]\n",
      "loss: 0.640439  [44800/60000]\n",
      "loss: 0.585297  [51200/60000]\n",
      "loss: 0.415224  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.474703 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.332519  [    0/60000]\n",
      "loss: 0.471564  [ 6400/60000]\n",
      "loss: 0.294953  [12800/60000]\n",
      "loss: 0.507395  [19200/60000]\n",
      "loss: 0.432779  [25600/60000]\n",
      "loss: 0.462187  [32000/60000]\n",
      "loss: 0.458287  [38400/60000]\n",
      "loss: 0.638657  [44800/60000]\n",
      "loss: 0.583803  [51200/60000]\n",
      "loss: 0.413635  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.473342 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

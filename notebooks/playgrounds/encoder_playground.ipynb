{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_models_and_utils/encoder\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "import network_models.soundsream_models_and_utils.encoder.ss_encoder_downmapping as ed\n",
    "importlib.reload(ed)\n",
    "from network_models.soundsream_models_and_utils.encoder.transformer import Encoder\n",
    "\n",
    "#encoder = Encoder(vocab_size=1024, embed_dim=512, n_heads=1, ff_dim=0, n_layers=2, dropout=0)\n",
    "encoder = ed.EncoderDownmapping(embed_dim=512, n_heads=4, ff_dim=2, n_layers=1, dropout=0, output=1024, max_seq_len=175).to(device)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 12:02:46.824484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-16 12:02:47.491311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-16 12:02:47.491373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-16 12:02:47.491378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings.pkl\", device=\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# data_set[0][0][0].T[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_models_and_utils/encoder\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "torch.unsqueeze(data_set[0][0][0].T,0).shape\n",
    "\n",
    "batch = torch.stack([ data_set[1][0][0], data_set[0][0][0], data_set[2][0][0], data_set[3][0][0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# batch = torch.stack([ data_set[1][0][0].T, data_set[0][0][0].T, data_set[2][0][0].T, data_set[3][0][0].T])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "batch = torch.transpose(batch, 1,2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 175, 512])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 175, 512])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_emo = [data_set[0][1], data_set[1][1], data_set[2][1], data_set[3][1]]\n",
    "batch.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 1024])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    encoder = encoder.to(\"cpu\")\n",
    "    x = encoder(batch)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoder1 = encoder.to(\"cuda\")\n",
    "    batch1 = batch.to(\"cuda\")\n",
    "    x_cuda = encoder1(batch1)\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.0999e+00,  1.5010e+00, -5.8182e-01,  ...,  1.0235e-01,\n",
      "           1.0431e+00,  1.3878e+00],\n",
      "         [-1.2212e+00, -8.2663e-02,  2.2457e-02,  ...,  3.1075e-01,\n",
      "           2.2923e-01,  8.4323e-01],\n",
      "         [-1.0300e+00, -3.5000e-01,  6.2621e-01,  ...,  1.0394e+00,\n",
      "          -3.0595e-01,  1.7874e-01],\n",
      "         ...,\n",
      "         [-6.2423e+00,  1.8420e+00, -7.6485e-01,  ..., -4.3404e-01,\n",
      "           1.6344e+00,  1.8389e+00],\n",
      "         [-6.1685e+00,  1.9278e+00, -7.4513e-01,  ..., -4.5462e-01,\n",
      "           1.6922e+00,  1.8381e+00],\n",
      "         [-6.2048e+00,  1.9243e+00, -7.4410e-01,  ..., -4.4282e-01,\n",
      "           1.6600e+00,  1.8191e+00]],\n",
      "\n",
      "        [[-2.3367e+00,  1.6229e+00, -2.9810e-01,  ...,  2.0379e-01,\n",
      "           1.0990e+00,  1.3267e+00],\n",
      "         [-1.6375e+00,  7.5411e-02,  3.3088e-01,  ...,  5.0821e-01,\n",
      "           2.5376e-01,  9.4094e-01],\n",
      "         [-1.3727e+00, -2.5153e-01,  9.4419e-01,  ...,  1.1065e+00,\n",
      "          -3.5122e-01,  1.3705e-01],\n",
      "         ...,\n",
      "         [-2.5371e+00,  1.2031e+00,  9.0726e-01,  ...,  8.9288e-01,\n",
      "          -9.6375e-01,  6.8689e-01],\n",
      "         [-2.5353e+00,  1.1988e+00,  9.2843e-01,  ...,  8.8895e-01,\n",
      "          -9.3930e-01,  6.7064e-01],\n",
      "         [-1.3251e+00,  1.7883e+00, -1.9286e-01,  ...,  1.0835e+00,\n",
      "          -1.2741e+00,  3.8863e-01]],\n",
      "\n",
      "        [[-2.2045e+00,  1.5727e+00, -3.6236e-01,  ...,  1.9561e-01,\n",
      "           1.0971e+00,  1.3750e+00],\n",
      "         [-1.3060e+00, -2.9123e-02,  2.3921e-01,  ...,  3.8212e-01,\n",
      "           2.8762e-01,  8.6017e-01],\n",
      "         [-1.1245e+00, -2.9821e-01,  8.3829e-01,  ...,  1.1083e+00,\n",
      "          -2.4553e-01,  1.9211e-01],\n",
      "         ...,\n",
      "         [-9.9561e+00,  3.3368e+00, -6.3301e-02,  ..., -9.6854e-01,\n",
      "           7.5672e-01,  1.6697e+00],\n",
      "         [-9.9655e+00,  3.3220e+00, -7.2525e-02,  ..., -9.5214e-01,\n",
      "           7.3521e-01,  1.6786e+00],\n",
      "         [-9.9981e+00,  3.2907e+00, -5.3287e-02,  ..., -9.2727e-01,\n",
      "           6.9953e-01,  1.6509e+00]],\n",
      "\n",
      "        [[-2.2396e+00,  1.5930e+00, -3.9794e-01,  ...,  1.5256e-01,\n",
      "           1.0416e+00,  1.3580e+00],\n",
      "         [-1.3551e+00, -6.1464e-04,  2.0464e-01,  ...,  3.4002e-01,\n",
      "           2.1826e-01,  8.4142e-01],\n",
      "         [-1.1700e+00, -2.7003e-01,  8.0345e-01,  ...,  1.0626e+00,\n",
      "          -3.1841e-01,  1.6993e-01],\n",
      "         ...,\n",
      "         [-7.4719e+00,  1.9963e+00, -6.2346e-04,  ..., -1.2691e+00,\n",
      "           1.2163e+00,  1.1778e+00],\n",
      "         [-7.5928e+00,  2.1923e+00, -4.4313e-01,  ..., -1.3148e+00,\n",
      "           1.1594e+00,  1.4881e+00],\n",
      "         [-7.6176e+00,  2.2772e+00, -1.8242e-01,  ..., -1.0084e+00,\n",
      "           1.3211e+00,  1.3808e+00]]])\n",
      "tensor([[[-2.0999e+00,  1.5010e+00, -5.8182e-01,  ...,  1.0235e-01,\n",
      "           1.0431e+00,  1.3878e+00],\n",
      "         [-1.2212e+00, -8.2663e-02,  2.2457e-02,  ...,  3.1075e-01,\n",
      "           2.2923e-01,  8.4323e-01],\n",
      "         [-1.0300e+00, -3.5000e-01,  6.2621e-01,  ...,  1.0394e+00,\n",
      "          -3.0595e-01,  1.7874e-01],\n",
      "         ...,\n",
      "         [-6.2423e+00,  1.8420e+00, -7.6485e-01,  ..., -4.3404e-01,\n",
      "           1.6344e+00,  1.8389e+00],\n",
      "         [-6.1685e+00,  1.9278e+00, -7.4513e-01,  ..., -4.5462e-01,\n",
      "           1.6922e+00,  1.8381e+00],\n",
      "         [-6.2048e+00,  1.9243e+00, -7.4410e-01,  ..., -4.4282e-01,\n",
      "           1.6600e+00,  1.8191e+00]],\n",
      "\n",
      "        [[-2.3367e+00,  1.6229e+00, -2.9810e-01,  ...,  2.0379e-01,\n",
      "           1.0990e+00,  1.3267e+00],\n",
      "         [-1.6375e+00,  7.5411e-02,  3.3088e-01,  ...,  5.0821e-01,\n",
      "           2.5376e-01,  9.4094e-01],\n",
      "         [-1.3727e+00, -2.5153e-01,  9.4419e-01,  ...,  1.1065e+00,\n",
      "          -3.5122e-01,  1.3705e-01],\n",
      "         ...,\n",
      "         [-2.5371e+00,  1.2031e+00,  9.0726e-01,  ...,  8.9288e-01,\n",
      "          -9.6375e-01,  6.8689e-01],\n",
      "         [-2.5353e+00,  1.1988e+00,  9.2843e-01,  ...,  8.8895e-01,\n",
      "          -9.3930e-01,  6.7064e-01],\n",
      "         [-1.3251e+00,  1.7883e+00, -1.9286e-01,  ...,  1.0835e+00,\n",
      "          -1.2741e+00,  3.8863e-01]],\n",
      "\n",
      "        [[-2.2045e+00,  1.5727e+00, -3.6236e-01,  ...,  1.9561e-01,\n",
      "           1.0971e+00,  1.3750e+00],\n",
      "         [-1.3060e+00, -2.9123e-02,  2.3921e-01,  ...,  3.8212e-01,\n",
      "           2.8762e-01,  8.6017e-01],\n",
      "         [-1.1245e+00, -2.9821e-01,  8.3829e-01,  ...,  1.1083e+00,\n",
      "          -2.4553e-01,  1.9211e-01],\n",
      "         ...,\n",
      "         [-9.9561e+00,  3.3368e+00, -6.3301e-02,  ..., -9.6854e-01,\n",
      "           7.5672e-01,  1.6697e+00],\n",
      "         [-9.9655e+00,  3.3220e+00, -7.2525e-02,  ..., -9.5214e-01,\n",
      "           7.3521e-01,  1.6786e+00],\n",
      "         [-9.9981e+00,  3.2907e+00, -5.3287e-02,  ..., -9.2727e-01,\n",
      "           6.9953e-01,  1.6509e+00]],\n",
      "\n",
      "        [[-2.2396e+00,  1.5930e+00, -3.9794e-01,  ...,  1.5256e-01,\n",
      "           1.0416e+00,  1.3580e+00],\n",
      "         [-1.3551e+00, -6.1464e-04,  2.0464e-01,  ...,  3.4002e-01,\n",
      "           2.1826e-01,  8.4142e-01],\n",
      "         [-1.1700e+00, -2.7003e-01,  8.0345e-01,  ...,  1.0626e+00,\n",
      "          -3.1841e-01,  1.6993e-01],\n",
      "         ...,\n",
      "         [-7.4719e+00,  1.9963e+00, -6.2346e-04,  ..., -1.2691e+00,\n",
      "           1.2163e+00,  1.1778e+00],\n",
      "         [-7.5928e+00,  2.1923e+00, -4.4313e-01,  ..., -1.3148e+00,\n",
      "           1.1594e+00,  1.4881e+00],\n",
      "         [-7.6176e+00,  2.2772e+00, -1.8242e-01,  ..., -1.0084e+00,\n",
      "           1.3211e+00,  1.3808e+00]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch)\n",
    "print(batch1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[345.9051, 261.1588, 311.9456, 299.9271],\n",
      "        [261.1588, 335.4135, 261.3019, 260.6291],\n",
      "        [311.9456, 261.3019, 341.6087, 302.7792],\n",
      "        [299.9271, 260.6291, 302.7792, 337.2212]]) tensor([[345.9051, 261.1589, 311.9456, 299.9271],\n",
      "        [261.1589, 335.4135, 261.3019, 260.6291],\n",
      "        [311.9456, 261.3019, 341.6087, 302.7791],\n",
      "        [299.9271, 260.6291, 302.7791, 337.2211]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "mul = torch.matmul(x, x.T)\n",
    "F.softmax(mul/np.sqrt(torch.sum(torch.matmul(x, x.T), dim=0)), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "mul_cuda = torch.matmul(x_cuda, x_cuda.T)\n",
    "\n",
    "print(mul, mul_cuda)\n",
    "\n",
    "# x1=torch.dot(x[0],x[0])\n",
    "# x2=torch.dot(x[0],x[1])\n",
    "# x3=torch.dot(x[0],x[2])\n",
    "# x4=torch.dot(x[0],x[3])\n",
    "# calcLoss=[]\n",
    "# for elem in x:\n",
    "#     calcLoss.append(torch.dot(elem, x[0]))\n",
    "#     calcLoss.append(torch.dot(elem, x[1]))\n",
    "#     calcLoss.append(torch.dot(elem, x[2]))\n",
    "#     calcLoss.append(torch.dot(elem, x[3]))\n",
    "# t = torch.reshape(torch.asarray(calcLoss), (4,4))\n",
    "# #torch.softmax(t[0]/340, dim=0)\n",
    "# t\n",
    "# #F.softmax(t[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_932512/2714952727.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(torch.tensor(np.asarray([-20, 0.1, 0.2])))\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([8.8592e-10, 4.7502e-01, 5.2498e-01], dtype=torch.float64)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder.parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.]])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[352.3570, 285.2893, 318.3849, 310.8500],\n        [285.2893, 360.8303, 283.4177, 289.1945],\n        [318.3849, 283.4177, 347.4364, 307.3763],\n        [310.8500, 289.1945, 307.3763, 356.1323]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul = torch.matmul(x, x.T)\n",
    "mul"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mF\u001B[49m\u001B[38;5;241m.\u001B[39msoftmax(torch\u001B[38;5;241m.\u001B[39mmatmul(x, x\u001B[38;5;241m.\u001B[39mT)\u001B[38;5;241m/\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(torch\u001B[38;5;241m.\u001B[39mmatmul(x, x\u001B[38;5;241m.\u001B[39mT), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "F.softmax(torch.matmul(x, x.T)/ torch.sum(torch.matmul(x, x.T), dim=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 998.2489, 1117.8684, 1119.7424, 1106.6016])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.matmul(x, x.T), dim=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5410, 0.0850, 0.2286, 0.1660],\n        [0.0822, 0.7395, 0.0852, 0.0902],\n        [0.2083, 0.0805, 0.5187, 0.1505],\n        [0.1685, 0.0950, 0.1675, 0.5933]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = torch.max(mul, dim=0)[0]\n",
    "F.softmax(mul/np.sqrt(torch.sum(torch.matmul(x, x.T), dim=0)), dim=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.7136, 0.0195, 0.1759, 0.1184],\n        [0.0166, 0.9355, 0.0178, 0.0249],\n        [0.1697, 0.0202, 0.6930, 0.1295],\n        [0.1000, 0.0247, 0.1134, 0.7272]])"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(mul/np.sqrt(1024), dim=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

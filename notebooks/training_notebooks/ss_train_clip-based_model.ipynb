{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 13:58:51.389107: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 13:58:51.849502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-25 13:58:51.849561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-25 13:58:51.849565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from network_models.soundsream_models_and_utils.clip_like.encoder.ss_dims_class_model import SS_Enc_Class_Dims\n",
    "from network_models.soundsream_models_and_utils.ss_encoderbased_model import SSClipBasedModel\n",
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "import gc\n",
    "\n",
    "from network_models.soundsream_models_and_utils.ss_wrapper_trainer_experiments import ExperimentsTrainer\n",
    "import torch\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 8\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/\"\n",
    "safe_model_every = 500\n",
    "epochs = 15001\n",
    "save_highest_acc_min_acc = 0.5\n",
    "lr = 1e-5\n",
    "gc.collect()\n",
    "\n",
    "# data_set= ss_encoded_dataset_full(\n",
    "#     csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings_clip_like.pkl\", device=\"cuda\")\n",
    "# trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "#\n",
    "# torch.manual_seed(300)\n",
    "# model = SSClipBasedModel(dropout=0.3).to(device)\n",
    "\n",
    "\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings_clip_like_tessBased_noCafe.pkl\", device=\"cuda\")\n",
    "trainDS, valDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "trainDS, testDs = train_val_dataset(trainDS, val_split=0.1, seed=100)\n",
    "torch.manual_seed(33333)\n",
    "#model = SS_Enc_Class_Dims().to(device)\n",
    "model = SSClipBasedModel().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.745208  [    0/ 4176]\n",
      "loss: 0.163839  [  800/ 4176]\n",
      "loss: 0.531979  [ 1600/ 4176]\n",
      "loss: 1.061602  [ 2400/ 4176]\n",
      "loss: 1.377526  [ 3200/ 4176]\n",
      "loss: 1.211050  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.597     0.800     0.533    60\n",
      " disgust     0.597     0.560     0.610    77\n",
      "    fear     0.597     0.559     0.514    74\n",
      "   happy     0.597     0.495     0.684    76\n",
      " neutral     0.597     0.789     0.517    58\n",
      "     sad     0.597     0.530     0.611    72\n",
      "surprise     0.597     0.739     0.723    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.597     0.639     0.599    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 1.066759 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep0_acc_60.md \n",
      "\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep0_acc_60\"!  new accuracy: 59.7\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.191379  [    0/ 4176]\n",
      "loss: 1.069217  [  800/ 4176]\n",
      "loss: 0.546683  [ 1600/ 4176]\n",
      "loss: 0.977943  [ 2400/ 4176]\n",
      "loss: 0.465531  [ 3200/ 4176]\n",
      "loss: 1.596308  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.625     0.769     0.500    60\n",
      " disgust     0.625     0.529     0.597    77\n",
      "    fear     0.625     0.597     0.622    74\n",
      "   happy     0.625     0.525     0.697    76\n",
      " neutral     0.625     0.791     0.586    58\n",
      "     sad     0.625     0.638     0.611    72\n",
      "surprise     0.625     0.771     0.787    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.625     0.660     0.629    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.046464 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep1_acc_62.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep0_acc_60\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep1_acc_62\"! Old accuracy: 59.7, new accuracy: 62.5\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.943112  [    0/ 4176]\n",
      "loss: 1.240308  [  800/ 4176]\n",
      "loss: 0.688376  [ 1600/ 4176]\n",
      "loss: 1.878292  [ 2400/ 4176]\n",
      "loss: 0.759374  [ 3200/ 4176]\n",
      "loss: 0.979037  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.627     0.721     0.517    60\n",
      " disgust     0.627     0.580     0.610    77\n",
      "    fear     0.627     0.611     0.595    74\n",
      "   happy     0.627     0.509     0.711    76\n",
      " neutral     0.627     0.773     0.586    58\n",
      "     sad     0.627     0.662     0.597    72\n",
      "surprise     0.627     0.717     0.809    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.627     0.653     0.632    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.042519 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep2_acc_63.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep1_acc_62\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep2_acc_63\"! Old accuracy: 62.5, new accuracy: 62.7\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.151383  [    0/ 4176]\n",
      "loss: 0.605723  [  800/ 4176]\n",
      "loss: 1.417231  [ 1600/ 4176]\n",
      "loss: 0.673302  [ 2400/ 4176]\n",
      "loss: 0.839742  [ 3200/ 4176]\n",
      "loss: 0.449119  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.629     0.775     0.517    60\n",
      " disgust     0.629     0.632     0.558    77\n",
      "    fear     0.629     0.591     0.703    74\n",
      "   happy     0.629     0.505     0.724    76\n",
      " neutral     0.629     0.842     0.552    58\n",
      "     sad     0.629     0.579     0.611    72\n",
      "surprise     0.629     0.778     0.745    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.629     0.672     0.630    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.051979 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep3_acc_63.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep2_acc_63\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep3_acc_63\"! Old accuracy: 62.7, new accuracy: 62.9\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.716934  [    0/ 4176]\n",
      "loss: 0.914407  [  800/ 4176]\n",
      "loss: 0.733558  [ 1600/ 4176]\n",
      "loss: 0.529712  [ 2400/ 4176]\n",
      "loss: 1.373043  [ 3200/ 4176]\n",
      "loss: 0.610055  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.634     0.825     0.550    60\n",
      " disgust     0.634     0.553     0.610    77\n",
      "    fear     0.634     0.600     0.649    74\n",
      "   happy     0.634     0.584     0.684    76\n",
      " neutral     0.634     0.868     0.569    58\n",
      "     sad     0.634     0.564     0.611    72\n",
      "surprise     0.634     0.685     0.787    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.634     0.669     0.637    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.036103 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep4_acc_63.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep3_acc_63\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep4_acc_63\"! Old accuracy: 62.9, new accuracy: 63.4\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.998721  [    0/ 4176]\n",
      "loss: 0.446323  [  800/ 4176]\n",
      "loss: 0.916260  [ 1600/ 4176]\n",
      "loss: 0.800164  [ 2400/ 4176]\n",
      "loss: 0.759535  [ 3200/ 4176]\n",
      "loss: 0.621434  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.625     0.723     0.567    60\n",
      " disgust     0.625     0.616     0.584    77\n",
      "    fear     0.625     0.553     0.635    74\n",
      "   happy     0.625     0.573     0.671    76\n",
      " neutral     0.625     0.821     0.552    58\n",
      "     sad     0.625     0.597     0.597    72\n",
      "surprise     0.625     0.644     0.809    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.625     0.647     0.631    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.036716 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.667382  [    0/ 4176]\n",
      "loss: 1.188443  [  800/ 4176]\n",
      "loss: 0.677769  [ 1600/ 4176]\n",
      "loss: 1.218183  [ 2400/ 4176]\n",
      "loss: 0.354760  [ 3200/ 4176]\n",
      "loss: 0.667247  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.636     0.706     0.600    60\n",
      " disgust     0.636     0.511     0.623    77\n",
      "    fear     0.636     0.667     0.622    74\n",
      "   happy     0.636     0.553     0.684    76\n",
      " neutral     0.636     0.872     0.586    58\n",
      "     sad     0.636     0.632     0.597    72\n",
      "surprise     0.636     0.735     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.636     0.668     0.640    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.040148 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep6_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep4_acc_63\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep6_acc_64\"! Old accuracy: 63.4, new accuracy: 63.6\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.438010  [    0/ 4176]\n",
      "loss: 0.281843  [  800/ 4176]\n",
      "loss: 1.587226  [ 1600/ 4176]\n",
      "loss: 1.049703  [ 2400/ 4176]\n",
      "loss: 1.207385  [ 3200/ 4176]\n",
      "loss: 0.919103  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.634     0.667     0.533    60\n",
      " disgust     0.634     0.611     0.571    77\n",
      "    fear     0.634     0.575     0.676    74\n",
      "   happy     0.634     0.547     0.684    76\n",
      " neutral     0.634     0.778     0.603    58\n",
      "     sad     0.634     0.620     0.611    72\n",
      "surprise     0.634     0.804     0.787    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.634     0.657     0.638    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.053860 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.869487  [    0/ 4176]\n",
      "loss: 0.554444  [  800/ 4176]\n",
      "loss: 0.702351  [ 1600/ 4176]\n",
      "loss: 1.262039  [ 2400/ 4176]\n",
      "loss: 0.854039  [ 3200/ 4176]\n",
      "loss: 1.419263  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.640     0.833     0.583    60\n",
      " disgust     0.640     0.652     0.558    77\n",
      "    fear     0.640     0.562     0.730    74\n",
      "   happy     0.640     0.515     0.697    76\n",
      " neutral     0.640     0.872     0.586    58\n",
      "     sad     0.640     0.579     0.611    72\n",
      "surprise     0.640     0.810     0.723    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.640     0.689     0.641    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.038062 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep8_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep6_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep8_acc_64\"! Old accuracy: 63.6, new accuracy: 64.0\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.072399  [    0/ 4176]\n",
      "loss: 2.066223  [  800/ 4176]\n",
      "loss: 0.586376  [ 1600/ 4176]\n",
      "loss: 0.371305  [ 2400/ 4176]\n",
      "loss: 0.457230  [ 3200/ 4176]\n",
      "loss: 0.593188  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.625     0.714     0.583    60\n",
      " disgust     0.625     0.623     0.558    77\n",
      "    fear     0.625     0.636     0.662    74\n",
      "   happy     0.625     0.510     0.697    76\n",
      " neutral     0.625     0.941     0.552    58\n",
      "     sad     0.625     0.517     0.625    72\n",
      "surprise     0.625     0.750     0.702    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.625     0.670     0.626    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.047618 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.587908  [    0/ 4176]\n",
      "loss: 0.395554  [  800/ 4176]\n",
      "loss: 0.694635  [ 1600/ 4176]\n",
      "loss: 0.236957  [ 2400/ 4176]\n",
      "loss: 0.734996  [ 3200/ 4176]\n",
      "loss: 0.605122  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.629     0.642     0.567    60\n",
      " disgust     0.629     0.608     0.584    77\n",
      "    fear     0.629     0.605     0.662    74\n",
      "   happy     0.629     0.527     0.645    76\n",
      " neutral     0.629     0.837     0.621    58\n",
      "     sad     0.629     0.614     0.597    72\n",
      "surprise     0.629     0.720     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.629     0.650     0.635    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.064437 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.934760  [    0/ 4176]\n",
      "loss: 0.555327  [  800/ 4176]\n",
      "loss: 0.960573  [ 1600/ 4176]\n",
      "loss: 0.498382  [ 2400/ 4176]\n",
      "loss: 0.743022  [ 3200/ 4176]\n",
      "loss: 1.286437  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.625     0.647     0.550    60\n",
      " disgust     0.625     0.600     0.584    77\n",
      "    fear     0.625     0.622     0.689    74\n",
      "   happy     0.625     0.526     0.671    76\n",
      " neutral     0.625     0.868     0.569    58\n",
      "     sad     0.625     0.603     0.611    72\n",
      "surprise     0.625     0.688     0.702    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.625     0.650     0.625    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.053095 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.678012  [    0/ 4176]\n",
      "loss: 0.743981  [  800/ 4176]\n",
      "loss: 0.816923  [ 1600/ 4176]\n",
      "loss: 1.127067  [ 2400/ 4176]\n",
      "loss: 0.238046  [ 3200/ 4176]\n",
      "loss: 0.947903  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.631     0.727     0.533    60\n",
      " disgust     0.631     0.632     0.558    77\n",
      "    fear     0.631     0.598     0.662    74\n",
      "   happy     0.631     0.565     0.684    76\n",
      " neutral     0.631     0.773     0.586    58\n",
      "     sad     0.631     0.570     0.625    72\n",
      "surprise     0.631     0.691     0.809    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.631     0.651     0.637    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 1.052527 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.113067  [    0/ 4176]\n",
      "loss: 0.473595  [  800/ 4176]\n",
      "loss: 0.856372  [ 1600/ 4176]\n",
      "loss: 1.032596  [ 2400/ 4176]\n",
      "loss: 0.477086  [ 3200/ 4176]\n",
      "loss: 0.862795  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.634     0.825     0.550    60\n",
      " disgust     0.634     0.642     0.558    77\n",
      "    fear     0.634     0.542     0.703    74\n",
      "   happy     0.634     0.554     0.671    76\n",
      " neutral     0.634     0.791     0.586    58\n",
      "     sad     0.634     0.582     0.639    72\n",
      "surprise     0.634     0.745     0.745    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.634     0.669     0.636    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.052135 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.364086  [    0/ 4176]\n",
      "loss: 0.425298  [  800/ 4176]\n",
      "loss: 0.245543  [ 1600/ 4176]\n",
      "loss: 0.533741  [ 2400/ 4176]\n",
      "loss: 0.981630  [ 3200/ 4176]\n",
      "loss: 0.567227  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.623     0.673     0.550    60\n",
      " disgust     0.623     0.562     0.584    77\n",
      "    fear     0.623     0.654     0.689    74\n",
      "   happy     0.623     0.545     0.632    76\n",
      " neutral     0.623     0.850     0.586    58\n",
      "     sad     0.623     0.536     0.625    72\n",
      "surprise     0.623     0.733     0.702    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.623     0.651     0.624    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.074810 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.549478  [    0/ 4176]\n",
      "loss: 0.975623  [  800/ 4176]\n",
      "loss: 1.102095  [ 1600/ 4176]\n",
      "loss: 0.594713  [ 2400/ 4176]\n",
      "loss: 0.852032  [ 3200/ 4176]\n",
      "loss: 1.205676  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.614     0.702     0.550    60\n",
      " disgust     0.614     0.544     0.558    77\n",
      "    fear     0.614     0.644     0.635    74\n",
      "   happy     0.614     0.500     0.671    76\n",
      " neutral     0.614     0.825     0.569    58\n",
      "     sad     0.614     0.568     0.583    72\n",
      "surprise     0.614     0.735     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.614     0.645     0.619    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.058277 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.259244  [    0/ 4176]\n",
      "loss: 0.868513  [  800/ 4176]\n",
      "loss: 1.434024  [ 1600/ 4176]\n",
      "loss: 0.803892  [ 2400/ 4176]\n",
      "loss: 1.063514  [ 3200/ 4176]\n",
      "loss: 0.886393  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.625     0.596     0.567    60\n",
      " disgust     0.625     0.642     0.558    77\n",
      "    fear     0.625     0.551     0.662    74\n",
      "   happy     0.625     0.567     0.671    76\n",
      " neutral     0.625     0.846     0.569    58\n",
      "     sad     0.625     0.642     0.597    72\n",
      "surprise     0.625     0.673     0.787    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.625     0.645     0.630    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.079210 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.840333  [    0/ 4176]\n",
      "loss: 0.610426  [  800/ 4176]\n",
      "loss: 0.520335  [ 1600/ 4176]\n",
      "loss: 0.320114  [ 2400/ 4176]\n",
      "loss: 1.197837  [ 3200/ 4176]\n",
      "loss: 1.122421  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.642     0.766     0.600    60\n",
      " disgust     0.642     0.573     0.610    77\n",
      "    fear     0.642     0.558     0.716    74\n",
      "   happy     0.642     0.591     0.684    76\n",
      " neutral     0.642     0.892     0.569    58\n",
      "     sad     0.642     0.594     0.569    72\n",
      "surprise     0.642     0.783     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.642     0.680     0.645    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.045438 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep17_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep8_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep17_acc_64\"! Old accuracy: 64.0, new accuracy: 64.2\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.308212  [    0/ 4176]\n",
      "loss: 0.570154  [  800/ 4176]\n",
      "loss: 0.572389  [ 1600/ 4176]\n",
      "loss: 0.542264  [ 2400/ 4176]\n",
      "loss: 1.094813  [ 3200/ 4176]\n",
      "loss: 1.188448  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.636     0.700     0.583    60\n",
      " disgust     0.636     0.588     0.610    77\n",
      "    fear     0.636     0.636     0.662    74\n",
      "   happy     0.636     0.581     0.658    76\n",
      " neutral     0.636     0.814     0.603    58\n",
      "     sad     0.636     0.564     0.611    72\n",
      "surprise     0.636     0.700     0.745    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.636     0.655     0.639    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.035124 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.651880  [    0/ 4176]\n",
      "loss: 0.621199  [  800/ 4176]\n",
      "loss: 0.570476  [ 1600/ 4176]\n",
      "loss: 0.312143  [ 2400/ 4176]\n",
      "loss: 0.842342  [ 3200/ 4176]\n",
      "loss: 0.623411  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.634     0.739     0.567    60\n",
      " disgust     0.634     0.565     0.623    77\n",
      "    fear     0.634     0.610     0.676    74\n",
      "   happy     0.634     0.578     0.632    76\n",
      " neutral     0.634     0.875     0.603    58\n",
      "     sad     0.634     0.566     0.597    72\n",
      "surprise     0.634     0.692     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.634     0.661     0.638    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.045204 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.835110  [    0/ 4176]\n",
      "loss: 1.039840  [  800/ 4176]\n",
      "loss: 0.696095  [ 1600/ 4176]\n",
      "loss: 0.445282  [ 2400/ 4176]\n",
      "loss: 0.864442  [ 3200/ 4176]\n",
      "loss: 0.738580  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.631     0.773     0.567    60\n",
      " disgust     0.631     0.527     0.636    77\n",
      "    fear     0.631     0.613     0.662    74\n",
      "   happy     0.631     0.556     0.658    76\n",
      " neutral     0.631     0.850     0.586    58\n",
      "     sad     0.631     0.631     0.569    72\n",
      "surprise     0.631     0.692     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.631     0.663     0.635    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 1.034083 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.477953  [    0/ 4176]\n",
      "loss: 1.301413  [  800/ 4176]\n",
      "loss: 1.621124  [ 1600/ 4176]\n",
      "loss: 0.885847  [ 2400/ 4176]\n",
      "loss: 0.845261  [ 3200/ 4176]\n",
      "loss: 0.947008  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.631     0.780     0.533    60\n",
      " disgust     0.631     0.600     0.623    77\n",
      "    fear     0.631     0.527     0.649    74\n",
      "   happy     0.631     0.580     0.671    76\n",
      " neutral     0.631     0.865     0.552    58\n",
      "     sad     0.631     0.613     0.639    72\n",
      "surprise     0.631     0.692     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.631     0.665     0.633    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 1.048630 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.590766  [    0/ 4176]\n",
      "loss: 0.492120  [  800/ 4176]\n",
      "loss: 0.553165  [ 1600/ 4176]\n",
      "loss: 1.568471  [ 2400/ 4176]\n",
      "loss: 1.099886  [ 3200/ 4176]\n",
      "loss: 0.652067  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.638     0.756     0.517    60\n",
      " disgust     0.638     0.605     0.636    77\n",
      "    fear     0.638     0.540     0.730    74\n",
      "   happy     0.638     0.595     0.618    76\n",
      " neutral     0.638     0.872     0.586    58\n",
      "     sad     0.638     0.595     0.611    72\n",
      "surprise     0.638     0.740     0.787    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.638     0.672     0.641    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.035768 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.771041  [    0/ 4176]\n",
      "loss: 0.576854  [  800/ 4176]\n",
      "loss: 1.038222  [ 1600/ 4176]\n",
      "loss: 0.494001  [ 2400/ 4176]\n",
      "loss: 0.651885  [ 3200/ 4176]\n",
      "loss: 1.275083  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.625     0.825     0.550    60\n",
      " disgust     0.625     0.579     0.571    77\n",
      "    fear     0.625     0.519     0.730    74\n",
      "   happy     0.625     0.556     0.658    76\n",
      " neutral     0.625     0.919     0.586    58\n",
      "     sad     0.625     0.579     0.611    72\n",
      "surprise     0.625     0.756     0.660    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.625     0.676     0.624    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.035894 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.902446  [    0/ 4176]\n",
      "loss: 0.905593  [  800/ 4176]\n",
      "loss: 0.467903  [ 1600/ 4176]\n",
      "loss: 0.853766  [ 2400/ 4176]\n",
      "loss: 1.194013  [ 3200/ 4176]\n",
      "loss: 0.674195  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.649     0.762     0.533    60\n",
      " disgust     0.649     0.608     0.623    77\n",
      "    fear     0.649     0.564     0.716    74\n",
      "   happy     0.649     0.595     0.658    76\n",
      " neutral     0.649     0.875     0.603    58\n",
      "     sad     0.649     0.625     0.625    72\n",
      "surprise     0.649     0.717     0.809    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.649     0.678     0.653    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.017254 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep24_acc_65.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep17_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_clip/Nr3_noCafe/emo_reco_best_ep24_acc_65\"! Old accuracy: 64.2, new accuracy: 64.9\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.309849  [    0/ 4176]\n",
      "loss: 0.446055  [  800/ 4176]\n",
      "loss: 1.004314  [ 1600/ 4176]\n",
      "loss: 0.642153  [ 2400/ 4176]\n",
      "loss: 0.459620  [ 3200/ 4176]\n",
      "loss: 0.637437  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.638     0.694     0.567    60\n",
      " disgust     0.638     0.586     0.662    77\n",
      "    fear     0.638     0.568     0.622    74\n",
      "   happy     0.638     0.635     0.618    76\n",
      " neutral     0.638     0.725     0.638    58\n",
      "     sad     0.638     0.647     0.611    72\n",
      "surprise     0.638     0.685     0.787    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.638     0.649     0.644    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.047607 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.702214  [    0/ 4176]\n",
      "loss: 0.859718  [  800/ 4176]\n",
      "loss: 1.059039  [ 1600/ 4176]\n",
      "loss: 1.022716  [ 2400/ 4176]\n",
      "loss: 0.255010  [ 3200/ 4176]\n",
      "loss: 0.893516  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.612     0.846     0.550    60\n",
      " disgust     0.612     0.621     0.532    77\n",
      "    fear     0.612     0.486     0.716    74\n",
      "   happy     0.612     0.571     0.632    76\n",
      " neutral     0.612     0.821     0.552    58\n",
      "     sad     0.612     0.517     0.625    72\n",
      "surprise     0.612     0.800     0.681    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.612     0.666     0.613    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.040800 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.625385  [    0/ 4176]\n",
      "loss: 0.730356  [  800/ 4176]\n",
      "loss: 0.824778  [ 1600/ 4176]\n",
      "loss: 1.303884  [ 2400/ 4176]\n",
      "loss: 0.412374  [ 3200/ 4176]\n",
      "loss: 1.113173  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.631     0.688     0.550    60\n",
      " disgust     0.631     0.608     0.584    77\n",
      "    fear     0.631     0.548     0.689    74\n",
      "   happy     0.631     0.598     0.645    76\n",
      " neutral     0.631     0.868     0.569    58\n",
      "     sad     0.631     0.597     0.639    72\n",
      "surprise     0.631     0.692     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.631     0.657     0.635    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 1.044659 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.745883  [    0/ 4176]\n",
      "loss: 0.608266  [  800/ 4176]\n",
      "loss: 0.684889  [ 1600/ 4176]\n",
      "loss: 1.072512  [ 2400/ 4176]\n",
      "loss: 0.722247  [ 3200/ 4176]\n",
      "loss: 0.592822  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.621     0.786     0.550    60\n",
      " disgust     0.621     0.579     0.571    77\n",
      "    fear     0.621     0.522     0.649    74\n",
      "   happy     0.621     0.573     0.618    76\n",
      " neutral     0.621     0.829     0.586    58\n",
      "     sad     0.621     0.577     0.625    72\n",
      "surprise     0.621     0.698     0.787    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.621     0.652     0.627    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1.036677 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.685557  [    0/ 4176]\n",
      "loss: 1.407129  [  800/ 4176]\n",
      "loss: 0.943508  [ 1600/ 4176]\n",
      "loss: 0.624676  [ 2400/ 4176]\n",
      "loss: 0.957811  [ 3200/ 4176]\n",
      "loss: 0.891773  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.623     0.791     0.567    60\n",
      " disgust     0.623     0.475     0.610    77\n",
      "    fear     0.623     0.583     0.662    74\n",
      "   happy     0.623     0.592     0.592    76\n",
      " neutral     0.623     0.868     0.569    58\n",
      "     sad     0.623     0.577     0.625    72\n",
      "surprise     0.623     0.783     0.766    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.623     0.667     0.627    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.065467 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.720449  [    0/ 4176]\n",
      "loss: 0.257023  [  800/ 4176]\n",
      "loss: 0.586335  [ 1600/ 4176]\n",
      "loss: 0.365649  [ 2400/ 4176]\n",
      "loss: 0.398256  [ 3200/ 4176]\n",
      "loss: 0.368850  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.625     0.842     0.533    60\n",
      " disgust     0.625     0.614     0.558    77\n",
      "    fear     0.625     0.509     0.730    74\n",
      "   happy     0.625     0.583     0.645    76\n",
      " neutral     0.625     0.842     0.552    58\n",
      "     sad     0.625     0.549     0.625    72\n",
      "surprise     0.625     0.761     0.745    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.625     0.672     0.627    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.064470 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.753859  [    0/ 4176]\n",
      "loss: 0.329422  [  800/ 4176]\n",
      "loss: 1.015596  [ 1600/ 4176]\n",
      "loss: 0.417814  [ 2400/ 4176]\n",
      "loss: 1.160577  [ 3200/ 4176]\n",
      "loss: 0.533961  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.610     0.750     0.550    60\n",
      " disgust     0.610     0.548     0.597    77\n",
      "    fear     0.610     0.526     0.689    74\n",
      "   happy     0.610     0.529     0.605    76\n",
      " neutral     0.610     0.914     0.552    58\n",
      "     sad     0.610     0.573     0.597    72\n",
      "surprise     0.610     0.762     0.681    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.610     0.657     0.610    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.056088 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.043463  [    0/ 4176]\n",
      "loss: 0.628250  [  800/ 4176]\n",
      "loss: 0.525445  [ 1600/ 4176]\n",
      "loss: 0.502623  [ 2400/ 4176]\n",
      "loss: 0.688265  [ 3200/ 4176]\n",
      "loss: 0.406405  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.621     0.696     0.533    60\n",
      " disgust     0.621     0.592     0.584    77\n",
      "    fear     0.621     0.521     0.676    74\n",
      "   happy     0.621     0.562     0.658    76\n",
      " neutral     0.621     0.868     0.569    58\n",
      "     sad     0.621     0.613     0.639    72\n",
      "surprise     0.621     0.727     0.681    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.621     0.654     0.620    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1.058374 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.602313  [    0/ 4176]\n",
      "loss: 0.568666  [  800/ 4176]\n",
      "loss: 1.334479  [ 1600/ 4176]\n",
      "loss: 1.248128  [ 2400/ 4176]\n",
      "loss: 0.763865  [ 3200/ 4176]\n",
      "loss: 0.567556  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.621     0.681     0.533    60\n",
      " disgust     0.621     0.534     0.610    77\n",
      "    fear     0.621     0.590     0.662    74\n",
      "   happy     0.621     0.575     0.605    76\n",
      " neutral     0.621     0.761     0.603    58\n",
      "     sad     0.621     0.611     0.611    72\n",
      "surprise     0.621     0.729     0.745    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.621     0.640     0.624    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1.068996 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.431460  [    0/ 4176]\n",
      "loss: 1.058104  [  800/ 4176]\n",
      "loss: 0.679599  [ 1600/ 4176]\n",
      "loss: 1.170745  [ 2400/ 4176]\n",
      "loss: 0.480953  [ 3200/ 4176]\n",
      "loss: 0.762331  [ 4000/ 4176]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.631     0.711     0.533    60\n",
      " disgust     0.631     0.564     0.571    77\n",
      "    fear     0.631     0.571     0.703    74\n",
      "   happy     0.631     0.580     0.618    76\n",
      " neutral     0.631     0.857     0.621    58\n",
      "     sad     0.631     0.618     0.653    72\n",
      "surprise     0.631     0.686     0.745    47\n",
      "                                          464\n",
      "\n",
      " \n",
      "     avg     0.631     0.656     0.635    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 1.060603 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.477925  [    0/ 4176]\n",
      "loss: 1.025557  [  800/ 4176]\n",
      "loss: 0.966523  [ 1600/ 4176]\n",
      "loss: 0.590162  [ 2400/ 4176]\n",
      "loss: 0.634461  [ 3200/ 4176]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 19\u001B[0m\n\u001B[1;32m     11\u001B[0m lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-4\u001B[39m\n\u001B[1;32m     12\u001B[0m trainer \u001B[38;5;241m=\u001B[39m sset\u001B[38;5;241m.\u001B[39mSSGenModelTrainer(lr\u001B[38;5;241m=\u001B[39mlr, num_epochs\u001B[38;5;241m=\u001B[39mepochs, model\u001B[38;5;241m=\u001B[39mmodel, train_dataset\u001B[38;5;241m=\u001B[39mtrainDS,\n\u001B[1;32m     13\u001B[0m                             eval_dataset\u001B[38;5;241m=\u001B[39mtestDs,\n\u001B[1;32m     14\u001B[0m                             device\u001B[38;5;241m=\u001B[39mdevice, labelList\u001B[38;5;241m=\u001B[39mdata_set\u001B[38;5;241m.\u001B[39mencoded_dataset\u001B[38;5;241m.\u001B[39mlabel_list,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m                             save_highest_acc_min_acc\u001B[38;5;241m=\u001B[39msave_highest_acc_min_acc,\n\u001B[1;32m     18\u001B[0m                             model_path \u001B[38;5;241m=\u001B[39m models_dir)\n\u001B[0;32m---> 19\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:75\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# this is the trainloop\u001B[39;00m\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;66;03m# --------------------- testloop and evaluation- ---------------\u001B[39;00m\n\u001B[1;32m     78\u001B[0m acc, true, preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loop(test_dataloader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:118\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train_loop\u001B[0;34m(self, dataloader, model, loss_fn, optimizer, epoch)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;66;03m# Backpropagation\u001B[39;00m\n\u001B[1;32m    117\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 118\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_models_and_utils/encoder\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import network_models.soundsream_models_and_utils.ss_trainer_gen_models as sset\n",
    "importlib.reload(sset)\n",
    "\n",
    "lr = 1e-4\n",
    "trainer = sset.SSGenModelTrainer(lr=lr, num_epochs=epochs, model=model, train_dataset=trainDS,\n",
    "                            eval_dataset=testDs,\n",
    "                            device=device, labelList=data_set.encoded_dataset.label_list,\n",
    "                            batch_size=batch_size,\n",
    "                            save_model_every=safe_model_every,\n",
    "                            save_highest_acc_min_acc=save_highest_acc_min_acc,\n",
    "                            model_path = models_dir)\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

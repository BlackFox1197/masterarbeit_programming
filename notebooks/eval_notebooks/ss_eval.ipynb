{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 17:59:10.224841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 17:59:10.677940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 17:59:10.678016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 17:59:10.678021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import SSDimRedModel\n",
    "from network_models.soundsream_models_and_utils.ss_model_conv import SSConvModel3Sec\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from network_models.soundsream_models_and_utils.ss_complex_conv_net import SSComplexConvModel3Sec\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncs_betterSS_12_1_relwrap_music.pkl\", device=\"cuda\")\n",
    "\n",
    "\n",
    "modelDimRed = SSDimRedModel(eval_mode= True).cuda()\n",
    "modelConv = SSConvModel3Sec(xSize=512, ySize=175, eval_mode= True).cuda()\n",
    "modelComplexConv = SSComplexConvModel3Sec(eval_mode=True).to(\"cuda\")\n",
    "\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "trainDS, valDs = train_val_dataset(trainDS, val_split=0.1, seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "#modelConv.load_state_dict(torch.load(\"../content/soundstream/experiments/experiment_v_12_1_NR3_relu/Run_Nr_0/conv/emo_reco_best_ep852_acc_75.pth\"))\n",
    "#modelDimRed.load_state_dict(torch.load(\"../content/soundstream/experiments/experiment_v_12_1_NR3_relu/Run_Nr_0/dimred/emo_reco_best_ep824_acc_70.pth\"))\n",
    "modelDimRed.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep105_acc_96.pth\"))\n",
    "#modelComplexConv.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/conv_complex/Nr2_tess/emo_reco_best_ep92_acc_100.pth\"))\n",
    "#modelComplexConv.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/conv_complex/Nr4/emo_reco_best_ep95_acc_69.pth\"))\n",
    "#modelComplexConv.load_state_dict(torch.load(\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/conv_complex/Nr2_tess/emo_reco_best_ep92_acc_100.pth\"))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from utils.utils__evalutation import evaluate\n",
    "import gc\n",
    "\n",
    "\n",
    "def evaluateLoc(device, model, dataset):\n",
    "\n",
    "    return evaluate(device, model, dataset, batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 6092\n",
      "60 of 6092\n",
      "120 of 6092\n",
      "180 of 6092\n",
      "240 of 6092\n",
      "300 of 6092\n",
      "360 of 6092\n",
      "420 of 6092\n",
      "480 of 6092\n",
      "540 of 6092\n",
      "600 of 6092\n",
      "660 of 6092\n",
      "720 of 6092\n",
      "780 of 6092\n",
      "840 of 6092\n",
      "900 of 6092\n",
      "960 of 6092\n",
      "1020 of 6092\n",
      "1080 of 6092\n",
      "1140 of 6092\n",
      "1200 of 6092\n",
      "1260 of 6092\n",
      "1320 of 6092\n",
      "1380 of 6092\n",
      "1440 of 6092\n",
      "1500 of 6092\n",
      "1560 of 6092\n",
      "1620 of 6092\n",
      "1680 of 6092\n",
      "1740 of 6092\n",
      "1800 of 6092\n",
      "1860 of 6092\n",
      "1920 of 6092\n",
      "1980 of 6092\n",
      "2040 of 6092\n",
      "2100 of 6092\n",
      "2160 of 6092\n",
      "2220 of 6092\n",
      "2280 of 6092\n",
      "2340 of 6092\n",
      "2400 of 6092\n",
      "2460 of 6092\n",
      "2520 of 6092\n",
      "2580 of 6092\n",
      "2640 of 6092\n",
      "2700 of 6092\n",
      "2760 of 6092\n",
      "2820 of 6092\n",
      "2880 of 6092\n",
      "2940 of 6092\n",
      "3000 of 6092\n",
      "3060 of 6092\n",
      "3120 of 6092\n",
      "3180 of 6092\n",
      "3240 of 6092\n",
      "3300 of 6092\n",
      "3360 of 6092\n",
      "3420 of 6092\n",
      "3480 of 6092\n",
      "3540 of 6092\n",
      "3600 of 6092\n",
      "3660 of 6092\n",
      "3720 of 6092\n",
      "3780 of 6092\n",
      "3840 of 6092\n",
      "3900 of 6092\n",
      "3960 of 6092\n",
      "4020 of 6092\n",
      "4080 of 6092\n",
      "4140 of 6092\n",
      "4200 of 6092\n",
      "4260 of 6092\n",
      "4320 of 6092\n",
      "4380 of 6092\n",
      "4440 of 6092\n",
      "4500 of 6092\n",
      "4560 of 6092\n",
      "4620 of 6092\n",
      "4680 of 6092\n",
      "4740 of 6092\n",
      "4800 of 6092\n",
      "4860 of 6092\n",
      "4920 of 6092\n",
      "4980 of 6092\n",
      "5040 of 6092\n",
      "5100 of 6092\n",
      "5160 of 6092\n",
      "5220 of 6092\n",
      "5280 of 6092\n",
      "5340 of 6092\n",
      "5400 of 6092\n",
      "5460 of 6092\n",
      "5520 of 6092\n",
      "5580 of 6092\n",
      "5640 of 6092\n",
      "5700 of 6092\n",
      "5760 of 6092\n",
      "5820 of 6092\n",
      "5880 of 6092\n",
      "5940 of 6092\n",
      "6000 of 6092\n",
      "6060 of 6092\n",
      "------------------ Conv: ----------------\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.300     0.300     0.405    927\n",
      " disgust     0.300     0.321     0.524    928\n",
      "    fear     0.300     0.182     0.089    886\n",
      "   happy     0.300     0.243     0.157    928\n",
      " neutral     0.300     0.416     0.175    759\n",
      "     sad     0.300     0.439     0.455    928\n",
      "surprise     0.300     0.184     0.254    736\n",
      "                                          6092\n",
      "\n",
      " \n",
      "     avg     0.300     0.298     0.294    \n",
      "\n",
      "                   angry     disgust        fear       happy     neutral         sad    surprise    support\n",
      "       angry       0.405       0.135       0.080       0.072       0.017       0.038       0.254        927\n",
      "     disgust       0.155       0.524       0.045       0.048       0.037       0.094       0.097        928\n",
      "        fear       0.331       0.054       0.089       0.173       0.027       0.138       0.188        886\n",
      "       happy       0.218       0.232       0.108       0.157       0.022       0.042       0.222        928\n",
      "     neutral       0.128       0.235       0.026       0.063       0.175       0.321       0.051        759\n",
      "         sad       0.073       0.087       0.092       0.115       0.078       0.455       0.100        928\n",
      "    surprise       0.094       0.515       0.045       0.046       0.029       0.018       0.254        736\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.eval_utils import classificationReport, confusion_matrix\n",
    "trueConv, predsConv = evaluateLoc(\"cuda\", modelDimRed, data_set)\n",
    "print(\"------------------ Conv: ----------------\")\n",
    "classificationReport(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "confusion_matrix(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 610\n",
      "60 of 610\n",
      "120 of 610\n",
      "180 of 610\n",
      "240 of 610\n",
      "300 of 610\n",
      "360 of 610\n",
      "420 of 610\n",
      "480 of 610\n",
      "540 of 610\n",
      "600 of 610\n",
      "0 of 610\n",
      "60 of 610\n",
      "120 of 610\n",
      "180 of 610\n",
      "240 of 610\n",
      "300 of 610\n",
      "360 of 610\n",
      "420 of 610\n",
      "480 of 610\n",
      "540 of 610\n",
      "600 of 610\n",
      "------------------ Conv: ----------------\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.746     0.705     0.798    99\n",
      " disgust     0.746     0.826     0.710    107\n",
      "    fear     0.746     0.756     0.775    80\n",
      "   happy     0.746     0.611     0.714    77\n",
      " neutral     0.746     0.787     0.779    95\n",
      "     sad     0.746     0.833     0.714    91\n",
      "surprise     0.746     0.710     0.721    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.746     0.747     0.745    \n",
      "\n",
      "                   angry     disgust        fear       happy     neutral         sad    surprise    support\n",
      "       angry       0.798       0.040       0.030       0.061       0.020       0.010       0.040         99\n",
      "     disgust       0.112       0.710       0.009       0.037       0.112       0.009       0.009        107\n",
      "        fear       0.037       0.000       0.775       0.087       0.000       0.050       0.050         80\n",
      "       happy       0.091       0.065       0.052       0.714       0.000       0.013       0.065         77\n",
      "     neutral       0.053       0.032       0.021       0.053       0.779       0.042       0.021         95\n",
      "         sad       0.022       0.022       0.088       0.066       0.066       0.714       0.022         91\n",
      "    surprise       0.066       0.033       0.033       0.115       0.000       0.033       0.721         61\n",
      "\n",
      "------------------ DimRed: ----------------\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.773     0.687    99\n",
      " disgust     0.705     0.806     0.738    107\n",
      "    fear     0.705     0.622     0.575    80\n",
      "   happy     0.705     0.690     0.636    77\n",
      " neutral     0.705     0.813     0.779    95\n",
      "     sad     0.705     0.630     0.747    91\n",
      "surprise     0.705     0.575     0.754    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.705     0.701     0.702    \n",
      "\n",
      "                   angry     disgust        fear       happy     neutral         sad    surprise    support\n",
      "       angry       0.687       0.040       0.061       0.061       0.010       0.040       0.101         99\n",
      "     disgust       0.065       0.738       0.028       0.028       0.019       0.112       0.009        107\n",
      "        fear       0.062       0.037       0.575       0.087       0.025       0.113       0.100         80\n",
      "       happy       0.039       0.026       0.065       0.636       0.065       0.026       0.143         77\n",
      "     neutral       0.032       0.021       0.021       0.011       0.779       0.126       0.011         95\n",
      "         sad       0.022       0.077       0.055       0.022       0.044       0.747       0.033         91\n",
      "    surprise       0.000       0.016       0.115       0.049       0.049       0.016       0.754         61\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.eval_utils import classificationReport, confusion_matrix\n",
    "\n",
    "trueConv, predsConv = evaluateLoc(\"cuda\", modelConv, testDs)\n",
    "trueDimRed, predsDimRed = evaluateLoc(\"cuda\", modelDimRed, testDs)\n",
    "\n",
    "print(\"------------------ Conv: ----------------\")\n",
    "classificationReport(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "confusion_matrix(trueConv, predsConv, data_set.encoded_dataset.label_list)\n",
    "print(\"------------------ DimRed: ----------------\")\n",
    "classificationReport(trueDimRed, predsDimRed, data_set.encoded_dataset.label_list)\n",
    "confusion_matrix(trueDimRed, predsDimRed, data_set.encoded_dataset.label_list)\n",
    "\n",
    "\n",
    "print(\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

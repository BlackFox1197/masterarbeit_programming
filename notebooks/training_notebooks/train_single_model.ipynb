{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_model_conv import SSConvModel3Sec\n",
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import  SmallDimRed\n",
    "from network_models.soundsream_models_and_utils.ss_complex_conv_net import SSComplexConvModel3Sec\n",
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 10\n",
    "# models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr2/\"\n",
    "#models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/3_5_sec_dimred/Nr1/\"\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments_final/Run_nr_1_singled/conv/\"\n",
    "trials_per_model_type = 2\n",
    "epochs = 1000\n",
    "save_highest_acc_min_acc = 0.5\n",
    "save_model_every = 50\n",
    "lr = 1e-4\n",
    "lr_quotient = 2\n",
    "gc.collect()\n",
    "#data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncs_betterSS_12_1_relwrap_music_tess.pkl\", device=\"cuda\")\n",
    "#data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks_clip/content/datasets/mfcc/mfcc_dataset_3_5_sec.pkl\", device=device)\n",
    "data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks_clip/content/datasets/soundstream_encoded/allEncodings_noInducednoStimuli_3_5_sec_v12_1_basic.pkl\", device=device)\n",
    "\n",
    "\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.2, seed=100)\n",
    "testDs, valDs = train_val_dataset(testDs, val_split=0.5, seed=100)\n",
    "torch.manual_seed(420)\n",
    "model = SSConvModel3Sec(xSize=512, ySize=175).to(device)\n",
    "#model = SSComplexConvModel3Sec().to(device)\n",
    "# model = SmallDimRed(x_size=110).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_trainer_gen_models import SSGenModelTrainer\n",
    "\n",
    "trainer = SSGenModelTrainer(lr=lr, num_epochs=epochs, model=model, train_dataset=trainDS,\n",
    "                            eval_dataset=valDs,\n",
    "                            device=device, labelList=data_set.encoded_dataset.label_list,\n",
    "                            batch_size=batch_size,\n",
    "                            save_model_every=save_model_every,\n",
    "                            save_highest_acc_min_acc=save_highest_acc_min_acc,\n",
    "                            model_path = models_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.871831  [ 1000/ 4873]\n",
      "loss: 1.867749  [ 2000/ 4873]\n",
      "loss: 2.057991  [ 3000/ 4873]\n",
      "loss: 2.064220  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.131     0.000     0.000    105\n",
      " disgust     0.131     0.000     0.000    109\n",
      "    fear     0.131     0.131     1.000    80\n",
      "   happy     0.131     0.000     0.000    81\n",
      " neutral     0.131     0.000     0.000    84\n",
      "     sad     0.131     0.000     0.000    87\n",
      "surprise     0.131     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.131     0.019     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 1.982867 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.052060  [ 1000/ 4873]\n",
      "loss: 1.828333  [ 2000/ 4873]\n",
      "loss: 1.949472  [ 3000/ 4873]\n",
      "loss: 2.027665  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.131     0.000     0.000    105\n",
      " disgust     0.131     0.000     0.000    109\n",
      "    fear     0.131     0.131     1.000    80\n",
      "   happy     0.131     0.000     0.000    81\n",
      " neutral     0.131     0.000     0.000    84\n",
      "     sad     0.131     0.000     0.000    87\n",
      "surprise     0.131     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.131     0.019     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 1.975861 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.015553  [ 1000/ 4873]\n",
      "loss: 1.863189  [ 2000/ 4873]\n",
      "loss: 1.834197  [ 3000/ 4873]\n",
      "loss: 1.950772  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.131     0.000     0.000    105\n",
      " disgust     0.131     0.000     0.000    109\n",
      "    fear     0.131     0.131     1.000    80\n",
      "   happy     0.131     0.000     0.000    81\n",
      " neutral     0.131     0.000     0.000    84\n",
      "     sad     0.131     0.000     0.000    87\n",
      "surprise     0.131     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.131     0.019     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 1.945398 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.917864  [ 1000/ 4873]\n",
      "loss: 1.857142  [ 2000/ 4873]\n",
      "loss: 1.706259  [ 3000/ 4873]\n",
      "loss: 2.018733  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.131     0.000     0.000    105\n",
      " disgust     0.131     0.000     0.000    109\n",
      "    fear     0.131     0.131     1.000    80\n",
      "   happy     0.131     0.000     0.000    81\n",
      " neutral     0.131     0.000     0.000    84\n",
      "     sad     0.131     0.000     0.000    87\n",
      "surprise     0.131     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.131     0.019     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 1.835585 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.772864  [ 1000/ 4873]\n",
      "loss: 1.811636  [ 2000/ 4873]\n",
      "loss: 1.578961  [ 3000/ 4873]\n",
      "loss: 1.858902  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.131     0.000     0.000    105\n",
      " disgust     0.131     0.000     0.000    109\n",
      "    fear     0.131     0.132     1.000    80\n",
      "   happy     0.131     0.000     0.000    81\n",
      " neutral     0.131     0.000     0.000    84\n",
      "     sad     0.131     0.000     0.000    87\n",
      "surprise     0.131     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.131     0.019     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 1.781842 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.811060  [ 1000/ 4873]\n",
      "loss: 1.849457  [ 2000/ 4873]\n",
      "loss: 1.718712  [ 3000/ 4873]\n",
      "loss: 1.572673  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.228     0.841     0.352    105\n",
      " disgust     0.228     0.000     0.000    109\n",
      "    fear     0.228     0.145     0.950    80\n",
      "   happy     0.228     0.605     0.321    81\n",
      " neutral     0.228     0.000     0.000    84\n",
      "     sad     0.228     0.000     0.000    87\n",
      "surprise     0.228     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.228     0.227     0.232    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 22.8%, Avg loss: 1.731862 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.881355  [ 1000/ 4873]\n",
      "loss: 1.740915  [ 2000/ 4873]\n",
      "loss: 1.817635  [ 3000/ 4873]\n",
      "loss: 1.676109  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.389     0.673     0.724    105\n",
      " disgust     0.389     0.000     0.000    109\n",
      "    fear     0.389     0.241     0.613    80\n",
      "   happy     0.389     0.452     0.407    81\n",
      " neutral     0.389     0.319     0.262    84\n",
      "     sad     0.389     0.375     0.655    87\n",
      "surprise     0.389     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.389     0.294     0.380    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 38.9%, Avg loss: 1.683612 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.758208  [ 1000/ 4873]\n",
      "loss: 1.625228  [ 2000/ 4873]\n",
      "loss: 1.595599  [ 3000/ 4873]\n",
      "loss: 1.740823  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.402     0.727     0.686    105\n",
      " disgust     0.402     0.000     0.000    109\n",
      "    fear     0.402     0.323     0.625    80\n",
      "   happy     0.402     0.411     0.543    81\n",
      " neutral     0.402     0.260     0.238    84\n",
      "     sad     0.402     0.343     0.678    87\n",
      "surprise     0.402     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.402     0.295     0.396    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 1.657093 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.619785  [ 1000/ 4873]\n",
      "loss: 1.494234  [ 2000/ 4873]\n",
      "loss: 1.420662  [ 3000/ 4873]\n",
      "loss: 1.636956  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.402     0.638     0.771    105\n",
      " disgust     0.402     0.500     0.028    109\n",
      "    fear     0.402     0.339     0.512    80\n",
      "   happy     0.402     0.360     0.617    81\n",
      " neutral     0.402     0.286     0.071    84\n",
      "     sad     0.402     0.327     0.736    87\n",
      "surprise     0.402     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.402     0.350     0.391    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 1.608193 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.430967  [ 1000/ 4873]\n",
      "loss: 1.665425  [ 2000/ 4873]\n",
      "loss: 1.637259  [ 3000/ 4873]\n",
      "loss: 1.344092  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.410     0.686     0.771    105\n",
      " disgust     0.410     0.400     0.037    109\n",
      "    fear     0.410     0.400     0.550    80\n",
      "   happy     0.410     0.364     0.679    81\n",
      " neutral     0.410     0.125     0.048    84\n",
      "     sad     0.410     0.328     0.713    87\n",
      "surprise     0.410     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.410     0.329     0.400    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 1.589940 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.430711  [ 1000/ 4873]\n",
      "loss: 1.788664  [ 2000/ 4873]\n",
      "loss: 1.790974  [ 3000/ 4873]\n",
      "loss: 1.388550  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.369     0.471     0.857    105\n",
      " disgust     0.369     0.571     0.037    109\n",
      "    fear     0.369     0.252     0.325    80\n",
      "   happy     0.369     0.382     0.519    81\n",
      " neutral     0.369     0.241     0.083    84\n",
      "     sad     0.369     0.329     0.644    87\n",
      "surprise     0.369     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.369     0.321     0.352    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 36.9%, Avg loss: 1.608005 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.586973  [ 1000/ 4873]\n",
      "loss: 1.320540  [ 2000/ 4873]\n",
      "loss: 1.262687  [ 3000/ 4873]\n",
      "loss: 1.590906  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.407     0.648     0.771    105\n",
      " disgust     0.407     0.429     0.083    109\n",
      "    fear     0.407     0.435     0.500    80\n",
      "   happy     0.407     0.358     0.654    81\n",
      " neutral     0.407     0.071     0.012    84\n",
      "     sad     0.407     0.305     0.736    87\n",
      "surprise     0.407     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.407     0.321     0.394    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 1.534942 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.259130  [ 1000/ 4873]\n",
      "loss: 1.265224  [ 2000/ 4873]\n",
      "loss: 1.394630  [ 3000/ 4873]\n",
      "loss: 1.266382  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.407     0.562     0.771    105\n",
      " disgust     0.407     0.259     0.064    109\n",
      "    fear     0.407     0.475     0.475    80\n",
      "   happy     0.407     0.412     0.667    81\n",
      " neutral     0.407     0.214     0.036    84\n",
      "     sad     0.407     0.304     0.747    87\n",
      "surprise     0.407     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.407     0.318     0.394    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 1.520849 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.261075  [ 1000/ 4873]\n",
      "loss: 1.620684  [ 2000/ 4873]\n",
      "loss: 1.331432  [ 3000/ 4873]\n",
      "loss: 1.023045  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.408     0.582     0.743    105\n",
      " disgust     0.408     0.381     0.073    109\n",
      "    fear     0.408     0.594     0.512    80\n",
      "   happy     0.408     0.431     0.654    81\n",
      " neutral     0.408     0.125     0.024    84\n",
      "     sad     0.408     0.271     0.770    87\n",
      "surprise     0.408     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.408     0.341     0.397    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.529685 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.432742  [ 1000/ 4873]\n",
      "loss: 1.358968  [ 2000/ 4873]\n",
      "loss: 1.179327  [ 3000/ 4873]\n",
      "loss: 1.188044  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.384     0.475     0.819    105\n",
      " disgust     0.384     0.125     0.018    109\n",
      "    fear     0.384     0.410     0.425    80\n",
      "   happy     0.384     0.426     0.642    81\n",
      " neutral     0.384     0.286     0.024    84\n",
      "     sad     0.384     0.289     0.667    87\n",
      "surprise     0.384     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.384     0.287     0.371    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 38.4%, Avg loss: 1.563370 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.065392  [ 1000/ 4873]\n",
      "loss: 1.149538  [ 2000/ 4873]\n",
      "loss: 1.430638  [ 3000/ 4873]\n",
      "loss: 1.315768  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.410     0.543     0.848    105\n",
      " disgust     0.410     0.200     0.046    109\n",
      "    fear     0.410     0.450     0.450    80\n",
      "   happy     0.410     0.384     0.691    81\n",
      " neutral     0.410     0.167     0.024    84\n",
      "     sad     0.410     0.339     0.713    87\n",
      "surprise     0.410     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.410     0.297     0.396    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 1.529558 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.783911  [ 1000/ 4873]\n",
      "loss: 1.476141  [ 2000/ 4873]\n",
      "loss: 0.835183  [ 3000/ 4873]\n",
      "loss: 1.187310  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.413     0.554     0.829    105\n",
      " disgust     0.413     0.227     0.092    109\n",
      "    fear     0.413     0.557     0.425    80\n",
      "   happy     0.413     0.404     0.704    81\n",
      " neutral     0.413     0.200     0.012    84\n",
      "     sad     0.413     0.312     0.724    87\n",
      "surprise     0.413     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.413     0.322     0.398    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 1.485780 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.418667  [ 1000/ 4873]\n",
      "loss: 1.374175  [ 2000/ 4873]\n",
      "loss: 1.175548  [ 3000/ 4873]\n",
      "loss: 1.096063  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.418     0.602     0.762    105\n",
      " disgust     0.418     0.333     0.110    109\n",
      "    fear     0.418     0.527     0.487    80\n",
      "   happy     0.418     0.377     0.679    81\n",
      " neutral     0.418     0.267     0.048    84\n",
      "     sad     0.418     0.316     0.747    87\n",
      "surprise     0.418     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.418     0.346     0.405    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.8%, Avg loss: 1.507208 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.126411  [ 1000/ 4873]\n",
      "loss: 0.938485  [ 2000/ 4873]\n",
      "loss: 1.179745  [ 3000/ 4873]\n",
      "loss: 0.913545  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.415     0.514     0.867    105\n",
      " disgust     0.415     0.281     0.083    109\n",
      "    fear     0.415     0.507     0.463    80\n",
      "   happy     0.415     0.433     0.642    81\n",
      " neutral     0.415     0.308     0.048    84\n",
      "     sad     0.415     0.308     0.690    87\n",
      "surprise     0.415     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.415     0.336     0.399    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 1.543893 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.832493  [ 1000/ 4873]\n",
      "loss: 1.032949  [ 2000/ 4873]\n",
      "loss: 0.727498  [ 3000/ 4873]\n",
      "loss: 0.881540  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.423     0.500     0.810    105\n",
      " disgust     0.423     0.361     0.119    109\n",
      "    fear     0.423     0.519     0.500    80\n",
      "   happy     0.423     0.412     0.691    81\n",
      " neutral     0.423     0.250     0.048    84\n",
      "     sad     0.423     0.343     0.690    87\n",
      "surprise     0.423     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.423     0.341     0.408    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 1.591862 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.237983  [ 1000/ 4873]\n",
      "loss: 1.245939  [ 2000/ 4873]\n",
      "loss: 0.908045  [ 3000/ 4873]\n",
      "loss: 0.988972  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.408     0.555     0.819    105\n",
      " disgust     0.408     0.205     0.083    109\n",
      "    fear     0.408     0.534     0.487    80\n",
      "   happy     0.408     0.390     0.679    81\n",
      " neutral     0.408     0.000     0.000    84\n",
      "     sad     0.408     0.305     0.690    87\n",
      "surprise     0.408     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.408     0.284     0.394    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.546987 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.177006  [ 1000/ 4873]\n",
      "loss: 1.033102  [ 2000/ 4873]\n",
      "loss: 1.487637  [ 3000/ 4873]\n",
      "loss: 1.556296  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.413     0.553     0.848    105\n",
      " disgust     0.413     0.235     0.147    109\n",
      "    fear     0.413     0.544     0.463    80\n",
      "   happy     0.413     0.431     0.654    81\n",
      " neutral     0.413     0.000     0.000    84\n",
      "     sad     0.413     0.300     0.655    87\n",
      "surprise     0.413     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.413     0.295     0.395    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 1.513927 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.209701  [ 1000/ 4873]\n",
      "loss: 1.060949  [ 2000/ 4873]\n",
      "loss: 1.029478  [ 3000/ 4873]\n",
      "loss: 0.996394  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.410     0.549     0.848    105\n",
      " disgust     0.410     0.213     0.092    109\n",
      "    fear     0.410     0.477     0.512    80\n",
      "   happy     0.410     0.427     0.617    81\n",
      " neutral     0.410     0.000     0.000    84\n",
      "     sad     0.410     0.303     0.690    87\n",
      "surprise     0.410     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.410     0.281     0.394    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 1.562997 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.435708  [ 1000/ 4873]\n",
      "loss: 0.970773  [ 2000/ 4873]\n",
      "loss: 1.039449  [ 3000/ 4873]\n",
      "loss: 0.769823  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.408     0.574     0.810    105\n",
      " disgust     0.408     0.215     0.156    109\n",
      "    fear     0.408     0.538     0.525    80\n",
      "   happy     0.408     0.490     0.617    81\n",
      " neutral     0.408     0.000     0.000    84\n",
      "     sad     0.408     0.271     0.632    87\n",
      "surprise     0.408     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.408     0.298     0.391    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.536908 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.919382  [ 1000/ 4873]\n",
      "loss: 0.873582  [ 2000/ 4873]\n",
      "loss: 0.902618  [ 3000/ 4873]\n",
      "loss: 0.880540  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.407     0.528     0.800    105\n",
      " disgust     0.407     0.226     0.128    109\n",
      "    fear     0.407     0.525     0.525    80\n",
      "   happy     0.407     0.474     0.667    81\n",
      " neutral     0.407     0.000     0.000    84\n",
      "     sad     0.407     0.277     0.621    87\n",
      "surprise     0.407     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.407     0.290     0.392    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 1.553935 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.741505  [ 1000/ 4873]\n",
      "loss: 1.042297  [ 2000/ 4873]\n",
      "loss: 1.005134  [ 3000/ 4873]\n",
      "loss: 0.625266  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.393     0.532     0.790    105\n",
      " disgust     0.393     0.210     0.119    109\n",
      "    fear     0.393     0.559     0.475    80\n",
      "   happy     0.393     0.441     0.642    81\n",
      " neutral     0.393     0.000     0.000    84\n",
      "     sad     0.393     0.262     0.621    87\n",
      "surprise     0.393     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.393     0.286     0.378    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.3%, Avg loss: 1.508524 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.713490  [ 1000/ 4873]\n",
      "loss: 0.859826  [ 2000/ 4873]\n",
      "loss: 0.711346  [ 3000/ 4873]\n",
      "loss: 0.915395  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.416     0.606     0.790    105\n",
      " disgust     0.416     0.243     0.165    109\n",
      "    fear     0.416     0.545     0.600    80\n",
      "   happy     0.416     0.441     0.691    81\n",
      " neutral     0.416     0.000     0.000    84\n",
      "     sad     0.416     0.266     0.563    87\n",
      "surprise     0.416     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.416     0.300     0.401    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 1.560222 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.629511  [ 1000/ 4873]\n",
      "loss: 0.946953  [ 2000/ 4873]\n",
      "loss: 0.692181  [ 3000/ 4873]\n",
      "loss: 1.294970  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.403     0.577     0.819    105\n",
      " disgust     0.403     0.149     0.119    109\n",
      "    fear     0.403     0.554     0.512    80\n",
      "   happy     0.403     0.500     0.667    81\n",
      " neutral     0.403     0.000     0.000    84\n",
      "     sad     0.403     0.271     0.598    87\n",
      "surprise     0.403     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.403     0.293     0.388    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 1.583181 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.922763  [ 1000/ 4873]\n",
      "loss: 0.971709  [ 2000/ 4873]\n",
      "loss: 0.917888  [ 3000/ 4873]\n",
      "loss: 0.577459  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.400     0.517     0.857    105\n",
      " disgust     0.400     0.239     0.147    109\n",
      "    fear     0.400     0.488     0.512    80\n",
      "   happy     0.400     0.480     0.605    81\n",
      " neutral     0.400     0.000     0.000    84\n",
      "     sad     0.400     0.262     0.552    87\n",
      "surprise     0.400     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.400     0.284     0.382    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 1.648891 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.913280  [ 1000/ 4873]\n",
      "loss: 0.723257  [ 2000/ 4873]\n",
      "loss: 0.770466  [ 3000/ 4873]\n",
      "loss: 0.740736  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.405     0.548     0.819    105\n",
      " disgust     0.405     0.234     0.202    109\n",
      "    fear     0.405     0.597     0.500    80\n",
      "   happy     0.405     0.468     0.642    81\n",
      " neutral     0.405     0.000     0.000    84\n",
      "     sad     0.405     0.260     0.540    87\n",
      "surprise     0.405     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.405     0.301     0.386    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 1.592125 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.731971  [ 1000/ 4873]\n",
      "loss: 0.672982  [ 2000/ 4873]\n",
      "loss: 0.637852  [ 3000/ 4873]\n",
      "loss: 0.750004  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.410     0.539     0.790    105\n",
      " disgust     0.410     0.197     0.138    109\n",
      "    fear     0.410     0.584     0.650    80\n",
      "   happy     0.410     0.505     0.630    81\n",
      " neutral     0.410     0.000     0.000    84\n",
      "     sad     0.410     0.258     0.563    87\n",
      "surprise     0.410     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.410     0.298     0.396    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 1.570451 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.057486  [ 1000/ 4873]\n",
      "loss: 0.745421  [ 2000/ 4873]\n",
      "loss: 1.635056  [ 3000/ 4873]\n",
      "loss: 0.608978  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.430     0.561     0.790    105\n",
      " disgust     0.430     0.264     0.174    109\n",
      "    fear     0.430     0.526     0.625    80\n",
      "   happy     0.430     0.488     0.753    81\n",
      " neutral     0.430     0.000     0.000    84\n",
      "     sad     0.430     0.288     0.563    87\n",
      "surprise     0.430     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.430     0.304     0.415    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 1.619504 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.266498  [ 1000/ 4873]\n",
      "loss: 0.481955  [ 2000/ 4873]\n",
      "loss: 0.794739  [ 3000/ 4873]\n",
      "loss: 0.604634  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.395     0.509     0.810    105\n",
      " disgust     0.395     0.172     0.138    109\n",
      "    fear     0.395     0.479     0.575    80\n",
      "   happy     0.395     0.554     0.568    81\n",
      " neutral     0.395     0.000     0.000    84\n",
      "     sad     0.395     0.277     0.563    87\n",
      "surprise     0.395     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.395     0.285     0.379    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.682150 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.846212  [ 1000/ 4873]\n",
      "loss: 0.804461  [ 2000/ 4873]\n",
      "loss: 0.610187  [ 3000/ 4873]\n",
      "loss: 0.615593  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.416     0.486     0.848    105\n",
      " disgust     0.416     0.260     0.174    109\n",
      "    fear     0.416     0.450     0.613    80\n",
      "   happy     0.416     0.557     0.605    81\n",
      " neutral     0.416     0.000     0.000    84\n",
      "     sad     0.416     0.306     0.552    87\n",
      "surprise     0.416     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.416     0.294     0.399    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 1.784585 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.882502  [ 1000/ 4873]\n",
      "loss: 0.518841  [ 2000/ 4873]\n",
      "loss: 0.895406  [ 3000/ 4873]\n",
      "loss: 0.839173  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.416     0.563     0.810    105\n",
      " disgust     0.416     0.235     0.211    109\n",
      "    fear     0.416     0.544     0.613    80\n",
      "   happy     0.416     0.500     0.617    81\n",
      " neutral     0.416     0.000     0.000    84\n",
      "     sad     0.416     0.275     0.540    87\n",
      "surprise     0.416     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.416     0.302     0.399    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 1.669006 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.753267  [ 1000/ 4873]\n",
      "loss: 0.946542  [ 2000/ 4873]\n",
      "loss: 0.742117  [ 3000/ 4873]\n",
      "loss: 0.672035  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.402     0.583     0.771    105\n",
      " disgust     0.402     0.152     0.138    109\n",
      "    fear     0.402     0.579     0.550    80\n",
      "   happy     0.402     0.505     0.617    81\n",
      " neutral     0.402     0.000     0.000    84\n",
      "     sad     0.402     0.279     0.632    87\n",
      "surprise     0.402     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.402     0.300     0.387    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 1.677468 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.622205  [ 1000/ 4873]\n",
      "loss: 0.639233  [ 2000/ 4873]\n",
      "loss: 0.840113  [ 3000/ 4873]\n",
      "loss: 1.330391  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.405     0.584     0.762    105\n",
      " disgust     0.405     0.154     0.147    109\n",
      "    fear     0.405     0.585     0.475    80\n",
      "   happy     0.405     0.470     0.679    81\n",
      " neutral     0.405     0.000     0.000    84\n",
      "     sad     0.405     0.310     0.667    87\n",
      "surprise     0.405     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.405     0.300     0.390    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 1.642639 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.061505  [ 1000/ 4873]\n",
      "loss: 0.407654  [ 2000/ 4873]\n",
      "loss: 0.780115  [ 3000/ 4873]\n",
      "loss: 1.365118  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.416     0.613     0.829    105\n",
      " disgust     0.416     0.160     0.147    109\n",
      "    fear     0.416     0.500     0.613    80\n",
      "   happy     0.416     0.453     0.654    81\n",
      " neutral     0.416     0.000     0.000    84\n",
      "     sad     0.416     0.320     0.563    87\n",
      "surprise     0.416     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.416     0.292     0.401    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 1.667483 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.786212  [ 1000/ 4873]\n",
      "loss: 0.563550  [ 2000/ 4873]\n",
      "loss: 0.917796  [ 3000/ 4873]\n",
      "loss: 0.752191  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.397     0.570     0.810    105\n",
      " disgust     0.397     0.113     0.138    109\n",
      "    fear     0.397     0.535     0.575    80\n",
      "   happy     0.397     0.458     0.605    81\n",
      " neutral     0.397     0.000     0.000    84\n",
      "     sad     0.397     0.348     0.540    87\n",
      "surprise     0.397     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.397     0.289     0.381    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.724317 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.739597  [ 1000/ 4873]\n",
      "loss: 0.865897  [ 2000/ 4873]\n",
      "loss: 0.653920  [ 3000/ 4873]\n",
      "loss: 1.016001  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.413     0.589     0.790    105\n",
      " disgust     0.413     0.160     0.211    109\n",
      "    fear     0.413     0.533     0.600    80\n",
      "   happy     0.413     0.490     0.605    81\n",
      " neutral     0.413     0.000     0.000    84\n",
      "     sad     0.413     0.363     0.563    87\n",
      "surprise     0.413     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.413     0.305     0.396    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 1.721017 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.610972  [ 1000/ 4873]\n",
      "loss: 0.592478  [ 2000/ 4873]\n",
      "loss: 0.968363  [ 3000/ 4873]\n",
      "loss: 0.688911  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.402     0.542     0.790    105\n",
      " disgust     0.402     0.145     0.193    109\n",
      "    fear     0.402     0.603     0.512    80\n",
      "   happy     0.402     0.505     0.593    81\n",
      " neutral     0.402     0.000     0.000    84\n",
      "     sad     0.402     0.349     0.598    87\n",
      "surprise     0.402     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.402     0.306     0.384    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 1.709189 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.708401  [ 1000/ 4873]\n",
      "loss: 0.842061  [ 2000/ 4873]\n",
      "loss: 0.661522  [ 3000/ 4873]\n",
      "loss: 0.788732  [ 4000/ 4873]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.411     0.645     0.762    105\n",
      " disgust     0.411     0.127     0.174    109\n",
      "    fear     0.411     0.553     0.588    80\n",
      "   happy     0.411     0.526     0.630    81\n",
      " neutral     0.411     0.000     0.000    84\n",
      "     sad     0.411     0.351     0.621    87\n",
      "surprise     0.411     0.000     0.000    64\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.411     0.314     0.396    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.1%, Avg loss: 1.655439 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.697573  [ 1000/ 4873]\n",
      "loss: 0.842823  [ 2000/ 4873]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:81\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;66;03m# this is the trainloop\u001B[39;00m\n\u001B[0;32m---> 81\u001B[0m epoch_train_losses \u001B[38;5;241m=\u001B[39m epoch_train_losses \u001B[38;5;241m+\u001B[39m  [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[1;32m     83\u001B[0m \u001B[38;5;66;03m# --------------------- testloop and evaluation- ---------------\u001B[39;00m\n\u001B[1;32m     84\u001B[0m acc, true, preds, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loop(test_dataloader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:133\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train_loop\u001B[0;34m(self, dataloader, model, loss_fn, optimizer, epoch)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;66;03m# Backpropagation\u001B[39;00m\n\u001B[1;32m    132\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 133\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    137\u001B[0m fullLoss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import SSDimRedModel, SmallDimRed\n",
    "model = SmallDimRed(x_size=110)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module.parameters of SmallDimRed(\n  (base_linear1): Linear(in_features=300, out_features=100, bias=True)\n  (base_linear2): Linear(in_features=100, out_features=4, bias=True)\n  (base_linear3): Linear(in_features=4, out_features=4, bias=True)\n  (base_linear4): Linear(in_features=4, out_features=7, bias=True)\n  (dropouts): Dropout(p=0.2, inplace=False)\n  (linear1): Linear(in_features=110, out_features=500, bias=True)\n  (linear2): Linear(in_features=500, out_features=300, bias=True)\n)>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

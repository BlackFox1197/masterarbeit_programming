{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fbCls1d2yBs"
   },
   "source": [
    "# Emotion Recognition in Greek Speech Using Wav2Vec 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp37lZOV2042"
   },
   "source": [
    "**Wav2Vec 2.0** is a pretrained model for Automatic Speech Recognition (ASR) and was released in [September 2020](https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/) by Alexei Baevski, Michael Auli, and Alex Conneau.  Soon after the superior performance of Wav2Vec2 was demonstrated on the English ASR dataset LibriSpeech, *Facebook AI* presented XLSR-Wav2Vec2 (click [here](https://arxiv.org/abs/2006.13979)). XLSR stands for *cross-lingual  speech representations* and refers to XLSR-Wav2Vec2`s ability to learn speech representations that are useful across multiple languages.\n",
    "\n",
    "Similar to Wav2Vec2, XLSR-Wav2Vec2 learns powerful speech representations from hundreds of thousands of hours of speech in more than 50 languages of unlabeled speech. Similar, to [BERT's masked language modeling](http://jalammar.github.io/illustrated-bert/), the model learns contextualized speech representations by randomly masking feature vectors before passing them to a transformer network.\n",
    "\n",
    "![wav2vec2_structure](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/xlsr_wav2vec2.png)\n",
    "\n",
    "The authors show for the first time that massively pretraining an ASR model on cross-lingual unlabeled speech data, followed by language-specific fine-tuning on very little labeled data achieves state-of-the-art results. See Table 1-5 of the official [paper](https://arxiv.org/pdf/2006.13979.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0xJwDkA3QQR"
   },
   "source": [
    "During fine-tuning week hosted by HuggingFace, more than 300 people participated in tuning XLSR-Wav2Vec2's pretrained on low-resources ASR dataset for more than 50 languages. This model is fine-tuned using [Connectionist Temporal Classification](https://distill.pub/2017/ctc/) (CTC), an algorithm used to train neural networks for sequence-to-sequence problems and mainly in Automatic Speech Recognition and handwriting recognition. Follow this [notebook](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_Tune_XLSR_Wav2Vec2_on_Turkish_ASR_with_%F0%9F%A4%97_Transformers.ipynb#scrollTo=Gx9OdDYrCtQ1) for more information about XLSR-Wav2Vec2 fine-tuning.\n",
    "\n",
    "This model was shown significant results in many low-resources languages. You can see the [competition board](https://paperswithcode.com/dataset/common-voice) or even testing the models from the [HuggingFace hub](https://huggingface.co/models?filter=xlsr-fine-tuning-week). \n",
    "\n",
    "\n",
    "In this notebook, we will go through how to use this model to recognize the emotional aspects of speech in a language (or even as a general view using for every classification problem). Before going any further, we need to install some handy packages and define some enviroment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cp4-LTa2uphv",
    "outputId": "b1490098-4140-4d72-f59e-756ca705cf83"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%env LC_ALL=C.UTF-8\n",
    "%env LANG=C.UTF-8\n",
    "%env TRANSFORMERS_CACHE=content/cache\n",
    "%env HF_DATASETS_CACHE=content/cache\n",
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krC50MmmvBWJ"
   },
   "source": [
    "## Prepare Data\n",
    "\n",
    "For this particular example, we use [Acted Emotional Speech Dynamic Database – AESDD](http://m3c.web.auth.gr/research/aesdd-speech-emotion-recognition/) provided by Multidisciplinary Media & Mediated Communication Research Group ([M3C](http://m3c.web.auth.gr/)). \n",
    "\n",
    "The Acted Emotional Speech Dynamic Database (AESDD) is a publically available speech emotion recognition dataset that contains utterances of acted emotional speech in the Greek language for five different emotions `sadness`, `disgust`, `happiness`, `anger`, and `fear`.\n",
    "\n",
    "The dataset consists of directories of emotions; each folder includes specific emotions. We need to loop over directories and save the paths related to each class based on the directory name.\n",
    "\n",
    "```bash\n",
    ".\n",
    "├── Tools\\ and\\ Documentation\n",
    "│   ├── ESTrainer.mlapp\n",
    "│   ├── Speech\\ Emotion\\ Recognition\\ Adapted\\ to\\ Multimodal\\ Semantic\\ Repositories_documentation.pdf\n",
    "│   ├── Speech\\ Emotion\\ Recognition\\ for\\ Performance\\ Interaction.pdf\n",
    "│   └── readme.txt\n",
    "├── anger\n",
    "│   ├── a01\\ (1).wav\n",
    "│   ├── a01\\ (2).wav\n",
    "│   ├── ...\n",
    "├── disgust\n",
    "│   ├── d01\\ (1).wav\n",
    "│   ├── d01\\ (2).wav\n",
    "│   ├── ...\n",
    "├── fear\n",
    "│   ├── f01\\ (1).wav\n",
    "│   ├── f01\\ (2).wav\n",
    "│   ├── ...\n",
    "├── happiness\n",
    "│   ├── h01\\ (1).wav\n",
    "│   ├── h01\\ (2).wav\n",
    "│   ├── ...\n",
    "└── sadness\n",
    "    ├── s01\\ (1).wav\n",
    "    ├── s01\\ (2).wav\n",
    "    ├── ...\n",
    "\n",
    "6 directories, 609 files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pFSqZ0jwCMSv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MXAESg_Dqr6",
    "outputId": "2820808d-37db-41ab-edd5-af0a097d9281"
   },
   "outputs": [],
   "source": [
    "# data = []\n",
    "#\n",
    "# for path in tqdm(Path(\"/content/data/aesdd\").glob(\"**/*.wav\")):\n",
    "#     name = str(path).split('/')[-1].split('.')[0]\n",
    "#     label = str(path).split('/')[-2]\n",
    "#\n",
    "#     try:\n",
    "#         # There are some broken files\n",
    "#         s = torchaudio.load(path)\n",
    "#         data.append({\n",
    "#             \"name\": name,\n",
    "#             \"path\": path,\n",
    "#             \"emotion\": label\n",
    "#         })\n",
    "#     except Exception as e:\n",
    "#         # print(str(path), e)\n",
    "#         pass\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/bin/python\n",
      "['angry', 'angry', 'ps', 'happy', 'fear', 'sad', 'fear', 'ps', 'happy', 'disgust', 'sad', 'sad', 'happy', 'disgust', 'disgust', 'fear', 'sad', 'happy', 'angry', 'happy', 'disgust', 'disgust', 'happy', 'happy', 'disgust', 'disgust', 'angry', 'happy', 'disgust', 'sad', 'sad', 'happy', 'ps', 'disgust', 'sad', 'disgust', 'fear', 'disgust', 'happy', 'happy', 'happy', 'sad', 'fear', 'fear', 'fear', 'sad', 'ps', 'angry', 'sad', 'disgust', 'angry', 'happy', 'happy', 'fear', 'fear', 'happy', 'angry', 'sad', 'happy', 'fear', 'fear', 'angry', 'happy', 'happy', 'angry', 'happy', 'happy', 'fear', 'happy', 'fear', 'happy', 'happy', 'angry', 'sad', 'fear', 'ps', 'ps', 'angry', 'happy', 'happy', 'sad', 'ps', 'ps', 'ps', 'angry', 'angry', 'disgust', 'ps', 'ps', 'sad', 'happy', 'ps', 'happy', 'disgust', 'disgust', 'sad', 'sad', 'happy', 'angry', 'angry', 'sad', 'happy', 'happy', 'ps', 'disgust', 'sad', 'fear', 'ps', 'happy', 'fear', 'sad', 'disgust', 'disgust', 'fear', 'angry', 'happy', 'sad', 'ps', 'fear', 'sad', 'disgust', 'disgust', 'disgust', 'angry', 'angry', 'sad', 'happy', 'angry', 'happy', 'ps', 'sad', 'fear', 'disgust', 'fear', 'disgust', 'disgust', 'disgust', 'ps', 'fear', 'sad', 'fear', 'sad', 'happy', 'fear', 'fear', 'ps', 'sad', 'angry', 'angry', 'happy', 'happy', 'fear', 'ps', 'fear', 'ps', 'fear', 'disgust', 'ps', 'happy', 'fear', 'angry', 'sad', 'sad', 'fear', 'disgust', 'fear', 'ps', 'angry', 'disgust', 'fear', 'sad', 'disgust', 'disgust', 'fear', 'ps', 'ps', 'ps', 'sad', 'ps', 'happy', 'sad', 'happy', 'happy', 'disgust', 'sad', 'fear', 'happy', 'angry', 'disgust', 'sad', 'happy', 'fear', 'ps', 'ps', 'angry', 'sad', 'angry', 'angry', 'sad', 'happy', 'fear', 'angry', 'sad', 'happy', 'happy', 'ps', 'angry', 'sad', 'angry', 'fear', 'angry', 'disgust', 'happy', 'fear', 'happy', 'ps', 'happy', 'sad', 'happy', 'fear', 'angry', 'fear', 'disgust', 'fear', 'sad', 'fear', 'sad', 'sad', 'sad', 'sad', 'disgust', 'fear', 'fear', 'angry', 'disgust', 'fear', 'fear', 'angry', 'happy', 'sad', 'fear', 'angry', 'happy', 'disgust', 'disgust', 'disgust', 'happy', 'disgust', 'ps', 'ps', 'sad', 'disgust', 'angry', 'sad', 'happy', 'fear', 'angry', 'angry', 'happy', 'happy', 'angry', 'sad', 'disgust', 'ps', 'ps', 'angry', 'ps', 'disgust', 'angry', 'sad', 'happy', 'ps', 'sad', 'ps', 'ps', 'disgust', 'ps', 'ps', 'happy', 'fear', 'fear', 'happy', 'disgust', 'sad', 'fear', 'ps', 'disgust', 'fear', 'ps', 'fear', 'disgust', 'ps', 'ps', 'angry', 'angry', 'sad', 'ps', 'disgust', 'disgust', 'ps', 'happy', 'fear', 'sad', 'angry', 'disgust', 'happy', 'disgust', 'disgust', 'angry', 'angry', 'sad', 'ps', 'disgust', 'fear', 'angry', 'angry', 'fear', 'fear', 'angry', 'angry', 'fear', 'ps', 'angry', 'disgust', 'ps', 'disgust', 'happy', 'happy', 'sad', 'angry', 'sad', 'angry', 'ps', 'happy', 'disgust', 'disgust', 'angry', 'angry', 'ps', 'disgust', 'fear', 'fear', 'sad', 'ps', 'sad', 'happy', 'ps', 'disgust', 'ps', 'sad', 'disgust', 'disgust', 'sad', 'disgust', 'happy', 'happy', 'angry', 'sad', 'disgust', 'happy', 'sad', 'angry', 'ps', 'angry', 'happy', 'fear', 'sad', 'ps', 'ps', 'sad', 'fear', 'fear', 'fear', 'angry', 'angry', 'fear', 'fear', 'angry', 'fear', 'ps', 'disgust', 'angry', 'angry', 'angry', 'happy', 'fear', 'fear', 'fear', 'happy', 'ps', 'disgust', 'angry', 'ps', 'angry', 'angry', 'disgust', 'ps', 'angry', 'ps', 'sad', 'sad', 'happy', 'disgust', 'ps', 'happy', 'fear', 'disgust', 'disgust', 'angry', 'angry', 'disgust', 'fear', 'sad', 'disgust', 'disgust', 'sad', 'happy', 'disgust', 'happy', 'angry', 'ps', 'happy', 'fear', 'fear', 'fear', 'disgust', 'angry', 'disgust', 'sad', 'fear', 'fear', 'ps', 'sad', 'sad', 'fear', 'fear', 'disgust', 'sad', 'fear', 'happy', 'angry', 'angry', 'disgust', 'happy', 'ps', 'angry', 'ps', 'happy', 'sad', 'ps', 'fear', 'angry', 'disgust', 'happy', 'sad', 'fear', 'fear', 'ps', 'disgust', 'fear', 'sad', 'fear', 'fear', 'angry', 'sad', 'ps', 'disgust', 'ps', 'angry', 'ps', 'angry', 'fear', 'ps', 'disgust', 'disgust', 'sad', 'happy', 'sad', 'angry', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'fear', 'ps', 'ps', 'sad', 'sad', 'sad', 'angry', 'sad', 'happy', 'disgust', 'ps', 'happy', 'happy', 'sad', 'angry', 'happy', 'fear', 'ps', 'fear', 'fear', 'angry', 'ps', 'happy', 'disgust', 'fear', 'happy', 'happy', 'disgust', 'sad', 'happy', 'fear', 'sad', 'happy', 'ps', 'sad', 'disgust', 'disgust', 'angry', 'sad', 'happy', 'ps', 'happy', 'disgust', 'sad', 'angry', 'ps', 'fear', 'ps', 'sad', 'sad', 'fear', 'disgust', 'disgust', 'ps', 'angry', 'fear', 'angry', 'happy', 'angry', 'happy', 'disgust', 'ps', 'happy', 'happy', 'disgust', 'angry', 'angry', 'fear', 'ps', 'disgust', 'ps', 'happy', 'disgust', 'sad', 'ps', 'disgust', 'angry', 'happy', 'ps', 'disgust', 'sad', 'angry', 'angry', 'sad', 'happy', 'happy', 'happy', 'happy', 'fear', 'ps', 'happy', 'ps', 'fear', 'happy', 'disgust', 'ps', 'disgust', 'disgust', 'sad', 'angry', 'sad', 'sad', 'happy', 'happy', 'ps', 'disgust', 'disgust', 'disgust', 'angry', 'ps', 'fear', 'fear', 'happy', 'fear', 'angry', 'happy', 'sad', 'happy', 'angry', 'happy', 'fear', 'angry', 'ps', 'ps', 'angry', 'fear', 'disgust', 'disgust', 'ps', 'ps', 'fear', 'happy', 'ps', 'angry', 'ps', 'fear', 'disgust', 'angry', 'angry', 'happy', 'sad', 'ps', 'disgust', 'sad', 'sad', 'sad', 'sad', 'angry', 'disgust', 'fear', 'angry', 'sad', 'angry', 'happy', 'angry', 'happy', 'disgust', 'ps', 'sad', 'disgust', 'ps', 'fear', 'happy', 'angry', 'sad', 'disgust', 'angry', 'ps', 'sad', 'angry', 'disgust', 'fear', 'sad', 'happy', 'disgust', 'fear', 'disgust', 'happy', 'happy', 'angry', 'ps', 'angry', 'fear', 'sad', 'fear', 'disgust', 'happy', 'angry', 'ps', 'fear', 'happy', 'ps', 'angry', 'sad', 'ps', 'fear', 'fear', 'angry', 'ps', 'sad', 'ps', 'fear', 'disgust', 'disgust', 'fear', 'fear', 'ps', 'ps', 'fear', 'disgust', 'fear', 'sad', 'ps', 'happy', 'ps', 'sad', 'fear', 'disgust', 'disgust', 'fear', 'ps', 'angry', 'disgust', 'sad', 'angry', 'ps', 'fear', 'angry', 'disgust', 'angry', 'angry', 'ps', 'sad', 'ps', 'ps', 'happy', 'angry', 'sad', 'fear', 'ps', 'disgust', 'sad', 'angry', 'ps', 'angry', 'sad', 'disgust', 'fear', 'angry', 'angry', 'fear', 'happy', 'disgust', 'fear', 'happy', 'disgust', 'disgust', 'happy', 'angry', 'sad', 'fear', 'ps', 'sad', 'disgust', 'angry', 'happy', 'ps', 'happy', 'sad', 'happy', 'ps', 'sad', 'angry', 'angry', 'sad', 'fear', 'ps', 'ps', 'sad', 'sad', 'sad', 'disgust']\n",
      "['../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_100_70dB.wav']\n",
      "Dataset is loaded\n",
      "Step 0: 2400\n",
      "Step 1: 2400\n",
      "Labels:  ['disgust' 'happy' 'fear' 'ps' 'angry' 'sad']\n",
      "\n",
      "(1920, 2)\n",
      "(480, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104556/1070268662.py:67: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(\"status\", 1)\n"
     ]
    }
   ],
   "source": [
    "def load_custom_dataset():\n",
    "    paths = []\n",
    "    testpaths = []\n",
    "    testlabels = []\n",
    "    terminator = 'D:/Uni/19.Master/Daten/terminator.wav'\n",
    "    print(sys.executable)\n",
    "    emotions = []\n",
    "    # for dirname, _, filenames in os.walk('Daten/TESS Toronto emotional speech set data'):\n",
    "    # D:\\Uni\\19.Master\\DATEN\n",
    "    for dirname, _, filenames in os.walk('../tess'):\n",
    "        for filename in filenames:\n",
    "            label = filename.split('_')[-1]\n",
    "            label = label.split('.')[0]\n",
    "            if (label != 'neutral'):\n",
    "                emotions.append(label.lower())\n",
    "                paths.append(os.path.join(dirname, filename))\n",
    "    for dirname, _, filenames in os.walk('../Stimuli_Intensitätsmorphs'):\n",
    "        for filename in filenames:\n",
    "\n",
    "            intens = filename.split('_')[-2]\n",
    "            emot = filename.split('_')[1]\n",
    "            label = emot\n",
    "            match label:\n",
    "                case 'ang':\n",
    "                    label = 'angry'\n",
    "                case 'dis':\n",
    "                    label = 'disgust'\n",
    "                case 'fea':\n",
    "                    label = 'fear'\n",
    "                case 'hap':\n",
    "                    label = 'happy'\n",
    "                case 'sad':\n",
    "                    label = 'sad'\n",
    "                case 'sur':\n",
    "                    label = 'ps'\n",
    "            if (emot != 'ple'):\n",
    "                testpaths.append(os.path.join(dirname, filename))\n",
    "                testlabels.append(label.lower())\n",
    "    com_labels = testlabels + emotions\n",
    "    com_paths = testpaths + paths\n",
    "    print(testlabels)\n",
    "    print(testpaths)\n",
    "    print('Dataset is loaded')\n",
    "    return paths, emotions, testpaths, testlabels\n",
    "trainpaths, trainlabels, testpaths, testlabels = load_custom_dataset()\n",
    "\n",
    "###create dataframes for training and testing###\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF[\"path\"] = trainpaths\n",
    "trainDF[\"emotion\"] = trainlabels\n",
    "\n",
    "testDF = pd.DataFrame()\n",
    "testDF[\"path\"] = testpaths\n",
    "testDF[\"emotion\"] = testlabels\n",
    "\n",
    "\n",
    "testDF\n",
    "\n",
    "# Filter broken and non-existed paths\n",
    "df = trainDF\n",
    "df.head()\n",
    "\n",
    "print(f\"Step 0: {len(df)}\")\n",
    "\n",
    "df[\"status\"] = df[\"path\"].apply(lambda path: True if os.path.exists(path) else None)\n",
    "df = df.dropna(subset=[\"path\"])\n",
    "df = df.drop(\"status\", 1)\n",
    "print(f\"Step 1: {len(df)}\")\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()\n",
    "\n",
    "#----------------------------Let’s explore how many labels (emotions) are in the dataset with what distribution.\n",
    "print(\"Labels: \", df[\"emotion\"].unique())\n",
    "print()\n",
    "df.groupby(\"emotion\").count()[[\"path\"]]\n",
    "\n",
    "\n",
    "#------------------------------For training purposes, we need to split data into train test sets; in this specific example, we break with a 20% rate for the test set.\n",
    "\n",
    "\n",
    "#save_path = \"/content/data\"\n",
    "save_path=\"content/data\"\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=101, stratify=df[\"emotion\"])\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv(f\"{save_path}/train.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "test_df.to_csv(f\"{save_path}/test.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                               path  emotion\n0                ../tess/OAF_Fear/OAF_bean_fear.wav     fear\n1     ../tess/OAF_Pleasant_surprise/OAF_germ_ps.wav       ps\n2              ../tess/YAF_angry/YAF_boat_angry.wav    angry\n3              ../tess/YAF_angry/YAF_hash_angry.wav    angry\n4           ../tess/YAF_disgust/YAF_get_disgust.wav  disgust\n...                                             ...      ...\n1915           ../tess/OAF_angry/OAF_note_angry.wav    angry\n1916           ../tess/OAF_happy/OAF_doll_happy.wav    happy\n1917           ../tess/OAF_angry/OAF_king_angry.wav    angry\n1918  ../tess/OAF_Pleasant_surprise/OAF_team_ps.wav       ps\n1919            ../tess/YAF_fear/YAF_chain_fear.wav     fear\n\n[1920 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../tess/OAF_Fear/OAF_bean_fear.wav</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../tess/OAF_Pleasant_surprise/OAF_germ_ps.wav</td>\n      <td>ps</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../tess/YAF_angry/YAF_boat_angry.wav</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../tess/YAF_angry/YAF_hash_angry.wav</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../tess/YAF_disgust/YAF_get_disgust.wav</td>\n      <td>disgust</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1915</th>\n      <td>../tess/OAF_angry/OAF_note_angry.wav</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>1916</th>\n      <td>../tess/OAF_happy/OAF_doll_happy.wav</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>1917</th>\n      <td>../tess/OAF_angry/OAF_king_angry.wav</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>1918</th>\n      <td>../tess/OAF_Pleasant_surprise/OAF_team_ps.wav</td>\n      <td>ps</td>\n    </tr>\n    <tr>\n      <th>1919</th>\n      <td>../tess/YAF_fear/YAF_chain_fear.wav</td>\n      <td>fear</td>\n    </tr>\n  </tbody>\n</table>\n<p>1920 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2hwRai7BNrx"
   },
   "source": [
    "Let's display some random sample of the dataset and run it a couple of times to get a feeling for the audio and the emotional label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DZaQ_sP5xkIX"
   },
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "# import librosa\n",
    "# import IPython.display as ipd\n",
    "# import numpy as np\n",
    "#\n",
    "# idx = np.random.randint(0, len(df))\n",
    "# sample = df.iloc[idx]\n",
    "# path = sample[\"path\"]\n",
    "# label = sample[\"emotion\"]\n",
    "#\n",
    "#\n",
    "# print(f\"ID Location: {idx}\")\n",
    "# print(f\"      Label: {label}\")\n",
    "# print()\n",
    "#\n",
    "# speech, sr = torchaudio.load(path)\n",
    "# speech = speech[0].numpy().squeeze()\n",
    "# speech = librosa.resample(np.asarray(speech), sr, 16_000)\n",
    "# ipd.Audio(data=np.asarray(speech), autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcnD-d_rDElt"
   },
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nnVfxQYDDIc6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration data-07433ea064acca3d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/data to /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/cache/csv/data-07433ea064acca3d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63f34466432c41abbe095b689492a28f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "text/plain": "Extracting data files #1:   0%|          | 0/1 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb69765331074b5eb24f91e8ea24756c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files #0:   0%|          | 0/1 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ecde69b94d6b4f138369a1286760c78a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c79b0dfdbbe4b34b74181e42d16d704"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:714: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating validation split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdb52a93e6e14b2ca01e51cb68ac9655"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/cache/csv/data-07433ea064acca3d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:714: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e27efae5ef0447919fa33951aff59b69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the created dataset using datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"train.csv\",\n",
    "    \"validation\": \"test.csv\",\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"content/data/\", data_files=data_files, delimiter=\"\\t\", )\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"validation\"]\n",
    "\n",
    "# We need to specify the input and output column\n",
    "input_column = \"path\"\n",
    "output_column = \"emotion\"\n",
    "# we need to distinguish the unique labels in our SER dataset\n",
    "label_list = train_dataset.unique(output_column)\n",
    "label_list.sort()  # Let's sort it for determinism\n",
    "num_labels = len(label_list)\n",
    "#print(f\"A classification problem with {num_labels} classes: {label_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TkGYrVTFR6Y"
   },
   "source": [
    "In order to preprocess the audio into our classification model, we need to set up the relevant Wav2Vec2 assets regarding our language in this case `lighteternal/wav2vec2-large-xlsr-53-greek` fine-tuned by [Dimitris Papadopoulos](https://huggingface.co/lighteternal/wav2vec2-large-xlsr-53-greek). To handle the context representations in any audio length we use a merge strategy plan (pooling mode) to concatenate that 3D representations into 2D representations.\n",
    "\n",
    "There are three merge strategies `mean`, `sum`, and `max`. In this example, we achieved better results on the mean approach. In the following, we need to initiate the config and the feature extractor from the Dimitris model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9Y1adr7vFrq7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 10:30:22.873006: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-13 10:30:23.391930: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 10:30:23.391986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 10:30:23.391992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "\n",
    "#model_name_or_path = \"lighteternal/wav2vec2-large-xlsr-53-greek\"\n",
    "model_name_or_path = \"jonatasgrosman/wav2vec2-large-xlsr-53-german\"\n",
    "pooling_mode = \"mean\"\n",
    "\n",
    "\n",
    "# config\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    label2id={label: i for i, label in enumerate(label_list)},\n",
    "    id2label={i: label for i, label in enumerate(label_list)},\n",
    "    finetuning_task=\"wav2vec2_clf\",\n",
    ")\n",
    "setattr(config, 'pooling_mode', pooling_mode)\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path, )\n",
    "target_sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(f\"The target sampling rate: {target_sampling_rate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbGuYgLqHXZg"
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLk-eM1DFjtE"
   },
   "source": [
    "So far, we downloaded, loaded, and split the SER dataset into train and test sets. The instantiated our strategy configuration for using context representations in our classification problem SER. Now, we need to extract features from the audio path in context representation tensors and feed them into our classification model to determine the emotion in the speech.\n",
    "\n",
    "Since the audio file is saved in the `.wav` format, it is easy to use **[Librosa](https://librosa.org/doc/latest/index.html)** or others, but we suppose that the format may be in the `.mp3` format in case of generality. We found that the **[Torchaudio](https://pytorch.org/audio/stable/index.html)** library works best for reading in `.mp3` data.\n",
    "\n",
    "An audio file usually stores both its values and the sampling rate with which the speech signal was digitalized. We want to store both in the dataset and write a **map(...)** function accordingly. Also, we need to handle the string labels into integers for our specific classification task in this case, the **single-label classification** you may want to use for your **regression** or even **multi-label classification**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6UqlIV3uGxDA"
   },
   "outputs": [],
   "source": [
    "import utils.audio_dataset_utils as audioUtils\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    speech_list = [audioUtils.speech_file_to_array_librosa(path, target_sampling_rate) for path in examples[input_column]]\n",
    "    target_list = [audioUtils.label_to_id(label, label_list) for label in examples[output_column]]\n",
    "\n",
    "    result = processor(speech_list, sampling_rate=target_sampling_rate)\n",
    "    result[\"labels\"] = list(target_list)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ioP8FfR2GxHi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/96 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "288a34d3467748e49c14636692a44ef6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:164: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ed57b68732e449da39a63a350c47de1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batch_size=20,\n",
    "    batched=True,\n",
    "    #num_proc=4\n",
    ")\n",
    "eval_dataset = eval_dataset.map(\n",
    "    preprocess_function,\n",
    "    batch_size=20,\n",
    "    batched=True,\n",
    "    #num_proc=4\n",
    ")\n",
    "\n",
    "\n",
    "# train_dataset.load_from_disk(dataset_path=\"content/datasets/trainSet\")\n",
    "# eval_dataset.load_from_disk(dataset_path=\"content/datasets/evalSet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# train_dataset.save_to_disk(dataset_path=\"content/datasets/trainSet\")\n",
    "# eval_dataset.save_to_disk(dataset_path=\"content/datasets/evalSet\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['../tess/OAF_Fear/OAF_bean_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_germ_ps.wav',\n '../tess/YAF_angry/YAF_boat_angry.wav',\n '../tess/YAF_angry/YAF_hash_angry.wav',\n '../tess/YAF_disgust/YAF_get_disgust.wav',\n '../tess/OAF_Sad/OAF_when_sad.wav',\n '../tess/YAF_happy/YAF_make_happy.wav',\n '../tess/OAF_angry/OAF_death_angry.wav',\n '../tess/YAF_happy/YAF_hall_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_life_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_cause_ps.wav',\n '../tess/OAF_Sad/OAF_hall_sad.wav',\n '../tess/YAF_sad/YAF_lose_sad.wav',\n '../tess/OAF_happy/OAF_back_happy.wav',\n '../tess/YAF_sad/YAF_goose_sad.wav',\n '../tess/YAF_sad/YAF_take_sad.wav',\n '../tess/YAF_disgust/YAF_door_disgust.wav',\n '../tess/YAF_sad/YAF_life_sad.wav',\n '../tess/OAF_disgust/OAF_hurl_disgust.wav',\n '../tess/OAF_happy/OAF_turn_happy.wav',\n '../tess/YAF_sad/YAF_jar_sad.wav',\n '../tess/OAF_Sad/OAF_get_sad.wav',\n '../tess/OAF_Sad/OAF_pass_sad.wav',\n '../tess/OAF_disgust/OAF_south_disgust.wav',\n '../tess/OAF_angry/OAF_boat_angry.wav',\n '../tess/OAF_Sad/OAF_pool_sad.wav',\n '../tess/OAF_disgust/OAF_nice_disgust.wav',\n '../tess/YAF_disgust/YAF_met_disgust.wav',\n '../tess/OAF_disgust/OAF_goal_disgust.wav',\n '../tess/OAF_angry/OAF_rat_angry.wav',\n '../tess/OAF_Fear/OAF_back_fear.wav',\n '../tess/YAF_angry/YAF_whip_angry.wav',\n '../tess/YAF_disgust/YAF_doll_disgust.wav',\n '../tess/OAF_Fear/OAF_bought_fear.wav',\n '../tess/OAF_happy/OAF_pearl_happy.wav',\n '../tess/YAF_angry/YAF_laud_angry.wav',\n '../tess/OAF_Fear/OAF_calm_fear.wav',\n '../tess/YAF_angry/YAF_void_angry.wav',\n '../tess/OAF_happy/OAF_jug_happy.wav',\n '../tess/OAF_happy/OAF_week_happy.wav',\n '../tess/YAF_happy/YAF_ditch_happy.wav',\n '../tess/YAF_disgust/YAF_team_disgust.wav',\n '../tess/OAF_Fear/OAF_check_fear.wav',\n '../tess/YAF_fear/YAF_search_fear.wav',\n '../tess/YAF_happy/YAF_late_happy.wav',\n '../tess/YAF_happy/YAF_pike_happy.wav',\n '../tess/OAF_angry/OAF_time_angry.wav',\n '../tess/OAF_angry/OAF_hire_angry.wav',\n '../tess/YAF_disgust/YAF_pike_disgust.wav',\n '../tess/YAF_fear/YAF_pike_fear.wav',\n '../tess/OAF_happy/OAF_road_happy.wav',\n '../tess/YAF_angry/YAF_fat_angry.wav',\n '../tess/YAF_disgust/YAF_thought_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_germ_ps.wav',\n '../tess/OAF_happy/OAF_gap_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_week_ps.wav',\n '../tess/YAF_sad/YAF_choice_sad.wav',\n '../tess/OAF_Sad/OAF_germ_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_ring_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_said_ps.wav',\n '../tess/YAF_fear/YAF_seize_fear.wav',\n '../tess/OAF_Sad/OAF_dead_sad.wav',\n '../tess/OAF_Sad/OAF_gin_sad.wav',\n '../tess/OAF_Fear/OAF_thin_fear.wav',\n '../tess/YAF_happy/YAF_sour_happy.wav',\n '../tess/OAF_Fear/OAF_pad_fear.wav',\n '../tess/YAF_fear/YAF_yearn_fear.wav',\n '../tess/OAF_Fear/OAF_name_fear.wav',\n '../tess/YAF_fear/YAF_sell_fear.wav',\n '../tess/YAF_happy/YAF_talk_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_void_ps.wav',\n '../tess/OAF_Fear/OAF_mode_fear.wav',\n '../tess/YAF_sad/YAF_bite_sad.wav',\n '../tess/YAF_angry/YAF_lean_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_ripe_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_hole_ps.wav',\n '../tess/OAF_Sad/OAF_mess_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_half_ps.wav',\n '../tess/YAF_sad/YAF_ring_sad.wav',\n '../tess/YAF_angry/YAF_long_angry.wav',\n '../tess/YAF_disgust/YAF_ditch_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_fail_ps.wav',\n '../tess/OAF_disgust/OAF_pass_disgust.wav',\n '../tess/YAF_angry/YAF_dip_angry.wav',\n '../tess/YAF_angry/YAF_mill_angry.wav',\n '../tess/OAF_Sad/OAF_kick_sad.wav',\n '../tess/OAF_Fear/OAF_dodge_fear.wav',\n '../tess/YAF_angry/YAF_gaze_angry.wav',\n '../tess/OAF_Fear/OAF_sail_fear.wav',\n '../tess/OAF_Fear/OAF_fall_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_white_ps.wav',\n '../tess/OAF_Fear/OAF_met_fear.wav',\n '../tess/OAF_happy/OAF_whip_happy.wav',\n '../tess/YAF_sad/YAF_search_sad.wav',\n '../tess/OAF_Fear/OAF_lose_fear.wav',\n '../tess/YAF_disgust/YAF_keen_disgust.wav',\n '../tess/YAF_angry/YAF_such_angry.wav',\n '../tess/OAF_Sad/OAF_came_sad.wav',\n '../tess/YAF_sad/YAF_neat_sad.wav',\n '../tess/YAF_fear/YAF_reach_fear.wav',\n '../tess/YAF_happy/YAF_jail_happy.wav',\n '../tess/OAF_disgust/OAF_bite_disgust.wav',\n '../tess/OAF_Fear/OAF_note_fear.wav',\n '../tess/YAF_disgust/YAF_mop_disgust.wav',\n '../tess/YAF_happy/YAF_chalk_happy.wav',\n '../tess/OAF_disgust/OAF_five_disgust.wav',\n '../tess/YAF_sad/YAF_keen_sad.wav',\n '../tess/OAF_disgust/OAF_ring_disgust.wav',\n '../tess/YAF_disgust/YAF_merge_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_check_ps.wav',\n '../tess/YAF_fear/YAF_wash_fear.wav',\n '../tess/OAF_Fear/OAF_sell_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_chat_ps.wav',\n '../tess/YAF_disgust/YAF_death_disgust.wav',\n '../tess/OAF_Fear/OAF_voice_fear.wav',\n '../tess/OAF_Fear/OAF_judge_fear.wav',\n '../tess/OAF_disgust/OAF_read_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_food_ps.wav',\n '../tess/YAF_fear/YAF_shout_fear.wav',\n '../tess/YAF_happy/YAF_bite_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_yearn_ps.wav',\n '../tess/OAF_disgust/OAF_shawl_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_limb_ps.wav',\n '../tess/OAF_Sad/OAF_jar_sad.wav',\n '../tess/OAF_angry/OAF_fail_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_get_ps.wav',\n '../tess/YAF_fear/YAF_moon_fear.wav',\n '../tess/OAF_angry/OAF_doll_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_time_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_wag_ps.wav',\n '../tess/YAF_sad/YAF_late_sad.wav',\n '../tess/YAF_angry/YAF_lore_angry.wav',\n '../tess/OAF_Sad/OAF_wag_sad.wav',\n '../tess/OAF_disgust/OAF_ditch_disgust.wav',\n '../tess/OAF_Fear/OAF_bone_fear.wav',\n '../tess/YAF_angry/YAF_neat_angry.wav',\n '../tess/YAF_sad/YAF_shawl_sad.wav',\n '../tess/YAF_happy/YAF_chief_happy.wav',\n '../tess/OAF_disgust/OAF_witch_disgust.wav',\n '../tess/YAF_disgust/YAF_should_disgust.wav',\n '../tess/OAF_happy/OAF_dip_happy.wav',\n '../tess/OAF_Sad/OAF_name_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_knock_ps.wav',\n '../tess/YAF_happy/YAF_seize_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_lot_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_bought_ps.wav',\n '../tess/YAF_sad/YAF_said_sad.wav',\n '../tess/OAF_Sad/OAF_half_sad.wav',\n '../tess/YAF_fear/YAF_kite_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_boat_ps.wav',\n '../tess/OAF_Sad/OAF_lot_sad.wav',\n '../tess/YAF_disgust/YAF_hit_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_vine_ps.wav',\n '../tess/OAF_angry/OAF_rot_angry.wav',\n '../tess/OAF_Sad/OAF_keep_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_tough_ps.wav',\n '../tess/YAF_angry/YAF_keg_angry.wav',\n '../tess/YAF_disgust/YAF_bar_disgust.wav',\n '../tess/OAF_Sad/OAF_raid_sad.wav',\n '../tess/OAF_disgust/OAF_dab_disgust.wav',\n '../tess/OAF_Fear/OAF_death_fear.wav',\n '../tess/OAF_Sad/OAF_bath_sad.wav',\n '../tess/YAF_happy/YAF_page_happy.wav',\n '../tess/YAF_happy/YAF_laud_happy.wav',\n '../tess/YAF_sad/YAF_mess_sad.wav',\n '../tess/OAF_disgust/OAF_ton_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_mess_ps.wav',\n '../tess/OAF_Fear/OAF_when_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_dime_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_goal_ps.wav',\n '../tess/YAF_sad/YAF_fail_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_room_ps.wav',\n '../tess/YAF_fear/YAF_bar_fear.wav',\n '../tess/OAF_happy/OAF_tool_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_hall_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_lease_ps.wav',\n '../tess/YAF_happy/YAF_gun_happy.wav',\n '../tess/OAF_disgust/OAF_half_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_hush_ps.wav',\n '../tess/YAF_fear/YAF_perch_fear.wav',\n '../tess/OAF_Fear/OAF_bite_fear.wav',\n '../tess/YAF_disgust/YAF_mode_disgust.wav',\n '../tess/YAF_fear/YAF_thin_fear.wav',\n '../tess/OAF_Fear/OAF_jail_fear.wav',\n '../tess/OAF_happy/OAF_boat_happy.wav',\n '../tess/OAF_Fear/OAF_late_fear.wav',\n '../tess/YAF_fear/YAF_base_fear.wav',\n '../tess/YAF_happy/YAF_ton_happy.wav',\n '../tess/OAF_angry/OAF_cause_angry.wav',\n '../tess/YAF_sad/YAF_pool_sad.wav',\n '../tess/OAF_Fear/OAF_soap_fear.wav',\n '../tess/OAF_angry/OAF_half_angry.wav',\n '../tess/OAF_disgust/OAF_mop_disgust.wav',\n '../tess/YAF_disgust/YAF_gas_disgust.wav',\n '../tess/OAF_Fear/OAF_jar_fear.wav',\n '../tess/YAF_happy/YAF_mouse_happy.wav',\n '../tess/OAF_disgust/OAF_shout_disgust.wav',\n '../tess/OAF_happy/OAF_shirt_happy.wav',\n '../tess/OAF_Fear/OAF_read_fear.wav',\n '../tess/YAF_angry/YAF_good_angry.wav',\n '../tess/YAF_happy/YAF_have_happy.wav',\n '../tess/OAF_angry/OAF_keep_angry.wav',\n '../tess/OAF_happy/OAF_dead_happy.wav',\n '../tess/OAF_disgust/OAF_size_disgust.wav',\n '../tess/OAF_disgust/OAF_jar_disgust.wav',\n '../tess/OAF_angry/OAF_voice_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_deep_ps.wav',\n '../tess/OAF_happy/OAF_sour_happy.wav',\n '../tess/YAF_fear/YAF_red_fear.wav',\n '../tess/OAF_disgust/OAF_soup_disgust.wav',\n '../tess/YAF_sad/YAF_mob_sad.wav',\n '../tess/YAF_sad/YAF_chalk_sad.wav',\n '../tess/OAF_happy/OAF_deep_happy.wav',\n '../tess/YAF_fear/YAF_voice_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_said_ps.wav',\n '../tess/YAF_sad/YAF_name_sad.wav',\n '../tess/OAF_disgust/OAF_merge_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_dodge_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_dime_ps.wav',\n '../tess/OAF_Fear/OAF_sub_fear.wav',\n '../tess/OAF_angry/OAF_lease_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_doll_ps.wav',\n '../tess/YAF_disgust/YAF_tip_disgust.wav',\n '../tess/OAF_angry/OAF_gap_angry.wav',\n '../tess/OAF_happy/OAF_mop_happy.wav',\n '../tess/YAF_sad/YAF_keep_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_rough_ps.wav',\n '../tess/YAF_disgust/YAF_hate_disgust.wav',\n '../tess/YAF_fear/YAF_wife_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_kill_ps.wav',\n '../tess/OAF_disgust/OAF_talk_disgust.wav',\n '../tess/YAF_disgust/YAF_pick_disgust.wav',\n '../tess/OAF_happy/OAF_half_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_nice_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_search_ps.wav',\n '../tess/YAF_happy/YAF_bone_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_came_ps.wav',\n '../tess/YAF_disgust/YAF_yes_disgust.wav',\n '../tess/OAF_Fear/OAF_gun_fear.wav',\n '../tess/OAF_Sad/OAF_take_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_near_ps.wav',\n '../tess/OAF_angry/OAF_ring_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_pass_ps.wav',\n '../tess/YAF_angry/YAF_tire_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_luck_ps.wav',\n '../tess/OAF_disgust/OAF_haze_disgust.wav',\n '../tess/YAF_angry/YAF_merge_angry.wav',\n '../tess/OAF_angry/OAF_neat_angry.wav',\n '../tess/OAF_Fear/OAF_walk_fear.wav',\n '../tess/YAF_sad/YAF_jail_sad.wav',\n '../tess/OAF_Sad/OAF_moon_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_seize_ps.wav',\n '../tess/YAF_disgust/YAF_king_disgust.wav',\n '../tess/OAF_Sad/OAF_dip_sad.wav',\n '../tess/YAF_sad/YAF_pike_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_mode_ps.wav',\n '../tess/YAF_happy/YAF_third_happy.wav',\n '../tess/YAF_disgust/YAF_lease_disgust.wav',\n '../tess/OAF_happy/OAF_haze_happy.wav',\n '../tess/YAF_sad/YAF_page_sad.wav',\n '../tess/YAF_fear/YAF_hurl_fear.wav',\n '../tess/YAF_fear/YAF_choice_fear.wav',\n '../tess/YAF_happy/YAF_vote_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_lose_ps.wav',\n '../tess/YAF_disgust/YAF_road_disgust.wav',\n '../tess/YAF_sad/YAF_time_sad.wav',\n '../tess/YAF_fear/YAF_lore_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_dodge_ps.wav',\n '../tess/YAF_disgust/YAF_pearl_disgust.wav',\n '../tess/YAF_happy/YAF_home_happy.wav',\n '../tess/YAF_disgust/YAF_raid_disgust.wav',\n '../tess/OAF_angry/OAF_tire_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_choice_ps.wav',\n '../tess/YAF_disgust/YAF_voice_disgust.wav',\n '../tess/YAF_fear/YAF_learn_fear.wav',\n '../tess/YAF_sad/YAF_half_sad.wav',\n '../tess/OAF_angry/OAF_lid_angry.wav',\n '../tess/OAF_happy/OAF_vine_happy.wav',\n '../tess/YAF_happy/YAF_vine_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_boat_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_live_ps.wav',\n '../tess/OAF_happy/OAF_pole_happy.wav',\n '../tess/OAF_angry/OAF_door_angry.wav',\n '../tess/YAF_fear/YAF_ripe_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_met_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_late_ps.wav',\n '../tess/OAF_Fear/OAF_rough_fear.wav',\n '../tess/YAF_happy/YAF_wheat_happy.wav',\n '../tess/OAF_disgust/OAF_back_disgust.wav',\n '../tess/YAF_fear/YAF_live_fear.wav',\n '../tess/YAF_fear/YAF_rose_fear.wav',\n '../tess/YAF_angry/YAF_pole_angry.wav',\n '../tess/YAF_angry/YAF_fail_angry.wav',\n '../tess/OAF_happy/OAF_pick_happy.wav',\n '../tess/OAF_disgust/OAF_fail_disgust.wav',\n '../tess/YAF_fear/YAF_phone_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_rush_ps.wav',\n '../tess/YAF_angry/YAF_fit_angry.wav',\n '../tess/OAF_Sad/OAF_young_sad.wav',\n '../tess/YAF_fear/YAF_pass_fear.wav',\n '../tess/YAF_sad/YAF_cheek_sad.wav',\n '../tess/OAF_Fear/OAF_vote_fear.wav',\n '../tess/OAF_disgust/OAF_bean_disgust.wav',\n '../tess/YAF_fear/YAF_nag_fear.wav',\n '../tess/YAF_angry/YAF_jail_angry.wav',\n '../tess/OAF_happy/OAF_read_happy.wav',\n '../tess/YAF_disgust/YAF_germ_disgust.wav',\n '../tess/YAF_sad/YAF_nag_sad.wav',\n '../tess/OAF_angry/OAF_deep_angry.wav',\n '../tess/YAF_happy/YAF_hurl_happy.wav',\n '../tess/YAF_disgust/YAF_seize_disgust.wav',\n '../tess/OAF_Sad/OAF_tell_sad.wav',\n '../tess/OAF_disgust/OAF_keg_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_perch_ps.wav',\n '../tess/OAF_Sad/OAF_haze_sad.wav',\n '../tess/OAF_disgust/OAF_pad_disgust.wav',\n '../tess/OAF_Fear/OAF_should_fear.wav',\n '../tess/OAF_Sad/OAF_fit_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_ring_ps.wav',\n '../tess/YAF_happy/YAF_cheek_happy.wav',\n '../tess/OAF_Sad/OAF_sour_sad.wav',\n '../tess/OAF_angry/OAF_dodge_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_door_ps.wav',\n '../tess/YAF_sad/YAF_numb_sad.wav',\n '../tess/YAF_happy/YAF_tool_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_pike_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_dip_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_shack_ps.wav',\n '../tess/OAF_angry/OAF_hush_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_walk_ps.wav',\n '../tess/YAF_fear/YAF_jail_fear.wav',\n '../tess/YAF_fear/YAF_dodge_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_sour_ps.wav',\n '../tess/OAF_disgust/OAF_cause_disgust.wav',\n '../tess/YAF_disgust/YAF_calm_disgust.wav',\n '../tess/OAF_Sad/OAF_yes_sad.wav',\n '../tess/OAF_disgust/OAF_phone_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_knock_ps.wav',\n '../tess/OAF_disgust/OAF_boat_disgust.wav',\n '../tess/YAF_fear/YAF_ditch_fear.wav',\n '../tess/YAF_angry/YAF_thought_angry.wav',\n '../tess/YAF_happy/YAF_south_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_laud_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_limb_ps.wav',\n '../tess/OAF_disgust/OAF_neat_disgust.wav',\n '../tess/YAF_disgust/YAF_mood_disgust.wav',\n '../tess/YAF_angry/YAF_nice_angry.wav',\n '../tess/OAF_disgust/OAF_moon_disgust.wav',\n '../tess/OAF_happy/OAF_ring_happy.wav',\n '../tess/OAF_Sad/OAF_ring_sad.wav',\n '../tess/OAF_angry/OAF_bean_angry.wav',\n '../tess/OAF_happy/OAF_juice_happy.wav',\n '../tess/OAF_happy/OAF_dog_happy.wav',\n '../tess/YAF_fear/YAF_lease_fear.wav',\n '../tess/YAF_disgust/YAF_whip_disgust.wav',\n '../tess/YAF_fear/YAF_judge_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_jug_ps.wav',\n '../tess/YAF_disgust/YAF_choice_disgust.wav',\n '../tess/OAF_happy/OAF_germ_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_goal_ps.wav',\n '../tess/YAF_happy/YAF_keep_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_dab_ps.wav',\n '../tess/OAF_angry/OAF_yearn_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_shirt_ps.wav',\n '../tess/YAF_sad/YAF_read_sad.wav',\n '../tess/OAF_disgust/OAF_rain_disgust.wav',\n '../tess/OAF_angry/OAF_keen_angry.wav',\n '../tess/OAF_Sad/OAF_lid_sad.wav',\n '../tess/YAF_happy/YAF_dip_happy.wav',\n '../tess/OAF_angry/OAF_road_angry.wav',\n '../tess/YAF_happy/YAF_lot_happy.wav',\n '../tess/YAF_happy/YAF_pick_happy.wav',\n '../tess/YAF_angry/YAF_chain_angry.wav',\n '../tess/YAF_sad/YAF_gin_sad.wav',\n '../tess/OAF_Sad/OAF_thought_sad.wav',\n '../tess/OAF_disgust/OAF_laud_disgust.wav',\n '../tess/OAF_happy/OAF_bone_happy.wav',\n '../tess/YAF_happy/YAF_raid_happy.wav',\n '../tess/OAF_disgust/OAF_gas_disgust.wav',\n '../tess/OAF_angry/OAF_loaf_angry.wav',\n '../tess/YAF_disgust/YAF_peg_disgust.wav',\n '../tess/YAF_fear/YAF_bean_fear.wav',\n '../tess/YAF_disgust/YAF_vine_disgust.wav',\n '../tess/YAF_sad/YAF_king_sad.wav',\n '../tess/YAF_sad/YAF_road_sad.wav',\n '../tess/YAF_fear/YAF_sail_fear.wav',\n '../tess/OAF_Sad/OAF_pearl_sad.wav',\n '../tess/YAF_happy/YAF_mill_happy.wav',\n '../tess/YAF_disgust/YAF_near_disgust.wav',\n '../tess/OAF_happy/OAF_which_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_laud_ps.wav',\n '../tess/OAF_disgust/OAF_book_disgust.wav',\n '../tess/OAF_Fear/OAF_team_fear.wav',\n '../tess/OAF_Sad/OAF_bean_sad.wav',\n '../tess/OAF_angry/OAF_tip_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_sure_ps.wav',\n '../tess/OAF_Sad/OAF_pick_sad.wav',\n '../tess/OAF_angry/OAF_near_angry.wav',\n '../tess/YAF_happy/YAF_death_happy.wav',\n '../tess/OAF_Sad/OAF_dog_sad.wav',\n '../tess/YAF_fear/YAF_rot_fear.wav',\n '../tess/OAF_Fear/OAF_wire_fear.wav',\n '../tess/YAF_angry/YAF_moon_angry.wav',\n '../tess/OAF_Sad/OAF_mode_sad.wav',\n '../tess/OAF_Sad/OAF_doll_sad.wav',\n '../tess/OAF_disgust/OAF_beg_disgust.wav',\n '../tess/YAF_disgust/YAF_void_disgust.wav',\n '../tess/OAF_happy/OAF_wag_happy.wav',\n '../tess/OAF_Sad/OAF_peg_sad.wav',\n '../tess/YAF_fear/YAF_road_fear.wav',\n '../tess/OAF_happy/OAF_shack_happy.wav',\n '../tess/YAF_happy/YAF_long_happy.wav',\n '../tess/YAF_fear/YAF_tool_fear.wav',\n '../tess/YAF_angry/YAF_dead_angry.wav',\n '../tess/YAF_happy/YAF_moon_happy.wav',\n '../tess/YAF_sad/YAF_juice_sad.wav',\n '../tess/OAF_Sad/OAF_loaf_sad.wav',\n '../tess/OAF_Sad/OAF_make_sad.wav',\n '../tess/OAF_Fear/OAF_ton_fear.wav',\n '../tess/OAF_happy/OAF_rag_happy.wav',\n '../tess/YAF_sad/YAF_lean_sad.wav',\n '../tess/OAF_Sad/OAF_laud_sad.wav',\n '../tess/YAF_disgust/YAF_rose_disgust.wav',\n '../tess/OAF_angry/OAF_such_angry.wav',\n '../tess/OAF_angry/OAF_gas_angry.wav',\n '../tess/OAF_angry/OAF_five_angry.wav',\n '../tess/OAF_Sad/OAF_kill_sad.wav',\n '../tess/OAF_happy/OAF_goal_happy.wav',\n '../tess/YAF_sad/YAF_south_sad.wav',\n '../tess/YAF_sad/YAF_talk_sad.wav',\n '../tess/OAF_Sad/OAF_yearn_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_should_ps.wav',\n '../tess/OAF_Sad/OAF_gap_sad.wav',\n '../tess/OAF_Fear/OAF_shall_fear.wav',\n '../tess/YAF_angry/YAF_thumb_angry.wav',\n '../tess/YAF_disgust/YAF_make_disgust.wav',\n '../tess/YAF_disgust/YAF_tell_disgust.wav',\n '../tess/OAF_Fear/OAF_sour_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_when_ps.wav',\n '../tess/OAF_disgust/OAF_tip_disgust.wav',\n '../tess/OAF_Fear/OAF_talk_fear.wav',\n '../tess/OAF_Sad/OAF_chief_sad.wav',\n '../tess/YAF_happy/YAF_when_happy.wav',\n '../tess/OAF_disgust/OAF_time_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_sell_ps.wav',\n '../tess/OAF_disgust/OAF_base_disgust.wav',\n '../tess/OAF_happy/OAF_far_happy.wav',\n '../tess/YAF_disgust/YAF_gaze_disgust.wav',\n '../tess/YAF_sad/YAF_dime_sad.wav',\n '../tess/YAF_angry/YAF_base_angry.wav',\n '../tess/OAF_angry/OAF_soup_angry.wav',\n '../tess/YAF_happy/YAF_said_happy.wav',\n '../tess/OAF_angry/OAF_cab_angry.wav',\n '../tess/YAF_angry/YAF_dab_angry.wav',\n '../tess/OAF_happy/OAF_limb_happy.wav',\n '../tess/OAF_angry/OAF_mode_angry.wav',\n '../tess/YAF_sad/YAF_hit_sad.wav',\n '../tess/OAF_Sad/OAF_live_sad.wav',\n '../tess/OAF_happy/OAF_have_happy.wav',\n '../tess/YAF_happy/YAF_wag_happy.wav',\n '../tess/YAF_sad/YAF_make_sad.wav',\n '../tess/OAF_disgust/OAF_chair_disgust.wav',\n '../tess/OAF_Fear/OAF_chair_fear.wav',\n '../tess/YAF_fear/YAF_page_fear.wav',\n '../tess/OAF_happy/OAF_voice_happy.wav',\n '../tess/OAF_happy/OAF_food_happy.wav',\n '../tess/OAF_angry/OAF_lore_angry.wav',\n '../tess/OAF_Sad/OAF_life_sad.wav',\n '../tess/OAF_Sad/OAF_shout_sad.wav',\n '../tess/OAF_happy/OAF_take_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_rain_ps.wav',\n '../tess/OAF_Fear/OAF_door_fear.wav',\n '../tess/YAF_happy/YAF_whip_happy.wav',\n '../tess/OAF_Fear/OAF_lot_fear.wav',\n '../tess/OAF_angry/OAF_mob_angry.wav',\n '../tess/YAF_disgust/YAF_shirt_disgust.wav',\n '../tess/YAF_angry/YAF_note_angry.wav',\n '../tess/OAF_Fear/OAF_jug_fear.wav',\n '../tess/OAF_disgust/OAF_wife_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_tire_ps.wav',\n '../tess/OAF_Fear/OAF_week_fear.wav',\n '../tess/YAF_fear/YAF_jar_fear.wav',\n '../tess/OAF_disgust/OAF_learn_disgust.wav',\n '../tess/OAF_angry/OAF_mess_angry.wav',\n '../tess/OAF_happy/OAF_gun_happy.wav',\n '../tess/OAF_angry/OAF_match_angry.wav',\n '../tess/YAF_sad/YAF_fat_sad.wav',\n '../tess/YAF_fear/YAF_germ_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_wash_ps.wav',\n '../tess/YAF_fear/YAF_knock_fear.wav',\n '../tess/YAF_disgust/YAF_book_disgust.wav',\n '../tess/OAF_disgust/OAF_voice_disgust.wav',\n '../tess/YAF_fear/YAF_have_fear.wav',\n '../tess/YAF_sad/YAF_gas_sad.wav',\n '../tess/OAF_angry/OAF_kite_angry.wav',\n '../tess/YAF_happy/YAF_hash_happy.wav',\n '../tess/YAF_happy/YAF_pad_happy.wav',\n '../tess/OAF_Sad/OAF_hire_sad.wav',\n '../tess/YAF_happy/YAF_fall_happy.wav',\n '../tess/OAF_Sad/OAF_chair_sad.wav',\n '../tess/OAF_disgust/OAF_lid_disgust.wav',\n '../tess/OAF_angry/OAF_burn_angry.wav',\n '../tess/OAF_happy/OAF_hate_happy.wav',\n '../tess/YAF_angry/YAF_raid_angry.wav',\n '../tess/YAF_happy/YAF_reach_happy.wav',\n '../tess/YAF_happy/YAF_bath_happy.wav',\n '../tess/YAF_sad/YAF_should_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_wash_ps.wav',\n '../tess/YAF_happy/YAF_wire_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_merge_ps.wav',\n '../tess/OAF_disgust/OAF_reach_disgust.wav',\n '../tess/YAF_angry/YAF_tell_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_phone_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_jar_ps.wav',\n '../tess/OAF_Sad/OAF_should_sad.wav',\n '../tess/YAF_happy/YAF_pearl_happy.wav',\n '../tess/OAF_happy/OAF_tell_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_such_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_numb_ps.wav',\n '../tess/YAF_fear/YAF_young_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_road_ps.wav',\n '../tess/YAF_happy/YAF_red_happy.wav',\n '../tess/OAF_Fear/OAF_puff_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_pass_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_sub_ps.wav',\n '../tess/OAF_Sad/OAF_fat_sad.wav',\n '../tess/YAF_angry/YAF_book_angry.wav',\n '../tess/OAF_Sad/OAF_page_sad.wav',\n '../tess/OAF_Sad/OAF_wife_sad.wav',\n '../tess/OAF_Sad/OAF_calm_sad.wav',\n '../tess/YAF_disgust/YAF_cab_disgust.wav',\n '../tess/OAF_Fear/OAF_thumb_fear.wav',\n '../tess/OAF_angry/OAF_room_angry.wav',\n '../tess/YAF_fear/YAF_met_fear.wav',\n '../tess/YAF_fear/YAF_youth_fear.wav',\n '../tess/YAF_angry/YAF_rot_angry.wav',\n '../tess/OAF_Sad/OAF_neat_sad.wav',\n '../tess/OAF_disgust/OAF_lose_disgust.wav',\n '../tess/OAF_angry/OAF_page_angry.wav',\n '../tess/OAF_disgust/OAF_luck_disgust.wav',\n '../tess/OAF_Fear/OAF_red_fear.wav',\n '../tess/YAF_fear/YAF_thought_fear.wav',\n '../tess/YAF_angry/YAF_hall_angry.wav',\n '../tess/YAF_sad/YAF_near_sad.wav',\n '../tess/YAF_happy/YAF_tape_happy.wav',\n '../tess/OAF_Fear/OAF_said_fear.wav',\n '../tess/OAF_disgust/OAF_keep_disgust.wav',\n '../tess/YAF_sad/YAF_wheat_sad.wav',\n '../tess/OAF_Sad/OAF_hash_sad.wav',\n '../tess/YAF_happy/YAF_base_happy.wav',\n '../tess/YAF_disgust/YAF_lid_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_love_ps.wav',\n '../tess/OAF_disgust/OAF_thought_disgust.wav',\n '../tess/OAF_happy/OAF_page_happy.wav',\n '../tess/OAF_happy/OAF_king_happy.wav',\n '../tess/OAF_angry/OAF_dime_angry.wav',\n '../tess/OAF_disgust/OAF_when_disgust.wav',\n '../tess/YAF_fear/YAF_chalk_fear.wav',\n '../tess/YAF_disgust/YAF_ring_disgust.wav',\n '../tess/OAF_angry/OAF_long_angry.wav',\n '../tess/YAF_happy/YAF_burn_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_pad_ps.wav',\n '../tess/OAF_Sad/OAF_home_sad.wav',\n '../tess/OAF_angry/OAF_laud_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_talk_ps.wav',\n '../tess/OAF_disgust/OAF_yes_disgust.wav',\n '../tess/YAF_angry/YAF_phone_angry.wav',\n '../tess/YAF_disgust/YAF_page_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_home_ps.wav',\n '../tess/YAF_disgust/YAF_rot_disgust.wav',\n '../tess/OAF_Fear/OAF_dip_fear.wav',\n '../tess/OAF_Sad/OAF_hit_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_shawl_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_wire_ps.wav',\n '../tess/OAF_angry/OAF_mouse_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_gun_ps.wav',\n '../tess/YAF_happy/YAF_size_happy.wav',\n '../tess/YAF_fear/YAF_hire_fear.wav',\n '../tess/YAF_fear/YAF_gun_fear.wav',\n '../tess/YAF_sad/YAF_lease_sad.wav',\n '../tess/OAF_angry/OAF_dead_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_shout_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_jar_ps.wav',\n '../tess/OAF_happy/OAF_mess_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_chain_ps.wav',\n '../tess/YAF_sad/YAF_chief_sad.wav',\n '../tess/OAF_angry/OAF_third_angry.wav',\n '../tess/YAF_fear/YAF_mouse_fear.wav',\n '../tess/OAF_Fear/OAF_rush_fear.wav',\n '../tess/YAF_happy/YAF_shawl_happy.wav',\n '../tess/YAF_fear/YAF_life_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_sail_ps.wav',\n '../tess/YAF_happy/YAF_dodge_happy.wav',\n '../tess/OAF_happy/OAF_witch_happy.wav',\n '../tess/OAF_Sad/OAF_door_sad.wav',\n '../tess/OAF_angry/OAF_ripe_angry.wav',\n '../tess/OAF_Sad/OAF_deep_sad.wav',\n '../tess/YAF_angry/YAF_hit_angry.wav',\n '../tess/OAF_disgust/OAF_chief_disgust.wav',\n '../tess/YAF_sad/YAF_gaze_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_size_ps.wav',\n '../tess/YAF_angry/YAF_puff_angry.wav',\n '../tess/YAF_fear/YAF_hit_fear.wav',\n '../tess/OAF_Fear/OAF_keen_fear.wav',\n '../tess/OAF_Fear/OAF_road_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_pool_ps.wav',\n '../tess/OAF_angry/OAF_limb_angry.wav',\n '../tess/OAF_Fear/OAF_young_fear.wav',\n '../tess/YAF_angry/YAF_sheep_angry.wav',\n '../tess/YAF_sad/YAF_perch_sad.wav',\n '../tess/YAF_happy/YAF_rag_happy.wav',\n '../tess/OAF_Fear/OAF_size_fear.wav',\n '../tess/OAF_Sad/OAF_bought_sad.wav',\n '../tess/OAF_Sad/OAF_king_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_peg_ps.wav',\n '../tess/OAF_angry/OAF_food_angry.wav',\n '../tess/YAF_sad/YAF_ripe_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_keg_ps.wav',\n '../tess/OAF_angry/OAF_bite_angry.wav',\n '../tess/OAF_happy/OAF_pool_happy.wav',\n '../tess/OAF_Fear/OAF_keg_fear.wav',\n '../tess/OAF_angry/OAF_book_angry.wav',\n '../tess/YAF_disgust/YAF_read_disgust.wav',\n '../tess/YAF_angry/YAF_should_angry.wav',\n '../tess/YAF_angry/YAF_live_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_keep_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_gin_ps.wav',\n '../tess/OAF_happy/OAF_thumb_happy.wav',\n '../tess/OAF_Sad/OAF_jail_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_get_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_mill_ps.wav',\n '../tess/OAF_disgust/OAF_search_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_far_ps.wav',\n '../tess/YAF_angry/YAF_red_angry.wav',\n '../tess/YAF_happy/YAF_learn_happy.wav',\n '../tess/OAF_Sad/OAF_base_sad.wav',\n '../tess/OAF_Sad/OAF_nag_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_haze_ps.wav',\n '../tess/YAF_angry/YAF_page_angry.wav',\n '../tess/OAF_Sad/OAF_rag_sad.wav',\n '../tess/YAF_fear/YAF_take_fear.wav',\n '../tess/OAF_Sad/OAF_red_sad.wav',\n '../tess/OAF_angry/OAF_dip_angry.wav',\n '../tess/YAF_angry/YAF_chair_angry.wav',\n '../tess/OAF_angry/OAF_size_angry.wav',\n '../tess/OAF_angry/OAF_shawl_angry.wav',\n '../tess/YAF_angry/YAF_turn_angry.wav',\n '../tess/OAF_angry/OAF_talk_angry.wav',\n '../tess/OAF_disgust/OAF_bought_disgust.wav',\n '../tess/YAF_disgust/YAF_cheek_disgust.wav',\n '../tess/YAF_angry/YAF_witch_angry.wav',\n '../tess/YAF_sad/YAF_gun_sad.wav',\n '../tess/OAF_Sad/OAF_cool_sad.wav',\n '../tess/YAF_disgust/YAF_note_disgust.wav',\n '../tess/YAF_happy/YAF_sure_happy.wav',\n '../tess/YAF_angry/YAF_tip_angry.wav',\n '../tess/OAF_happy/OAF_mode_happy.wav',\n '../tess/YAF_angry/YAF_lid_angry.wav',\n '../tess/YAF_happy/YAF_note_happy.wav',\n '../tess/YAF_fear/YAF_mess_fear.wav',\n '../tess/YAF_sad/YAF_third_sad.wav',\n '../tess/YAF_happy/YAF_chat_happy.wav',\n '../tess/YAF_sad/YAF_rose_sad.wav',\n '../tess/OAF_Fear/OAF_such_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_numb_ps.wav',\n '../tess/YAF_sad/YAF_size_sad.wav',\n '../tess/YAF_angry/YAF_bought_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_learn_ps.wav',\n '../tess/YAF_happy/YAF_shirt_happy.wav',\n '../tess/OAF_happy/OAF_hush_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_rag_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_take_ps.wav',\n '../tess/YAF_fear/YAF_loaf_fear.wav',\n '../tess/YAF_disgust/YAF_south_disgust.wav',\n '../tess/OAF_Fear/OAF_get_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_note_ps.wav',\n '../tess/OAF_happy/OAF_name_happy.wav',\n '../tess/OAF_disgust/OAF_sail_disgust.wav',\n '../tess/OAF_happy/OAF_choice_happy.wav',\n '../tess/YAF_fear/YAF_fit_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_hate_ps.wav',\n '../tess/OAF_Sad/OAF_walk_sad.wav',\n '../tess/OAF_disgust/OAF_jail_disgust.wav',\n '../tess/YAF_sad/YAF_bone_sad.wav',\n '../tess/OAF_Fear/OAF_make_fear.wav',\n '../tess/OAF_Sad/OAF_team_sad.wav',\n '../tess/YAF_sad/YAF_hire_sad.wav',\n '../tess/YAF_happy/YAF_calm_happy.wav',\n '../tess/OAF_Fear/OAF_shack_fear.wav',\n '../tess/OAF_disgust/OAF_get_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_keen_ps.wav',\n '../tess/YAF_angry/YAF_road_angry.wav',\n '../tess/OAF_Fear/OAF_gin_fear.wav',\n '../tess/YAF_happy/YAF_hit_happy.wav',\n '../tess/YAF_disgust/YAF_youth_disgust.wav',\n '../tess/YAF_angry/YAF_calm_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_keg_ps.wav',\n '../tess/YAF_angry/YAF_time_angry.wav',\n '../tess/YAF_sad/YAF_wire_sad.wav',\n '../tess/YAF_happy/YAF_puff_happy.wav',\n '../tess/YAF_disgust/YAF_hush_disgust.wav',\n '../tess/YAF_angry/YAF_sub_angry.wav',\n '../tess/OAF_angry/OAF_pick_angry.wav',\n '../tess/OAF_angry/OAF_should_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_name_ps.wav',\n '../tess/YAF_sad/YAF_thought_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_bean_ps.wav',\n '../tess/YAF_sad/YAF_kite_sad.wav',\n '../tess/OAF_happy/OAF_judge_happy.wav',\n '../tess/YAF_sad/YAF_room_sad.wav',\n '../tess/OAF_Sad/OAF_shack_sad.wav',\n '../tess/YAF_happy/YAF_dog_happy.wav',\n '../tess/OAF_happy/OAF_beg_happy.wav',\n '../tess/YAF_fear/YAF_thumb_fear.wav',\n '../tess/OAF_happy/OAF_south_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_ton_ps.wav',\n '../tess/OAF_disgust/OAF_doll_disgust.wav',\n '../tess/OAF_disgust/OAF_void_disgust.wav',\n '../tess/YAF_disgust/YAF_shack_disgust.wav',\n '../tess/OAF_angry/OAF_late_angry.wav',\n '../tess/YAF_sad/YAF_judge_sad.wav',\n '../tess/OAF_Sad/OAF_judge_sad.wav',\n '../tess/OAF_Sad/OAF_join_sad.wav',\n '../tess/YAF_sad/YAF_shall_sad.wav',\n '../tess/YAF_sad/YAF_wife_sad.wav',\n '../tess/YAF_sad/YAF_note_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_haze_ps.wav',\n '../tess/YAF_angry/YAF_gap_angry.wav',\n '../tess/OAF_angry/OAF_cheek_angry.wav',\n '../tess/OAF_disgust/OAF_walk_disgust.wav',\n '../tess/OAF_Fear/OAF_mouse_fear.wav',\n '../tess/YAF_angry/YAF_ditch_angry.wav',\n '../tess/OAF_Sad/OAF_thin_sad.wav',\n '../tess/OAF_angry/OAF_love_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_witch_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_make_ps.wav',\n '../tess/OAF_happy/OAF_get_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_calm_ps.wav',\n '../tess/YAF_fear/YAF_fail_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_vote_ps.wav',\n '../tess/OAF_happy/OAF_rain_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_gas_ps.wav',\n '../tess/OAF_Fear/OAF_mop_fear.wav',\n '../tess/OAF_Sad/OAF_wash_sad.wav',\n '../tess/OAF_disgust/OAF_chat_disgust.wav',\n '../tess/OAF_Fear/OAF_chief_fear.wav',\n '../tess/YAF_disgust/YAF_half_disgust.wav',\n '../tess/YAF_sad/YAF_dog_sad.wav',\n '../tess/YAF_pleasant_surprised/YAF_tire_ps.wav',\n '../tess/OAF_happy/OAF_bar_happy.wav',\n '../tess/YAF_fear/YAF_came_fear.wav',\n '../tess/OAF_Fear/OAF_yes_fear.wav',\n '../tess/OAF_happy/OAF_hit_happy.wav',\n '../tess/YAF_disgust/YAF_wag_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_kick_ps.wav',\n '../tess/OAF_Fear/OAF_fail_fear.wav',\n '../tess/YAF_fear/YAF_near_fear.wav',\n '../tess/OAF_Fear/OAF_yearn_fear.wav',\n '../tess/YAF_sad/YAF_phone_sad.wav',\n '../tess/OAF_Fear/OAF_ring_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_pain_ps.wav',\n '../tess/OAF_disgust/OAF_dog_disgust.wav',\n '../tess/OAF_disgust/OAF_mood_disgust.wav',\n '../tess/OAF_Sad/OAF_gun_sad.wav',\n '../tess/OAF_disgust/OAF_late_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_young_ps.wav',\n '../tess/YAF_fear/YAF_pool_fear.wav',\n '../tess/OAF_Sad/OAF_nice_sad.wav',\n '../tess/OAF_happy/OAF_gaze_happy.wav',\n '../tess/OAF_Fear/OAF_juice_fear.wav',\n '../tess/OAF_angry/OAF_wire_angry.wav',\n '../tess/YAF_sad/YAF_rain_sad.wav',\n '../tess/OAF_disgust/OAF_tape_disgust.wav',\n '../tess/OAF_disgust/OAF_pain_disgust.wav',\n '../tess/YAF_sad/YAF_soup_sad.wav',\n '../tess/YAF_happy/YAF_shall_happy.wav',\n '../tess/YAF_disgust/YAF_cool_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_rain_ps.wav',\n '../tess/OAF_disgust/OAF_date_disgust.wav',\n '../tess/YAF_disgust/YAF_hire_disgust.wav',\n '../tess/OAF_Fear/OAF_cause_fear.wav',\n '../tess/YAF_happy/YAF_yes_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_pole_ps.wav',\n '../tess/OAF_angry/OAF_phone_angry.wav',\n '../tess/OAF_Sad/OAF_long_sad.wav',\n '../tess/YAF_angry/YAF_ripe_angry.wav',\n '../tess/OAF_Sad/OAF_pike_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_gap_ps.wav',\n '../tess/YAF_disgust/YAF_boat_disgust.wav',\n '../tess/OAF_Fear/OAF_shout_fear.wav',\n '../tess/YAF_angry/YAF_lease_angry.wav',\n '../tess/OAF_angry/OAF_rose_angry.wav',\n '../tess/YAF_happy/YAF_chain_happy.wav',\n '../tess/YAF_disgust/YAF_gap_disgust.wav',\n '../tess/YAF_happy/YAF_near_happy.wav',\n '../tess/OAF_angry/OAF_merge_angry.wav',\n '../tess/OAF_Sad/OAF_puff_sad.wav',\n '../tess/YAF_happy/YAF_mood_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_deep_ps.wav',\n '../tess/YAF_fear/YAF_puff_fear.wav',\n '../tess/OAF_angry/OAF_good_angry.wav',\n '../tess/YAF_sad/YAF_home_sad.wav',\n '../tess/OAF_Pleasant_surprise/OAF_third_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_death_ps.wav',\n '../tess/OAF_Fear/OAF_hole_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_juice_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_lean_ps.wav',\n '../tess/OAF_disgust/OAF_soap_disgust.wav',\n '../tess/OAF_angry/OAF_goal_angry.wav',\n '../tess/OAF_disgust/OAF_good_disgust.wav',\n '../tess/YAF_angry/YAF_pain_angry.wav',\n '../tess/YAF_happy/YAF_haze_happy.wav',\n '../tess/YAF_angry/YAF_rose_angry.wav',\n '../tess/OAF_disgust/OAF_love_disgust.wav',\n '../tess/OAF_Fear/OAF_pick_fear.wav',\n '../tess/YAF_angry/YAF_king_angry.wav',\n '../tess/YAF_disgust/YAF_name_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_doll_ps.wav',\n '../tess/OAF_angry/OAF_sure_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_shall_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_which_ps.wav',\n '../tess/YAF_happy/YAF_lease_happy.wav',\n '../tess/OAF_happy/OAF_lean_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_goose_ps.wav',\n '../tess/OAF_Fear/OAF_tool_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_lore_ps.wav',\n '../tess/YAF_fear/YAF_goose_fear.wav',\n '../tess/YAF_disgust/YAF_hole_disgust.wav',\n '../tess/YAF_fear/YAF_note_fear.wav',\n '../tess/YAF_disgust/YAF_chair_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_perch_ps.wav',\n '../tess/YAF_angry/YAF_late_angry.wav',\n '../tess/OAF_Fear/OAF_search_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_void_ps.wav',\n '../tess/OAF_happy/OAF_tough_happy.wav',\n '../tess/OAF_angry/OAF_kill_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_pole_ps.wav',\n '../tess/YAF_sad/YAF_lot_sad.wav',\n '../tess/YAF_angry/YAF_ring_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_should_ps.wav',\n '../tess/OAF_disgust/OAF_knock_disgust.wav',\n '../tess/YAF_fear/YAF_raise_fear.wav',\n '../tess/YAF_sad/YAF_rough_sad.wav',\n '../tess/YAF_fear/YAF_bite_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_beg_ps.wav',\n '../tess/OAF_angry/OAF_wheat_angry.wav',\n '../tess/YAF_angry/YAF_wag_angry.wav',\n '../tess/OAF_Sad/OAF_sell_sad.wav',\n '../tess/OAF_happy/OAF_goose_happy.wav',\n '../tess/OAF_disgust/OAF_thumb_disgust.wav',\n '../tess/YAF_sad/YAF_youth_sad.wav',\n '../tess/OAF_Fear/OAF_deep_fear.wav',\n '../tess/YAF_disgust/YAF_five_disgust.wav',\n '../tess/OAF_happy/OAF_came_happy.wav',\n '../tess/OAF_Pleasant_surprise/OAF_south_ps.wav',\n '../tess/YAF_happy/YAF_hire_happy.wav',\n '../tess/YAF_sad/YAF_dab_sad.wav',\n '../tess/YAF_sad/YAF_dead_sad.wav',\n '../tess/YAF_disgust/YAF_kick_disgust.wav',\n '../tess/YAF_sad/YAF_boat_sad.wav',\n '../tess/OAF_disgust/OAF_pick_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_nag_ps.wav',\n '../tess/OAF_Sad/OAF_choice_sad.wav',\n '../tess/OAF_Sad/OAF_such_sad.wav',\n '../tess/YAF_angry/YAF_rough_angry.wav',\n '../tess/YAF_pleasant_surprised/YAF_thin_ps.wav',\n '../tess/OAF_disgust/OAF_youth_disgust.wav',\n '../tess/OAF_disgust/OAF_lore_disgust.wav',\n '../tess/YAF_angry/YAF_gas_angry.wav',\n '../tess/YAF_sad/YAF_rag_sad.wav',\n '../tess/OAF_happy/OAF_pad_happy.wav',\n '../tess/OAF_Fear/OAF_whip_fear.wav',\n '../tess/YAF_happy/YAF_name_happy.wav',\n '../tess/OAF_angry/OAF_dog_angry.wav',\n '../tess/OAF_angry/OAF_pole_angry.wav',\n '../tess/YAF_sad/YAF_rush_sad.wav',\n '../tess/YAF_sad/YAF_beg_sad.wav',\n '../tess/YAF_fear/YAF_deep_fear.wav',\n '../tess/YAF_sad/YAF_goal_sad.wav',\n '../tess/YAF_angry/YAF_bite_angry.wav',\n '../tess/OAF_happy/OAF_rough_happy.wav',\n '../tess/OAF_Fear/OAF_pool_fear.wav',\n '../tess/OAF_Sad/OAF_book_sad.wav',\n '../tess/YAF_angry/YAF_cool_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_wheat_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_gin_ps.wav',\n '../tess/YAF_angry/YAF_doll_angry.wav',\n '../tess/OAF_Fear/OAF_hit_fear.wav',\n '../tess/OAF_angry/OAF_hole_angry.wav',\n '../tess/YAF_disgust/YAF_take_disgust.wav',\n '../tess/OAF_angry/OAF_jug_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_chair_ps.wav',\n '../tess/OAF_angry/OAF_judge_angry.wav',\n '../tess/OAF_angry/OAF_make_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_pick_ps.wav',\n '../tess/OAF_Sad/OAF_goose_sad.wav',\n '../tess/OAF_happy/OAF_nice_happy.wav',\n '../tess/YAF_sad/YAF_knock_sad.wav',\n '../tess/YAF_disgust/YAF_knock_disgust.wav',\n '../tess/OAF_happy/OAF_live_happy.wav',\n '../tess/YAF_angry/YAF_kick_angry.wav',\n '../tess/OAF_Fear/OAF_lease_fear.wav',\n '../tess/YAF_sad/YAF_burn_sad.wav',\n '../tess/YAF_fear/YAF_kick_fear.wav',\n '../tess/OAF_disgust/OAF_wheat_disgust.wav',\n '../tess/YAF_fear/YAF_half_fear.wav',\n '../tess/YAF_happy/YAF_which_happy.wav',\n '../tess/YAF_fear/YAF_lid_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_book_ps.wav',\n '../tess/OAF_angry/OAF_keg_angry.wav',\n '../tess/YAF_angry/YAF_gun_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_ton_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_young_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_five_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_half_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_shirt_ps.wav',\n '../tess/YAF_angry/YAF_team_angry.wav',\n '../tess/OAF_disgust/OAF_rush_disgust.wav',\n '../tess/YAF_disgust/YAF_fail_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_youth_ps.wav',\n '../tess/YAF_disgust/YAF_rag_disgust.wav',\n '../tess/OAF_Fear/OAF_take_fear.wav',\n '../tess/YAF_pleasant_surprised/YAF_match_ps.wav',\n '../tess/OAF_disgust/OAF_keen_disgust.wav',\n '../tess/YAF_angry/YAF_haze_angry.wav',\n '../tess/OAF_disgust/OAF_sell_disgust.wav',\n '../tess/OAF_Fear/OAF_keep_fear.wav',\n '../tess/YAF_disgust/YAF_hall_disgust.wav',\n '../tess/OAF_Fear/OAF_pearl_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_hit_ps.wav',\n '../tess/YAF_pleasant_surprised/YAF_chalk_ps.wav',\n '../tess/OAF_Fear/OAF_rot_fear.wav',\n '../tess/YAF_angry/YAF_pearl_angry.wav',\n '../tess/OAF_disgust/OAF_goose_disgust.wav',\n '../tess/YAF_fear/YAF_kill_fear.wav',\n '../tess/OAF_disgust/OAF_mode_disgust.wav',\n '../tess/OAF_Pleasant_surprise/OAF_peg_ps.wav',\n '../tess/OAF_angry/OAF_moon_angry.wav',\n '../tess/OAF_angry/OAF_ton_angry.wav',\n '../tess/YAF_angry/YAF_have_angry.wav',\n '../tess/OAF_disgust/OAF_live_disgust.wav',\n '../tess/YAF_disgust/YAF_join_disgust.wav',\n '../tess/OAF_disgust/OAF_rough_disgust.wav',\n '../tess/YAF_disgust/YAF_chain_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_gap_ps.wav',\n '../tess/OAF_Fear/OAF_pole_fear.wav',\n '../tess/OAF_Fear/OAF_dab_fear.wav',\n '../tess/YAF_disgust/YAF_search_disgust.wav',\n '../tess/YAF_fear/YAF_chief_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_pike_ps.wav',\n '../tess/YAF_happy/YAF_hate_happy.wav',\n '../tess/OAF_happy/OAF_wire_happy.wav',\n '../tess/OAF_angry/OAF_thin_angry.wav',\n '../tess/OAF_happy/OAF_hall_happy.wav',\n '../tess/YAF_disgust/YAF_thumb_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_third_ps.wav',\n '../tess/YAF_fear/YAF_merge_fear.wav',\n '../tess/YAF_happy/YAF_such_happy.wav',\n '../tess/OAF_Sad/OAF_mouse_sad.wav',\n '../tess/OAF_disgust/OAF_yearn_disgust.wav',\n '../tess/YAF_happy/YAF_search_happy.wav',\n '../tess/YAF_sad/YAF_fall_sad.wav',\n '../tess/OAF_Fear/OAF_seize_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_puff_ps.wav',\n '../tess/OAF_Fear/OAF_lore_fear.wav',\n '../tess/OAF_disgust/OAF_bone_disgust.wav',\n '../tess/YAF_happy/YAF_soap_happy.wav',\n '../tess/YAF_happy/YAF_thumb_happy.wav',\n '../tess/YAF_happy/YAF_rough_happy.wav',\n '../tess/YAF_pleasant_surprised/YAF_read_ps.wav',\n '../tess/OAF_Sad/OAF_soap_sad.wav',\n '../tess/OAF_disgust/OAF_cool_disgust.wav',\n '../tess/YAF_fear/YAF_void_fear.wav',\n '../tess/YAF_sad/YAF_sour_sad.wav',\n '../tess/YAF_disgust/YAF_sell_disgust.wav',\n '../tess/YAF_angry/YAF_judge_angry.wav',\n '../tess/OAF_Sad/OAF_mop_sad.wav',\n '../tess/OAF_angry/OAF_pain_angry.wav',\n '../tess/OAF_Sad/OAF_merge_sad.wav',\n '../tess/YAF_angry/YAF_tough_angry.wav',\n '../tess/YAF_angry/YAF_met_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_five_ps.wav',\n '../tess/YAF_angry/YAF_nag_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_lid_ps.wav',\n '../tess/YAF_sad/YAF_rot_sad.wav',\n '../tess/OAF_Sad/OAF_mood_sad.wav',\n '../tess/YAF_sad/YAF_luck_sad.wav',\n '../tess/OAF_disgust/OAF_said_disgust.wav',\n '../tess/OAF_Fear/OAF_moon_fear.wav',\n '../tess/OAF_Pleasant_surprise/OAF_king_ps.wav',\n '../tess/OAF_disgust/OAF_long_disgust.wav',\n '../tess/YAF_pleasant_surprised/YAF_rose_ps.wav',\n '../tess/OAF_angry/OAF_pool_angry.wav',\n '../tess/YAF_angry/YAF_love_angry.wav',\n '../tess/OAF_Pleasant_surprise/OAF_read_ps.wav',\n '../tess/OAF_Pleasant_surprise/OAF_mood_ps.wav',\n '../tess/YAF_fear/YAF_keg_fear.wav',\n '../tess/OAF_disgust/OAF_food_disgust.wav',\n '../tess/OAF_Sad/OAF_pain_sad.wav',\n '../tess/YAF_disgust/YAF_fit_disgust.wav',\n ...]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eu1qcRucHk6d"
   },
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# print(f\"Training input_values: {train_dataset[idx]['input_values']}\")\n",
    "# print(f\"Training attention_mask: {train_dataset[idx]['attention_mask']}\")\n",
    "# print(f\"Training labels: {train_dataset[idx]['labels']} - {train_dataset[idx]['emotion']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcrEgJO9Hmx7"
   },
   "source": [
    "Great, now we've successfully read all the audio files, resampled the audio files to 16kHz, and mapped each audio to the corresponding label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL7q6DfcH0Fs"
   },
   "source": [
    "## Model\n",
    "\n",
    "Before diving into the training part, we need to build our classification model based on the merge strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network_models.w2v_emotion_model.model as KNNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrBrR1b7zvUL"
   },
   "source": [
    "## Training\n",
    "\n",
    "The data is processed so that we are ready to start setting up the training pipeline. We will make use of 🤗's [Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer) for which we essentially need to do the following:\n",
    "\n",
    "- Define a data collator. In contrast to most NLP models, XLSR-Wav2Vec2 has a much larger input length than output length. *E.g.*, a sample of input length 50000 has an output length of no more than 100. Given the large input sizes, it is much more efficient to pad the training batches dynamically meaning that all training samples should only be padded to the longest sample in their batch and not the overall longest sample. Therefore, fine-tuning XLSR-Wav2Vec2 requires a special padding data collator, which we will define below\n",
    "\n",
    "- Evaluation metric. During training, the model should be evaluated on the word error rate. We should define a `compute_metrics` function accordingly\n",
    "\n",
    "- Load a pretrained checkpoint. We need to load a pretrained checkpoint and configure it correctly for training.\n",
    "\n",
    "- Define the training configuration.\n",
    "\n",
    "After having fine-tuned the model, we will correctly evaluate it on the test data and verify that it has indeed learned to correctly transcribe speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji9-n1eUIKZc"
   },
   "source": [
    "### Set-up Trainer\n",
    "\n",
    "Let's start by defining the data collator. The code for the data collator was copied from [this example](https://github.com/huggingface/transformers/blob/9a06b6b11bdfc42eea08fa91d0c737d1863c99e3/examples/research_projects/wav2vec2/run_asr.py#L81).\n",
    "\n",
    "Without going into too many details, in contrast to the common data collators, this data collator treats the `input_values` and `labels` differently and thus applies to separate padding functions on them (again making use of XLSR-Wav2Vec2's context manager). This is necessary because in speech input and output are of different modalities meaning that they should not be treated by the same padding function.\n",
    "Analogous to the common data collators, the padding tokens in the labels with `-100` so that those tokens are **not** taken into account when computing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rkM0VLIwy903"
   },
   "outputs": [],
   "source": [
    "import network_models.w2v_emotion_model.trainer as trainerUtils\n",
    "data_collator = trainerUtils.DataCollatorCTCWithPadding(processor=processor, padding=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYxy2IR-KcU2"
   },
   "source": [
    "Next, the evaluation metric is defined. There are many pre-defined metrics for classification/regression problems, but in this case, we would continue with just **Accuracy** for classification and **MSE** for regression. You can define other metrics on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LL8I5MKvPnth"
   },
   "outputs": [],
   "source": [
    "is_regression = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XK26Z6IfR36K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.squeeze(preds) if is_regression else np.argmax(preds, axis=1)\n",
    "\n",
    "    if is_regression:\n",
    "        return {\"mse\": ((preds - p.label_ids) ** 2).mean().item()}\n",
    "    else:\n",
    "        return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsH_nKJdK28o"
   },
   "source": [
    "Now, we can load the pretrained XLSR-Wav2Vec2 checkpoint into our classification model with a pooling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0Tl6iKAUR4EL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-german were not used when initializing Wav2Vec2ForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSpeechClassification were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-german and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = KNNModel.Wav2Vec2ForSpeechClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqF4rNMzI1M5"
   },
   "source": [
    "The first component of XLSR-Wav2Vec2 consists of a stack of CNN layers that are used to extract acoustically meaningful - but contextually independent - features from the raw speech signal. This part of the model has already been sufficiently trained during pretraining and as stated in the [paper](https://arxiv.org/pdf/2006.13979.pdf) does not need to be fine-tuned anymore. \n",
    "Thus, we can set the `requires_grad` to `False` for all parameters of the *feature extraction* part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KHMhxFGoR4Hb"
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0HzBneBK84G"
   },
   "source": [
    "In a final step, we define all parameters related to training. \n",
    "To give more explanation on some of the parameters:\n",
    "- `learning_rate` and `weight_decay` were heuristically tuned until fine-tuning has become stable. Note that those parameters strongly depend on the Common Voice dataset and might be suboptimal for other speech datasets.\n",
    "\n",
    "For more explanations on other parameters, one can take a look at the [docs](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer#trainingarguments).\n",
    "\n",
    "**Note**: If one wants to save the trained models in his/her google drive the commented-out `output_dir` can be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future use we can create our training script, we do it in a simple way. You can add more on you own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all instances can be passed to Trainer and we are ready to start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3tPqZ12BLCJk"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vUtWjldAI9-H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"content/models\",\n",
    "    # output_dir=\"/content/gdrive/MyDrive/wav2vec2-xlsr-greek-speech-emotion-recognition\"\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=5.0,\n",
    "    fp16=True,\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "trainer = trainerUtils.CTCTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gGLwJAOLtDg"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpN6xlWCLxJ7"
   },
   "source": [
    "Training will take between 10 and 60 minutes depending on the GPU allocated to this notebook. \n",
    "\n",
    "In case you want to use this google colab to fine-tune your model, you should make sure that your training doesn't stop due to inactivity. A simple hack to prevent this is to paste the following code into the console of this tab (right mouse click -> inspect -> Console tab and insert code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyYZH7YZL8a9"
   },
   "source": [
    "```javascript\n",
    "function ConnectButton(){\n",
    "    console.log(\"Connect pushed\"); \n",
    "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
    "}\n",
    "setInterval(ConnectButton,60000);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6M8bNvLLJnG1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: emotion, path. If emotion, path are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1920\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 3\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1600\n",
      "  Number of trainable parameters = 312284294\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1600 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 9.77 GiB total capacity; 5.71 GiB already allocated; 92.00 MiB free; 5.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# gc.collect()\u001B[39;00m\n\u001B[1;32m      4\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m----> 5\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/trainer.py:1527\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m   1524\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1525\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1526\u001B[0m )\n\u001B[0;32m-> 1527\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1528\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1531\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1532\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/trainer.py:1775\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1773\u001B[0m         tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   1774\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1775\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1778\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1779\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1780\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/w2v_emotion_model/trainer.py:111\u001B[0m, in \u001B[0;36mCTCTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m    108\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_cuda_amp:\n\u001B[0;32m--> 111\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_apex:\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m amp\u001B[38;5;241m.\u001B[39mscale_loss(loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer) \u001B[38;5;28;01mas\u001B[39;00m scaled_loss:\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 9.77 GiB total capacity; 5.71 GiB already allocated; 92.00 MiB free; 5.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.memory_allocated()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir='content/modelTess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3prIN9eiMBHo"
   },
   "source": [
    "The training loss goes down and we can see that the Acurracy on the test set also improves nicely. Because this notebook is just for demonstration purposes, we can stop here.\n",
    "\n",
    "The resulting model of this notebook has been saved to [m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition](https://huggingface.co/m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition)\n",
    "\n",
    "As a final check, let's load the model and verify that it indeed has learned to recognize the emotion in the speech.\n",
    "\n",
    "Let's first load the pretrained checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsaOTx_FVm0i"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tGNY7hRXO44"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYxg1Tfo2VUw"
   },
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"csv\", data_files={\"validation\": \"content/data/test.csv\"}, delimiter=\"\\t\")[\"validation\"]\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgZFkMDHW_Um"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ESFEXeaWgua"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"content/model\"\n",
    "#config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "#processor = Wav2Vec2Processor.from_pretrained(model_name_or_path)\n",
    "model = KNNModel.Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path).to(device)\n",
    "#model1 = torch.load(model_name_or_path)\n",
    "\n",
    "#model_name_or_path = \"jonatasgrosman/wav2vec2-large-xlsr-53-german\"\n",
    "#processor = Wav2Vec2Processor.from_pretrained(model_name_or_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkEd4w8IV7kZ"
   },
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    speech_array = speech_array.squeeze().numpy()\n",
    "    speech_array = librosa.resample(np.asarray(speech_array), sampling_rate, processor.feature_extractor.sampling_rate)\n",
    "\n",
    "    batch[\"speech\"] = speech_array\n",
    "    return batch\n",
    "\n",
    "\n",
    "def predict(batch):\n",
    "    features = processor(batch[\"speech\"], sampling_rate=processor.feature_extractor.sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = features.attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits \n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    batch[\"predicted\"] = pred_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4P6P6XwW85p"
   },
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.map(speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_oZJzHsXKHv"
   },
   "outputs": [],
   "source": [
    "result = test_dataset.map(predict, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnfJLZvAaxTo"
   },
   "outputs": [],
   "source": [
    "label_names = [config.id2label[i] for i in range(config.num_labels)]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRtajzvTabeH"
   },
   "outputs": [],
   "source": [
    "y_true = [config.label2id[name] for name in result[\"emotion\"]]\n",
    "\n",
    "\n",
    "y_pred = result[\"predicted\"]\n",
    "\n",
    "print(y_true[:5])\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['predicted'])\n",
    "#config.label2id['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUt5rIppXrzl"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ylb2Z6Xke2ro"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQzCioPhWIiX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DocavTvQWIr_"
   },
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "##model_name_or_path = \"m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition\"\n",
    "## config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "#processor = Wav2Vec2Processor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "#model = KNNModel.Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SSs95o9WIvK"
   },
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "\n",
    "\n",
    "def predict(path, sampling_rate):\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    features = processor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = features.attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits\n",
    "\n",
    "    scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "    outputs = [{\"Emotion\": config.id2label[i], \"Score\": f\"{round(score * 100, 3):.1f}%\"} for i, score in enumerate(scores)]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "STYLES = \"\"\"\n",
    "<style>\n",
    "div.display_data {\n",
    "    margin: 0 auto;\n",
    "    max-width: 500px;\n",
    "}\n",
    "table.xxx {\n",
    "    margin: 50px !important;\n",
    "    float: right !important;\n",
    "    clear: both !important;\n",
    "}\n",
    "table.xxx td {\n",
    "    min-width: 300px !important;\n",
    "    text-align: center !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\".strip()\n",
    "\n",
    "def prediction(df_row):\n",
    "    path, emotion = df_row[\"path\"], df_row[\"emotion\"]\n",
    "    df = pd.DataFrame([{\"Emotion\": emotion, \"Sentence\": \"    \"}])\n",
    "    setup = {\n",
    "        'border': 2,\n",
    "        'show_dimensions': True,\n",
    "        'justify': 'center',\n",
    "        'classes': 'xxx',\n",
    "        'escape': False,\n",
    "    }\n",
    "    ipd.display(ipd.HTML(STYLES + df.to_html(**setup) + \"<br />\"))\n",
    "    speech, sr = torchaudio.load(path)\n",
    "    speech = speech[0].numpy().squeeze()\n",
    "    speech = librosa.resample(np.asarray(speech), sr, sampling_rate)\n",
    "    ipd.display(ipd.Audio(data=np.asarray(speech), autoplay=True, rate=sampling_rate))\n",
    "\n",
    "    outputs = predict(path, sampling_rate)\n",
    "    r = pd.DataFrame(outputs)\n",
    "    ipd.display(ipd.HTML(STYLES + r.to_html(**setup) + \"<br />\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UD7oUP20YwYT"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"content/data/test.csv\", sep=\"\\t\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlJO2LfVWIyT"
   },
   "outputs": [],
   "source": [
    "prediction(test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzoKOgpoWI1K"
   },
   "outputs": [],
   "source": [
    "prediction(trainDF.iloc[245])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nqwbTTXSfMO"
   },
   "outputs": [],
   "source": [
    "prediction(test.iloc[2])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Emotion recognition in Greek speech using Wav2Vec2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

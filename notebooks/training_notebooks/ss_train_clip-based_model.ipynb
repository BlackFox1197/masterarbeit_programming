{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 15:39:44.518302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 15:39:44.942185: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 15:39:44.942248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 15:39:44.942252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from network_models.soundsream_models_and_utils.clip_like.encoder.ss_dims_class_model import SS_Enc_Class_Dims\n",
    "from network_models.soundsream_models_and_utils.ss_encoderbased_model import SSClipBasedModel\n",
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "import gc\n",
    "\n",
    "from network_models.soundsream_models_and_utils.ss_wrapper_trainer_experiments import ExperimentsTrainer\n",
    "import torch\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 8\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/from_dims/Nr1/\"\n",
    "safe_model_every = 500\n",
    "epochs = 15001\n",
    "save_highest_acc_min_acc = 0.5\n",
    "lr = 1e-5\n",
    "gc.collect()\n",
    "\n",
    "# data_set= ss_encoded_dataset_full(\n",
    "#     csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings_clip_like.pkl\", device=\"cuda\")\n",
    "# trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "#\n",
    "# torch.manual_seed(300)\n",
    "# model = SSClipBasedModel(dropout=0.3).to(device)\n",
    "\n",
    "\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings_encoder.pkl\", device=\"cuda\")\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "torch.manual_seed(33333)\n",
    "model = SS_Enc_Class_Dims().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.049359  [    0/ 5482]\n",
      "loss: 2.073763  [  800/ 5482]\n",
      "loss: 2.053428  [ 1600/ 5482]\n",
      "loss: 1.858222  [ 2400/ 5482]\n",
      "loss: 2.076379  [ 3200/ 5482]\n",
      "loss: 2.136603  [ 4000/ 5482]\n",
      "loss: 1.926294  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.092     0.000     0.000    99\n",
      " disgust     0.092     0.000     0.000    107\n",
      "    fear     0.092     0.000     0.000    80\n",
      "   happy     0.092     0.128     0.377    77\n",
      " neutral     0.092     0.000     0.000    95\n",
      "     sad     0.092     0.100     0.011    91\n",
      "surprise     0.092     0.070     0.426    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.092     0.043     0.116    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 9.2%, Avg loss: 2.049791 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.967340  [    0/ 5482]\n",
      "loss: 1.792139  [  800/ 5482]\n",
      "loss: 1.991874  [ 1600/ 5482]\n",
      "loss: 1.942977  [ 2400/ 5482]\n",
      "loss: 1.867873  [ 3200/ 5482]\n",
      "loss: 2.017460  [ 4000/ 5482]\n",
      "loss: 1.989723  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.092     0.000     0.000    99\n",
      " disgust     0.092     0.000     0.000    107\n",
      "    fear     0.092     0.000     0.000    80\n",
      "   happy     0.092     0.125     0.390    77\n",
      " neutral     0.092     0.000     0.000    95\n",
      "     sad     0.092     0.100     0.011    91\n",
      "surprise     0.092     0.070     0.410    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.092     0.042     0.116    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 9.2%, Avg loss: 2.044823 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.922829  [    0/ 5482]\n",
      "loss: 1.973142  [  800/ 5482]\n",
      "loss: 1.953408  [ 1600/ 5482]\n",
      "loss: 2.011608  [ 2400/ 5482]\n",
      "loss: 1.829516  [ 3200/ 5482]\n",
      "loss: 1.785418  [ 4000/ 5482]\n",
      "loss: 1.963508  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.093     0.000     0.000    99\n",
      " disgust     0.093     0.000     0.000    107\n",
      "    fear     0.093     0.000     0.000    80\n",
      "   happy     0.093     0.124     0.403    77\n",
      " neutral     0.093     0.000     0.000    95\n",
      "     sad     0.093     0.091     0.011    91\n",
      "surprise     0.093     0.072     0.410    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.093     0.041     0.118    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 9.3%, Avg loss: 2.040152 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.181162  [    0/ 5482]\n",
      "loss: 2.099035  [  800/ 5482]\n",
      "loss: 1.873059  [ 1600/ 5482]\n",
      "loss: 2.106117  [ 2400/ 5482]\n",
      "loss: 1.838285  [ 3200/ 5482]\n",
      "loss: 1.901208  [ 4000/ 5482]\n",
      "loss: 1.824954  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.093     0.000     0.000    99\n",
      " disgust     0.093     0.000     0.000    107\n",
      "    fear     0.093     0.000     0.000    80\n",
      "   happy     0.093     0.123     0.416    77\n",
      " neutral     0.093     0.000     0.000    95\n",
      "     sad     0.093     0.154     0.022    91\n",
      "surprise     0.093     0.069     0.377    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.093     0.049     0.116    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 9.3%, Avg loss: 2.035742 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.071203  [    0/ 5482]\n",
      "loss: 2.036430  [  800/ 5482]\n",
      "loss: 1.864253  [ 1600/ 5482]\n",
      "loss: 1.995718  [ 2400/ 5482]\n",
      "loss: 1.775886  [ 3200/ 5482]\n",
      "loss: 2.136191  [ 4000/ 5482]\n",
      "loss: 2.032901  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.097     0.000     0.000    99\n",
      " disgust     0.097     0.000     0.000    107\n",
      "    fear     0.097     0.000     0.000    80\n",
      "   happy     0.097     0.129     0.455    77\n",
      " neutral     0.097     0.000     0.000    95\n",
      "     sad     0.097     0.154     0.022    91\n",
      "surprise     0.097     0.068     0.361    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.097     0.050     0.120    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 9.7%, Avg loss: 2.031578 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.057394  [    0/ 5482]\n",
      "loss: 1.975296  [  800/ 5482]\n",
      "loss: 1.969556  [ 1600/ 5482]\n",
      "loss: 1.937186  [ 2400/ 5482]\n",
      "loss: 2.026361  [ 3200/ 5482]\n",
      "loss: 2.025066  [ 4000/ 5482]\n",
      "loss: 1.853778  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.102     0.000     0.000    99\n",
      " disgust     0.102     0.000     0.000    107\n",
      "    fear     0.102     0.000     0.000    80\n",
      "   happy     0.102     0.134     0.494    77\n",
      " neutral     0.102     0.000     0.000    95\n",
      "     sad     0.102     0.154     0.022    91\n",
      "surprise     0.102     0.070     0.361    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.102     0.051     0.125    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.2%, Avg loss: 2.027684 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.949012  [    0/ 5482]\n",
      "loss: 1.943020  [  800/ 5482]\n",
      "loss: 1.985863  [ 1600/ 5482]\n",
      "loss: 1.944181  [ 2400/ 5482]\n",
      "loss: 1.969361  [ 3200/ 5482]\n",
      "loss: 1.804768  [ 4000/ 5482]\n",
      "loss: 2.100998  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.136     0.000     0.000    99\n",
      " disgust     0.136     0.000     0.000    107\n",
      "    fear     0.136     0.000     0.000    80\n",
      "   happy     0.136     0.145     0.766    77\n",
      " neutral     0.136     0.000     0.000    95\n",
      "     sad     0.136     0.143     0.022    91\n",
      "surprise     0.136     0.116     0.361    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.136     0.058     0.164    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.6%, Avg loss: 2.023882 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.018934  [    0/ 5482]\n",
      "loss: 2.048721  [  800/ 5482]\n",
      "loss: 2.073590  [ 1600/ 5482]\n",
      "loss: 1.887875  [ 2400/ 5482]\n",
      "loss: 1.956724  [ 3200/ 5482]\n",
      "loss: 1.916931  [ 4000/ 5482]\n",
      "loss: 2.044049  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.139     0.000     0.000    99\n",
      " disgust     0.139     0.000     0.000    107\n",
      "    fear     0.139     0.000     0.000    80\n",
      "   happy     0.139     0.144     0.792    77\n",
      " neutral     0.139     0.000     0.000    95\n",
      "     sad     0.139     0.095     0.022    91\n",
      "surprise     0.139     0.134     0.361    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.139     0.053     0.168    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.9%, Avg loss: 2.020354 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.915686  [    0/ 5482]\n",
      "loss: 1.909376  [  800/ 5482]\n",
      "loss: 2.153479  [ 1600/ 5482]\n",
      "loss: 2.112328  [ 2400/ 5482]\n",
      "loss: 1.992460  [ 3200/ 5482]\n",
      "loss: 2.065067  [ 4000/ 5482]\n",
      "loss: 1.900168  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.138     0.000     0.000    99\n",
      " disgust     0.138     0.000     0.000    107\n",
      "    fear     0.138     0.000     0.000    80\n",
      "   happy     0.138     0.141     0.805    77\n",
      " neutral     0.138     0.000     0.000    95\n",
      "     sad     0.138     0.095     0.022    91\n",
      "surprise     0.138     0.134     0.328    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.138     0.053     0.165    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.8%, Avg loss: 2.016953 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.891614  [    0/ 5482]\n",
      "loss: 2.060094  [  800/ 5482]\n",
      "loss: 2.017942  [ 1600/ 5482]\n",
      "loss: 2.091588  [ 2400/ 5482]\n",
      "loss: 2.255217  [ 3200/ 5482]\n",
      "loss: 2.133984  [ 4000/ 5482]\n",
      "loss: 1.950010  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.130     0.000     0.000    99\n",
      " disgust     0.130     0.000     0.000    107\n",
      "    fear     0.130     0.000     0.000    80\n",
      "   happy     0.130     0.137     0.805    77\n",
      " neutral     0.130     0.000     0.000    95\n",
      "     sad     0.130     0.095     0.022    91\n",
      "surprise     0.130     0.112     0.246    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.130     0.049     0.153    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.0%, Avg loss: 2.013681 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.034128  [    0/ 5482]\n",
      "loss: 1.930253  [  800/ 5482]\n",
      "loss: 1.827808  [ 1600/ 5482]\n",
      "loss: 2.061750  [ 2400/ 5482]\n",
      "loss: 2.085440  [ 3200/ 5482]\n",
      "loss: 1.985281  [ 4000/ 5482]\n",
      "loss: 1.955268  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.130     0.000     0.000    99\n",
      " disgust     0.130     0.000     0.000    107\n",
      "    fear     0.130     0.000     0.000    80\n",
      "   happy     0.130     0.135     0.805    77\n",
      " neutral     0.130     0.000     0.000    95\n",
      "     sad     0.130     0.091     0.022    91\n",
      "surprise     0.130     0.116     0.246    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.130     0.049     0.153    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.0%, Avg loss: 2.010636 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.911468  [    0/ 5482]\n",
      "loss: 1.899558  [  800/ 5482]\n",
      "loss: 1.975048  [ 1600/ 5482]\n",
      "loss: 1.920238  [ 2400/ 5482]\n",
      "loss: 1.889768  [ 3200/ 5482]\n",
      "loss: 2.014636  [ 4000/ 5482]\n",
      "loss: 2.160028  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.126     0.000     0.000    99\n",
      " disgust     0.126     0.000     0.000    107\n",
      "    fear     0.126     0.000     0.000    80\n",
      "   happy     0.126     0.132     0.805    77\n",
      " neutral     0.126     0.000     0.000    95\n",
      "     sad     0.126     0.087     0.022    91\n",
      "surprise     0.126     0.113     0.213    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.126     0.047     0.149    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 12.6%, Avg loss: 2.007713 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.054928  [    0/ 5482]\n",
      "loss: 1.993501  [  800/ 5482]\n",
      "loss: 2.016695  [ 1600/ 5482]\n",
      "loss: 1.944576  [ 2400/ 5482]\n",
      "loss: 1.799973  [ 3200/ 5482]\n",
      "loss: 1.976409  [ 4000/ 5482]\n",
      "loss: 2.037207  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.128     0.000     0.000    99\n",
      " disgust     0.128     0.000     0.000    107\n",
      "    fear     0.128     0.000     0.000    80\n",
      "   happy     0.128     0.130     0.805    77\n",
      " neutral     0.128     0.000     0.000    95\n",
      "     sad     0.128     0.120     0.033    91\n",
      "surprise     0.128     0.120     0.213    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.128     0.053     0.150    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 12.8%, Avg loss: 2.004876 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.966265  [    0/ 5482]\n",
      "loss: 2.037694  [  800/ 5482]\n",
      "loss: 2.032972  [ 1600/ 5482]\n",
      "loss: 1.913311  [ 2400/ 5482]\n",
      "loss: 1.878342  [ 3200/ 5482]\n",
      "loss: 1.916603  [ 4000/ 5482]\n",
      "loss: 1.982724  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.130     0.000     0.000    99\n",
      " disgust     0.130     0.000     0.000    107\n",
      "    fear     0.130     0.000     0.000    80\n",
      "   happy     0.130     0.133     0.831    77\n",
      " neutral     0.130     0.000     0.000    95\n",
      "     sad     0.130     0.143     0.044    91\n",
      "surprise     0.130     0.111     0.180    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.130     0.055     0.151    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.0%, Avg loss: 2.002166 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.937554  [    0/ 5482]\n",
      "loss: 1.858252  [  800/ 5482]\n",
      "loss: 2.012646  [ 1600/ 5482]\n",
      "loss: 1.941595  [ 2400/ 5482]\n",
      "loss: 1.948170  [ 3200/ 5482]\n",
      "loss: 1.686239  [ 4000/ 5482]\n",
      "loss: 2.039500  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.128     0.000     0.000    99\n",
      " disgust     0.128     0.000     0.000    107\n",
      "    fear     0.128     0.000     0.000    80\n",
      "   happy     0.128     0.131     0.831    77\n",
      " neutral     0.128     0.000     0.000    95\n",
      "     sad     0.128     0.133     0.044    91\n",
      "surprise     0.128     0.111     0.164    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.128     0.054     0.148    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 12.8%, Avg loss: 1.999599 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.999106  [    0/ 5482]\n",
      "loss: 1.963746  [  800/ 5482]\n",
      "loss: 1.871557  [ 1600/ 5482]\n",
      "loss: 1.885871  [ 2400/ 5482]\n",
      "loss: 2.022362  [ 3200/ 5482]\n",
      "loss: 1.712624  [ 4000/ 5482]\n",
      "loss: 1.997769  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.134     0.000     0.000    99\n",
      " disgust     0.134     0.000     0.000    107\n",
      "    fear     0.134     0.000     0.000    80\n",
      "   happy     0.134     0.133     0.857    77\n",
      " neutral     0.134     0.000     0.000    95\n",
      "     sad     0.134     0.182     0.066    91\n",
      "surprise     0.134     0.123     0.164    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.134     0.063     0.155    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.4%, Avg loss: 1.997166 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.990565  [    0/ 5482]\n",
      "loss: 2.010144  [  800/ 5482]\n",
      "loss: 1.913985  [ 1600/ 5482]\n",
      "loss: 2.013632  [ 2400/ 5482]\n",
      "loss: 1.975496  [ 3200/ 5482]\n",
      "loss: 1.859522  [ 4000/ 5482]\n",
      "loss: 1.951586  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.130     0.000     0.000    99\n",
      " disgust     0.130     0.000     0.000    107\n",
      "    fear     0.130     0.000     0.000    80\n",
      "   happy     0.130     0.131     0.857    77\n",
      " neutral     0.130     0.000     0.000    95\n",
      "     sad     0.130     0.176     0.066    91\n",
      "surprise     0.130     0.099     0.115    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.130     0.058     0.148    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.0%, Avg loss: 1.994766 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.072440  [    0/ 5482]\n",
      "loss: 1.867161  [  800/ 5482]\n",
      "loss: 1.840603  [ 1600/ 5482]\n",
      "loss: 1.971361  [ 2400/ 5482]\n",
      "loss: 1.920603  [ 3200/ 5482]\n",
      "loss: 1.899531  [ 4000/ 5482]\n",
      "loss: 1.921145  [ 4800/ 5482]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.131     0.000     0.000    99\n",
      " disgust     0.131     0.000     0.000    107\n",
      "    fear     0.131     0.000     0.000    80\n",
      "   happy     0.131     0.131     0.870    77\n",
      " neutral     0.131     0.000     0.000    95\n",
      "     sad     0.131     0.167     0.066    91\n",
      "surprise     0.131     0.111     0.115    61\n",
      "                                          610\n",
      "\n",
      " \n",
      "     avg     0.131     0.058     0.150    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 1.992477 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.990007  [    0/ 5482]\n",
      "loss: 1.889130  [  800/ 5482]\n",
      "loss: 1.844161  [ 1600/ 5482]\n",
      "loss: 2.118166  [ 2400/ 5482]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 19\u001B[0m\n\u001B[1;32m     11\u001B[0m lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-5\u001B[39m\n\u001B[1;32m     12\u001B[0m trainer \u001B[38;5;241m=\u001B[39m sset\u001B[38;5;241m.\u001B[39mSSGenModelTrainer(lr\u001B[38;5;241m=\u001B[39mlr, num_epochs\u001B[38;5;241m=\u001B[39mepochs, model\u001B[38;5;241m=\u001B[39mmodel, train_dataset\u001B[38;5;241m=\u001B[39mtrainDS,\n\u001B[1;32m     13\u001B[0m                             eval_dataset\u001B[38;5;241m=\u001B[39mtestDs,\n\u001B[1;32m     14\u001B[0m                             device\u001B[38;5;241m=\u001B[39mdevice, labelList\u001B[38;5;241m=\u001B[39mdata_set\u001B[38;5;241m.\u001B[39mencoded_dataset\u001B[38;5;241m.\u001B[39mlabel_list,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m                             save_highest_acc_min_acc\u001B[38;5;241m=\u001B[39msave_highest_acc_min_acc,\n\u001B[1;32m     18\u001B[0m                             model_path \u001B[38;5;241m=\u001B[39m models_dir)\n\u001B[0;32m---> 19\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:75\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# this is the trainloop\u001B[39;00m\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;66;03m# --------------------- testloop and evaluation- ---------------\u001B[39;00m\n\u001B[1;32m     78\u001B[0m acc, true, preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loop(test_dataloader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:118\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train_loop\u001B[0;34m(self, dataloader, model, loss_fn, optimizer, epoch)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;66;03m# Backpropagation\u001B[39;00m\n\u001B[1;32m    117\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 118\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_models_and_utils/encoder\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import network_models.soundsream_models_and_utils.ss_trainer_gen_models as sset\n",
    "importlib.reload(sset)\n",
    "\n",
    "lr = 1e-5\n",
    "trainer = sset.SSGenModelTrainer(lr=lr, num_epochs=epochs, model=model, train_dataset=trainDS,\n",
    "                            eval_dataset=testDs,\n",
    "                            device=device, labelList=data_set.encoded_dataset.label_list,\n",
    "                            batch_size=batch_size,\n",
    "                            save_model_every=safe_model_every,\n",
    "                            save_highest_acc_min_acc=save_highest_acc_min_acc,\n",
    "                            model_path = models_dir)\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

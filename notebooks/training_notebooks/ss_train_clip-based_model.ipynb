{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 15:23:00.956463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 15:23:01.490084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 15:23:01.490142: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 15:23:01.490147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_encoderbased_model import SSClipBasedModel\n",
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "import gc\n",
    "\n",
    "from network_models.soundsream_models_and_utils.ss_wrapper_trainer_experiments import ExperimentsTrainer\n",
    "import torch\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 12\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/\"\n",
    "safe_model_every = 50\n",
    "epochs = 1000\n",
    "save_highest_acc_min_acc = 0.5\n",
    "lr = 1e-2\n",
    "gc.collect()\n",
    "\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings_clip_like.pkl\", device=\"cuda\")\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "\n",
    "torch.manual_seed(300)\n",
    "model = SSClipBasedModel(dropout=0.3).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.923230; classification loss: 0.680585;  cosine similarity loss: 1.893811\n",
      "[ 1400/ 5482] total-loss: 1.242031; classification loss: 1.085804;  cosine similarity loss: 1.866940\n",
      "[ 2800/ 5482] total-loss: 1.098298; classification loss: 0.907594;  cosine similarity loss: 1.861113\n",
      "[ 4200/ 5482] total-loss: 1.116884; classification loss: 0.926599;  cosine similarity loss: 1.878020\n",
      "[ 5600/ 5482] total-loss: 1.151461; classification loss: 0.973807;  cosine similarity loss: 1.862076\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.636     0.616     0.575    106\n",
      " disgust     0.636     0.662     0.811    106\n",
      "    fear     0.636     0.547     0.604    106\n",
      "   happy     0.636     0.719     0.387    106\n",
      " neutral     0.636     0.813     0.698    106\n",
      "     sad     0.636     0.641     0.708    106\n",
      "surprise     0.636     0.542     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.636     0.649     0.636    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.307084 \n",
      "\n",
      "classification loss: 1.055754;  cosine similarity loss: 1.893521 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep0_acc_63.md \n",
      "\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep0_acc_63\"!  new accuracy: 63.0\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.744700; classification loss: 0.470541;  cosine similarity loss: 1.841338\n",
      "[ 1400/ 5482] total-loss: 0.960907; classification loss: 0.734222;  cosine similarity loss: 1.867645\n",
      "[ 2800/ 5482] total-loss: 1.037861; classification loss: 0.828732;  cosine similarity loss: 1.874377\n",
      "[ 4200/ 5482] total-loss: 0.939073; classification loss: 0.709667;  cosine similarity loss: 1.856697\n",
      "[ 5600/ 5482] total-loss: 1.138839; classification loss: 0.949129;  cosine similarity loss: 1.897680\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.632     0.600     0.594    106\n",
      " disgust     0.632     0.659     0.802    106\n",
      "    fear     0.632     0.530     0.660    106\n",
      "   happy     0.632     0.700     0.396    106\n",
      " neutral     0.632     0.807     0.670    106\n",
      "     sad     0.632     0.661     0.698    106\n",
      "surprise     0.632     0.552     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.632     0.644     0.632    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.314254 \n",
      "\n",
      "classification loss: 1.064522;  cosine similarity loss: 1.896962 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.296816; classification loss: 1.141991;  cosine similarity loss: 1.916118\n",
      "[ 1400/ 5482] total-loss: 1.220693; classification loss: 1.060889;  cosine similarity loss: 1.859909\n",
      "[ 2800/ 5482] total-loss: 0.922376; classification loss: 0.683380;  cosine similarity loss: 1.878362\n",
      "[ 4200/ 5482] total-loss: 1.088733; classification loss: 0.890969;  cosine similarity loss: 1.879790\n",
      "[ 5600/ 5482] total-loss: 1.089277; classification loss: 0.882657;  cosine similarity loss: 1.915758\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.631     0.596     0.613    106\n",
      " disgust     0.631     0.659     0.802    106\n",
      "    fear     0.631     0.556     0.613    106\n",
      "   happy     0.631     0.623     0.406    106\n",
      " neutral     0.631     0.798     0.670    106\n",
      "     sad     0.631     0.652     0.708    106\n",
      "surprise     0.631     0.561     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.631     0.635     0.631    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.317958 \n",
      "\n",
      "classification loss: 1.070504;  cosine similarity loss: 1.895350 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.833007; classification loss: 0.564422;  cosine similarity loss: 1.907347\n",
      "[ 1400/ 5482] total-loss: 0.900071; classification loss: 0.657302;  cosine similarity loss: 1.871146\n",
      "[ 2800/ 5482] total-loss: 1.237532; classification loss: 1.077577;  cosine similarity loss: 1.877351\n",
      "[ 4200/ 5482] total-loss: 1.055017; classification loss: 0.843418;  cosine similarity loss: 1.901412\n",
      "[ 5600/ 5482] total-loss: 0.782116; classification loss: 0.513458;  cosine similarity loss: 1.856747\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.633     0.593     0.632    106\n",
      " disgust     0.633     0.664     0.802    106\n",
      "    fear     0.633     0.541     0.623    106\n",
      "   happy     0.633     0.652     0.406    106\n",
      " neutral     0.633     0.824     0.660    106\n",
      "     sad     0.633     0.658     0.689    106\n",
      "surprise     0.633     0.564     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.633     0.642     0.633    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.325055 \n",
      "\n",
      "classification loss: 1.077252;  cosine similarity loss: 1.903262 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.021045; classification loss: 0.798845;  cosine similarity loss: 1.909843\n",
      "[ 1400/ 5482] total-loss: 0.940973; classification loss: 0.700112;  cosine similarity loss: 1.904416\n",
      "[ 2800/ 5482] total-loss: 1.330668; classification loss: 1.180197;  cosine similarity loss: 1.932549\n",
      "[ 4200/ 5482] total-loss: 1.159888; classification loss: 0.967500;  cosine similarity loss: 1.929440\n",
      "[ 5600/ 5482] total-loss: 1.470774; classification loss: 1.356660;  cosine similarity loss: 1.927230\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.643     0.591     0.613    106\n",
      " disgust     0.643     0.664     0.802    106\n",
      "    fear     0.643     0.592     0.670    106\n",
      "   happy     0.643     0.652     0.406    106\n",
      " neutral     0.643     0.824     0.660    106\n",
      "     sad     0.643     0.664     0.726    106\n",
      "surprise     0.643     0.564     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.643     0.650     0.643    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.314728 \n",
      "\n",
      "classification loss: 1.066418;  cosine similarity loss: 1.894119 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep4_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep0_acc_63\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep4_acc_64\"! Old accuracy: 63.0, new accuracy: 63.7\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.157987; classification loss: 0.964153;  cosine similarity loss: 1.933325\n",
      "[ 1400/ 5482] total-loss: 1.122114; classification loss: 0.926536;  cosine similarity loss: 1.904427\n",
      "[ 2800/ 5482] total-loss: 1.226160; classification loss: 1.050391;  cosine similarity loss: 1.929235\n",
      "[ 4200/ 5482] total-loss: 0.823957; classification loss: 0.561268;  cosine similarity loss: 1.874715\n",
      "[ 5600/ 5482] total-loss: 1.168091; classification loss: 0.980382;  cosine similarity loss: 1.918925\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.644     0.582     0.604    106\n",
      " disgust     0.644     0.659     0.802    106\n",
      "    fear     0.644     0.587     0.670    106\n",
      "   happy     0.644     0.667     0.415    106\n",
      " neutral     0.644     0.845     0.670    106\n",
      "     sad     0.644     0.673     0.717    106\n",
      "surprise     0.644     0.563     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.644     0.654     0.644    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.308201 \n",
      "\n",
      "classification loss: 1.057779;  cosine similarity loss: 1.892521 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep5_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep4_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep5_acc_64\"! Old accuracy: 63.7, new accuracy: 63.8\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.780156; classification loss: 0.518972;  cosine similarity loss: 1.824891\n",
      "[ 1400/ 5482] total-loss: 1.013885; classification loss: 0.808178;  cosine similarity loss: 1.836712\n",
      "[ 2800/ 5482] total-loss: 1.541857; classification loss: 1.455926;  cosine similarity loss: 1.885582\n",
      "[ 4200/ 5482] total-loss: 0.895456; classification loss: 0.654139;  cosine similarity loss: 1.860723\n",
      "[ 5600/ 5482] total-loss: 0.829795; classification loss: 0.569474;  cosine similarity loss: 1.871082\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.632     0.577     0.604    106\n",
      " disgust     0.632     0.654     0.802    106\n",
      "    fear     0.632     0.565     0.613    106\n",
      "   happy     0.632     0.656     0.396    106\n",
      " neutral     0.632     0.833     0.660    106\n",
      "     sad     0.632     0.652     0.708    106\n",
      "surprise     0.632     0.553     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.632     0.641     0.632    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.314849 \n",
      "\n",
      "classification loss: 1.066418;  cosine similarity loss: 1.894520 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.025272; classification loss: 0.801532;  cosine similarity loss: 1.920231\n",
      "[ 1400/ 5482] total-loss: 1.287274; classification loss: 1.121437;  cosine similarity loss: 1.950621\n",
      "[ 2800/ 5482] total-loss: 1.005538; classification loss: 0.785466;  cosine similarity loss: 1.885826\n",
      "[ 4200/ 5482] total-loss: 0.739267; classification loss: 0.470595;  cosine similarity loss: 1.813958\n",
      "[ 5600/ 5482] total-loss: 0.866926; classification loss: 0.607703;  cosine similarity loss: 1.903820\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.640     0.587     0.604    106\n",
      " disgust     0.640     0.654     0.802    106\n",
      "    fear     0.640     0.569     0.623    106\n",
      "   happy     0.640     0.634     0.425    106\n",
      " neutral     0.640     0.847     0.679    106\n",
      "     sad     0.640     0.661     0.717    106\n",
      "surprise     0.640     0.578     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.640     0.647     0.640    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.316839 \n",
      "\n",
      "classification loss: 1.068775;  cosine similarity loss: 1.895656 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.889084; classification loss: 0.633082;  cosine similarity loss: 1.913092\n",
      "[ 1400/ 5482] total-loss: 0.801887; classification loss: 0.537433;  cosine similarity loss: 1.859702\n",
      "[ 2800/ 5482] total-loss: 1.025361; classification loss: 0.806049;  cosine similarity loss: 1.902611\n",
      "[ 4200/ 5482] total-loss: 0.987289; classification loss: 0.760208;  cosine similarity loss: 1.895614\n",
      "[ 5600/ 5482] total-loss: 1.305324; classification loss: 1.164253;  cosine similarity loss: 1.869610\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.636     0.565     0.613    106\n",
      " disgust     0.636     0.691     0.802    106\n",
      "    fear     0.636     0.591     0.613    106\n",
      "   happy     0.636     0.634     0.425    106\n",
      " neutral     0.636     0.807     0.670    106\n",
      "     sad     0.636     0.630     0.708    106\n",
      "surprise     0.636     0.569     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.636     0.641     0.636    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.326634 \n",
      "\n",
      "classification loss: 1.083637;  cosine similarity loss: 1.893627 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.174133; classification loss: 0.983124;  cosine similarity loss: 1.938166\n",
      "[ 1400/ 5482] total-loss: 1.726230; classification loss: 1.670801;  cosine similarity loss: 1.947942\n",
      "[ 2800/ 5482] total-loss: 0.988877; classification loss: 0.772594;  cosine similarity loss: 1.854008\n",
      "[ 4200/ 5482] total-loss: 1.652332; classification loss: 1.576278;  cosine similarity loss: 1.956547\n",
      "[ 5600/ 5482] total-loss: 0.831664; classification loss: 0.577297;  cosine similarity loss: 1.849133\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.642     0.589     0.623    106\n",
      " disgust     0.642     0.683     0.811    106\n",
      "    fear     0.642     0.581     0.642    106\n",
      "   happy     0.642     0.657     0.415    106\n",
      " neutral     0.642     0.807     0.670    106\n",
      "     sad     0.642     0.636     0.708    106\n",
      "surprise     0.642     0.579     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.642     0.647     0.642    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.317312 \n",
      "\n",
      "classification loss: 1.069207;  cosine similarity loss: 1.896225 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.858241; classification loss: 0.618752;  cosine similarity loss: 1.816199\n",
      "[ 1400/ 5482] total-loss: 0.857710; classification loss: 0.611165;  cosine similarity loss: 1.843889\n",
      "[ 2800/ 5482] total-loss: 1.232894; classification loss: 1.061615;  cosine similarity loss: 1.918010\n",
      "[ 4200/ 5482] total-loss: 0.997555; classification loss: 0.786274;  cosine similarity loss: 1.842679\n",
      "[ 5600/ 5482] total-loss: 1.003202; classification loss: 0.773372;  cosine similarity loss: 1.922523\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.640     0.588     0.632    106\n",
      " disgust     0.640     0.664     0.821    106\n",
      "    fear     0.640     0.591     0.613    106\n",
      "   happy     0.640     0.662     0.425    106\n",
      " neutral     0.640     0.843     0.660    106\n",
      "     sad     0.640     0.636     0.708    106\n",
      "surprise     0.640     0.559     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.640     0.649     0.640    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.316934 \n",
      "\n",
      "classification loss: 1.070720;  cosine similarity loss: 1.891433 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.871409; classification loss: 0.625669;  cosine similarity loss: 1.854370\n",
      "[ 1400/ 5482] total-loss: 1.021613; classification loss: 0.808234;  cosine similarity loss: 1.875127\n",
      "[ 2800/ 5482] total-loss: 0.678186; classification loss: 0.385319;  cosine similarity loss: 1.849655\n",
      "[ 4200/ 5482] total-loss: 0.991942; classification loss: 0.772397;  cosine similarity loss: 1.870122\n",
      "[ 5600/ 5482] total-loss: 0.920935; classification loss: 0.678611;  cosine similarity loss: 1.890232\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.639     0.591     0.613    106\n",
      " disgust     0.639     0.667     0.811    106\n",
      "    fear     0.639     0.593     0.632    106\n",
      "   happy     0.639     0.600     0.425    106\n",
      " neutral     0.639     0.854     0.660    106\n",
      "     sad     0.639     0.647     0.708    106\n",
      "surprise     0.639     0.564     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.639     0.645     0.639    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.317094 \n",
      "\n",
      "classification loss: 1.069907;  cosine similarity loss: 1.893862 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.023281; classification loss: 0.807733;  cosine similarity loss: 1.885469\n",
      "[ 1400/ 5482] total-loss: 0.921682; classification loss: 0.681137;  cosine similarity loss: 1.883858\n",
      "[ 2800/ 5482] total-loss: 1.265366; classification loss: 1.116869;  cosine similarity loss: 1.859352\n",
      "[ 4200/ 5482] total-loss: 1.172270; classification loss: 1.007117;  cosine similarity loss: 1.832882\n",
      "[ 5600/ 5482] total-loss: 1.266133; classification loss: 1.101207;  cosine similarity loss: 1.925839\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.639     0.602     0.613    106\n",
      " disgust     0.639     0.662     0.811    106\n",
      "    fear     0.639     0.596     0.642    106\n",
      "   happy     0.639     0.595     0.415    106\n",
      " neutral     0.639     0.830     0.689    106\n",
      "     sad     0.639     0.638     0.698    106\n",
      "surprise     0.639     0.571     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.639     0.642     0.639    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.314295 \n",
      "\n",
      "classification loss: 1.065650;  cosine similarity loss: 1.894466 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.069677; classification loss: 0.855933;  cosine similarity loss: 1.924652\n",
      "[ 1400/ 5482] total-loss: 1.941157; classification loss: 1.942558;  cosine similarity loss: 1.935555\n",
      "[ 2800/ 5482] total-loss: 0.852298; classification loss: 0.606958;  cosine similarity loss: 1.833656\n",
      "[ 4200/ 5482] total-loss: 0.727380; classification loss: 0.441821;  cosine similarity loss: 1.869617\n",
      "[ 5600/ 5482] total-loss: 1.145980; classification loss: 0.957178;  cosine similarity loss: 1.901190\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.635     0.583     0.632    106\n",
      " disgust     0.635     0.649     0.821    106\n",
      "    fear     0.635     0.581     0.642    106\n",
      "   happy     0.635     0.641     0.387    106\n",
      " neutral     0.635     0.843     0.660    106\n",
      "     sad     0.635     0.627     0.698    106\n",
      "surprise     0.635     0.577     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.635     0.643     0.635    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.317972 \n",
      "\n",
      "classification loss: 1.069754;  cosine similarity loss: 1.897147 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.127495; classification loss: 0.933427;  cosine similarity loss: 1.903769\n",
      "[ 1400/ 5482] total-loss: 1.528747; classification loss: 1.433447;  cosine similarity loss: 1.909947\n",
      "[ 2800/ 5482] total-loss: 0.865140; classification loss: 0.616327;  cosine similarity loss: 1.860391\n",
      "[ 4200/ 5482] total-loss: 1.164307; classification loss: 0.979734;  cosine similarity loss: 1.902599\n",
      "[ 5600/ 5482] total-loss: 0.970424; classification loss: 0.744821;  cosine similarity loss: 1.872838\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.642     0.588     0.632    106\n",
      " disgust     0.642     0.659     0.821    106\n",
      "    fear     0.642     0.604     0.632    106\n",
      "   happy     0.642     0.667     0.415    106\n",
      " neutral     0.642     0.855     0.670    106\n",
      "     sad     0.642     0.620     0.708    106\n",
      "surprise     0.642     0.565     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.642     0.651     0.642    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.315489 \n",
      "\n",
      "classification loss: 1.066999;  cosine similarity loss: 1.895298 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.060979; classification loss: 0.861879;  cosine similarity loss: 1.857380\n",
      "[ 1400/ 5482] total-loss: 0.946805; classification loss: 0.719541;  cosine similarity loss: 1.855859\n",
      "[ 2800/ 5482] total-loss: 0.918398; classification loss: 0.671675;  cosine similarity loss: 1.905290\n",
      "[ 4200/ 5482] total-loss: 1.085622; classification loss: 0.879376;  cosine similarity loss: 1.910604\n",
      "[ 5600/ 5482] total-loss: 0.886402; classification loss: 0.636047;  cosine similarity loss: 1.887821\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.647     0.574     0.623    106\n",
      " disgust     0.647     0.664     0.802    106\n",
      "    fear     0.647     0.585     0.651    106\n",
      "   happy     0.647     0.657     0.415    106\n",
      " neutral     0.647     0.852     0.708    106\n",
      "     sad     0.647     0.667     0.717    106\n",
      "surprise     0.647     0.580     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.647     0.654     0.647    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.314525 \n",
      "\n",
      "classification loss: 1.066852;  cosine similarity loss: 1.892429 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep15_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep5_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep15_acc_64\"! Old accuracy: 63.8, new accuracy: 64.1\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.927176; classification loss: 0.685101;  cosine similarity loss: 1.895477\n",
      "[ 1400/ 5482] total-loss: 0.723268; classification loss: 0.451617;  cosine similarity loss: 1.809874\n",
      "[ 2800/ 5482] total-loss: 0.995572; classification loss: 0.767966;  cosine similarity loss: 1.905994\n",
      "[ 4200/ 5482] total-loss: 1.162411; classification loss: 0.978991;  cosine similarity loss: 1.896090\n",
      "[ 5600/ 5482] total-loss: 0.836177; classification loss: 0.576872;  cosine similarity loss: 1.873398\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.642     0.590     0.651    106\n",
      " disgust     0.642     0.675     0.802    106\n",
      "    fear     0.642     0.584     0.623    106\n",
      "   happy     0.642     0.652     0.425    106\n",
      " neutral     0.642     0.839     0.689    106\n",
      "     sad     0.642     0.632     0.698    106\n",
      "surprise     0.642     0.566     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.642     0.648     0.642    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.317007 \n",
      "\n",
      "classification loss: 1.069680;  cosine similarity loss: 1.894105 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.956173; classification loss: 0.719215;  cosine similarity loss: 1.904006\n",
      "[ 1400/ 5482] total-loss: 1.254964; classification loss: 1.095216;  cosine similarity loss: 1.893955\n",
      "[ 2800/ 5482] total-loss: 0.982881; classification loss: 0.753793;  cosine similarity loss: 1.899234\n",
      "[ 4200/ 5482] total-loss: 0.934566; classification loss: 0.702136;  cosine similarity loss: 1.864284\n",
      "[ 5600/ 5482] total-loss: 1.116699; classification loss: 0.916791;  cosine similarity loss: 1.916334\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.639     0.573     0.632    106\n",
      " disgust     0.639     0.675     0.802    106\n",
      "    fear     0.639     0.579     0.623    106\n",
      "   happy     0.639     0.647     0.415    106\n",
      " neutral     0.639     0.849     0.689    106\n",
      "     sad     0.639     0.636     0.708    106\n",
      "surprise     0.639     0.566     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.639     0.646     0.639    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.315156 \n",
      "\n",
      "classification loss: 1.068914;  cosine similarity loss: 1.889722 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.116666; classification loss: 0.918187;  cosine similarity loss: 1.910585\n",
      "[ 1400/ 5482] total-loss: 1.173025; classification loss: 0.986567;  cosine similarity loss: 1.918857\n",
      "[ 2800/ 5482] total-loss: 1.282507; classification loss: 1.117014;  cosine similarity loss: 1.944479\n",
      "[ 4200/ 5482] total-loss: 0.641267; classification loss: 0.345528;  cosine similarity loss: 1.824220\n",
      "[ 5600/ 5482] total-loss: 1.012302; classification loss: 0.797789;  cosine similarity loss: 1.870352\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.644     0.573     0.632    106\n",
      " disgust     0.644     0.680     0.802    106\n",
      "    fear     0.644     0.578     0.632    106\n",
      "   happy     0.644     0.642     0.406    106\n",
      " neutral     0.644     0.852     0.708    106\n",
      "     sad     0.644     0.655     0.717    106\n",
      "surprise     0.644     0.575     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.644     0.651     0.644    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.321694 \n",
      "\n",
      "classification loss: 1.077972;  cosine similarity loss: 1.890379 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.902206; classification loss: 0.661482;  cosine similarity loss: 1.865101\n",
      "[ 1400/ 5482] total-loss: 0.977757; classification loss: 0.758102;  cosine similarity loss: 1.856375\n",
      "[ 2800/ 5482] total-loss: 0.692770; classification loss: 0.406474;  cosine similarity loss: 1.837951\n",
      "[ 4200/ 5482] total-loss: 1.211694; classification loss: 1.043141;  cosine similarity loss: 1.885903\n",
      "[ 5600/ 5482] total-loss: 1.146500; classification loss: 0.965658;  cosine similarity loss: 1.869868\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.644     0.579     0.623    106\n",
      " disgust     0.644     0.697     0.802    106\n",
      "    fear     0.644     0.580     0.651    106\n",
      "   happy     0.644     0.629     0.415    106\n",
      " neutral     0.644     0.841     0.698    106\n",
      "     sad     0.644     0.655     0.698    106\n",
      "surprise     0.644     0.569     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.644     0.650     0.644    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.319397 \n",
      "\n",
      "classification loss: 1.071727;  cosine similarity loss: 1.897292 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.145474; classification loss: 0.954097;  cosine similarity loss: 1.910981\n",
      "[ 1400/ 5482] total-loss: 1.218767; classification loss: 1.048440;  cosine similarity loss: 1.900072\n",
      "[ 2800/ 5482] total-loss: 0.944991; classification loss: 0.709091;  cosine similarity loss: 1.888593\n",
      "[ 4200/ 5482] total-loss: 0.776343; classification loss: 0.512137;  cosine similarity loss: 1.833166\n",
      "[ 5600/ 5482] total-loss: 1.105474; classification loss: 0.904715;  cosine similarity loss: 1.908509\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.644     0.574     0.623    106\n",
      " disgust     0.644     0.680     0.802    106\n",
      "    fear     0.644     0.580     0.651    106\n",
      "   happy     0.644     0.646     0.396    106\n",
      " neutral     0.644     0.854     0.717    106\n",
      "     sad     0.644     0.641     0.708    106\n",
      "surprise     0.644     0.580     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.644     0.651     0.644    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.322624 \n",
      "\n",
      "classification loss: 1.077229;  cosine similarity loss: 1.895213 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.979056; classification loss: 0.758776;  cosine similarity loss: 1.860175\n",
      "[ 1400/ 5482] total-loss: 1.018600; classification loss: 0.801108;  cosine similarity loss: 1.888564\n",
      "[ 2800/ 5482] total-loss: 1.056127; classification loss: 0.846752;  cosine similarity loss: 1.893628\n",
      "[ 4200/ 5482] total-loss: 1.148611; classification loss: 0.963949;  cosine similarity loss: 1.887258\n",
      "[ 5600/ 5482] total-loss: 1.174828; classification loss: 0.987579;  cosine similarity loss: 1.923820\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.643     0.571     0.642    106\n",
      " disgust     0.643     0.672     0.811    106\n",
      "    fear     0.643     0.586     0.613    106\n",
      "   happy     0.643     0.643     0.425    106\n",
      " neutral     0.643     0.859     0.689    106\n",
      "     sad     0.643     0.643     0.698    106\n",
      "surprise     0.643     0.579     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.643     0.650     0.643    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.319573 \n",
      "\n",
      "classification loss: 1.074393;  cosine similarity loss: 1.891661 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.108727; classification loss: 0.914869;  cosine similarity loss: 1.884160\n",
      "[ 1400/ 5482] total-loss: 0.811387; classification loss: 0.558604;  cosine similarity loss: 1.822519\n",
      "[ 2800/ 5482] total-loss: 0.943929; classification loss: 0.715535;  cosine similarity loss: 1.857502\n",
      "[ 4200/ 5482] total-loss: 1.038963; classification loss: 0.828779;  cosine similarity loss: 1.879700\n",
      "[ 5600/ 5482] total-loss: 1.078020; classification loss: 0.871837;  cosine similarity loss: 1.902752\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.644     0.589     0.623    106\n",
      " disgust     0.644     0.685     0.802    106\n",
      "    fear     0.644     0.593     0.632    106\n",
      "   happy     0.644     0.620     0.415    106\n",
      " neutral     0.644     0.851     0.698    106\n",
      "     sad     0.644     0.628     0.717    106\n",
      "surprise     0.644     0.579     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.644     0.649     0.644    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.321794 \n",
      "\n",
      "classification loss: 1.078367;  cosine similarity loss: 1.889791 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.968028; classification loss: 0.751895;  cosine similarity loss: 1.832557\n",
      "[ 1400/ 5482] total-loss: 1.490156; classification loss: 1.380241;  cosine similarity loss: 1.929814\n",
      "[ 2800/ 5482] total-loss: 1.427748; classification loss: 1.302029;  cosine similarity loss: 1.930626\n",
      "[ 4200/ 5482] total-loss: 1.197297; classification loss: 1.023208;  cosine similarity loss: 1.893650\n",
      "[ 5600/ 5482] total-loss: 1.091266; classification loss: 0.891318;  cosine similarity loss: 1.891058\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.639     0.569     0.623    106\n",
      " disgust     0.639     0.683     0.811    106\n",
      "    fear     0.639     0.578     0.632    106\n",
      "   happy     0.639     0.656     0.396    106\n",
      " neutral     0.639     0.839     0.689    106\n",
      "     sad     0.639     0.636     0.708    106\n",
      "surprise     0.639     0.565     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.639     0.646     0.639    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.305259 \n",
      "\n",
      "classification loss: 1.052655;  cosine similarity loss: 1.894667 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.052571; classification loss: 0.836508;  cosine similarity loss: 1.916821\n",
      "[ 1400/ 5482] total-loss: 0.719734; classification loss: 0.440495;  cosine similarity loss: 1.836691\n",
      "[ 2800/ 5482] total-loss: 0.825315; classification loss: 0.571890;  cosine similarity loss: 1.839013\n",
      "[ 4200/ 5482] total-loss: 0.795534; classification loss: 0.528434;  cosine similarity loss: 1.863931\n",
      "[ 5600/ 5482] total-loss: 1.060261; classification loss: 0.852695;  cosine similarity loss: 1.890525\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.640     0.574     0.623    106\n",
      " disgust     0.640     0.702     0.802    106\n",
      "    fear     0.640     0.573     0.632    106\n",
      "   happy     0.640     0.632     0.406    106\n",
      " neutral     0.640     0.839     0.689    106\n",
      "     sad     0.640     0.639     0.717    106\n",
      "surprise     0.640     0.565     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.640     0.646     0.640    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.319145 \n",
      "\n",
      "classification loss: 1.072194;  cosine similarity loss: 1.895364 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.908101; classification loss: 0.655113;  cosine similarity loss: 1.920050\n",
      "[ 1400/ 5482] total-loss: 0.817054; classification loss: 0.542449;  cosine similarity loss: 1.915473\n",
      "[ 2800/ 5482] total-loss: 0.889408; classification loss: 0.650155;  cosine similarity loss: 1.846422\n",
      "[ 4200/ 5482] total-loss: 1.069804; classification loss: 0.869311;  cosine similarity loss: 1.871776\n",
      "[ 5600/ 5482] total-loss: 1.142110; classification loss: 0.947392;  cosine similarity loss: 1.920981\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.642     0.574     0.660    106\n",
      " disgust     0.642     0.669     0.802    106\n",
      "    fear     0.642     0.580     0.613    106\n",
      "   happy     0.642     0.662     0.406    106\n",
      " neutral     0.642     0.841     0.698    106\n",
      "     sad     0.642     0.649     0.698    106\n",
      "surprise     0.642     0.570     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.642     0.649     0.642    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.323017 \n",
      "\n",
      "classification loss: 1.077480;  cosine similarity loss: 1.895939 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.661665; classification loss: 0.374956;  cosine similarity loss: 1.808500\n",
      "[ 1400/ 5482] total-loss: 0.856310; classification loss: 0.607729;  cosine similarity loss: 1.850636\n",
      "[ 2800/ 5482] total-loss: 0.958161; classification loss: 0.726062;  cosine similarity loss: 1.886553\n",
      "[ 4200/ 5482] total-loss: 1.215833; classification loss: 1.045189;  cosine similarity loss: 1.898409\n",
      "[ 5600/ 5482] total-loss: 0.794904; classification loss: 0.520783;  cosine similarity loss: 1.891389\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.647     0.574     0.660    106\n",
      " disgust     0.647     0.685     0.802    106\n",
      "    fear     0.647     0.595     0.623    106\n",
      "   happy     0.647     0.657     0.415    106\n",
      " neutral     0.647     0.844     0.717    106\n",
      "     sad     0.647     0.647     0.708    106\n",
      "surprise     0.647     0.571     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.647     0.653     0.647    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.316453 \n",
      "\n",
      "classification loss: 1.068981;  cosine similarity loss: 1.893886 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.531763; classification loss: 1.428899;  cosine similarity loss: 1.943221\n",
      "[ 1400/ 5482] total-loss: 0.813226; classification loss: 0.551180;  cosine similarity loss: 1.861407\n",
      "[ 2800/ 5482] total-loss: 1.093439; classification loss: 0.884404;  cosine similarity loss: 1.929582\n",
      "[ 4200/ 5482] total-loss: 1.160310; classification loss: 0.970464;  cosine similarity loss: 1.919693\n",
      "[ 5600/ 5482] total-loss: 1.037358; classification loss: 0.820577;  cosine similarity loss: 1.904482\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.647     0.569     0.660    106\n",
      " disgust     0.647     0.680     0.802    106\n",
      "    fear     0.647     0.590     0.651    106\n",
      "   happy     0.647     0.667     0.396    106\n",
      " neutral     0.647     0.851     0.698    106\n",
      "     sad     0.647     0.658     0.708    106\n",
      "surprise     0.647     0.575     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.647     0.656     0.647    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.317768 \n",
      "\n",
      "classification loss: 1.071356;  cosine similarity loss: 1.892728 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.526478; classification loss: 1.427552;  cosine similarity loss: 1.922180\n",
      "[ 1400/ 5482] total-loss: 0.993349; classification loss: 0.771438;  cosine similarity loss: 1.880995\n",
      "[ 2800/ 5482] total-loss: 1.110185; classification loss: 0.911004;  cosine similarity loss: 1.906908\n",
      "[ 4200/ 5482] total-loss: 1.343368; classification loss: 1.198692;  cosine similarity loss: 1.922072\n",
      "[ 5600/ 5482] total-loss: 0.767473; classification loss: 0.501123;  cosine similarity loss: 1.832874\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.647     0.574     0.660    106\n",
      " disgust     0.647     0.708     0.802    106\n",
      "    fear     0.647     0.579     0.623    106\n",
      "   happy     0.647     0.657     0.415    106\n",
      " neutral     0.647     0.851     0.698    106\n",
      "     sad     0.647     0.636     0.708    106\n",
      "surprise     0.647     0.579     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.647     0.655     0.647    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.327891 \n",
      "\n",
      "classification loss: 1.085096;  cosine similarity loss: 1.894413 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.179843; classification loss: 0.990523;  cosine similarity loss: 1.937124\n",
      "[ 1400/ 5482] total-loss: 0.833605; classification loss: 0.583972;  cosine similarity loss: 1.832137\n",
      "[ 2800/ 5482] total-loss: 0.949262; classification loss: 0.726285;  cosine similarity loss: 1.841169\n",
      "[ 4200/ 5482] total-loss: 0.795608; classification loss: 0.527642;  cosine similarity loss: 1.867471\n",
      "[ 5600/ 5482] total-loss: 1.209029; classification loss: 1.031928;  cosine similarity loss: 1.917432\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.648     0.570     0.651    106\n",
      " disgust     0.648     0.697     0.802    106\n",
      "    fear     0.648     0.588     0.632    106\n",
      "   happy     0.648     0.657     0.415    106\n",
      " neutral     0.648     0.844     0.717    106\n",
      "     sad     0.648     0.649     0.698    106\n",
      "surprise     0.648     0.579     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.648     0.655     0.648    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.326855 \n",
      "\n",
      "classification loss: 1.084481;  cosine similarity loss: 1.892394 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep29_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep15_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep29_acc_64\"! Old accuracy: 64.1, new accuracy: 64.2\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.837355; classification loss: 0.592317;  cosine similarity loss: 1.817503\n",
      "[ 1400/ 5482] total-loss: 1.120582; classification loss: 0.940778;  cosine similarity loss: 1.839796\n",
      "[ 2800/ 5482] total-loss: 1.143428; classification loss: 0.956293;  cosine similarity loss: 1.891966\n",
      "[ 4200/ 5482] total-loss: 0.975942; classification loss: 0.744650;  cosine similarity loss: 1.901109\n",
      "[ 5600/ 5482] total-loss: 0.746102; classification loss: 0.471560;  cosine similarity loss: 1.844272\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.655     0.575     0.651    106\n",
      " disgust     0.655     0.694     0.811    106\n",
      "    fear     0.655     0.588     0.660    106\n",
      "   happy     0.655     0.647     0.415    106\n",
      " neutral     0.655     0.854     0.717    106\n",
      "     sad     0.655     0.670     0.708    106\n",
      "surprise     0.655     0.600     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.655     0.661     0.655    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.329896 \n",
      "\n",
      "classification loss: 1.086745;  cosine similarity loss: 1.897247 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep30_acc_65.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep29_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/encoder/Nr1/emo_reco_best_ep30_acc_65\"! Old accuracy: 64.2, new accuracy: 64.9\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.821709; classification loss: 0.564532;  cosine similarity loss: 1.850417\n",
      "[ 1400/ 5482] total-loss: 1.000018; classification loss: 0.784002;  cosine similarity loss: 1.864078\n",
      "[ 2800/ 5482] total-loss: 1.126616; classification loss: 0.934108;  cosine similarity loss: 1.896646\n",
      "[ 4200/ 5482] total-loss: 1.041434; classification loss: 0.833660;  cosine similarity loss: 1.872530\n",
      "[ 5600/ 5482] total-loss: 1.137614; classification loss: 0.956946;  cosine similarity loss: 1.860285\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.647     0.570     0.651    106\n",
      " disgust     0.647     0.680     0.802    106\n",
      "    fear     0.647     0.580     0.613    106\n",
      "   happy     0.647     0.647     0.415    106\n",
      " neutral     0.647     0.865     0.726    106\n",
      "     sad     0.647     0.652     0.708    106\n",
      "surprise     0.647     0.580     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.647     0.654     0.647    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.329310 \n",
      "\n",
      "classification loss: 1.087771;  cosine similarity loss: 1.892902 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.041596; classification loss: 0.822659;  cosine similarity loss: 1.917341\n",
      "[ 1400/ 5482] total-loss: 0.760292; classification loss: 0.488983;  cosine similarity loss: 1.845528\n",
      "[ 2800/ 5482] total-loss: 0.778546; classification loss: 0.501430;  cosine similarity loss: 1.887011\n",
      "[ 4200/ 5482] total-loss: 0.899192; classification loss: 0.652456;  cosine similarity loss: 1.886133\n",
      "[ 5600/ 5482] total-loss: 0.751647; classification loss: 0.478456;  cosine similarity loss: 1.844407\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.644     0.580     0.651    106\n",
      " disgust     0.644     0.688     0.811    106\n",
      "    fear     0.644     0.575     0.613    106\n",
      "   happy     0.644     0.662     0.425    106\n",
      " neutral     0.644     0.843     0.708    106\n",
      "     sad     0.644     0.643     0.698    106\n",
      "surprise     0.644     0.566     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.644     0.651     0.644    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.327349 \n",
      "\n",
      "classification loss: 1.084568;  cosine similarity loss: 1.893836 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.957348; classification loss: 0.720985;  cosine similarity loss: 1.902799\n",
      "[ 1400/ 5482] total-loss: 1.061914; classification loss: 0.846880;  cosine similarity loss: 1.922053\n",
      "[ 2800/ 5482] total-loss: 1.204520; classification loss: 1.030005;  cosine similarity loss: 1.902580\n",
      "[ 4200/ 5482] total-loss: 1.450936; classification loss: 1.335501;  cosine similarity loss: 1.912675\n",
      "[ 5600/ 5482] total-loss: 0.997268; classification loss: 0.767709;  cosine similarity loss: 1.915505\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.643     0.566     0.651    106\n",
      " disgust     0.643     0.680     0.802    106\n",
      "    fear     0.643     0.579     0.623    106\n",
      "   happy     0.643     0.638     0.415    106\n",
      " neutral     0.643     0.849     0.689    106\n",
      "     sad     0.643     0.652     0.708    106\n",
      "surprise     0.643     0.586     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.643     0.650     0.643    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.334017 \n",
      "\n",
      "classification loss: 1.093642;  cosine similarity loss: 1.894893 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.016376; classification loss: 0.794550;  cosine similarity loss: 1.903683\n",
      "[ 1400/ 5482] total-loss: 1.052589; classification loss: 0.846682;  cosine similarity loss: 1.876215\n",
      "[ 2800/ 5482] total-loss: 0.845838; classification loss: 0.584292;  cosine similarity loss: 1.892023\n",
      "[ 4200/ 5482] total-loss: 1.148706; classification loss: 0.957418;  cosine similarity loss: 1.913859\n",
      "[ 5600/ 5482] total-loss: 1.210407; classification loss: 1.047811;  cosine similarity loss: 1.860788\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.635     0.569     0.623    106\n",
      " disgust     0.635     0.697     0.802    106\n",
      "    fear     0.635     0.555     0.623    106\n",
      "   happy     0.635     0.623     0.406    106\n",
      " neutral     0.635     0.839     0.689    106\n",
      "     sad     0.635     0.644     0.717    106\n",
      "surprise     0.635     0.559     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.635     0.641     0.635    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.333249 \n",
      "\n",
      "classification loss: 1.092503;  cosine similarity loss: 1.894989 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.491383; classification loss: 1.386181;  cosine similarity loss: 1.912192\n",
      "[ 1400/ 5482] total-loss: 1.265058; classification loss: 1.110461;  cosine similarity loss: 1.883446\n",
      "[ 2800/ 5482] total-loss: 0.975713; classification loss: 0.747351;  cosine similarity loss: 1.889158\n",
      "[ 4200/ 5482] total-loss: 1.068527; classification loss: 0.859634;  cosine similarity loss: 1.904098\n",
      "[ 5600/ 5482] total-loss: 0.711807; classification loss: 0.421530;  cosine similarity loss: 1.872916\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.640     0.576     0.642    106\n",
      " disgust     0.640     0.675     0.802    106\n",
      "    fear     0.640     0.563     0.632    106\n",
      "   happy     0.640     0.609     0.396    106\n",
      " neutral     0.640     0.843     0.708    106\n",
      "     sad     0.640     0.664     0.708    106\n",
      "surprise     0.640     0.583     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.640     0.645     0.640    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.311669 \n",
      "\n",
      "classification loss: 1.064965;  cosine similarity loss: 1.887312 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.127326; classification loss: 0.944513;  cosine similarity loss: 1.858578\n",
      "[ 1400/ 5482] total-loss: 1.096879; classification loss: 0.897653;  cosine similarity loss: 1.893784\n",
      "[ 2800/ 5482] total-loss: 0.971435; classification loss: 0.741882;  cosine similarity loss: 1.889646\n",
      "[ 4200/ 5482] total-loss: 0.782925; classification loss: 0.524465;  cosine similarity loss: 1.816763\n",
      "[ 5600/ 5482] total-loss: 1.132247; classification loss: 0.940921;  cosine similarity loss: 1.897552\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.637     0.574     0.623    106\n",
      " disgust     0.637     0.672     0.792    106\n",
      "    fear     0.637     0.555     0.623    106\n",
      "   happy     0.637     0.597     0.406    106\n",
      " neutral     0.637     0.851     0.698    106\n",
      "     sad     0.637     0.661     0.717    106\n",
      "surprise     0.637     0.587     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.637     0.642     0.637    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.325681 \n",
      "\n",
      "classification loss: 1.078692;  cosine similarity loss: 1.901989 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.930317; classification loss: 0.692880;  cosine similarity loss: 1.880065\n",
      "[ 1400/ 5482] total-loss: 0.925448; classification loss: 0.689322;  cosine similarity loss: 1.869953\n",
      "[ 2800/ 5482] total-loss: 0.983849; classification loss: 0.754570;  cosine similarity loss: 1.900963\n",
      "[ 4200/ 5482] total-loss: 0.893361; classification loss: 0.640910;  cosine similarity loss: 1.903167\n",
      "[ 5600/ 5482] total-loss: 0.831513; classification loss: 0.575576;  cosine similarity loss: 1.855258\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.637     0.563     0.632    106\n",
      " disgust     0.637     0.677     0.811    106\n",
      "    fear     0.637     0.563     0.632    106\n",
      "   happy     0.637     0.618     0.396    106\n",
      " neutral     0.637     0.849     0.689    106\n",
      "     sad     0.637     0.643     0.698    106\n",
      "surprise     0.637     0.593     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.637     0.644     0.637    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.326337 \n",
      "\n",
      "classification loss: 1.085266;  cosine similarity loss: 1.888835 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.912136; classification loss: 0.663764;  cosine similarity loss: 1.905623\n",
      "[ 1400/ 5482] total-loss: 0.850605; classification loss: 0.602862;  cosine similarity loss: 1.841578\n",
      "[ 2800/ 5482] total-loss: 0.900249; classification loss: 0.655944;  cosine similarity loss: 1.877468\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 19\u001B[0m\n\u001B[1;32m     11\u001B[0m lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-4\u001B[39m\n\u001B[1;32m     12\u001B[0m trainer \u001B[38;5;241m=\u001B[39m sset\u001B[38;5;241m.\u001B[39mSSGenModelTrainer(lr\u001B[38;5;241m=\u001B[39mlr, num_epochs\u001B[38;5;241m=\u001B[39mepochs, model\u001B[38;5;241m=\u001B[39mmodel, train_dataset\u001B[38;5;241m=\u001B[39mtrainDS,\n\u001B[1;32m     13\u001B[0m                             eval_dataset\u001B[38;5;241m=\u001B[39mtestDs,\n\u001B[1;32m     14\u001B[0m                             device\u001B[38;5;241m=\u001B[39mdevice, labelList\u001B[38;5;241m=\u001B[39mdata_set\u001B[38;5;241m.\u001B[39mencoded_dataset\u001B[38;5;241m.\u001B[39mlabel_list,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m                             save_highest_acc_min_acc\u001B[38;5;241m=\u001B[39msave_highest_acc_min_acc,\n\u001B[1;32m     18\u001B[0m                             model_path \u001B[38;5;241m=\u001B[39m models_dir, regularize_dims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 19\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:76\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# this is the trainloop\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# --------------------- testloop and evaluation- ---------------\u001B[39;00m\n\u001B[1;32m     79\u001B[0m acc, true, preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loop(test_dataloader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:98\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train_loop\u001B[0;34m(self, dataloader, model, loss_fn, optimizer, epoch)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_loop\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataloader, model, loss_fn, optimizer, epoch):\n\u001B[1;32m     97\u001B[0m     size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataloader\u001B[38;5;241m.\u001B[39mdataset)\n\u001B[0;32m---> 98\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch, (X, z) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[1;32m    100\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(X) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m    101\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    623\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 624\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_profile_name):\n\u001B[1;32m    625\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m             \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/autograd/profiler.py:487\u001B[0m, in \u001B[0;36mrecord_function.__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;66;03m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001B[39;00m\n\u001B[1;32m    484\u001B[0m     \u001B[38;5;66;03m# class (https://github.com/pytorch/pytorch/issues/35026).\u001B[39;00m\n\u001B[1;32m    485\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 487\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__enter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39m_record_function_enter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs)\n\u001B[1;32m    489\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_models_and_utils/encoder\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import network_models.soundsream_models_and_utils.ss_trainer_gen_models as sset\n",
    "importlib.reload(sset)\n",
    "\n",
    "lr = 1e-4\n",
    "trainer = sset.SSGenModelTrainer(lr=lr, num_epochs=epochs, model=model, train_dataset=trainDS,\n",
    "                            eval_dataset=testDs,\n",
    "                            device=device, labelList=data_set.encoded_dataset.label_list,\n",
    "                            batch_size=batch_size,\n",
    "                            save_model_every=safe_model_every,\n",
    "                            save_highest_acc_min_acc=save_highest_acc_min_acc,\n",
    "                            model_path = models_dir, regularize_dims=True)\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% ...generating encoding\r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "\n",
    "# module_path = str(Path.cwd().parents[0] / \"utils\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/w2v_emotion_model\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_lstm\")\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "\n",
    "import utils.wav2Vec_utils as w2vU\n",
    "import utils.audio_dataset_utils as ADU\n",
    "import network_models.soundstream_lstm.LSTM_dataset as lds\n",
    "import network_models.soundstream_lstm.CombinedEmoDataset_7_Emo as ced\n",
    "import  network_models.w2v_emotion_model.custom_collator as cc\n",
    "import network_models.w2v_emotion_model.custom_model as cm\n",
    "import network_models.w2v_emotion_model.model_trainer as ct\n",
    "import gc\n",
    "\n",
    "model_name_or_path = \"facebook/wav2vec2-large-960h-lv60-self\"\n",
    "pooling_mode = \"mean\"\n",
    "device = \"cuda\"\n",
    "emo_dataset = ced.CombinedEmoDataSet_7_emos(directory_tess=\"/home/ckwdani/Music/emotionDatasets/converted_mono/tess\",\n",
    "                                             directory_cafe=\"/home/ckwdani/Music/emotionDatasets/converted_mono/cafe\",\n",
    "                                             directory_ravdess=\"/home/ckwdani/Music/emotionDatasets/converted_mono/RAVDESS Audio_Speech_Actors_01-24\",\n",
    "                                             directory_mesd=\"/home/ckwdani/Music/emotionDatasets/converted_mono/mesd\",\n",
    "                                             device=\"cpu\")\n",
    "\n",
    "emo_dataset = lds.AudioEmotionTessDataset(directory=\"/home/ckwdani/Music/emotionDatasets/converted_mono/tess\", device=device)\n",
    "processor, sr = w2vU.init_w2v2(num_labels=len(emo_dataset.label_list), label_list=emo_dataset.label_list, device=device)\n",
    "newSet = lds.AudioEmotionTessWav2VecDataset(emo_dataset, processor= processor, sampling_rate=sr)\n",
    "gc.collect()\n",
    "model = cm.Wav2Vec2ForSpeechClassification(model_name_or_path=model_name_or_path, pooling_mode=\"mean\", device=device)\n",
    "model.freeze_feature_extractor()\n",
    "\n",
    "\n",
    "trainSet, evalSet = ADU.train_val_dataset(newSet, 0.1)\n",
    "trainSet, evalSet = ADU.train_val_dataset(evalSet, 0.1)\n",
    "\n",
    "\n",
    "data_collator = cc.DataCollatorCTCWithPadding(processor=processor, padding=True, num_labels=len(newSet.dataSet.label_list))\n",
    "\n",
    "# trainer = ct.ModelTrainer(model=model, need_reshape=False, train_dataset=trainSet, eval_dataset=evalSet, device=device, batch_size=2, save_model_every=500, num_epochs=5001, model_path=\"../content/classifier/W2VClassifier/Nr1/\", data_collator=data_collator)\n",
    "# gc.collect()\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(\"../content/classifier/W2VClassifier/Nr1/emo_reco_950.pth\"))\n",
    "#model.from_pretrained()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.826298  [    0/  248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/w2v_emotion_model/custom_model.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y = softmax(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.821     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.464     0.167     1.000    3\n",
      "     ps     0.786     0.200     0.333    3\n",
      "    sad     0.750     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.755     0.052     0.190    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 1.964465 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.994363  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.893     1.000     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.500     0.077     0.333    3\n",
      "     ps     0.786     0.333     1.000    3\n",
      "    sad     0.714     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.201     0.226    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.942327 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.944698  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.500     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.464     0.071     0.333    3\n",
      "     ps     0.821     0.000     0.000    3\n",
      "    sad     0.536     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.735     0.082     0.083    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 7.1%, Avg loss: 1.967530 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.972177  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.500     0.077     0.333    3\n",
      "     ps     0.821     0.000     0.000    3\n",
      "    sad     0.643     0.182     0.667    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.037     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.951635 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.909775  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.750     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.714     0.222     0.667    3\n",
      "     ps     0.679     0.125     0.333    3\n",
      "    sad     0.679     0.125     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.755     0.067     0.190    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 1.959782 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.944281  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.893     1.000     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.607     0.100     0.333    3\n",
      "     ps     0.643     0.000     0.000    3\n",
      "    sad     0.607     0.100     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.171     0.131    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.958113 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.959650  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.607     0.000     0.000    3\n",
      "     ps     0.643     0.111     0.333    3\n",
      "    sad     0.500     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.724     0.016     0.048    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 1.957853 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.975341  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.821     0.333     0.667    3\n",
      "     ps     0.571     0.000     0.000    3\n",
      "    sad     0.500     0.077     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.059     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.944576 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.971989  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.821     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.821     0.333     0.667    3\n",
      "     ps     0.643     0.111     0.333    3\n",
      "    sad     0.536     0.083     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.755     0.075     0.190    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 1.953701 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.893392  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.750     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.821     0.333     0.667    3\n",
      "     ps     0.679     0.125     0.333    3\n",
      "    sad     0.571     0.091     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.755     0.078     0.190    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 1.942576 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.932293  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.821     1.000     0.167    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.250     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.679     0.125     0.333    3\n",
      "     ps     0.679     0.000     0.000    3\n",
      "    sad     0.571     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.196     0.107    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.966098 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.941443  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.250     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.643     0.111     0.333    3\n",
      "     ps     0.893     0.500     1.000    3\n",
      "    sad     0.571     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.123     0.226    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.941779 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.956130  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.821     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.429     0.118     0.667    3\n",
      "     ps     0.821     0.000     0.000    3\n",
      "    sad     0.679     0.125     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.035     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.964789 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.940639  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.929     1.000     0.500    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.500     0.077     0.333    3\n",
      "     ps     0.821     0.250     0.333    3\n",
      "    sad     0.643     0.111     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.205     0.214    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.939975 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.965062  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.571     0.200     1.000    3\n",
      "     ps     0.714     0.000     0.000    3\n",
      "    sad     0.821     0.333     0.667    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.076     0.238    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.958400 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.949719  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.750     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.536     0.083     0.333    3\n",
      "     ps     0.714     0.143     0.333    3\n",
      "    sad     0.679     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.735     0.032     0.095    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 7.1%, Avg loss: 1.946011 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.916658  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.333     0.500    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.643     0.182     0.667    3\n",
      "     ps     0.857     0.333     0.333    3\n",
      "    sad     0.750     0.250     0.667    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.786     0.157     0.310    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.946494 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.983889  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.500     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.750     0.167     0.333    3\n",
      "     ps     0.750     0.167     0.333    3\n",
      "    sad     0.393     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.119     0.131    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.944808 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.935481  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.714     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.893     0.500     0.667    3\n",
      "     ps     0.643     0.182     0.667    3\n",
      "    sad     0.643     0.182     0.667    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.776     0.123     0.286    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 21.4%, Avg loss: 1.927043 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.908306  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.750     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.643     0.182     0.667    3\n",
      "     ps     0.607     0.000     0.000    3\n",
      "    sad     0.679     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.735     0.026     0.095    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 7.1%, Avg loss: 1.950136 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.945104  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.893     1.000     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.786     0.000     0.000    3\n",
      "     ps     0.250     0.000     0.000    3\n",
      "    sad     0.750     0.167     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.735     0.167     0.083    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 7.1%, Avg loss: 1.949671 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.965581  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.750     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.714     0.143     0.333    3\n",
      "     ps     0.714     0.273     1.000    3\n",
      "    sad     0.643     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.755     0.059     0.190    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 1.957576 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.954391  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.500     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.643     0.111     0.333    3\n",
      "     ps     0.714     0.273     1.000    3\n",
      "    sad     0.679     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.126     0.226    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.950783 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.977557  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.714     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.786     0.200     0.333    3\n",
      "     ps     0.464     0.071     0.333    3\n",
      "    sad     0.786     0.200     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.067     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.953545 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.900814  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.750     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.643     0.111     0.333    3\n",
      "     ps     0.607     0.167     0.667    3\n",
      "    sad     0.750     0.167     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.755     0.063     0.190    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 1.937333 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.934776  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.750     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.536     0.083     0.333    3\n",
      "     ps     0.643     0.182     0.667    3\n",
      "    sad     0.821     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.038     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.961997 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.955702  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.821     0.000     0.000    3\n",
      "     ps     0.321     0.100     0.667    3\n",
      "    sad     0.821     0.250     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.745     0.050     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 1.944670 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.872041  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.821     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.821     0.250     0.333    3\n",
      "     ps     0.464     0.125     0.667    3\n",
      "    sad     0.786     0.286     0.667    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.094     0.238    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.936672 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.910570  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.500     0.000     0.000    3\n",
      "     ps     0.536     0.143     0.667    3\n",
      "    sad     0.786     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.735     0.020     0.095    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 7.1%, Avg loss: 1.934496 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.901168  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.714     0.000     0.000    6\n",
      "disgust     0.821     0.000     0.000    4\n",
      "   fear     0.821     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.821     0.333     0.667    3\n",
      "     ps     0.571     0.200     1.000    3\n",
      "    sad     0.786     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.076     0.238    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.932875 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.916622  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.821     0.000     0.000    4\n",
      "   fear     0.786     0.000     0.000    4\n",
      "  happy     0.857     1.000     0.200    5\n",
      "neutral     0.643     0.231     1.000    3\n",
      "     ps     0.714     0.000     0.000    3\n",
      "    sad     0.821     0.333     0.667    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.776     0.223     0.267    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 21.4%, Avg loss: 1.943704 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.907199  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.821     1.000     0.167    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.893     1.000     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.714     0.222     0.667    3\n",
      "     ps     0.607     0.214     1.000    3\n",
      "    sad     0.929     0.667     0.667    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.806     0.443     0.393    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 32.1%, Avg loss: 1.922984 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.013165  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.821     1.000     0.167    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.500     0.133     0.667    3\n",
      "     ps     0.821     0.333     0.667    3\n",
      "    sad     0.750     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.210     0.214    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.934203 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.994008  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.750     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.750     0.200     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.750     0.300     1.000    3\n",
      "     ps     0.679     0.000     0.000    3\n",
      "    sad     0.750     0.167     0.333    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.765     0.095     0.226    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 1.954905 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.952000  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.857     0.500     0.250    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.750     0.250     0.667    3\n",
      "     ps     0.571     0.200     1.000    3\n",
      "    sad     0.786     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.776     0.136     0.274    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 21.4%, Avg loss: 1.944686 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.909848  [    0/  248]\n",
      "7\n",
      "          accuracy  precision  recall   support\n",
      "  angry     0.786     0.000     0.000    6\n",
      "disgust     0.857     0.000     0.000    4\n",
      "   fear     0.786     0.000     0.000    4\n",
      "  happy     0.821     0.000     0.000    5\n",
      "neutral     0.821     0.000     0.000    3\n",
      "     ps     0.286     0.053     0.333    3\n",
      "    sad     0.714     0.000     0.000    3\n",
      "                                         28\n",
      "\n",
      " \n",
      "    avg     0.724     0.008     0.048    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 1.938699 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.900275  [    0/  248]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m trainer \u001B[38;5;241m=\u001B[39m ct\u001B[38;5;241m.\u001B[39mModelTrainer(model\u001B[38;5;241m=\u001B[39mmodel, need_reshape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, train_dataset\u001B[38;5;241m=\u001B[39mtrainSet, eval_dataset\u001B[38;5;241m=\u001B[39mevalSet, device\u001B[38;5;241m=\u001B[39mdevice, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, save_model_every\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5001\u001B[39m, model_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../content/classifier/W2VClassifier/Nr2_fullDs/\u001B[39m\u001B[38;5;124m\"\u001B[39m, data_collator\u001B[38;5;241m=\u001B[39mdata_collator, labelList\u001B[38;5;241m=\u001B[39memo_dataset\u001B[38;5;241m.\u001B[39mlabel_list)\n\u001B[1;32m      3\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[0;32m----> 4\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/w2v_emotion_model/model_trainer.py:57\u001B[0m, in \u001B[0;36mModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memo_reco_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 57\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loop(test_dataloader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/w2v_emotion_model/model_trainer.py:73\u001B[0m, in \u001B[0;36mModelTrainer.train_loop\u001B[0;34m(self, dataloader, model, loss_fn, optimizer)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# Compute prediction and loss\u001B[39;00m\n\u001B[1;32m     72\u001B[0m z \u001B[38;5;241m=\u001B[39m z\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 73\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, z)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;66;03m# Backpropagation\u001B[39;00m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/w2v_emotion_model/custom_model.py:89\u001B[0m, in \u001B[0;36mWav2Vec2ForSpeechClassification.forward\u001B[0;34m(self, input_values)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m     86\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     87\u001B[0m         input_values,\n\u001B[1;32m     88\u001B[0m ):\n\u001B[0;32m---> 89\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwav2vec2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;66;03m#hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\u001B[39;00m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1311\u001B[0m, in \u001B[0;36mWav2Vec2Model.forward\u001B[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1306\u001B[0m hidden_states, extract_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_projection(extract_features)\n\u001B[1;32m   1307\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mask_hidden_states(\n\u001B[1;32m   1308\u001B[0m     hidden_states, mask_time_indices\u001B[38;5;241m=\u001B[39mmask_time_indices, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask\n\u001B[1;32m   1309\u001B[0m )\n\u001B[0;32m-> 1311\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1312\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1313\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1314\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1315\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1316\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1317\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1319\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madapter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:794\u001B[0m, in \u001B[0;36mWav2Vec2Encoder.forward\u001B[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    788\u001B[0m         layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m    789\u001B[0m             create_custom_forward(layer),\n\u001B[1;32m    790\u001B[0m             hidden_states,\n\u001B[1;32m    791\u001B[0m             attention_mask,\n\u001B[1;32m    792\u001B[0m         )\n\u001B[1;32m    793\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 794\u001B[0m         layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    797\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    799\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m skip_the_layer:\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:682\u001B[0m, in \u001B[0;36mWav2Vec2EncoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, output_attentions)\u001B[0m\n\u001B[1;32m    679\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m attn_residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    681\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(hidden_states)\n\u001B[0;32m--> 682\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    683\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_layer_norm(hidden_states)\n\u001B[1;32m    685\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (hidden_states,)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:651\u001B[0m, in \u001B[0;36mWav2Vec2FeedForward.forward\u001B[0;34m(self, hidden_states)\u001B[0m\n\u001B[1;32m    649\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states):\n\u001B[1;32m    650\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate_dense(hidden_states)\n\u001B[0;32m--> 651\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mintermediate_act_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    652\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate_dropout(hidden_states)\n\u001B[1;32m    654\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_dense(hidden_states)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/activations.py:57\u001B[0m, in \u001B[0;36mGELUActivation.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mact\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(ct)\n",
    "trainer = ct.ModelTrainer(model=model, need_reshape=False, train_dataset=trainSet, eval_dataset=evalSet, device=device, batch_size=4, save_model_every=100, num_epochs=5001, model_path=\"../content/classifier/W2VClassifier/Nr2_fullDs/\", data_collator=data_collator, labelList=emo_dataset.label_list)\n",
    "gc.collect()\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 14:35:00.784088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 14:35:01.452112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-25 14:35:01.452175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-25 14:35:01.452179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from network_models.soundsream_models_and_utils.clip_like.encoder.ss_encoder_downmapping import EncoderDownmapping\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 8\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/encoder/clip_no_cafe/\"\n",
    "# epochs =200\n",
    "# save_every = 40\n",
    "# start_lr = 2e-6\n",
    "gc.collect()\n",
    "\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/ss_encs/allEncodings_v12_1_basic_no_cafe.pkl\", device=device)\n",
    "\n",
    "enc_model = EncoderDownmapping(embed_dim=512, n_heads=4, ff_dim=2, n_layers=1, dropout=0.2, output=1024, max_seq_len=175).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.834954  [    0/ 5156]\n",
      "loss: 1.905351  [ 1400/ 5156]\n",
      "loss: 1.664407  [ 2800/ 5156]\n",
      "loss: 1.805090  [ 4200/ 5156]\n",
      "685.2301576137543\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.488863  [    0/ 5156]\n",
      "loss: 1.985811  [ 1400/ 5156]\n",
      "loss: 1.815875  [ 2800/ 5156]\n",
      "loss: 1.512536  [ 4200/ 5156]\n",
      "654.6781507730484\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.599014  [    0/ 5156]\n",
      "loss: 1.448031  [ 1400/ 5156]\n",
      "loss: 1.725785  [ 2800/ 5156]\n",
      "loss: 1.713914  [ 4200/ 5156]\n",
      "639.7306598424911\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.652514  [    0/ 5156]\n",
      "loss: 1.331454  [ 1400/ 5156]\n",
      "loss: 1.510826  [ 2800/ 5156]\n",
      "loss: 1.564602  [ 4200/ 5156]\n",
      "625.4605289697647\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.820543  [    0/ 5156]\n",
      "loss: 1.472909  [ 1400/ 5156]\n",
      "loss: 1.444741  [ 2800/ 5156]\n",
      "loss: 1.372090  [ 4200/ 5156]\n",
      "617.5720125436783\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.557454  [    0/ 5156]\n",
      "loss: 1.664058  [ 1400/ 5156]\n",
      "loss: 1.518547  [ 2800/ 5156]\n",
      "loss: 1.700667  [ 4200/ 5156]\n",
      "610.3059033155441\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.517442  [    0/ 5156]\n",
      "loss: 1.385963  [ 1400/ 5156]\n",
      "loss: 1.638349  [ 2800/ 5156]\n",
      "loss: 1.976042  [ 4200/ 5156]\n",
      "605.2697639465332\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.646947  [    0/ 5156]\n",
      "loss: 1.383713  [ 1400/ 5156]\n",
      "loss: 1.745345  [ 2800/ 5156]\n",
      "loss: 1.361911  [ 4200/ 5156]\n",
      "596.8187934160233\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.573274  [    0/ 5156]\n",
      "loss: 1.487299  [ 1400/ 5156]\n",
      "loss: 1.361336  [ 2800/ 5156]\n",
      "loss: 1.477125  [ 4200/ 5156]\n",
      "590.4088336229324\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.608636  [    0/ 5156]\n",
      "loss: 1.547524  [ 1400/ 5156]\n",
      "loss: 1.433749  [ 2800/ 5156]\n",
      "loss: 1.280278  [ 4200/ 5156]\n",
      "583.7884863615036\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.674450  [    0/ 5156]\n",
      "loss: 1.444949  [ 1400/ 5156]\n",
      "loss: 1.468156  [ 2800/ 5156]\n",
      "loss: 1.304255  [ 4200/ 5156]\n",
      "578.747273683548\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.663534  [    0/ 5156]\n",
      "loss: 1.454507  [ 1400/ 5156]\n",
      "loss: 1.316052  [ 2800/ 5156]\n",
      "loss: 1.490112  [ 4200/ 5156]\n",
      "573.7253082990646\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.472774  [    0/ 5156]\n",
      "loss: 1.528131  [ 1400/ 5156]\n",
      "loss: 1.390752  [ 2800/ 5156]\n",
      "loss: 1.322577  [ 4200/ 5156]\n",
      "571.4229205846786\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.273630  [    0/ 5156]\n",
      "loss: 1.376925  [ 1400/ 5156]\n",
      "loss: 1.298722  [ 2800/ 5156]\n",
      "loss: 1.279645  [ 4200/ 5156]\n",
      "567.7396898269653\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.377698  [    0/ 5156]\n",
      "loss: 1.344236  [ 1400/ 5156]\n",
      "loss: 1.420731  [ 2800/ 5156]\n",
      "loss: 1.248177  [ 4200/ 5156]\n",
      "562.5431329011917\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.473644  [    0/ 5156]\n",
      "loss: 1.238466  [ 1400/ 5156]\n",
      "loss: 1.337892  [ 2800/ 5156]\n",
      "loss: 1.407280  [ 4200/ 5156]\n",
      "562.6785310506821\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.500761  [    0/ 5156]\n",
      "loss: 1.288574  [ 1400/ 5156]\n",
      "loss: 1.338130  [ 2800/ 5156]\n",
      "loss: 1.410618  [ 4200/ 5156]\n",
      "555.5593764781952\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.330192  [    0/ 5156]\n",
      "loss: 1.435344  [ 1400/ 5156]\n",
      "loss: 1.401695  [ 2800/ 5156]\n",
      "loss: 1.297905  [ 4200/ 5156]\n",
      "553.7590341567993\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.331710  [    0/ 5156]\n",
      "loss: 1.331001  [ 1400/ 5156]\n",
      "loss: 1.306183  [ 2800/ 5156]\n",
      "loss: 1.219111  [ 4200/ 5156]\n",
      "549.7624262571335\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.346347  [    0/ 5156]\n",
      "loss: 1.281808  [ 1400/ 5156]\n",
      "loss: 1.259265  [ 2800/ 5156]\n",
      "loss: 1.263341  [ 4200/ 5156]\n",
      "547.6129461526871\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.518290  [    0/ 5156]\n",
      "loss: 1.414455  [ 1400/ 5156]\n",
      "loss: 1.400338  [ 2800/ 5156]\n",
      "loss: 1.355167  [ 4200/ 5156]\n",
      "544.6452150344849\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.468177  [    0/ 5156]\n",
      "loss: 1.345064  [ 1400/ 5156]\n",
      "loss: 1.311236  [ 2800/ 5156]\n",
      "loss: 1.373844  [ 4200/ 5156]\n",
      "541.4703719615936\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.391249  [    0/ 5156]\n",
      "loss: 1.424588  [ 1400/ 5156]\n",
      "loss: 1.292202  [ 2800/ 5156]\n",
      "loss: 1.279062  [ 4200/ 5156]\n",
      "536.2082766294479\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.323838  [    0/ 5156]\n",
      "loss: 1.627698  [ 1400/ 5156]\n",
      "loss: 1.301162  [ 2800/ 5156]\n",
      "loss: 1.319865  [ 4200/ 5156]\n",
      "535.5831114053726\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.331017  [    0/ 5156]\n",
      "loss: 1.401913  [ 1400/ 5156]\n",
      "loss: 1.315975  [ 2800/ 5156]\n",
      "loss: 1.386285  [ 4200/ 5156]\n",
      "532.343670129776\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.207921  [    0/ 5156]\n",
      "loss: 1.370463  [ 1400/ 5156]\n",
      "loss: 1.555625  [ 2800/ 5156]\n",
      "loss: 1.306823  [ 4200/ 5156]\n",
      "530.029804110527\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.399024  [    0/ 5156]\n",
      "loss: 1.320258  [ 1400/ 5156]\n",
      "loss: 1.202621  [ 2800/ 5156]\n",
      "loss: 1.205407  [ 4200/ 5156]\n",
      "527.9899599552155\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.412020  [    0/ 5156]\n",
      "loss: 1.301317  [ 1400/ 5156]\n",
      "loss: 1.509672  [ 2800/ 5156]\n",
      "loss: 1.346337  [ 4200/ 5156]\n",
      "525.5328714847565\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.402368  [    0/ 5156]\n",
      "loss: 1.382055  [ 1400/ 5156]\n",
      "loss: 1.361710  [ 2800/ 5156]\n",
      "loss: 1.419451  [ 4200/ 5156]\n",
      "524.1702939271927\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.320558  [    0/ 5156]\n",
      "loss: 1.304823  [ 1400/ 5156]\n",
      "loss: 1.312234  [ 2800/ 5156]\n",
      "loss: 1.319352  [ 4200/ 5156]\n",
      "521.6153192520142\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.282773  [    0/ 5156]\n",
      "loss: 1.375257  [ 1400/ 5156]\n",
      "loss: 1.245733  [ 2800/ 5156]\n",
      "loss: 1.370142  [ 4200/ 5156]\n",
      "517.5801388025284\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.343297  [    0/ 5156]\n",
      "loss: 1.351487  [ 1400/ 5156]\n",
      "loss: 1.222331  [ 2800/ 5156]\n",
      "loss: 1.309027  [ 4200/ 5156]\n",
      "515.4814841747284\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.247707  [    0/ 5156]\n",
      "loss: 1.253514  [ 1400/ 5156]\n",
      "loss: 1.203141  [ 2800/ 5156]\n",
      "loss: 1.208097  [ 4200/ 5156]\n",
      "514.3361303806305\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.392234  [    0/ 5156]\n",
      "loss: 1.279193  [ 1400/ 5156]\n",
      "loss: 1.403568  [ 2800/ 5156]\n",
      "loss: 1.308331  [ 4200/ 5156]\n",
      "513.5852612257004\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.277749  [    0/ 5156]\n",
      "loss: 1.261241  [ 1400/ 5156]\n",
      "loss: 1.345601  [ 2800/ 5156]\n",
      "loss: 1.165126  [ 4200/ 5156]\n",
      "512.4980223178864\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.293561  [    0/ 5156]\n",
      "loss: 1.214567  [ 1400/ 5156]\n",
      "loss: 1.251546  [ 2800/ 5156]\n",
      "loss: 1.226983  [ 4200/ 5156]\n",
      "507.6429822444916\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.266789  [    0/ 5156]\n",
      "loss: 1.361892  [ 1400/ 5156]\n",
      "loss: 1.314626  [ 2800/ 5156]\n",
      "loss: 1.290142  [ 4200/ 5156]\n",
      "506.46909511089325\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.317148  [    0/ 5156]\n",
      "loss: 1.397411  [ 1400/ 5156]\n",
      "loss: 1.247843  [ 2800/ 5156]\n",
      "loss: 1.328822  [ 4200/ 5156]\n",
      "506.13236236572266\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.304183  [    0/ 5156]\n",
      "loss: 1.222084  [ 1400/ 5156]\n",
      "loss: 1.289728  [ 2800/ 5156]\n",
      "loss: 1.269758  [ 4200/ 5156]\n",
      "505.5296025276184\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.294817  [    0/ 5156]\n",
      "loss: 1.345021  [ 1400/ 5156]\n",
      "loss: 1.258117  [ 2800/ 5156]\n",
      "loss: 1.272870  [ 4200/ 5156]\n",
      "502.00511491298676\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.247348  [    0/ 5156]\n",
      "loss: 1.185902  [ 1400/ 5156]\n",
      "loss: 1.287459  [ 2800/ 5156]\n",
      "loss: 1.351396  [ 4200/ 5156]\n",
      "503.27938199043274\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.208500  [    0/ 5156]\n",
      "loss: 1.172718  [ 1400/ 5156]\n",
      "loss: 1.322515  [ 2800/ 5156]\n",
      "loss: 1.241411  [ 4200/ 5156]\n",
      "501.5019738674164\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.223907  [    0/ 5156]\n",
      "loss: 1.318764  [ 1400/ 5156]\n",
      "loss: 1.432644  [ 2800/ 5156]\n",
      "loss: 1.225196  [ 4200/ 5156]\n",
      "497.8440650701523\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.285275  [    0/ 5156]\n",
      "loss: 1.249632  [ 1400/ 5156]\n",
      "loss: 1.239884  [ 2800/ 5156]\n",
      "loss: 1.246512  [ 4200/ 5156]\n",
      "496.39145016670227\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.401937  [    0/ 5156]\n",
      "loss: 1.217012  [ 1400/ 5156]\n",
      "loss: 1.303456  [ 2800/ 5156]\n",
      "loss: 1.280883  [ 4200/ 5156]\n",
      "496.8182783126831\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.249800  [    0/ 5156]\n",
      "loss: 1.276746  [ 1400/ 5156]\n",
      "loss: 1.233522  [ 2800/ 5156]\n",
      "loss: 1.193543  [ 4200/ 5156]\n",
      "493.58672881126404\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.301176  [    0/ 5156]\n",
      "loss: 1.236678  [ 1400/ 5156]\n",
      "loss: 1.276943  [ 2800/ 5156]\n",
      "loss: 1.319974  [ 4200/ 5156]\n",
      "493.19282698631287\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.410144  [    0/ 5156]\n",
      "loss: 1.241032  [ 1400/ 5156]\n",
      "loss: 1.183990  [ 2800/ 5156]\n",
      "loss: 1.322171  [ 4200/ 5156]\n",
      "490.3592835664749\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.156139  [    0/ 5156]\n",
      "loss: 1.377433  [ 1400/ 5156]\n",
      "loss: 1.256531  [ 2800/ 5156]\n",
      "loss: 1.228900  [ 4200/ 5156]\n",
      "492.9344938993454\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.210083  [    0/ 5156]\n",
      "loss: 1.274708  [ 1400/ 5156]\n",
      "loss: 1.218204  [ 2800/ 5156]\n",
      "loss: 1.232363  [ 4200/ 5156]\n",
      "487.5039585828781\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.194921  [    0/ 5156]\n",
      "loss: 1.198835  [ 1400/ 5156]\n",
      "loss: 1.285430  [ 2800/ 5156]\n",
      "loss: 1.216314  [ 4200/ 5156]\n",
      "489.9690296649933\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.301501  [    0/ 5156]\n",
      "loss: 1.202559  [ 1400/ 5156]\n",
      "loss: 1.212406  [ 2800/ 5156]\n",
      "loss: 1.242925  [ 4200/ 5156]\n",
      "487.7396425008774\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 1.306299  [    0/ 5156]\n",
      "loss: 1.206514  [ 1400/ 5156]\n",
      "loss: 1.195524  [ 2800/ 5156]\n",
      "loss: 1.280266  [ 4200/ 5156]\n",
      "485.00519347190857\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.199355  [    0/ 5156]\n",
      "loss: 1.270626  [ 1400/ 5156]\n",
      "loss: 1.257934  [ 2800/ 5156]\n",
      "loss: 1.181141  [ 4200/ 5156]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_models_and_utils/encoder\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import network_models.soundsream_models_and_utils.clip_like.encoder.ss_encoder_trainer as sset\n",
    "import network_models.soundsream_models_and_utils.clip_like.mapping_down.ss_driect_dm_trainer as sddt\n",
    "\n",
    "epochs =1801\n",
    "save_every = 200\n",
    "start_lr = 1e-5\n",
    "\n",
    "#enc_trainer = sset.SSEncoderTrainer(batch_size=batch_size, num_epochs=epochs, model_path=models_dir, save_model_every=save_every, lr=start_lr, dataset=data_set, device=device, model=enc_model)\n",
    "enc_trainer = sddt.SSDirectDMTrainer(batch_size=batch_size, num_epochs=epochs, model_path=models_dir, save_model_every=save_every, lr=start_lr, dataset=data_set, device=device, model=enc_model, is_encoder=True)\n",
    "gc.collect()\n",
    "enc_trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

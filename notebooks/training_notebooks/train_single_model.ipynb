{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_model_conv import SSConvModel3Sec\n",
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import SSDimRedModel, SmallDimRed\n",
    "from network_models.soundsream_models_and_utils.ss_complex_conv_net import SSComplexConvModel3Sec\n",
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 12\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/mfcc/experiments/3_5_sec_dimred/Nr1/\"\n",
    "#models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/3_5_sec_dimred/Nr1/\"\n",
    "trials_per_model_type = 2\n",
    "epochs = 1000\n",
    "save_highest_acc_min_acc = 0.5\n",
    "save_model_every = 50\n",
    "lr = 1e-4\n",
    "lr_quotient = 2\n",
    "gc.collect()\n",
    "#data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncs_betterSS_12_1_relwrap_music_tess.pkl\", device=\"cuda\")\n",
    "data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks_clip/content/datasets/mfcc/mfcc_dataset_3_5_sec.pkl\", device=device)\n",
    "#data_set= ss_encoded_dataset_full(csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks_clip/content/datasets/soundstream_encoded/allEncodings_noInducednoStimuli_3_5_sec_v12_1_basic.pkl\", device=device)\n",
    "\n",
    "\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.2, seed=100)\n",
    "testDs, valDs = train_val_dataset(testDs, val_split=0.5, seed=100)\n",
    "torch.manual_seed(33333)\n",
    "#model = SSComplexConvModel3Sec().to(device)\n",
    "model = SmallDimRed(x_size=110).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_trainer_gen_models import SSGenModelTrainer\n",
    "\n",
    "trainer = SSGenModelTrainer(lr=lr, num_epochs=epochs, model=model, train_dataset=trainDS,\n",
    "                            eval_dataset=valDs,\n",
    "                            device=device, labelList=data_set.encoded_dataset.label_list,\n",
    "                            batch_size=batch_size,\n",
    "                            save_model_every=save_model_every,\n",
    "                            save_highest_acc_min_acc=save_highest_acc_min_acc,\n",
    "                            model_path = models_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.995284  [ 1200/ 4933]\n",
      "loss: 1.884744  [ 2400/ 4933]\n",
      "loss: 1.952392  [ 3600/ 4933]\n",
      "loss: 1.917071  [ 4800/ 4933]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.168     0.203     0.390    82\n",
      " disgust     0.168     0.000     0.000    87\n",
      "    fear     0.168     0.164     0.102    88\n",
      "   happy     0.168     0.152     0.562    89\n",
      " neutral     0.168     0.000     0.000    52\n",
      "     sad     0.168     0.143     0.011    90\n",
      "surprise     0.168     0.000     0.000    61\n",
      "                                          549\n",
      "\n",
      " \n",
      "     avg     0.168     0.094     0.152    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 16.8%, Avg loss: 1.890252 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.868779  [ 1200/ 4933]\n",
      "loss: 1.900339  [ 2400/ 4933]\n",
      "loss: 1.980956  [ 3600/ 4933]\n",
      "loss: 2.020185  [ 4800/ 4933]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import SSDimRedModel, SmallDimRed\n",
    "model = SmallDimRed(x_size=110)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Module.parameters of SmallDimRed(\n  (base_linear1): Linear(in_features=300, out_features=100, bias=True)\n  (base_linear2): Linear(in_features=100, out_features=4, bias=True)\n  (base_linear3): Linear(in_features=4, out_features=4, bias=True)\n  (base_linear4): Linear(in_features=4, out_features=7, bias=True)\n  (dropouts): Dropout(p=0.2, inplace=False)\n  (linear1): Linear(in_features=110, out_features=500, bias=True)\n  (linear2): Linear(in_features=500, out_features=300, bias=True)\n)>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

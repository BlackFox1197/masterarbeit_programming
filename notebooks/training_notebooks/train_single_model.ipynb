{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 17:30:11.004515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 17:30:11.546996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 17:30:11.547055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 17:30:11.547059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_model_dim_red import SSDimRedModel\n",
    "from network_models.soundsream_models_and_utils.ss_complex_conv_net import SSComplexConvModel3Sec\n",
    "from utils.audio_dataset_utils import train_val_dataset\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 12\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/\"\n",
    "trials_per_model_type = 2\n",
    "epochs = 1000\n",
    "save_highest_acc_min_acc = 0.5\n",
    "save_model_every = 50\n",
    "lr = 1e-4\n",
    "lr_quotient = 2\n",
    "gc.collect()\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncs_betterSS_12_1_relwrap_music_tess.pkl\", device=\"cuda\")\n",
    "\n",
    "\n",
    "trainDS, testDs = train_val_dataset(data_set, val_split=0.1, seed=100)\n",
    "trainDS, valDs = train_val_dataset(trainDS, val_split=0.1, seed=100)\n",
    "torch.manual_seed(33333)\n",
    "#model = SSComplexConvModel3Sec().to(device)\n",
    "model = SSDimRedModel().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from network_models.soundsream_models_and_utils.ss_trainer_gen_models import SSGenModelTrainer\n",
    "\n",
    "trainer = SSGenModelTrainer(lr=lr, num_epochs=epochs, model=model, train_dataset=trainDS,\n",
    "                            eval_dataset=valDs,\n",
    "                            device=device, labelList=data_set.encoded_dataset.label_list,\n",
    "                            batch_size=batch_size,\n",
    "                            save_model_every=save_model_every,\n",
    "                            save_highest_acc_min_acc=save_highest_acc_min_acc,\n",
    "                            model_path = models_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.041879  [    0/ 2233]\n",
      "loss: 1.909815  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.970900 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.947083  [    0/ 2233]\n",
      "loss: 1.943003  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.965771 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.967044  [    0/ 2233]\n",
      "loss: 1.960515  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.962788 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.917559  [    0/ 2233]\n",
      "loss: 1.952108  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.959958 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.912613  [    0/ 2233]\n",
      "loss: 1.985244  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.959477 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.943137  [    0/ 2233]\n",
      "loss: 1.888157  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.957467 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.975787  [    0/ 2233]\n",
      "loss: 1.945658  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.955660 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.948374  [    0/ 2233]\n",
      "loss: 1.970105  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.954280 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.939930  [    0/ 2233]\n",
      "loss: 1.959107  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.953721 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.932246  [    0/ 2233]\n",
      "loss: 1.968067  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.952895 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.941533  [    0/ 2233]\n",
      "loss: 1.934615  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.100     0.100     1.000    25\n",
      " disgust     0.100     0.000     0.000    36\n",
      "    fear     0.100     0.000     0.000    34\n",
      "   happy     0.100     0.000     0.000    36\n",
      " neutral     0.100     0.000     0.000    46\n",
      "     sad     0.100     0.000     0.000    31\n",
      "surprise     0.100     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.100     0.014     0.143    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 1.953638 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.940178  [    0/ 2233]\n",
      "loss: 1.952087  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.277     0.275     1.000    25\n",
      " disgust     0.277     0.000     0.000    36\n",
      "    fear     0.277     0.000     0.000    34\n",
      "   happy     0.277     0.929     0.361    36\n",
      " neutral     0.277     0.000     0.000    46\n",
      "     sad     0.277     0.215     1.000    31\n",
      "surprise     0.277     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.277     0.203     0.337    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 27.7%, Avg loss: 1.902149 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.863678  [    0/ 2233]\n",
      "loss: 1.873046  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.277     0.179     0.840    25\n",
      " disgust     0.277     0.000     0.000    36\n",
      "    fear     0.277     0.000     0.000    34\n",
      "   happy     0.277     0.680     0.472    36\n",
      " neutral     0.277     0.000     0.000    46\n",
      "     sad     0.277     0.290     1.000    31\n",
      "surprise     0.277     0.000     0.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.277     0.164     0.330    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 27.7%, Avg loss: 1.832604 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.914235  [    0/ 2233]\n",
      "loss: 1.686483  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.349     0.222     0.960    25\n",
      " disgust     0.349     0.000     0.000    36\n",
      "    fear     0.349     0.000     0.000    34\n",
      "   happy     0.349     0.739     0.472    36\n",
      " neutral     0.349     0.000     0.000    46\n",
      "     sad     0.349     0.483     0.935    31\n",
      "surprise     0.349     0.293     0.415    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.349     0.248     0.397    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 1.782243 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.859165  [    0/ 2233]\n",
      "loss: 1.646434  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.382     0.308     0.960    25\n",
      " disgust     0.382     0.000     0.000    36\n",
      "    fear     0.382     0.000     0.000    34\n",
      "   happy     0.382     0.667     0.500    36\n",
      " neutral     0.382     0.000     0.000    46\n",
      "     sad     0.382     0.405     0.968    31\n",
      "surprise     0.382     0.348     0.561    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.382     0.247     0.427    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 38.2%, Avg loss: 1.738829 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.751090  [    0/ 2233]\n",
      "loss: 1.728960  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.410     0.299     0.920    25\n",
      " disgust     0.410     0.000     0.000    36\n",
      "    fear     0.410     0.000     0.000    34\n",
      "   happy     0.410     0.679     0.528    36\n",
      " neutral     0.410     0.000     0.000    46\n",
      "     sad     0.410     0.547     0.935    31\n",
      "surprise     0.410     0.341     0.756    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.410     0.266     0.448    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 1.728344 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.683980  [    0/ 2233]\n",
      "loss: 1.699026  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.410     0.315     0.920    25\n",
      " disgust     0.410     0.000     0.000    36\n",
      "    fear     0.410     0.000     0.000    34\n",
      "   happy     0.410     0.654     0.472    36\n",
      " neutral     0.410     0.000     0.000    46\n",
      "     sad     0.410     0.453     0.935    31\n",
      "surprise     0.410     0.384     0.805    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.410     0.258     0.448    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 1.679977 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.649864  [    0/ 2233]\n",
      "loss: 1.604448  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.414     0.403     1.000    25\n",
      " disgust     0.414     0.500     0.028    36\n",
      "    fear     0.414     0.000     0.000    34\n",
      "   happy     0.414     0.692     0.500    36\n",
      " neutral     0.414     0.000     0.000    46\n",
      "     sad     0.414     0.390     0.968    31\n",
      "surprise     0.414     0.358     0.707    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.414     0.335     0.458    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 1.631283 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.695788  [    0/ 2233]\n",
      "loss: 1.609229  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.426     0.391     1.000    25\n",
      " disgust     0.426     0.500     0.028    36\n",
      "    fear     0.426     0.000     0.000    34\n",
      "   happy     0.426     0.643     0.500    36\n",
      " neutral     0.426     0.000     0.000    46\n",
      "     sad     0.426     0.491     0.903    31\n",
      "surprise     0.426     0.347     0.829    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.426     0.339     0.466    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.6%, Avg loss: 1.615855 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.674942  [    0/ 2233]\n",
      "loss: 1.760889  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.414     0.463     1.000    25\n",
      " disgust     0.414     0.000     0.000    36\n",
      "    fear     0.414     0.000     0.000    34\n",
      "   happy     0.414     0.850     0.472    36\n",
      " neutral     0.414     0.000     0.000    46\n",
      "     sad     0.414     0.330     1.000    31\n",
      "surprise     0.414     0.370     0.732    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.414     0.288     0.458    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 1.587530 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.578984  [    0/ 2233]\n",
      "loss: 1.731996  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.454     0.500     1.000    25\n",
      " disgust     0.454     0.500     0.056    36\n",
      "    fear     0.454     0.000     0.000    34\n",
      "   happy     0.454     0.607     0.472    36\n",
      " neutral     0.454     0.000     0.000    46\n",
      "     sad     0.454     0.446     0.935    31\n",
      "surprise     0.454     0.392     0.976    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.454     0.349     0.491    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.531301 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.371050  [    0/ 2233]\n",
      "loss: 1.591251  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.414     0.455     1.000    25\n",
      " disgust     0.414     0.000     0.000    36\n",
      "    fear     0.414     0.000     0.000    34\n",
      "   happy     0.414     0.810     0.472    36\n",
      " neutral     0.414     0.000     0.000    46\n",
      "     sad     0.414     0.326     1.000    31\n",
      "surprise     0.414     0.390     0.732    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.414     0.283     0.458    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 1.525909 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.290098  [    0/ 2233]\n",
      "loss: 1.392036  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.422     0.455     1.000    25\n",
      " disgust     0.422     0.000     0.000    36\n",
      "    fear     0.422     0.000     0.000    34\n",
      "   happy     0.422     0.818     0.500    36\n",
      " neutral     0.422     0.000     0.000    46\n",
      "     sad     0.422     0.320     1.000    31\n",
      "surprise     0.422     0.425     0.756    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.422     0.288     0.465    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.2%, Avg loss: 1.495799 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.441342  [    0/ 2233]\n",
      "loss: 1.470453  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.454     0.439     1.000    25\n",
      " disgust     0.454     0.500     0.028    36\n",
      "    fear     0.454     0.000     0.000    34\n",
      "   happy     0.454     0.944     0.472    36\n",
      " neutral     0.454     0.000     0.000    46\n",
      "     sad     0.454     0.537     0.935    31\n",
      "surprise     0.454     0.347     1.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.454     0.395     0.491    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.479085 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.352391  [    0/ 2233]\n",
      "loss: 1.431283  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.418     0.431     1.000    25\n",
      " disgust     0.418     0.000     0.000    36\n",
      "    fear     0.418     0.000     0.000    34\n",
      "   happy     0.418     0.895     0.472    36\n",
      " neutral     0.418     0.000     0.000    46\n",
      "     sad     0.418     0.341     1.000    31\n",
      "surprise     0.418     0.383     0.756    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.418     0.293     0.461    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.8%, Avg loss: 1.425611 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.365544  [    0/ 2233]\n",
      "loss: 1.510677  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.434     0.439     1.000    25\n",
      " disgust     0.434     0.000     0.000    36\n",
      "    fear     0.434     0.000     0.000    34\n",
      "   happy     0.434     0.850     0.472    36\n",
      " neutral     0.434     0.000     0.000    46\n",
      "     sad     0.434     0.348     1.000    31\n",
      "surprise     0.434     0.427     0.854    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.434     0.295     0.475    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 1.388187 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.402586  [    0/ 2233]\n",
      "loss: 1.439670  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.462     0.455     1.000    25\n",
      " disgust     0.462     1.000     0.056    36\n",
      "    fear     0.462     0.000     0.000    34\n",
      "   happy     0.462     0.810     0.472    36\n",
      " neutral     0.462     0.000     0.000    46\n",
      "     sad     0.462     0.408     1.000    31\n",
      "surprise     0.462     0.421     0.976    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.462     0.442     0.500    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.358053 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.290800  [    0/ 2233]\n",
      "loss: 1.813535  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.442     0.455     1.000    25\n",
      " disgust     0.442     1.000     0.028    36\n",
      "    fear     0.442     0.000     0.000    34\n",
      "   happy     0.442     0.692     0.500    36\n",
      " neutral     0.442     0.000     0.000    46\n",
      "     sad     0.442     0.574     0.871    31\n",
      "surprise     0.442     0.328     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.442     0.436     0.479    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.442599 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.567548  [    0/ 2233]\n",
      "loss: 1.231764  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.446     0.500     1.000    25\n",
      " disgust     0.446     1.000     0.028    36\n",
      "    fear     0.446     0.000     0.000    34\n",
      "   happy     0.446     0.581     0.500    36\n",
      " neutral     0.446     0.000     0.000    46\n",
      "     sad     0.446     0.408     1.000    31\n",
      "surprise     0.446     0.396     0.878    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.446     0.412     0.487    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 1.335552 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.348002  [    0/ 2233]\n",
      "loss: 1.177594  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.446     0.500     1.000    25\n",
      " disgust     0.446     0.000     0.000    36\n",
      "    fear     0.446     1.000     0.029    34\n",
      "   happy     0.446     0.692     0.500    36\n",
      " neutral     0.446     0.000     0.000    46\n",
      "     sad     0.446     0.365     1.000    31\n",
      "surprise     0.446     0.419     0.878    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.446     0.425     0.487    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 1.307432 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.220042  [    0/ 2233]\n",
      "loss: 1.393977  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.454     0.463     1.000    25\n",
      " disgust     0.454     1.000     0.056    36\n",
      "    fear     0.454     1.000     0.029    34\n",
      "   happy     0.454     0.810     0.472    36\n",
      " neutral     0.454     0.000     0.000    46\n",
      "     sad     0.454     0.365     1.000    31\n",
      "surprise     0.454     0.430     0.902    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.454     0.581     0.494    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.293497 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.229408  [    0/ 2233]\n",
      "loss: 1.269389  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.357     0.373     1.000    25\n",
      " disgust     0.357     0.000     0.000    36\n",
      "    fear     0.357     0.000     0.000    34\n",
      "   happy     0.357     0.864     0.528    36\n",
      " neutral     0.357     0.000     0.000    46\n",
      "     sad     0.357     0.284     1.000    31\n",
      "surprise     0.357     0.275     0.341    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.357     0.257     0.410    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 1.402689 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.200968  [    0/ 2233]\n",
      "loss: 1.118097  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.454     0.362     1.000    25\n",
      " disgust     0.454     1.000     0.056    36\n",
      "    fear     0.454     1.000     0.088    34\n",
      "   happy     0.454     0.857     0.667    36\n",
      " neutral     0.454     0.000     0.000    46\n",
      "     sad     0.454     0.441     0.968    31\n",
      "surprise     0.454     0.372     0.707    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.454     0.576     0.498    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.323706 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.480775  [    0/ 2233]\n",
      "loss: 1.287867  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.438     0.439     1.000    25\n",
      " disgust     0.438     0.000     0.000    36\n",
      "    fear     0.438     0.000     0.000    34\n",
      "   happy     0.438     0.857     0.500    36\n",
      " neutral     0.438     0.000     0.000    46\n",
      "     sad     0.438     0.360     1.000    31\n",
      "surprise     0.438     0.422     0.854    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.438     0.297     0.479    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.244131 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.313251  [    0/ 2233]\n",
      "loss: 1.218004  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.458     0.431     1.000    25\n",
      " disgust     0.458     0.400     0.056    36\n",
      "    fear     0.458     0.000     0.000    34\n",
      "   happy     0.458     0.944     0.472    36\n",
      " neutral     0.458     0.000     0.000    46\n",
      "     sad     0.458     0.437     1.000    31\n",
      "surprise     0.458     0.402     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.458     0.373     0.497    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 1.222868 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.214854  [    0/ 2233]\n",
      "loss: 1.240209  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.486     0.439     1.000    25\n",
      " disgust     0.486     0.750     0.083    36\n",
      "    fear     0.486     1.000     0.029    34\n",
      "   happy     0.486     0.957     0.611    36\n",
      " neutral     0.486     0.000     0.000    46\n",
      "     sad     0.486     0.425     1.000    31\n",
      "surprise     0.486     0.429     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.486     0.571     0.525    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 1.189113 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.162866  [    0/ 2233]\n",
      "loss: 1.209190  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.490     0.391     1.000    25\n",
      " disgust     0.490     0.500     0.028    36\n",
      "    fear     0.490     0.000     0.000    34\n",
      "   happy     0.490     0.903     0.778    36\n",
      " neutral     0.490     0.000     0.000    46\n",
      "     sad     0.490     0.508     0.968    31\n",
      "surprise     0.490     0.418     0.927    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.490     0.389     0.529    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.187947 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.081679  [    0/ 2233]\n",
      "loss: 1.247982  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.462     0.424     1.000    25\n",
      " disgust     0.462     0.625     0.139    36\n",
      "    fear     0.462     0.000     0.000    34\n",
      "   happy     0.462     0.913     0.583    36\n",
      " neutral     0.462     0.000     0.000    46\n",
      "     sad     0.462     0.373     1.000    31\n",
      "surprise     0.462     0.434     0.805    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.462     0.396     0.504    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.188355 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.072093  [    0/ 2233]\n",
      "loss: 1.215272  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.470     0.431     1.000    25\n",
      " disgust     0.470     0.500     0.111    36\n",
      "    fear     0.470     1.000     0.029    34\n",
      "   happy     0.470     1.000     0.528    36\n",
      " neutral     0.470     0.000     0.000    46\n",
      "     sad     0.470     0.397     1.000    31\n",
      "surprise     0.470     0.435     0.902    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.470     0.538     0.510    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.150690 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.175530  [    0/ 2233]\n",
      "loss: 1.283607  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.490     0.417     1.000    25\n",
      " disgust     0.490     0.667     0.222    36\n",
      "    fear     0.490     0.250     0.029    34\n",
      "   happy     0.490     1.000     0.639    36\n",
      " neutral     0.490     0.000     0.000    46\n",
      "     sad     0.490     0.456     1.000    31\n",
      "surprise     0.490     0.425     0.829    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.490     0.459     0.531    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.159079 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.022818  [    0/ 2233]\n",
      "loss: 1.136328  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.458     0.439     1.000    25\n",
      " disgust     0.458     0.000     0.000    36\n",
      "    fear     0.458     1.000     0.029    34\n",
      "   happy     0.458     0.931     0.750    36\n",
      " neutral     0.458     0.000     0.000    46\n",
      "     sad     0.458     0.383     1.000    31\n",
      "surprise     0.458     0.405     0.732    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.458     0.451     0.502    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 1.167432 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.140997  [    0/ 2233]\n",
      "loss: 1.512891  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.472     1.000    25\n",
      " disgust     0.534     0.800     0.111    36\n",
      "    fear     0.534     0.800     0.118    34\n",
      "   happy     0.534     0.791     0.944    36\n",
      " neutral     0.534     0.000     0.000    46\n",
      "     sad     0.534     0.528     0.903    31\n",
      "surprise     0.534     0.432     0.927    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.534     0.546     0.572    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.097236 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep41_acc_53.md \n",
      "\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep41_acc_53\"!  new accuracy: 53.4\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.964024  [    0/ 2233]\n",
      "loss: 0.998229  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.510     0.424     1.000    25\n",
      " disgust     0.510     0.833     0.139    36\n",
      "    fear     0.510     1.000     0.029    34\n",
      "   happy     0.510     0.900     0.750    36\n",
      " neutral     0.510     0.000     0.000    46\n",
      "     sad     0.510     0.556     0.968    31\n",
      "surprise     0.510     0.402     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.510     0.588     0.548    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.080370 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.078731  [    0/ 2233]\n",
      "loss: 1.236548  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.530     0.403     1.000    25\n",
      " disgust     0.530     0.875     0.194    36\n",
      "    fear     0.530     0.000     0.000    34\n",
      "   happy     0.530     0.825     0.917    36\n",
      " neutral     0.530     0.000     0.000    46\n",
      "     sad     0.530     0.583     0.903    31\n",
      "surprise     0.530     0.429     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.530     0.445     0.567    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.091471 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.093098  [    0/ 2233]\n",
      "loss: 1.190226  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.522     0.431     1.000    25\n",
      " disgust     0.522     0.600     0.167    36\n",
      "    fear     0.522     1.000     0.029    34\n",
      "   happy     0.522     0.838     0.861    36\n",
      " neutral     0.522     0.000     0.000    46\n",
      "     sad     0.522     0.508     1.000    31\n",
      "surprise     0.522     0.439     0.878    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.522     0.545     0.562    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.042333 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.015902  [    0/ 2233]\n",
      "loss: 0.952998  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.494     0.424     1.000    25\n",
      " disgust     0.494     0.556     0.139    36\n",
      "    fear     0.494     1.000     0.059    34\n",
      "   happy     0.494     0.733     0.917    36\n",
      " neutral     0.494     0.000     0.000    46\n",
      "     sad     0.494     0.492     0.968    31\n",
      "surprise     0.494     0.389     0.683    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.494     0.513     0.538    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.4%, Avg loss: 1.095922 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.941282  [    0/ 2233]\n",
      "loss: 0.768450  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.574     0.463     1.000    25\n",
      " disgust     0.574     0.810     0.472    36\n",
      "    fear     0.574     0.800     0.118    34\n",
      "   happy     0.574     0.805     0.917    36\n",
      " neutral     0.574     0.000     0.000    46\n",
      "     sad     0.574     0.743     0.839    31\n",
      "surprise     0.574     0.413     0.927    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.574     0.576     0.610    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 1.038625 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep46_acc_57.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep41_acc_53\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep46_acc_57\"! Old accuracy: 53.4, new accuracy: 57.4\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.905046  [    0/ 2233]\n",
      "loss: 0.945279  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.534     0.424     1.000    25\n",
      " disgust     0.534     0.750     0.333    36\n",
      "    fear     0.534     1.000     0.029    34\n",
      "   happy     0.534     0.865     0.889    36\n",
      " neutral     0.534     0.000     0.000    46\n",
      "     sad     0.534     0.554     1.000    31\n",
      "surprise     0.534     0.421     0.780    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.534     0.573     0.576    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.018111 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.196535  [    0/ 2233]\n",
      "loss: 0.994305  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.598     0.410     1.000    25\n",
      " disgust     0.598     0.611     0.306    36\n",
      "    fear     0.598     0.000     0.000    34\n",
      "   happy     0.598     0.923     0.667    36\n",
      " neutral     0.598     0.645     0.870    46\n",
      "     sad     0.598     0.588     0.968    31\n",
      "surprise     0.598     0.679     0.463    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.598     0.551     0.610    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.002333 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep48_acc_60.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep46_acc_57\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep48_acc_60\"! Old accuracy: 57.4, new accuracy: 59.8\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.170669  [    0/ 2233]\n",
      "loss: 0.864361  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.627     0.431     1.000    25\n",
      " disgust     0.627     0.684     0.361    36\n",
      "    fear     0.627     0.000     0.000    34\n",
      "   happy     0.627     0.882     0.833    36\n",
      " neutral     0.627     0.639     0.848    46\n",
      "     sad     0.627     0.625     0.968    31\n",
      "surprise     0.627     0.679     0.463    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.627     0.563     0.639    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.996716 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep49_acc_63.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep48_acc_60\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep49_acc_63\"! Old accuracy: 59.8, new accuracy: 62.7\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.109413  [    0/ 2233]\n",
      "loss: 0.857451  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.582     0.429     0.960    25\n",
      " disgust     0.582     0.625     0.278    36\n",
      "    fear     0.582     0.500     0.029    34\n",
      "   happy     0.582     0.958     0.639    36\n",
      " neutral     0.582     0.603     0.957    46\n",
      "     sad     0.582     0.604     0.935    31\n",
      "surprise     0.582     0.467     0.341    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.582     0.598     0.591    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 1.021528 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.077039  [    0/ 2233]\n",
      "loss: 0.797235  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.594     0.462     0.960    25\n",
      " disgust     0.594     0.688     0.306    36\n",
      "    fear     0.594     0.500     0.029    34\n",
      "   happy     0.594     0.867     0.722    36\n",
      " neutral     0.594     0.583     0.913    46\n",
      "     sad     0.594     0.617     0.935    31\n",
      "surprise     0.594     0.500     0.366    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.594     0.602     0.605    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 1.006694 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.954407  [    0/ 2233]\n",
      "loss: 0.915704  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.639     0.446     1.000    25\n",
      " disgust     0.639     0.630     0.472    36\n",
      "    fear     0.639     1.000     0.088    34\n",
      "   happy     0.639     0.935     0.806    36\n",
      " neutral     0.639     0.690     0.870    46\n",
      "     sad     0.639     0.556     0.968    31\n",
      "surprise     0.639     0.750     0.366    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.639     0.715     0.653    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.006154 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep52_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep49_acc_63\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep52_acc_64\"! Old accuracy: 62.7, new accuracy: 63.9\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.792651  [    0/ 2233]\n",
      "loss: 1.103277  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.631     0.424     1.000    25\n",
      " disgust     0.631     0.700     0.389    36\n",
      "    fear     0.631     1.000     0.029    34\n",
      "   happy     0.631     0.912     0.861    36\n",
      " neutral     0.631     0.632     0.935    46\n",
      "     sad     0.631     0.596     1.000    31\n",
      "surprise     0.631     0.800     0.293    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.631     0.723     0.644    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.948498 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.803793  [    0/ 2233]\n",
      "loss: 0.892089  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.622     0.410     1.000    25\n",
      " disgust     0.622     0.636     0.194    36\n",
      "    fear     0.622     0.000     0.000    34\n",
      "   happy     0.622     0.810     0.944    36\n",
      " neutral     0.622     0.741     0.870    46\n",
      "     sad     0.622     0.545     0.968    31\n",
      "surprise     0.622     0.760     0.463    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.622     0.557     0.634    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 0.978983 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.905997  [    0/ 2233]\n",
      "loss: 0.854858  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.631     0.463     1.000    25\n",
      " disgust     0.631     0.529     0.250    36\n",
      "    fear     0.631     0.750     0.088    34\n",
      "   happy     0.631     0.838     0.861    36\n",
      " neutral     0.631     0.683     0.891    46\n",
      "     sad     0.631     0.556     0.968    31\n",
      "surprise     0.631     0.783     0.439    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.631     0.657     0.642    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.945304 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.693068  [    0/ 2233]\n",
      "loss: 0.955970  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.671     0.500     1.000    25\n",
      " disgust     0.671     0.769     0.556    36\n",
      "    fear     0.671     0.875     0.206    34\n",
      "   happy     0.671     0.897     0.722    36\n",
      " neutral     0.671     0.630     1.000    46\n",
      "     sad     0.671     0.800     0.903    31\n",
      "surprise     0.671     0.536     0.366    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.671     0.715     0.679    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 0.939843 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep56_acc_67.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep52_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep56_acc_67\"! Old accuracy: 63.9, new accuracy: 67.1\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.151570  [    0/ 2233]\n",
      "loss: 0.725170  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.679     0.510     1.000    25\n",
      " disgust     0.679     0.800     0.333    36\n",
      "    fear     0.679     0.833     0.294    34\n",
      "   happy     0.679     0.773     0.944    36\n",
      " neutral     0.679     0.702     0.870    46\n",
      "     sad     0.679     0.630     0.935    31\n",
      "surprise     0.679     0.731     0.463    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.679     0.711     0.691    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.925944 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep57_acc_68.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep56_acc_67\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep57_acc_68\"! Old accuracy: 67.1, new accuracy: 67.9\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 1.031128  [    0/ 2233]\n",
      "loss: 1.017978  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.663     0.568     1.000    25\n",
      " disgust     0.663     0.833     0.556    36\n",
      "    fear     0.663     1.000     0.382    34\n",
      "   happy     0.663     0.958     0.639    36\n",
      " neutral     0.663     0.570     0.978    46\n",
      "     sad     0.663     0.667     0.968    31\n",
      "surprise     0.663     0.450     0.220    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.663     0.721     0.677    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.901695 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.971342  [    0/ 2233]\n",
      "loss: 0.832031  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.795     0.962     1.000    25\n",
      " disgust     0.795     0.560     0.389    36\n",
      "    fear     0.795     0.971     0.971    34\n",
      "   happy     0.795     0.886     0.861    36\n",
      " neutral     0.795     0.820     0.891    46\n",
      "     sad     0.795     0.574     1.000    31\n",
      "surprise     0.795     0.920     0.561    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.795     0.813     0.810    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.923635 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep59_acc_80.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep57_acc_68\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep59_acc_80\"! Old accuracy: 67.9, new accuracy: 79.5\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.848064  [    0/ 2233]\n",
      "loss: 1.135966  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.823     0.962     1.000    25\n",
      " disgust     0.823     0.688     0.306    36\n",
      "    fear     0.823     1.000     0.971    34\n",
      "   happy     0.823     0.857     1.000    36\n",
      " neutral     0.823     0.840     0.913    46\n",
      "     sad     0.823     0.585     1.000    31\n",
      "surprise     0.823     0.931     0.659    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.823     0.837     0.835    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.879508 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep60_acc_82.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep59_acc_80\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep60_acc_82\"! Old accuracy: 79.5, new accuracy: 82.3\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.960093  [    0/ 2233]\n",
      "loss: 0.762641  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.811     0.893     1.000    25\n",
      " disgust     0.811     0.692     0.500    36\n",
      "    fear     0.811     0.969     0.912    34\n",
      "   happy     0.811     0.968     0.833    36\n",
      " neutral     0.811     0.867     0.848    46\n",
      "     sad     0.811     0.564     1.000    31\n",
      "surprise     0.811     0.875     0.683    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.811     0.832     0.825    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.931013 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.773221  [    0/ 2233]\n",
      "loss: 0.661379  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.835     1.000     1.000    25\n",
      " disgust     0.835     0.850     0.472    36\n",
      "    fear     0.835     0.971     0.971    34\n",
      "   happy     0.835     0.833     0.972    36\n",
      " neutral     0.835     0.796     0.935    46\n",
      "     sad     0.835     0.638     0.968    31\n",
      "surprise     0.835     0.926     0.610    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.835     0.859     0.847    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.855892 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep62_acc_84.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep60_acc_82\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep62_acc_84\"! Old accuracy: 82.3, new accuracy: 83.5\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.867698  [    0/ 2233]\n",
      "loss: 0.717529  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.871     1.000     0.960    25\n",
      " disgust     0.871     0.905     0.528    36\n",
      "    fear     0.871     0.941     0.941    34\n",
      "   happy     0.871     0.892     0.917    36\n",
      " neutral     0.871     0.860     0.935    46\n",
      "     sad     0.871     0.769     0.968    31\n",
      "surprise     0.871     0.818     0.878    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.871     0.884     0.875    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.858065 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep63_acc_87.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep62_acc_84\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep63_acc_87\"! Old accuracy: 83.5, new accuracy: 87.1\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.904536  [    0/ 2233]\n",
      "loss: 0.803774  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.876     1.000     1.000    25\n",
      " disgust     0.876     0.769     0.556    36\n",
      "    fear     0.876     0.971     1.000    34\n",
      "   happy     0.876     0.868     0.917    36\n",
      " neutral     0.876     0.933     0.913    46\n",
      "     sad     0.876     0.698     0.968    31\n",
      "surprise     0.876     0.919     0.829    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.876     0.880     0.883    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.838158 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep64_acc_88.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep63_acc_87\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep64_acc_88\"! Old accuracy: 87.1, new accuracy: 87.6\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.738151  [    0/ 2233]\n",
      "loss: 0.620621  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.835     1.000     1.000    25\n",
      " disgust     0.835     0.682     0.417    36\n",
      "    fear     0.835     0.970     0.941    34\n",
      "   happy     0.835     0.886     0.861    36\n",
      " neutral     0.835     0.875     0.913    46\n",
      "     sad     0.835     0.608     1.000    31\n",
      "surprise     0.835     0.914     0.780    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.835     0.848     0.845    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.848624 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 1.087885  [    0/ 2233]\n",
      "loss: 0.858177  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.867     0.926     1.000    25\n",
      " disgust     0.867     0.880     0.611    36\n",
      "    fear     0.867     0.971     1.000    34\n",
      "   happy     0.867     0.857     1.000    36\n",
      " neutral     0.867     0.889     0.870    46\n",
      "     sad     0.867     0.769     0.968    31\n",
      "surprise     0.867     0.806     0.707    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.867     0.871     0.879    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.849259 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.816265  [    0/ 2233]\n",
      "loss: 0.986697  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.871     1.000     1.000    25\n",
      " disgust     0.871     0.960     0.667    36\n",
      "    fear     0.871     0.919     1.000    34\n",
      "   happy     0.871     0.912     0.861    36\n",
      " neutral     0.871     0.780     1.000    46\n",
      "     sad     0.871     0.879     0.935    31\n",
      "surprise     0.871     0.778     0.683    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.871     0.890     0.878    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.795317 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.786966  [    0/ 2233]\n",
      "loss: 0.617059  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.900     1.000     1.000    25\n",
      " disgust     0.900     0.885     0.639    36\n",
      "    fear     0.900     0.943     0.971    34\n",
      "   happy     0.900     0.825     0.917    36\n",
      " neutral     0.900     0.977     0.935    46\n",
      "     sad     0.900     0.784     0.935    31\n",
      "surprise     0.900     0.905     0.927    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.900     0.903     0.903    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.799362 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep68_acc_90.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep64_acc_88\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep68_acc_90\"! Old accuracy: 87.6, new accuracy: 90.0\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.816130  [    0/ 2233]\n",
      "loss: 0.772229  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.839     1.000     1.000    25\n",
      " disgust     0.839     0.760     0.528    36\n",
      "    fear     0.839     0.971     0.971    34\n",
      "   happy     0.839     1.000     0.694    36\n",
      " neutral     0.839     0.830     0.957    46\n",
      "     sad     0.839     0.674     1.000    31\n",
      "surprise     0.839     0.780     0.780    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.839     0.859     0.847    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.773144 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.803673  [    0/ 2233]\n",
      "loss: 0.733028  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.851     1.000     1.000    25\n",
      " disgust     0.851     0.818     0.750    36\n",
      "    fear     0.851     0.971     1.000    34\n",
      "   happy     0.851     0.962     0.694    36\n",
      " neutral     0.851     0.754     1.000    46\n",
      "     sad     0.851     0.853     0.935    31\n",
      "surprise     0.851     0.743     0.634    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.851     0.872     0.859    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.749884 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.744362  [    0/ 2233]\n",
      "loss: 0.582901  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.892     1.000     1.000    25\n",
      " disgust     0.892     0.750     0.583    36\n",
      "    fear     0.892     1.000     1.000    34\n",
      "   happy     0.892     0.837     1.000    36\n",
      " neutral     0.892     1.000     0.957    46\n",
      "     sad     0.892     0.721     1.000    31\n",
      "surprise     0.892     0.969     0.756    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.892     0.897     0.899    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.766644 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.762943  [    0/ 2233]\n",
      "loss: 0.637785  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.876     1.000     1.000    25\n",
      " disgust     0.876     0.759     0.611    36\n",
      "    fear     0.876     0.919     1.000    34\n",
      "   happy     0.876     0.838     0.861    36\n",
      " neutral     0.876     0.956     0.935    46\n",
      "     sad     0.876     0.705     1.000    31\n",
      "surprise     0.876     1.000     0.780    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.876     0.882     0.884    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.770922 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.836370  [    0/ 2233]\n",
      "loss: 0.775262  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.892     1.000     0.960    25\n",
      " disgust     0.892     0.714     0.694    36\n",
      "    fear     0.892     1.000     0.941    34\n",
      "   happy     0.892     0.912     0.861    36\n",
      " neutral     0.892     0.957     0.978    46\n",
      "     sad     0.892     0.738     1.000    31\n",
      "surprise     0.892     0.971     0.829    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.892     0.899     0.895    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.720317 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.771091  [    0/ 2233]\n",
      "loss: 0.540221  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.884     0.862     1.000    25\n",
      " disgust     0.884     0.926     0.694    36\n",
      "    fear     0.884     0.805     0.971    34\n",
      "   happy     0.884     0.865     0.889    36\n",
      " neutral     0.884     0.956     0.935    46\n",
      "     sad     0.884     0.857     0.968    31\n",
      "surprise     0.884     0.914     0.780    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.884     0.884     0.891    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.775567 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.277113  [    0/ 2233]\n",
      "loss: 0.623607  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.892     0.962     1.000    25\n",
      " disgust     0.892     0.853     0.806    36\n",
      "    fear     0.892     0.971     0.971    34\n",
      "   happy     0.892     0.729     0.972    36\n",
      " neutral     0.892     0.977     0.913    46\n",
      "     sad     0.892     0.879     0.935    31\n",
      "surprise     0.892     0.935     0.707    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.892     0.901     0.901    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.778202 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.629063  [    0/ 2233]\n",
      "loss: 0.797565  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.916     1.000     0.960    25\n",
      " disgust     0.916     0.964     0.750    36\n",
      "    fear     0.916     0.968     0.882    34\n",
      "   happy     0.916     0.833     0.972    36\n",
      " neutral     0.916     0.938     0.978    46\n",
      "     sad     0.916     0.938     0.968    31\n",
      "surprise     0.916     0.841     0.902    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.916     0.926     0.916    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.672958 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep76_acc_92.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep68_acc_90\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep76_acc_92\"! Old accuracy: 90.0, new accuracy: 91.6\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.563926  [    0/ 2233]\n",
      "loss: 0.768934  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.876     1.000     1.000    25\n",
      " disgust     0.876     0.579     0.611    36\n",
      "    fear     0.876     1.000     0.971    34\n",
      "   happy     0.876     1.000     0.861    36\n",
      " neutral     0.876     0.978     0.957    46\n",
      "     sad     0.876     0.689     1.000    31\n",
      "surprise     0.876     1.000     0.780    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.876     0.892     0.883    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.713274 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.016800  [    0/ 2233]\n",
      "loss: 0.638652  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.936     1.000     1.000    25\n",
      " disgust     0.936     0.879     0.806    36\n",
      "    fear     0.936     0.971     1.000    34\n",
      "   happy     0.936     0.868     0.917    36\n",
      " neutral     0.936     0.978     0.957    46\n",
      "     sad     0.936     0.935     0.935    31\n",
      "surprise     0.936     0.929     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.936     0.937     0.938    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.630693 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep78_acc_94.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep76_acc_92\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep78_acc_94\"! Old accuracy: 91.6, new accuracy: 93.6\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.735056  [    0/ 2233]\n",
      "loss: 0.500460  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.900     1.000     1.000    25\n",
      " disgust     0.900     0.689     0.861    36\n",
      "    fear     0.900     1.000     0.971    34\n",
      "   happy     0.900     1.000     0.750    36\n",
      " neutral     0.900     0.936     0.957    46\n",
      "     sad     0.900     0.861     1.000    31\n",
      "surprise     0.900     0.917     0.805    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.900     0.915     0.906    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.656555 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.722946  [    0/ 2233]\n",
      "loss: 0.838881  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.912     0.889     0.960    25\n",
      " disgust     0.912     0.964     0.750    36\n",
      "    fear     0.912     0.872     1.000    34\n",
      "   happy     0.912     0.919     0.944    36\n",
      " neutral     0.912     0.920     1.000    46\n",
      "     sad     0.912     0.968     0.968    31\n",
      "surprise     0.912     0.865     0.780    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.912     0.914     0.915    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.674726 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.663922  [    0/ 2233]\n",
      "loss: 1.028986  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.928     1.000     1.000    25\n",
      " disgust     0.928     0.857     0.833    36\n",
      "    fear     0.928     1.000     1.000    34\n",
      "   happy     0.928     1.000     0.750    36\n",
      " neutral     0.928     0.978     0.978    46\n",
      "     sad     0.928     0.909     0.968    31\n",
      "surprise     0.928     0.816     0.976    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.928     0.937     0.929    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.597287 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.679559  [    0/ 2233]\n",
      "loss: 0.966460  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.952     1.000     1.000    25\n",
      " disgust     0.952     0.909     0.833    36\n",
      "    fear     0.952     1.000     0.941    34\n",
      "   happy     0.952     0.923     1.000    36\n",
      " neutral     0.952     0.957     0.978    46\n",
      "     sad     0.952     0.968     0.968    31\n",
      "surprise     0.952     0.929     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.952     0.955     0.953    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.592095 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep82_acc_95.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep78_acc_94\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep82_acc_95\"! Old accuracy: 93.6, new accuracy: 95.2\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.716159  [    0/ 2233]\n",
      "loss: 0.550244  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.952     1.000     0.960    25\n",
      " disgust     0.952     0.969     0.861    36\n",
      "    fear     0.952     0.943     0.971    34\n",
      "   happy     0.952     0.897     0.972    36\n",
      " neutral     0.952     0.977     0.935    46\n",
      "     sad     0.952     0.912     1.000    31\n",
      "surprise     0.952     0.976     0.976    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.952     0.953     0.953    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.615122 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.336124  [    0/ 2233]\n",
      "loss: 0.400178  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.940     1.000     1.000    25\n",
      " disgust     0.940     0.853     0.806    36\n",
      "    fear     0.940     0.971     1.000    34\n",
      "   happy     0.940     0.969     0.861    36\n",
      " neutral     0.940     1.000     0.957    46\n",
      "     sad     0.940     0.909     0.968    31\n",
      "surprise     0.940     0.891     1.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.940     0.942     0.942    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.545111 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.622964  [    0/ 2233]\n",
      "loss: 0.685260  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.936     0.962     1.000    25\n",
      " disgust     0.936     1.000     0.750    36\n",
      "    fear     0.936     1.000     1.000    34\n",
      "   happy     0.936     0.818     1.000    36\n",
      " neutral     0.936     0.978     0.957    46\n",
      "     sad     0.936     0.939     1.000    31\n",
      "surprise     0.936     0.900     0.878    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.936     0.942     0.941    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.557933 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.332915  [    0/ 2233]\n",
      "loss: 0.643471  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.960     1.000     1.000    25\n",
      " disgust     0.960     0.935     0.806    36\n",
      "    fear     0.960     1.000     1.000    34\n",
      "   happy     0.960     0.971     0.917    36\n",
      " neutral     0.960     1.000     1.000    46\n",
      "     sad     0.960     0.912     1.000    31\n",
      "surprise     0.960     0.911     1.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.960     0.961     0.960    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.514049 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep86_acc_96.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep82_acc_95\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep86_acc_96\"! Old accuracy: 95.2, new accuracy: 96.0\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.537925  [    0/ 2233]\n",
      "loss: 0.693783  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.948     1.000     0.960    25\n",
      " disgust     0.948     0.966     0.778    36\n",
      "    fear     0.948     0.971     1.000    34\n",
      "   happy     0.948     0.944     0.944    36\n",
      " neutral     0.948     0.958     1.000    46\n",
      "     sad     0.948     0.912     1.000    31\n",
      "surprise     0.948     0.907     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.948     0.951     0.948    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.509157 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.541678  [    0/ 2233]\n",
      "loss: 0.510603  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.936     1.000     0.960    25\n",
      " disgust     0.936     0.882     0.833    36\n",
      "    fear     0.936     0.944     1.000    34\n",
      "   happy     0.936     0.814     0.972    36\n",
      " neutral     0.936     1.000     0.978    46\n",
      "     sad     0.936     0.938     0.968    31\n",
      "surprise     0.936     1.000     0.854    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.936     0.940     0.938    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.532287 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.584803  [    0/ 2233]\n",
      "loss: 0.803684  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.871     1.000     0.960    25\n",
      " disgust     0.871     1.000     0.639    36\n",
      "    fear     0.871     0.895     1.000    34\n",
      "   happy     0.871     0.630     0.944    36\n",
      " neutral     0.871     0.957     0.957    46\n",
      "     sad     0.871     0.939     1.000    31\n",
      "surprise     0.871     0.871     0.659    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.871     0.899     0.880    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.603899 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.647245  [    0/ 2233]\n",
      "loss: 0.515914  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.932     1.000     0.960    25\n",
      " disgust     0.932     0.789     0.833    36\n",
      "    fear     0.932     1.000     1.000    34\n",
      "   happy     0.932     0.857     1.000    36\n",
      " neutral     0.932     1.000     0.957    46\n",
      "     sad     0.932     0.912     1.000    31\n",
      "surprise     0.932     1.000     0.805    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.932     0.937     0.936    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.533353 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.407176  [    0/ 2233]\n",
      "loss: 0.413286  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.940     1.000     0.960    25\n",
      " disgust     0.940     0.861     0.861    36\n",
      "    fear     0.940     0.971     1.000    34\n",
      "   happy     0.940     0.857     1.000    36\n",
      " neutral     0.940     1.000     0.957    46\n",
      "     sad     0.940     0.968     0.968    31\n",
      "surprise     0.940     0.946     0.854    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.940     0.943     0.943    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.495629 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.519828  [    0/ 2233]\n",
      "loss: 0.341375  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.912     1.000     0.960    25\n",
      " disgust     0.912     1.000     0.750    36\n",
      "    fear     0.912     0.919     1.000    34\n",
      "   happy     0.912     0.761     0.972    36\n",
      " neutral     0.912     0.957     0.978    46\n",
      "     sad     0.912     0.968     0.968    31\n",
      "surprise     0.912     0.865     0.780    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.912     0.924     0.916    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.533534 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.584440  [    0/ 2233]\n",
      "loss: 0.354755  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.940     1.000     0.960    25\n",
      " disgust     0.940     0.786     0.917    36\n",
      "    fear     0.940     1.000     0.971    34\n",
      "   happy     0.940     0.970     0.889    36\n",
      " neutral     0.940     0.978     0.957    46\n",
      "     sad     0.940     0.886     1.000    31\n",
      "surprise     0.940     1.000     0.902    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.940     0.946     0.942    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.504934 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.298296  [    0/ 2233]\n",
      "loss: 0.613002  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.912     1.000     1.000    25\n",
      " disgust     0.912     0.882     0.833    36\n",
      "    fear     0.912     0.971     1.000    34\n",
      "   happy     0.912     0.818     1.000    36\n",
      " neutral     0.912     0.955     0.913    46\n",
      "     sad     0.912     0.886     1.000    31\n",
      "surprise     0.912     0.906     0.707    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.912     0.917     0.922    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.530952 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.704075  [    0/ 2233]\n",
      "loss: 0.373126  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.932     1.000     0.960    25\n",
      " disgust     0.932     0.745     0.972    36\n",
      "    fear     0.932     0.971     1.000    34\n",
      "   happy     0.932     1.000     0.861    36\n",
      " neutral     0.932     1.000     0.935    46\n",
      "     sad     0.932     0.938     0.968    31\n",
      "surprise     0.932     0.946     0.854    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.932     0.943     0.936    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.522244 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.512435  [    0/ 2233]\n",
      "loss: 0.358757  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.924     1.000     1.000    25\n",
      " disgust     0.924     0.762     0.889    36\n",
      "    fear     0.924     0.971     1.000    34\n",
      "   happy     0.924     0.968     0.833    36\n",
      " neutral     0.924     1.000     0.978    46\n",
      "     sad     0.924     0.938     0.968    31\n",
      "surprise     0.924     0.872     0.829    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.924     0.930     0.928    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.447017 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.382525  [    0/ 2233]\n",
      "loss: 0.709460  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.952     1.000     0.960    25\n",
      " disgust     0.952     1.000     0.778    36\n",
      "    fear     0.952     0.971     1.000    34\n",
      "   happy     0.952     0.900     1.000    36\n",
      " neutral     0.952     0.958     1.000    46\n",
      "     sad     0.952     0.967     0.935    31\n",
      "surprise     0.952     0.909     0.976    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.952     0.958     0.950    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.463826 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 1.202804  [    0/ 2233]\n",
      "loss: 0.378241  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.960     1.000     0.960    25\n",
      " disgust     0.960     1.000     0.778    36\n",
      "    fear     0.960     1.000     1.000    34\n",
      "   happy     0.960     0.900     1.000    36\n",
      " neutral     0.960     0.979     1.000    46\n",
      "     sad     0.960     0.939     1.000    31\n",
      "surprise     0.960     0.930     0.976    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.960     0.964     0.959    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.405450 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.356303  [    0/ 2233]\n",
      "loss: 0.470396  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.904     1.000     0.960    25\n",
      " disgust     0.904     0.867     0.722    36\n",
      "    fear     0.904     0.971     1.000    34\n",
      "   happy     0.904     0.967     0.806    36\n",
      " neutral     0.904     0.979     1.000    46\n",
      "     sad     0.904     0.962     0.806    31\n",
      "surprise     0.904     0.719     1.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.904     0.923     0.899    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.487850 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.416206  [    0/ 2233]\n",
      "loss: 0.640958  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.932     1.000     0.960    25\n",
      " disgust     0.932     0.935     0.806    36\n",
      "    fear     0.932     1.000     1.000    34\n",
      "   happy     0.932     0.818     1.000    36\n",
      " neutral     0.932     0.978     0.957    46\n",
      "     sad     0.932     0.886     1.000    31\n",
      "surprise     0.932     0.944     0.829    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.932     0.937     0.936    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.451998 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.394043  [    0/ 2233]\n",
      "loss: 0.423587  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.952     1.000     1.000    25\n",
      " disgust     0.952     0.825     0.917    36\n",
      "    fear     0.952     1.000     1.000    34\n",
      "   happy     0.952     1.000     0.833    36\n",
      " neutral     0.952     1.000     1.000    46\n",
      "     sad     0.952     0.912     1.000    31\n",
      "surprise     0.952     0.950     0.927    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.952     0.955     0.954    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.390883 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.322092  [    0/ 2233]\n",
      "loss: 0.389926  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.811     1.000     0.920    25\n",
      " disgust     0.811     0.516     0.889    36\n",
      "    fear     0.811     0.943     0.971    34\n",
      "   happy     0.811     0.791     0.944    36\n",
      " neutral     0.811     1.000     0.652    46\n",
      "     sad     0.811     0.912     1.000    31\n",
      "surprise     0.811     0.864     0.463    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.811     0.861     0.834    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.809947 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 1.186403  [    0/ 2233]\n",
      "loss: 0.366689  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.900     0.923     0.960    25\n",
      " disgust     0.900     1.000     0.583    36\n",
      "    fear     0.900     0.944     1.000    34\n",
      "   happy     0.900     0.761     0.972    36\n",
      " neutral     0.900     0.957     0.978    46\n",
      "     sad     0.900     0.968     0.968    31\n",
      "surprise     0.900     0.833     0.854    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.900     0.912     0.902    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.465038 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.581835  [    0/ 2233]\n",
      "loss: 0.363535  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.960     1.000     1.000    25\n",
      " disgust     0.960     0.967     0.806    36\n",
      "    fear     0.960     0.971     1.000    34\n",
      "   happy     0.960     0.897     0.972    36\n",
      " neutral     0.960     1.000     1.000    46\n",
      "     sad     0.960     0.967     0.935    31\n",
      "surprise     0.960     0.932     1.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.960     0.962     0.959    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.352425 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.330889  [    0/ 2233]\n",
      "loss: 0.927912  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.964     1.000     0.960    25\n",
      " disgust     0.964     0.969     0.861    36\n",
      "    fear     0.964     0.971     1.000    34\n",
      "   happy     0.964     0.878     1.000    36\n",
      " neutral     0.964     1.000     1.000    46\n",
      "     sad     0.964     0.968     0.968    31\n",
      "surprise     0.964     0.975     0.951    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.964     0.966     0.963    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.351490 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep105_acc_96.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep86_acc_96\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/dim_red/Nr1_tess/emo_reco_best_ep105_acc_96\"! Old accuracy: 96.0, new accuracy: 96.4\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.282328  [    0/ 2233]\n",
      "loss: 0.284488  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.944     1.000     1.000    25\n",
      " disgust     0.944     0.861     0.861    36\n",
      "    fear     0.944     1.000     1.000    34\n",
      "   happy     0.944     0.944     0.944    36\n",
      " neutral     0.944     1.000     0.957    46\n",
      "     sad     0.944     0.886     1.000    31\n",
      "surprise     0.944     0.923     0.878    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.944     0.945     0.949    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.390259 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.309716  [    0/ 2233]\n",
      "loss: 0.337519  [ 1200/ 2233]\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.948     1.000     0.960    25\n",
      " disgust     0.948     1.000     0.750    36\n",
      "    fear     0.948     0.971     1.000    34\n",
      "   happy     0.948     0.971     0.917    36\n",
      " neutral     0.948     1.000     1.000    46\n",
      "     sad     0.948     0.939     1.000    31\n",
      "surprise     0.948     0.820     1.000    41\n",
      "                                          249\n",
      "\n",
      " \n",
      "     avg     0.948     0.957     0.947    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.342528 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.200578  [    0/ 2233]\n",
      "loss: 0.411056  [ 1200/ 2233]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:75\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# this is the trainloop\u001B[39;00m\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;66;03m# --------------------- testloop and evaluation- ---------------\u001B[39;00m\n\u001B[1;32m     78\u001B[0m acc, true, preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loop(test_dataloader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:119\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train_loop\u001B[0;34m(self, dataloader, model, loss_fn, optimizer, epoch)\u001B[0m\n\u001B[1;32m    117\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m    118\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m--> 119\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    122\u001B[0m     loss, current \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem(), batch \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(X)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[0;32m--> 140\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     22\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 23\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     25\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/optim/adam.py:234\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure, grad_scaler)\u001B[0m\n\u001B[1;32m    231\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    232\u001B[0m             state_steps\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m--> 234\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m         \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m         \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m         \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m         \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m         \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m         \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m         \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m         \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m         \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m         \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m         \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m         \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m         \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m         \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m         \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m         \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/optim/adam.py:300\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    298\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 300\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    307\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/optim/adam.py:354\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    351\u001B[0m step_t \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight_decay \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 354\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[43mgrad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(param):\n\u001B[1;32m    357\u001B[0m     grad \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mview_as_real(grad)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

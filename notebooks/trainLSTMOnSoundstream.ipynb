{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 14:13:44 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2023-01-10 14:13:44.277071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-10 14:13:45.041109: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-10 14:13:45.041165: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-10 14:13:45.041169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": "SoundStream(\n  (encoder): Sequential(\n    (0): CausalConv1d(\n      (conv): Conv1d(1, 32, kernel_size=(7,), stride=(1,))\n    )\n    (1): Sequential(\n      (0): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (1): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), dilation=(3,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (2): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), dilation=(9,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (3): CausalConv1d(\n        (conv): Conv1d(32, 64, kernel_size=(4,), stride=(2,))\n      )\n    )\n    (2): Sequential(\n      (0): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (1): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(7,), stride=(1,), dilation=(3,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (2): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(7,), stride=(1,), dilation=(9,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (3): CausalConv1d(\n        (conv): Conv1d(64, 128, kernel_size=(8,), stride=(4,))\n      )\n    )\n    (3): Sequential(\n      (0): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (1): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), dilation=(3,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (2): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), dilation=(9,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (3): CausalConv1d(\n        (conv): Conv1d(128, 256, kernel_size=(10,), stride=(5,))\n      )\n    )\n    (4): Sequential(\n      (0): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (1): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), dilation=(3,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (2): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), dilation=(9,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (3): CausalConv1d(\n        (conv): Conv1d(256, 512, kernel_size=(16,), stride=(8,))\n      )\n    )\n    (5): CausalConv1d(\n      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,))\n    )\n  )\n  (encoder_attn): LocalMHA(\n    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n    (attn_fn): LocalAttention(\n      (dropout): Dropout(p=0.0, inplace=False)\n      (rel_pos): SinusoidalEmbeddings()\n    )\n    (to_out): Linear(in_features=512, out_features=512, bias=False)\n  )\n  (rq): ResidualVQ(\n    (layers): ModuleList(\n      (0): VectorQuantize(\n        (project_in): Identity()\n        (project_out): Identity()\n        (_codebook): EuclideanCodebook()\n      )\n      (1): VectorQuantize(\n        (project_in): Identity()\n        (project_out): Identity()\n        (_codebook): EuclideanCodebook()\n      )\n      (2): VectorQuantize(\n        (project_in): Identity()\n        (project_out): Identity()\n        (_codebook): EuclideanCodebook()\n      )\n      (3): VectorQuantize(\n        (project_in): Identity()\n        (project_out): Identity()\n        (_codebook): EuclideanCodebook()\n      )\n      (4): VectorQuantize(\n        (project_in): Identity()\n        (project_out): Identity()\n        (_codebook): EuclideanCodebook()\n      )\n      (5): VectorQuantize(\n        (project_in): Identity()\n        (project_out): Identity()\n        (_codebook): EuclideanCodebook()\n      )\n      (6): VectorQuantize(\n        (project_in): Identity()\n        (project_out): Identity()\n        (_codebook): EuclideanCodebook()\n      )\n      (7): VectorQuantize(\n        (project_in): Identity()\n        (project_out): Identity()\n        (_codebook): EuclideanCodebook()\n      )\n    )\n  )\n  (decoder_attn): LocalMHA(\n    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n    (attn_fn): LocalAttention(\n      (dropout): Dropout(p=0.0, inplace=False)\n      (rel_pos): SinusoidalEmbeddings()\n    )\n    (to_out): Linear(in_features=512, out_features=512, bias=False)\n  )\n  (decoder): Sequential(\n    (0): CausalConv1d(\n      (conv): Conv1d(512, 512, kernel_size=(7,), stride=(1,))\n    )\n    (1): Sequential(\n      (0): CausalConvTranspose1d(\n        (conv): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,))\n      )\n      (1): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (2): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), dilation=(3,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (3): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), dilation=(9,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n    )\n    (2): Sequential(\n      (0): CausalConvTranspose1d(\n        (conv): ConvTranspose1d(256, 128, kernel_size=(10,), stride=(5,))\n      )\n      (1): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (2): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), dilation=(3,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (3): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), dilation=(9,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n    )\n    (3): Sequential(\n      (0): CausalConvTranspose1d(\n        (conv): ConvTranspose1d(128, 64, kernel_size=(8,), stride=(4,))\n      )\n      (1): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (2): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(7,), stride=(1,), dilation=(3,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (3): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(7,), stride=(1,), dilation=(9,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n    )\n    (4): Sequential(\n      (0): CausalConvTranspose1d(\n        (conv): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,))\n      )\n      (1): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (2): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), dilation=(3,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n      (3): Residual(\n        (fn): Sequential(\n          (0): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), dilation=(9,))\n          )\n          (1): ELU(alpha=1.0)\n          (2): CausalConv1d(\n            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n          )\n          (3): ELU(alpha=1.0)\n        )\n      )\n    )\n    (5): CausalConv1d(\n      (conv): Conv1d(32, 1, kernel_size=(7,), stride=(1,))\n    )\n  )\n  (discriminators): ModuleList(\n    (0): MultiScaleDiscriminator(\n      (init_conv): Conv1d(1, 16, kernel_size=(7,), stride=(1,))\n      (conv_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv1d(16, 64, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (1): Sequential(\n          (0): Conv1d(64, 256, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (2): Sequential(\n          (0): Conv1d(256, 1024, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (3): Sequential(\n          (0): Conv1d(1024, 1024, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n      )\n      (final_conv): Sequential(\n        (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,))\n        (1): LeakyReLU(negative_slope=0.1)\n        (2): Conv1d(1024, 1, kernel_size=(1,), stride=(1,))\n      )\n    )\n    (1): MultiScaleDiscriminator(\n      (init_conv): Conv1d(1, 16, kernel_size=(7,), stride=(1,))\n      (conv_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv1d(16, 64, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (1): Sequential(\n          (0): Conv1d(64, 256, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (2): Sequential(\n          (0): Conv1d(256, 1024, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (3): Sequential(\n          (0): Conv1d(1024, 1024, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n      )\n      (final_conv): Sequential(\n        (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,))\n        (1): LeakyReLU(negative_slope=0.1)\n        (2): Conv1d(1024, 1, kernel_size=(1,), stride=(1,))\n      )\n    )\n    (2): MultiScaleDiscriminator(\n      (init_conv): Conv1d(1, 16, kernel_size=(7,), stride=(1,))\n      (conv_layers): ModuleList(\n        (0): Sequential(\n          (0): Conv1d(16, 64, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (1): Sequential(\n          (0): Conv1d(64, 256, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (2): Sequential(\n          (0): Conv1d(256, 1024, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n        (3): Sequential(\n          (0): Conv1d(1024, 1024, kernel_size=(8,), stride=(4,), padding=(4,), groups=4)\n          (1): LeakyReLU(negative_slope=0.1)\n        )\n      )\n      (final_conv): Sequential(\n        (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,))\n        (1): LeakyReLU(negative_slope=0.1)\n        (2): Conv1d(1024, 1, kernel_size=(1,), stride=(1,))\n      )\n    )\n  )\n  (stft_discriminator): STFTDiscriminator(\n    (init_conv): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n    (layers): ModuleList(\n      (0): Sequential(\n        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ModReLU()\n        (2): Conv2d(32, 32, kernel_size=(3, 4), stride=(1, 2), padding=(1, 2))\n      )\n      (1): Sequential(\n        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ModReLU()\n        (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n      )\n      (2): Sequential(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ModReLU()\n        (2): Conv2d(64, 128, kernel_size=(3, 4), stride=(1, 2), padding=(1, 2))\n      )\n      (3): Sequential(\n        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ModReLU()\n        (2): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n      )\n      (4): Sequential(\n        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ModReLU()\n        (2): Conv2d(128, 256, kernel_size=(3, 4), stride=(1, 2), padding=(1, 2))\n      )\n      (5): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ModReLU()\n        (2): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n      )\n    )\n    (final_conv): Conv2d(256, 1, kernel_size=(16, 1), stride=(1, 1))\n  )\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audiolm_pytorch import SoundStream, SoundStreamTrainer\n",
    "soundstream = SoundStream(\n",
    "    codebook_size = 1024,\n",
    "    rq_num_quantizers = 8,\n",
    ")\n",
    "soundstream.load(\"content/soundstream/results3/soundstream.9000.pt\")\n",
    "soundstream.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% ...generating encoding\r"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from importlib import reload\n",
    "import network_models.soundstream_lstm.LSTM_dataset as lds\n",
    "import torch.utils.data as data_utils\n",
    "#from network_models.soundstream_lstm.LSTM_dataset  import AudioEmotionTessDataset\n",
    "reload(lds)\n",
    "\n",
    "\n",
    "tess_dataset = lds.AudioEmotionTessDataset(\"../tess\")\n",
    "\n",
    "encoded_dataset = lds.AudioEmotionTessSoundStreamEncodedDataset(dataSet= tess_dataset, soundStream=soundstream)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import torch\n",
    "module_path = str(Path.cwd().parents[0] / \"network_models/soundstream_lstm\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import network_models.soundstream_lstm.small_model as sm\n",
    "importlib.reload(sm)\n",
    "\n",
    "\n",
    "import network_models.soundstream_lstm.soundstream_datacollator as datacollator\n",
    "importlib.reload(datacollator)\n",
    "data_collator = datacollator.SoundStreamDataCollator(200)\n",
    "\n",
    "# print(encoded_dataset.__getitem__(3).shape)\n",
    "model = sm.EmotionClassifierSevenEmos().to(\"cuda\")\n",
    "tensor = torch.tensor(encoded_dataset.__getitem__(3)[0])\n",
    "tensor = torch.nn.functional.pad(tensor, (0, 200 - tensor.shape[1], 0, 0))\n",
    "tensor = tensor.flatten()\n",
    "print(tensor[0].shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "from network_models.soundstream_lstm.soundstream_datacollator import SoundstreamModelTrainer\n",
    "from transformers import TrainingArguments, EvalPrediction\n",
    "\n",
    "is_regression = False\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_val_dataset(dataset, val_split=0.25):\n",
    "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "    datasets = {}\n",
    "    trainSet = Subset(dataset, train_idx)\n",
    "    valSet = Subset(dataset, val_idx)\n",
    "    return trainSet, valSet\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.squeeze(preds) if is_regression else np.argmax(preds, axis=0)\n",
    "\n",
    "    if is_regression:\n",
    "        return {\"mse\": ((preds - p.label_ids) ** 2).mean().item()}\n",
    "    else:\n",
    "        return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n",
    "\n",
    "\n",
    "train_dataset, eval_dataset = train_val_dataset(encoded_dataset, val_split=0.25)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"content/soundStreamClassModelsEmo\",\n",
    "    # output_dir=\"/content/gdrive/MyDrive/wav2vec2-xlsr-greek-speech-emotion-recognition\"\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=5.0,\n",
    "    fp16=True,\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "trainer = SoundstreamModelTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "#to override the collate_fn in dataloader because we have different sizes\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def pad_inputs(batch):\n",
    "    input_batch = [torch.nn.functional.pad(torch.tensor(input_val).to(\"cuda\"),\n",
    "                        (0, 400 - input_val.shape[1], 0, 0))\n",
    "                       for input_val in batch]\n",
    "    return torch.stack((input_batch[0], input_batch[1]))\n",
    "\n",
    "def pad_labels(batch):\n",
    "    enc_list=[]\n",
    "    for x in batch:\n",
    "        a = np.zeros(7,)\n",
    "        a[x] = 1\n",
    "        enc_list.append(a)\n",
    "    input_labels = [torch.tensor(label, dtype=torch.float32).to(\"cuda\")\n",
    "                    for label in enc_list]\n",
    "\n",
    "    return torch.stack((input_labels[0], input_labels[1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[ 0.30637577, -0.3240556 , -0.32908133, ...,  0.        ,\n          0.        ,  0.        ],\n        [-0.40834558, -0.06076266, -0.00050882, ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.08495785,  0.27482823, -0.03164213, ...,  0.        ,\n          0.        ,  0.        ],\n        ...,\n        [-0.32027078,  0.28586814,  0.36783856, ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.02696363, -0.08964451, -0.18721043, ...,  0.        ,\n          0.        ,  0.        ],\n        [-0.07458303, -0.1834232 , -0.1924202 , ...,  0.        ,\n          0.        ,  0.        ]], dtype=float32),\n array([4]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 1e-4\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(train_dataset, batch_size=10,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "evalLoader = torch.utils.data.DataLoader(eval_dataset, batch_size=10,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "train_dataset[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.863275  [    0/ 2100]\n",
      "loss: 1.246828  [  100/ 2100]\n",
      "loss: 1.953896  [  200/ 2100]\n",
      "loss: 1.854637  [  300/ 2100]\n",
      "loss: 1.851477  [  400/ 2100]\n",
      "loss: 1.848317  [  500/ 2100]\n",
      "loss: 1.844934  [  600/ 2100]\n",
      "loss: 2.002946  [  700/ 2100]\n",
      "loss: 1.838379  [  800/ 2100]\n",
      "loss: 1.835320  [  900/ 2100]\n",
      "loss: 1.832255  [ 1000/ 2100]\n",
      "loss: 1.828984  [ 1100/ 2100]\n",
      "loss: 1.825358  [ 1200/ 2100]\n",
      "loss: 1.821835  [ 1300/ 2100]\n",
      "loss: 1.818582  [ 1400/ 2100]\n",
      "loss: 1.814878  [ 1500/ 2100]\n",
      "loss: 1.811035  [ 1600/ 2100]\n",
      "loss: 1.807074  [ 1700/ 2100]\n",
      "loss: 1.803721  [ 1800/ 2100]\n",
      "loss: 1.963657  [ 1900/ 2100]\n",
      "loss: 1.795836  [ 2000/ 2100]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 63\u001B[0m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     62\u001B[0m     train_loop(train_dataloader, model, loss_fn, optimizer)\n\u001B[0;32m---> 63\u001B[0m     \u001B[43mtest_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[32], line 53\u001B[0m, in \u001B[0;36mtest_loop\u001B[0;34m(dataloader, model, loss_fn)\u001B[0m\n\u001B[1;32m     51\u001B[0m         y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     52\u001B[0m         pred \u001B[38;5;241m=\u001B[39m model(X\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m---> 53\u001B[0m         test_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     54\u001B[0m         correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (pred\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m y)\u001B[38;5;241m.\u001B[39mtype(torch\u001B[38;5;241m.\u001B[39mfloat)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     56\u001B[0m test_loss \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m num_batches\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1175\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1176\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3024\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3025\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import OneHotEncoder# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "def encodeLabel(label):\n",
    "    return enc.fit_transform(label).toarray()\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(\"cuda\")\n",
    "        y = y.to(\"cuda\")\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        # print()\n",
    "        #y = torch.tensor(encodeLabel(y.cpu())).to(\"cuda\")\n",
    "        y = torch.zeros(7, dtype=torch.long).to(\"cuda\").scatter_(dim=0, index=y[0][0], value=1)\n",
    "        loss = loss_fn(pred, y[0])\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(\"cuda\")\n",
    "            y = y.to(\"cuda\")\n",
    "            pred = model(X.to(\"cuda\"))\n",
    "            test_loss += loss_fn(pred, y.to(\"cuda\")).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# for epoch in range(300):\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(trainLoader, 0):\n",
    "#         #get input values and labels from the batch of the dataloaded\n",
    "#         # print(data)\n",
    "#         inputs, labels = data[0].to(\"cuda\"), data[1].to(\"cuda\")\n",
    "#\n",
    "#         # labels = data[1]\n",
    "#         #print(labels)\n",
    "#         #pad inputs\n",
    "#         # padded_inputs = pad_inputs(inputs)\n",
    "#         padded_labels = pad_labels(labels)\n",
    "#         #print(padded_inputs)\n",
    "#         #print(padded_labels)\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "#\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = model(inputs)\n",
    "#         #print(outputs)\n",
    "#         loss = criterion(outputs.to(torch.float32), labels.to(torch.float32))\n",
    "#         #print(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#\n",
    "#         # valid_loss = 0.0\n",
    "#         #\n",
    "#         # for i, data in enumerate(evalLoader, 0):\n",
    "#         #     inputs= data[0]\n",
    "#         #     labels = data[1]\n",
    "#         #     padded_inputs = pad_inputs(inputs)\n",
    "#         #     padded_labels = pad_labels(labels)\n",
    "#         #\n",
    "#         #     outputs = model(padded_inputs)\n",
    "#         #     loss = criterion(outputs, padded_labels)\n",
    "#         #     valid_loss = loss.item() * padded_inputs.size(0)\n",
    "#         #\n",
    "#         # print(valid_loss)\n",
    "#\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "#             running_loss = 0.0\n",
    "#\n",
    "# print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

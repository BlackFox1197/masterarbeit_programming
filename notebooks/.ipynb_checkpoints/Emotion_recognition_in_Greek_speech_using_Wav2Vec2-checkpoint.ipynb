{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fbCls1d2yBs"
   },
   "source": [
    "# Emotion Recognition in Greek Speech Using Wav2Vec 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp37lZOV2042"
   },
   "source": [
    "**Wav2Vec 2.0** is a pretrained model for Automatic Speech Recognition (ASR) and was released in [September 2020](https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/) by Alexei Baevski, Michael Auli, and Alex Conneau.  Soon after the superior performance of Wav2Vec2 was demonstrated on the English ASR dataset LibriSpeech, *Facebook AI* presented XLSR-Wav2Vec2 (click [here](https://arxiv.org/abs/2006.13979)). XLSR stands for *cross-lingual  speech representations* and refers to XLSR-Wav2Vec2`s ability to learn speech representations that are useful across multiple languages.\n",
    "\n",
    "Similar to Wav2Vec2, XLSR-Wav2Vec2 learns powerful speech representations from hundreds of thousands of hours of speech in more than 50 languages of unlabeled speech. Similar, to [BERT's masked language modeling](http://jalammar.github.io/illustrated-bert/), the model learns contextualized speech representations by randomly masking feature vectors before passing them to a transformer network.\n",
    "\n",
    "![wav2vec2_structure](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/xlsr_wav2vec2.png)\n",
    "\n",
    "The authors show for the first time that massively pretraining an ASR model on cross-lingual unlabeled speech data, followed by language-specific fine-tuning on very little labeled data achieves state-of-the-art results. See Table 1-5 of the official [paper](https://arxiv.org/pdf/2006.13979.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0xJwDkA3QQR"
   },
   "source": [
    "During fine-tuning week hosted by HuggingFace, more than 300 people participated in tuning XLSR-Wav2Vec2's pretrained on low-resources ASR dataset for more than 50 languages. This model is fine-tuned using [Connectionist Temporal Classification](https://distill.pub/2017/ctc/) (CTC), an algorithm used to train neural networks for sequence-to-sequence problems and mainly in Automatic Speech Recognition and handwriting recognition. Follow this [notebook](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_Tune_XLSR_Wav2Vec2_on_Turkish_ASR_with_%F0%9F%A4%97_Transformers.ipynb#scrollTo=Gx9OdDYrCtQ1) for more information about XLSR-Wav2Vec2 fine-tuning.\n",
    "\n",
    "This model was shown significant results in many low-resources languages. You can see the [competition board](https://paperswithcode.com/dataset/common-voice) or even testing the models from the [HuggingFace hub](https://huggingface.co/models?filter=xlsr-fine-tuning-week). \n",
    "\n",
    "\n",
    "In this notebook, we will go through how to use this model to recognize the emotional aspects of speech in a language (or even as a general view using for every classification problem). Before going any further, we need to install some handy packages and define some enviroment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cp4-LTa2uphv",
    "outputId": "b1490098-4140-4d72-f59e-756ca705cf83"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%env LC_ALL=C.UTF-8\n",
    "%env LANG=C.UTF-8\n",
    "%env TRANSFORMERS_CACHE=content/cache\n",
    "%env HF_DATASETS_CACHE=content/cache\n",
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krC50MmmvBWJ"
   },
   "source": [
    "## Prepare Data\n",
    "\n",
    "For this particular example, we use [Acted Emotional Speech Dynamic Database – AESDD](http://m3c.web.auth.gr/research/aesdd-speech-emotion-recognition/) provided by Multidisciplinary Media & Mediated Communication Research Group ([M3C](http://m3c.web.auth.gr/)). \n",
    "\n",
    "The Acted Emotional Speech Dynamic Database (AESDD) is a publically available speech emotion recognition dataset that contains utterances of acted emotional speech in the Greek language for five different emotions `sadness`, `disgust`, `happiness`, `anger`, and `fear`.\n",
    "\n",
    "The dataset consists of directories of emotions; each folder includes specific emotions. We need to loop over directories and save the paths related to each class based on the directory name.\n",
    "\n",
    "```bash\n",
    ".\n",
    "├── Tools\\ and\\ Documentation\n",
    "│   ├── ESTrainer.mlapp\n",
    "│   ├── Speech\\ Emotion\\ Recognition\\ Adapted\\ to\\ Multimodal\\ Semantic\\ Repositories_documentation.pdf\n",
    "│   ├── Speech\\ Emotion\\ Recognition\\ for\\ Performance\\ Interaction.pdf\n",
    "│   └── readme.txt\n",
    "├── anger\n",
    "│   ├── a01\\ (1).wav\n",
    "│   ├── a01\\ (2).wav\n",
    "│   ├── ...\n",
    "├── disgust\n",
    "│   ├── d01\\ (1).wav\n",
    "│   ├── d01\\ (2).wav\n",
    "│   ├── ...\n",
    "├── fear\n",
    "│   ├── f01\\ (1).wav\n",
    "│   ├── f01\\ (2).wav\n",
    "│   ├── ...\n",
    "├── happiness\n",
    "│   ├── h01\\ (1).wav\n",
    "│   ├── h01\\ (2).wav\n",
    "│   ├── ...\n",
    "└── sadness\n",
    "    ├── s01\\ (1).wav\n",
    "    ├── s01\\ (2).wav\n",
    "    ├── ...\n",
    "\n",
    "6 directories, 609 files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pFSqZ0jwCMSv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MXAESg_Dqr6",
    "outputId": "2820808d-37db-41ab-edd5-af0a097d9281"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for path in tqdm(Path(\"/content/data/aesdd\").glob(\"**/*.wav\")):\n",
    "    name = str(path).split('/')[-1].split('.')[0]\n",
    "    label = str(path).split('/')[-2]\n",
    "    \n",
    "    try:\n",
    "        # There are some broken files\n",
    "        s = torchaudio.load(path)\n",
    "        data.append({\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"emotion\": label\n",
    "        })\n",
    "    except Exception as e:\n",
    "        # print(str(path), e)\n",
    "        pass\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/bin/python\n",
      "['angry', 'angry', 'ps', 'happy', 'fear', 'sad', 'fear', 'ps', 'happy', 'disgust', 'sad', 'sad', 'happy', 'disgust', 'disgust', 'fear', 'sad', 'happy', 'angry', 'happy', 'disgust', 'disgust', 'happy', 'happy', 'disgust', 'disgust', 'angry', 'happy', 'disgust', 'sad', 'sad', 'happy', 'ps', 'disgust', 'sad', 'disgust', 'fear', 'disgust', 'happy', 'happy', 'happy', 'sad', 'fear', 'fear', 'fear', 'sad', 'ps', 'angry', 'sad', 'disgust', 'angry', 'happy', 'happy', 'fear', 'fear', 'happy', 'angry', 'sad', 'happy', 'fear', 'fear', 'angry', 'happy', 'happy', 'angry', 'happy', 'happy', 'fear', 'happy', 'fear', 'happy', 'happy', 'angry', 'sad', 'fear', 'ps', 'ps', 'angry', 'happy', 'happy', 'sad', 'ps', 'ps', 'ps', 'angry', 'angry', 'disgust', 'ps', 'ps', 'sad', 'happy', 'ps', 'happy', 'disgust', 'disgust', 'sad', 'sad', 'happy', 'angry', 'angry', 'sad', 'happy', 'happy', 'ps', 'disgust', 'sad', 'fear', 'ps', 'happy', 'fear', 'sad', 'disgust', 'disgust', 'fear', 'angry', 'happy', 'sad', 'ps', 'fear', 'sad', 'disgust', 'disgust', 'disgust', 'angry', 'angry', 'sad', 'happy', 'angry', 'happy', 'ps', 'sad', 'fear', 'disgust', 'fear', 'disgust', 'disgust', 'disgust', 'ps', 'fear', 'sad', 'fear', 'sad', 'happy', 'fear', 'fear', 'ps', 'sad', 'angry', 'angry', 'happy', 'happy', 'fear', 'ps', 'fear', 'ps', 'fear', 'disgust', 'ps', 'happy', 'fear', 'angry', 'sad', 'sad', 'fear', 'disgust', 'fear', 'ps', 'angry', 'disgust', 'fear', 'sad', 'disgust', 'disgust', 'fear', 'ps', 'ps', 'ps', 'sad', 'ps', 'happy', 'sad', 'happy', 'happy', 'disgust', 'sad', 'fear', 'happy', 'angry', 'disgust', 'sad', 'happy', 'fear', 'ps', 'ps', 'angry', 'sad', 'angry', 'angry', 'sad', 'happy', 'fear', 'angry', 'sad', 'happy', 'happy', 'ps', 'angry', 'sad', 'angry', 'fear', 'angry', 'disgust', 'happy', 'fear', 'happy', 'ps', 'happy', 'sad', 'happy', 'fear', 'angry', 'fear', 'disgust', 'fear', 'sad', 'fear', 'sad', 'sad', 'sad', 'sad', 'disgust', 'fear', 'fear', 'angry', 'disgust', 'fear', 'fear', 'angry', 'happy', 'sad', 'fear', 'angry', 'happy', 'disgust', 'disgust', 'disgust', 'happy', 'disgust', 'ps', 'ps', 'sad', 'disgust', 'angry', 'sad', 'happy', 'fear', 'angry', 'angry', 'happy', 'happy', 'angry', 'sad', 'disgust', 'ps', 'ps', 'angry', 'ps', 'disgust', 'angry', 'sad', 'happy', 'ps', 'sad', 'ps', 'ps', 'disgust', 'ps', 'ps', 'happy', 'fear', 'fear', 'happy', 'disgust', 'sad', 'fear', 'ps', 'disgust', 'fear', 'ps', 'fear', 'disgust', 'ps', 'ps', 'angry', 'angry', 'sad', 'ps', 'disgust', 'disgust', 'ps', 'happy', 'fear', 'sad', 'angry', 'disgust', 'happy', 'disgust', 'disgust', 'angry', 'angry', 'sad', 'ps', 'disgust', 'fear', 'angry', 'angry', 'fear', 'fear', 'angry', 'angry', 'fear', 'ps', 'angry', 'disgust', 'ps', 'disgust', 'happy', 'happy', 'sad', 'angry', 'sad', 'angry', 'ps', 'happy', 'disgust', 'disgust', 'angry', 'angry', 'ps', 'disgust', 'fear', 'fear', 'sad', 'ps', 'sad', 'happy', 'ps', 'disgust', 'ps', 'sad', 'disgust', 'disgust', 'sad', 'disgust', 'happy', 'happy', 'angry', 'sad', 'disgust', 'happy', 'sad', 'angry', 'ps', 'angry', 'happy', 'fear', 'sad', 'ps', 'ps', 'sad', 'fear', 'fear', 'fear', 'angry', 'angry', 'fear', 'fear', 'angry', 'fear', 'ps', 'disgust', 'angry', 'angry', 'angry', 'happy', 'fear', 'fear', 'fear', 'happy', 'ps', 'disgust', 'angry', 'ps', 'angry', 'angry', 'disgust', 'ps', 'angry', 'ps', 'sad', 'sad', 'happy', 'disgust', 'ps', 'happy', 'fear', 'disgust', 'disgust', 'angry', 'angry', 'disgust', 'fear', 'sad', 'disgust', 'disgust', 'sad', 'happy', 'disgust', 'happy', 'angry', 'ps', 'happy', 'fear', 'fear', 'fear', 'disgust', 'angry', 'disgust', 'sad', 'fear', 'fear', 'ps', 'sad', 'sad', 'fear', 'fear', 'disgust', 'sad', 'fear', 'happy', 'angry', 'angry', 'disgust', 'happy', 'ps', 'angry', 'ps', 'happy', 'sad', 'ps', 'fear', 'angry', 'disgust', 'happy', 'sad', 'fear', 'fear', 'ps', 'disgust', 'fear', 'sad', 'fear', 'fear', 'angry', 'sad', 'ps', 'disgust', 'ps', 'angry', 'ps', 'angry', 'fear', 'ps', 'disgust', 'disgust', 'sad', 'happy', 'sad', 'angry', 'sad', 'sad', 'sad', 'sad', 'ps', 'ps', 'ps', 'fear', 'ps', 'ps', 'sad', 'sad', 'sad', 'angry', 'sad', 'happy', 'disgust', 'ps', 'happy', 'happy', 'sad', 'angry', 'happy', 'fear', 'ps', 'fear', 'fear', 'angry', 'ps', 'happy', 'disgust', 'fear', 'happy', 'happy', 'disgust', 'sad', 'happy', 'fear', 'sad', 'happy', 'ps', 'sad', 'disgust', 'disgust', 'angry', 'sad', 'happy', 'ps', 'happy', 'disgust', 'sad', 'angry', 'ps', 'fear', 'ps', 'sad', 'sad', 'fear', 'disgust', 'disgust', 'ps', 'angry', 'fear', 'angry', 'happy', 'angry', 'happy', 'disgust', 'ps', 'happy', 'happy', 'disgust', 'angry', 'angry', 'fear', 'ps', 'disgust', 'ps', 'happy', 'disgust', 'sad', 'ps', 'disgust', 'angry', 'happy', 'ps', 'disgust', 'sad', 'angry', 'angry', 'sad', 'happy', 'happy', 'happy', 'happy', 'fear', 'ps', 'happy', 'ps', 'fear', 'happy', 'disgust', 'ps', 'disgust', 'disgust', 'sad', 'angry', 'sad', 'sad', 'happy', 'happy', 'ps', 'disgust', 'disgust', 'disgust', 'angry', 'ps', 'fear', 'fear', 'happy', 'fear', 'angry', 'happy', 'sad', 'happy', 'angry', 'happy', 'fear', 'angry', 'ps', 'ps', 'angry', 'fear', 'disgust', 'disgust', 'ps', 'ps', 'fear', 'happy', 'ps', 'angry', 'ps', 'fear', 'disgust', 'angry', 'angry', 'happy', 'sad', 'ps', 'disgust', 'sad', 'sad', 'sad', 'sad', 'angry', 'disgust', 'fear', 'angry', 'sad', 'angry', 'happy', 'angry', 'happy', 'disgust', 'ps', 'sad', 'disgust', 'ps', 'fear', 'happy', 'angry', 'sad', 'disgust', 'angry', 'ps', 'sad', 'angry', 'disgust', 'fear', 'sad', 'happy', 'disgust', 'fear', 'disgust', 'happy', 'happy', 'angry', 'ps', 'angry', 'fear', 'sad', 'fear', 'disgust', 'happy', 'angry', 'ps', 'fear', 'happy', 'ps', 'angry', 'sad', 'ps', 'fear', 'fear', 'angry', 'ps', 'sad', 'ps', 'fear', 'disgust', 'disgust', 'fear', 'fear', 'ps', 'ps', 'fear', 'disgust', 'fear', 'sad', 'ps', 'happy', 'ps', 'sad', 'fear', 'disgust', 'disgust', 'fear', 'ps', 'angry', 'disgust', 'sad', 'angry', 'ps', 'fear', 'angry', 'disgust', 'angry', 'angry', 'ps', 'sad', 'ps', 'ps', 'happy', 'angry', 'sad', 'fear', 'ps', 'disgust', 'sad', 'angry', 'ps', 'angry', 'sad', 'disgust', 'fear', 'angry', 'angry', 'fear', 'happy', 'disgust', 'fear', 'happy', 'disgust', 'disgust', 'happy', 'angry', 'sad', 'fear', 'ps', 'sad', 'disgust', 'angry', 'happy', 'ps', 'happy', 'sad', 'happy', 'ps', 'sad', 'angry', 'angry', 'sad', 'fear', 'ps', 'ps', 'sad', 'sad', 'sad', 'disgust']\n",
      "['../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sad_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_dis_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_hap_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w02_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_fea_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_hap_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w01_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w01_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w03_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_fea_w03_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w05_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_fea_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sad_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w03_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w01_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_dis_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_ang_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w05_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_ang_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sur_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_sur_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w01_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w05_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_dis_w02_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_fea_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_ang_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_fea_w03_c_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf04_fea_w02_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_hap_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_dis_w02_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w02_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_fea_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sur_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_dis_w02_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_ang_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf01_hap_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w05_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_hap_w05_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sad_w01_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_hap_w05_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_sur_w03_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_ang_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_ang_w03_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nm01_sad_w05_o_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_fea_w02_o_100_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sur_w03_c_25_70dB.wav', '../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_75_70dB.wav', '../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_50_70dB.wav', '../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_100_70dB.wav']\n",
      "Dataset is loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_10...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_50...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_10...</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_75...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_50...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_75...</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_75...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_50...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_50...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_10...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  emotion\n",
       "0    ../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_10...    angry\n",
       "1    ../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_50...    angry\n",
       "2    ../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_10...       ps\n",
       "3    ../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_75...    happy\n",
       "4    ../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_50...     fear\n",
       "..                                                 ...      ...\n",
       "763  ../Stimuli_Intensitätsmorphs/nm02_sur_w05_o_75...       ps\n",
       "764  ../Stimuli_Intensitätsmorphs/nm03_sad_w01_o_75...      sad\n",
       "765  ../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_50...      sad\n",
       "766  ../Stimuli_Intensitätsmorphs/nm04_sad_w01_c_50...      sad\n",
       "767  ../Stimuli_Intensitätsmorphs/nf02_dis_w05_o_10...  disgust\n",
       "\n",
       "[768 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_custom_dataset():\n",
    "    paths = []\n",
    "    testpaths = []\n",
    "    testlabels = []\n",
    "    terminator = 'D:/Uni/19.Master/Daten/terminator.wav'\n",
    "    print(sys.executable)\n",
    "    emotions = []\n",
    "    # for dirname, _, filenames in os.walk('Daten/TESS Toronto emotional speech set data'):\n",
    "    # D:\\Uni\\19.Master\\DATEN\n",
    "    for dirname, _, filenames in os.walk('../tess'):\n",
    "        for filename in filenames:\n",
    "            label = filename.split('_')[-1]\n",
    "            label = label.split('.')[0]\n",
    "            if (label != 'neutral'):\n",
    "                emotions.append(label.lower())\n",
    "                paths.append(os.path.join(dirname, filename))\n",
    "    for dirname, _, filenames in os.walk('../Stimuli_Intensitätsmorphs'):\n",
    "        for filename in filenames:\n",
    "\n",
    "            intens = filename.split('_')[-2]\n",
    "            emot = filename.split('_')[1]\n",
    "            label = emot\n",
    "            match label:\n",
    "                case 'ang':\n",
    "                    label = 'angry'\n",
    "                case 'dis':\n",
    "                    label = 'disgust'\n",
    "                case 'fea':\n",
    "                    label = 'fear'\n",
    "                case 'hap':\n",
    "                    label = 'happy'\n",
    "                case 'sad':\n",
    "                    label = 'sad'\n",
    "                case 'sur':\n",
    "                    label = 'ps'\n",
    "            if (emot != 'ple'):\n",
    "                testpaths.append(os.path.join(dirname, filename))\n",
    "                testlabels.append(label.lower())\n",
    "    com_labels = testlabels + emotions\n",
    "    com_paths = testpaths + paths\n",
    "    print(testlabels)\n",
    "    print(testpaths)\n",
    "    print('Dataset is loaded')\n",
    "    return paths, emotions, testpaths, testlabels\n",
    "trainpaths, trainlabels, testpaths, testlabels = load_custom_dataset()\n",
    "\n",
    "###create dataframes for training and testing###\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF[\"path\"] = trainpaths\n",
    "trainDF[\"emotion\"] = trainlabels\n",
    "\n",
    "testDF = pd.DataFrame()\n",
    "testDF[\"path\"] = testpaths\n",
    "testDF[\"emotion\"] = testlabels\n",
    "\n",
    "\n",
    "testDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "10b89ZpLDqx9",
    "outputId": "15e12e3f-6717-451e-91b3-3b70694921a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_10...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_50...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_10...</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_75...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_50...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path emotion\n",
       "0  ../Stimuli_Intensitätsmorphs/nf02_ang_w05_o_10...   angry\n",
       "1  ../Stimuli_Intensitätsmorphs/nm01_ang_w01_o_50...   angry\n",
       "2  ../Stimuli_Intensitätsmorphs/nf04_sur_w03_c_10...      ps\n",
       "3  ../Stimuli_Intensitätsmorphs/nf03_hap_w01_o_75...   happy\n",
       "4  ../Stimuli_Intensitätsmorphs/nm01_fea_w01_o_50...    fear"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = testDF\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "iMhTHur8voOp",
    "outputId": "453c81e0-f976-46c0-806b-76315a8cf85b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: 768\n",
      "Step 1: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48229/2154895978.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(\"status\", 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_25...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_75...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_25...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_10...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_50...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  emotion\n",
       "0  ../Stimuli_Intensitätsmorphs/nm02_ang_w05_o_25...    angry\n",
       "1  ../Stimuli_Intensitätsmorphs/nf01_sad_w02_c_75...      sad\n",
       "2  ../Stimuli_Intensitätsmorphs/nm01_dis_w02_c_25...  disgust\n",
       "3  ../Stimuli_Intensitätsmorphs/nf01_sad_w03_c_10...      sad\n",
       "4  ../Stimuli_Intensitätsmorphs/nm04_sad_w05_c_50...      sad"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter broken and non-existed paths\n",
    "\n",
    "print(f\"Step 0: {len(df)}\")\n",
    "\n",
    "df[\"status\"] = df[\"path\"].apply(lambda path: True if os.path.exists(path) else None)\n",
    "df = df.dropna(subset=[\"path\"])\n",
    "df = df.drop(\"status\", 1)\n",
    "print(f\"Step 1: {len(df)}\")\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWku4ra3Bp52"
   },
   "source": [
    "Let's explore how many labels (emotions) are in the dataset with what distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "beNpKMh5xXmX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  ['angry' 'sad' 'disgust' 'ps' 'fear' 'happy']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         path\n",
       "emotion      \n",
       "angry     128\n",
       "disgust   128\n",
       "fear      128\n",
       "happy     128\n",
       "ps        128\n",
       "sad       128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Labels: \", df[\"emotion\"].unique())\n",
    "print()\n",
    "df.groupby(\"emotion\").count()[[\"path\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2hwRai7BNrx"
   },
   "source": [
    "Let's display some random sample of the dataset and run it a couple of times to get a feeling for the audio and the emotional label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DZaQ_sP5xkIX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID Location: 483\n",
      "      Label: happy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48229/2414068180.py:18: FutureWarning: Pass orig_sr=44100, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  speech = librosa.resample(np.asarray(speech), sr, 16_000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchaudio\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "\n",
    "idx = np.random.randint(0, len(df))\n",
    "sample = df.iloc[idx]\n",
    "path = sample[\"path\"]\n",
    "label = sample[\"emotion\"]\n",
    "\n",
    "\n",
    "print(f\"ID Location: {idx}\")\n",
    "print(f\"      Label: {label}\")\n",
    "print()\n",
    "\n",
    "speech, sr = torchaudio.load(path)\n",
    "speech = speech[0].numpy().squeeze()\n",
    "speech = librosa.resample(np.asarray(speech), sr, 16_000)\n",
    "ipd.Audio(data=np.asarray(speech), autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WNjWoWRCmPk"
   },
   "source": [
    "For training purposes, we need to split data into train test sets; in this specific example, we break with a `20%` rate for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mlim-044xtJN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 2)\n",
      "(154, 2)\n"
     ]
    }
   ],
   "source": [
    "#save_path = \"/content/data\"\n",
    "save_path=\"content/data\"\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=101, stratify=df[\"emotion\"])\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "#train_df.to_csv(f\"{save_path}/train.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "#test_df.to_csv(f\"{save_path}/test.csv\", sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcnD-d_rDElt"
   },
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nnVfxQYDDIc6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration data-f5a87fddb5719e24\n",
      "Found cached dataset csv (/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/cache/csv/data-f5a87fddb5719e24/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d480c2641e40888660e986ec41a41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the created dataset using datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"train.csv\",\n",
    "    \"validation\": \"test.csv\",\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"content/data/\", data_files=data_files, delimiter=\"\\t\", )\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"validation\"]\n",
    "\n",
    "# We need to specify the input and output column\n",
    "input_column = \"path\"\n",
    "output_column = \"emotion\"\n",
    "# we need to distinguish the unique labels in our SER dataset\n",
    "label_list = train_dataset.unique(output_column)\n",
    "label_list.sort()  # Let's sort it for determinism\n",
    "num_labels = len(label_list)\n",
    "#print(f\"A classification problem with {num_labels} classes: {label_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TkGYrVTFR6Y"
   },
   "source": [
    "In order to preprocess the audio into our classification model, we need to set up the relevant Wav2Vec2 assets regarding our language in this case `lighteternal/wav2vec2-large-xlsr-53-greek` fine-tuned by [Dimitris Papadopoulos](https://huggingface.co/lighteternal/wav2vec2-large-xlsr-53-greek). To handle the context representations in any audio length we use a merge strategy plan (pooling mode) to concatenate that 3D representations into 2D representations.\n",
    "\n",
    "There are three merge strategies `mean`, `sum`, and `max`. In this example, we achieved better results on the mean approach. In the following, we need to initiate the config and the feature extractor from the Dimitris model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9Y1adr7vFrq7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 16:18:04.967173: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 16:18:05.608633: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:18:05.608794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:18:05.608799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "\n",
    "#model_name_or_path = \"lighteternal/wav2vec2-large-xlsr-53-greek\"\n",
    "model_name_or_path = \"jonatasgrosman/wav2vec2-large-xlsr-53-german\"\n",
    "pooling_mode = \"mean\"\n",
    "\n",
    "\n",
    "# config\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    label2id={label: i for i, label in enumerate(label_list)},\n",
    "    id2label={i: label for i, label in enumerate(label_list)},\n",
    "    finetuning_task=\"wav2vec2_clf\",\n",
    ")\n",
    "setattr(config, 'pooling_mode', pooling_mode)\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path, )\n",
    "target_sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(f\"The target sampling rate: {target_sampling_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbGuYgLqHXZg"
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLk-eM1DFjtE"
   },
   "source": [
    "So far, we downloaded, loaded, and split the SER dataset into train and test sets. The instantiated our strategy configuration for using context representations in our classification problem SER. Now, we need to extract features from the audio path in context representation tensors and feed them into our classification model to determine the emotion in the speech.\n",
    "\n",
    "Since the audio file is saved in the `.wav` format, it is easy to use **[Librosa](https://librosa.org/doc/latest/index.html)** or others, but we suppose that the format may be in the `.mp3` format in case of generality. We found that the **[Torchaudio](https://pytorch.org/audio/stable/index.html)** library works best for reading in `.mp3` data.\n",
    "\n",
    "An audio file usually stores both its values and the sampling rate with which the speech signal was digitalized. We want to store both in the dataset and write a **map(...)** function accordingly. Also, we need to handle the string labels into integers for our specific classification task in this case, the **single-label classification** you may want to use for your **regression** or even **multi-label classification**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6UqlIV3uGxDA"
   },
   "outputs": [],
   "source": [
    "import utils.audio_dataset_utils as audioUtils\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    speech_list = [audioUtils.speech_file_to_array_librosa(path, target_sampling_rate) for path in examples[input_column]]\n",
    "    target_list = [audioUtils.label_to_id(label, label_list) for label in examples[output_column]]\n",
    "\n",
    "    result = processor(speech_list, sampling_rate=target_sampling_rate)\n",
    "    result[\"labels\"] = list(target_list)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ioP8FfR2GxHi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/cache/csv/data-f5a87fddb5719e24/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-3b256eb0e70bbc35.arrow\n",
      "Loading cached processed dataset at /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/cache/csv/data-f5a87fddb5719e24/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-c8750dcec87c031b.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batch_size=50,\n",
    "    batched=True,\n",
    "    #num_proc=4\n",
    ")\n",
    "eval_dataset = eval_dataset.map(\n",
    "    preprocess_function,\n",
    "    batch_size=50,\n",
    "    batched=True,\n",
    "    #num_proc=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eu1qcRucHk6d"
   },
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# print(f\"Training input_values: {train_dataset[idx]['input_values']}\")\n",
    "# print(f\"Training attention_mask: {train_dataset[idx]['attention_mask']}\")\n",
    "# print(f\"Training labels: {train_dataset[idx]['labels']} - {train_dataset[idx]['emotion']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcrEgJO9Hmx7"
   },
   "source": [
    "Great, now we've successfully read all the audio files, resampled the audio files to 16kHz, and mapped each audio to the corresponding label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL7q6DfcH0Fs"
   },
   "source": [
    "## Model\n",
    "\n",
    "Before diving into the training part, we need to build our classification model based on the merge strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network_models.w2v_emotion_model.model as KNNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrBrR1b7zvUL"
   },
   "source": [
    "## Training\n",
    "\n",
    "The data is processed so that we are ready to start setting up the training pipeline. We will make use of 🤗's [Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer) for which we essentially need to do the following:\n",
    "\n",
    "- Define a data collator. In contrast to most NLP models, XLSR-Wav2Vec2 has a much larger input length than output length. *E.g.*, a sample of input length 50000 has an output length of no more than 100. Given the large input sizes, it is much more efficient to pad the training batches dynamically meaning that all training samples should only be padded to the longest sample in their batch and not the overall longest sample. Therefore, fine-tuning XLSR-Wav2Vec2 requires a special padding data collator, which we will define below\n",
    "\n",
    "- Evaluation metric. During training, the model should be evaluated on the word error rate. We should define a `compute_metrics` function accordingly\n",
    "\n",
    "- Load a pretrained checkpoint. We need to load a pretrained checkpoint and configure it correctly for training.\n",
    "\n",
    "- Define the training configuration.\n",
    "\n",
    "After having fine-tuned the model, we will correctly evaluate it on the test data and verify that it has indeed learned to correctly transcribe speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji9-n1eUIKZc"
   },
   "source": [
    "### Set-up Trainer\n",
    "\n",
    "Let's start by defining the data collator. The code for the data collator was copied from [this example](https://github.com/huggingface/transformers/blob/9a06b6b11bdfc42eea08fa91d0c737d1863c99e3/examples/research_projects/wav2vec2/run_asr.py#L81).\n",
    "\n",
    "Without going into too many details, in contrast to the common data collators, this data collator treats the `input_values` and `labels` differently and thus applies to separate padding functions on them (again making use of XLSR-Wav2Vec2's context manager). This is necessary because in speech input and output are of different modalities meaning that they should not be treated by the same padding function.\n",
    "Analogous to the common data collators, the padding tokens in the labels with `-100` so that those tokens are **not** taken into account when computing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rkM0VLIwy903"
   },
   "outputs": [],
   "source": [
    "import network_models.w2v_emotion_model.trainer as trainerUtils\n",
    "data_collator = trainerUtils.DataCollatorCTCWithPadding(processor=processor, padding=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYxy2IR-KcU2"
   },
   "source": [
    "Next, the evaluation metric is defined. There are many pre-defined metrics for classification/regression problems, but in this case, we would continue with just **Accuracy** for classification and **MSE** for regression. You can define other metrics on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LL8I5MKvPnth"
   },
   "outputs": [],
   "source": [
    "is_regression = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XK26Z6IfR36K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.squeeze(preds) if is_regression else np.argmax(preds, axis=1)\n",
    "\n",
    "    if is_regression:\n",
    "        return {\"mse\": ((preds - p.label_ids) ** 2).mean().item()}\n",
    "    else:\n",
    "        return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsH_nKJdK28o"
   },
   "source": [
    "Now, we can load the pretrained XLSR-Wav2Vec2 checkpoint into our classification model with a pooling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0Tl6iKAUR4EL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-german were not used when initializing Wav2Vec2ForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSpeechClassification were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-german and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = KNNModel.Wav2Vec2ForSpeechClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqF4rNMzI1M5"
   },
   "source": [
    "The first component of XLSR-Wav2Vec2 consists of a stack of CNN layers that are used to extract acoustically meaningful - but contextually independent - features from the raw speech signal. This part of the model has already been sufficiently trained during pretraining and as stated in the [paper](https://arxiv.org/pdf/2006.13979.pdf) does not need to be fine-tuned anymore. \n",
    "Thus, we can set the `requires_grad` to `False` for all parameters of the *feature extraction* part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KHMhxFGoR4Hb"
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0HzBneBK84G"
   },
   "source": [
    "In a final step, we define all parameters related to training. \n",
    "To give more explanation on some of the parameters:\n",
    "- `learning_rate` and `weight_decay` were heuristically tuned until fine-tuning has become stable. Note that those parameters strongly depend on the Common Voice dataset and might be suboptimal for other speech datasets.\n",
    "\n",
    "For more explanations on other parameters, one can take a look at the [docs](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer#trainingarguments).\n",
    "\n",
    "**Note**: If one wants to save the trained models in his/her google drive the commented-out `output_dir` can be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3tPqZ12BLCJk"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vUtWjldAI9-H"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"content/models\",\n",
    "    # output_dir=\"/content/gdrive/MyDrive/wav2vec2-xlsr-greek-speech-emotion-recognition\"\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=10.0,\n",
    "    fp16=True,\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAtuL0APLZSs"
   },
   "source": [
    "For future use we can create our training script, we do it in a simple way. You can add more on you own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KfW6uDolJYZv"
   },
   "outputs": [],
   "source": [
    "# from typing import Any, Dict, Union\n",
    "#\n",
    "# import torch\n",
    "# from packaging import version\n",
    "# from torch import nn\n",
    "#\n",
    "# from transformers import (\n",
    "#     Trainer,\n",
    "#     is_apex_available,\n",
    "# )\n",
    "#\n",
    "# if is_apex_available():\n",
    "#     from apex import amp\n",
    "#\n",
    "# if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n",
    "#     _is_native_amp_available = True\n",
    "#     from torch.cuda.amp import autocast\n",
    "#\n",
    "#\n",
    "# class CTCTrainer(Trainer):\n",
    "#     def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n",
    "#         torch.cuda.empty_cache()\n",
    "#         \"\"\"\n",
    "#         Perform a training step on a batch of inputs.\n",
    "#\n",
    "#         Subclass and override to inject custom behavior.\n",
    "#\n",
    "#         Args:\n",
    "#             model (:obj:`nn.Module`):\n",
    "#                 The model to train.\n",
    "#             inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "#                 The inputs and targets of the model.\n",
    "#\n",
    "#                 The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "#                 argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "#\n",
    "#         Return:\n",
    "#             :obj:`torch.Tensor`: The tensor with training loss on this batch.\n",
    "#         \"\"\"\n",
    "#\n",
    "#         model.train()\n",
    "#         inputs = self._prepare_inputs(inputs)\n",
    "#\n",
    "#         if self.use_cuda_amp:\n",
    "#             with autocast():\n",
    "#                 loss = self.compute_loss(model, inputs)\n",
    "#         else:\n",
    "#             loss = self.compute_loss(model, inputs)\n",
    "#\n",
    "#         if self.args.gradient_accumulation_steps > 1:\n",
    "#             loss = loss / self.args.gradient_accumulation_steps\n",
    "#\n",
    "#         if self.use_cuda_amp:\n",
    "#             self.scaler.scale(loss).backward()\n",
    "#         elif self.use_apex:\n",
    "#             with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "#                 scaled_loss.backward()\n",
    "#         elif self.deepspeed:\n",
    "#             self.deepspeed.backward(loss)\n",
    "#         else:\n",
    "#             loss.backward()\n",
    "#\n",
    "#         return loss.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv7Ju3qYJeJn"
   },
   "source": [
    "Now, all instances can be passed to Trainer and we are ready to start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nEFkfK45JYiZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = trainerUtils.CTCTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gGLwJAOLtDg"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpN6xlWCLxJ7"
   },
   "source": [
    "Training will take between 10 and 60 minutes depending on the GPU allocated to this notebook. \n",
    "\n",
    "In case you want to use this google colab to fine-tune your model, you should make sure that your training doesn't stop due to inactivity. A simple hack to prevent this is to paste the following code into the console of this tab (right mouse click -> inspect -> Console tab and insert code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyYZH7YZL8a9"
   },
   "source": [
    "```javascript\n",
    "function ConnectButton(){\n",
    "    console.log(\"Connect pushed\"); \n",
    "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
    "}\n",
    "setInterval(ConnectButton,60000);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6M8bNvLLJnG1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 614\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 770\n",
      "  Number of trainable parameters = 312284294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/770 : < :, Epoch 0.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-10\n",
      "Configuration saved in content/models/checkpoint-10/config.json\n",
      "Model weights saved in content/models/checkpoint-10/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-10/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-60] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-20\n",
      "Configuration saved in content/models/checkpoint-20/config.json\n",
      "Model weights saved in content/models/checkpoint-20/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-20/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-70] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-30\n",
      "Configuration saved in content/models/checkpoint-30/config.json\n",
      "Model weights saved in content/models/checkpoint-30/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-30/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-10] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-40\n",
      "Configuration saved in content/models/checkpoint-40/config.json\n",
      "Model weights saved in content/models/checkpoint-40/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-40/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-20] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-50\n",
      "Configuration saved in content/models/checkpoint-50/config.json\n",
      "Model weights saved in content/models/checkpoint-50/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-50/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-30] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-60\n",
      "Configuration saved in content/models/checkpoint-60/config.json\n",
      "Model weights saved in content/models/checkpoint-60/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-60/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-40] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-70\n",
      "Configuration saved in content/models/checkpoint-70/config.json\n",
      "Model weights saved in content/models/checkpoint-70/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-70/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-50] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-80\n",
      "Configuration saved in content/models/checkpoint-80/config.json\n",
      "Model weights saved in content/models/checkpoint-80/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-80/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-60] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-90\n",
      "Configuration saved in content/models/checkpoint-90/config.json\n",
      "Model weights saved in content/models/checkpoint-90/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-90/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-70] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-100\n",
      "Configuration saved in content/models/checkpoint-100/config.json\n",
      "Model weights saved in content/models/checkpoint-100/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-100/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-80] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-110\n",
      "Configuration saved in content/models/checkpoint-110/config.json\n",
      "Model weights saved in content/models/checkpoint-110/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-110/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-90] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-120\n",
      "Configuration saved in content/models/checkpoint-120/config.json\n",
      "Model weights saved in content/models/checkpoint-120/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-120/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-100] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-130\n",
      "Configuration saved in content/models/checkpoint-130/config.json\n",
      "Model weights saved in content/models/checkpoint-130/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-130/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-110] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-140\n",
      "Configuration saved in content/models/checkpoint-140/config.json\n",
      "Model weights saved in content/models/checkpoint-140/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-140/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-120] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-150\n",
      "Configuration saved in content/models/checkpoint-150/config.json\n",
      "Model weights saved in content/models/checkpoint-150/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-150/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-130] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-160\n",
      "Configuration saved in content/models/checkpoint-160/config.json\n",
      "Model weights saved in content/models/checkpoint-160/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-160/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-140] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-170\n",
      "Configuration saved in content/models/checkpoint-170/config.json\n",
      "Model weights saved in content/models/checkpoint-170/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-170/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-150] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-180\n",
      "Configuration saved in content/models/checkpoint-180/config.json\n",
      "Model weights saved in content/models/checkpoint-180/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-180/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-160] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-190\n",
      "Configuration saved in content/models/checkpoint-190/config.json\n",
      "Model weights saved in content/models/checkpoint-190/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-190/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-170] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-200\n",
      "Configuration saved in content/models/checkpoint-200/config.json\n",
      "Model weights saved in content/models/checkpoint-200/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-200/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-180] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-210\n",
      "Configuration saved in content/models/checkpoint-210/config.json\n",
      "Model weights saved in content/models/checkpoint-210/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-210/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-190] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-220\n",
      "Configuration saved in content/models/checkpoint-220/config.json\n",
      "Model weights saved in content/models/checkpoint-220/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-220/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-200] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-230\n",
      "Configuration saved in content/models/checkpoint-230/config.json\n",
      "Model weights saved in content/models/checkpoint-230/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-230/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-210] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-240\n",
      "Configuration saved in content/models/checkpoint-240/config.json\n",
      "Model weights saved in content/models/checkpoint-240/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-240/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-220] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-250\n",
      "Configuration saved in content/models/checkpoint-250/config.json\n",
      "Model weights saved in content/models/checkpoint-250/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-250/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-230] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-260\n",
      "Configuration saved in content/models/checkpoint-260/config.json\n",
      "Model weights saved in content/models/checkpoint-260/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-260/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-240] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-270\n",
      "Configuration saved in content/models/checkpoint-270/config.json\n",
      "Model weights saved in content/models/checkpoint-270/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-270/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-250] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-280\n",
      "Configuration saved in content/models/checkpoint-280/config.json\n",
      "Model weights saved in content/models/checkpoint-280/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-280/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-260] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-290\n",
      "Configuration saved in content/models/checkpoint-290/config.json\n",
      "Model weights saved in content/models/checkpoint-290/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-290/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-270] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-300\n",
      "Configuration saved in content/models/checkpoint-300/config.json\n",
      "Model weights saved in content/models/checkpoint-300/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-300/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-280] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-310\n",
      "Configuration saved in content/models/checkpoint-310/config.json\n",
      "Model weights saved in content/models/checkpoint-310/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-310/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-290] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-320\n",
      "Configuration saved in content/models/checkpoint-320/config.json\n",
      "Model weights saved in content/models/checkpoint-320/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-320/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-300] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-330\n",
      "Configuration saved in content/models/checkpoint-330/config.json\n",
      "Model weights saved in content/models/checkpoint-330/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-330/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-310] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-340\n",
      "Configuration saved in content/models/checkpoint-340/config.json\n",
      "Model weights saved in content/models/checkpoint-340/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-340/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-320] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-350\n",
      "Configuration saved in content/models/checkpoint-350/config.json\n",
      "Model weights saved in content/models/checkpoint-350/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-350/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-330] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-360\n",
      "Configuration saved in content/models/checkpoint-360/config.json\n",
      "Model weights saved in content/models/checkpoint-360/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-360/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-340] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-370\n",
      "Configuration saved in content/models/checkpoint-370/config.json\n",
      "Model weights saved in content/models/checkpoint-370/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-370/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-350] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-380\n",
      "Configuration saved in content/models/checkpoint-380/config.json\n",
      "Model weights saved in content/models/checkpoint-380/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-380/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-360] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-390\n",
      "Configuration saved in content/models/checkpoint-390/config.json\n",
      "Model weights saved in content/models/checkpoint-390/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-390/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-370] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-400\n",
      "Configuration saved in content/models/checkpoint-400/config.json\n",
      "Model weights saved in content/models/checkpoint-400/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-400/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-380] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-410\n",
      "Configuration saved in content/models/checkpoint-410/config.json\n",
      "Model weights saved in content/models/checkpoint-410/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-410/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-390] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-420\n",
      "Configuration saved in content/models/checkpoint-420/config.json\n",
      "Model weights saved in content/models/checkpoint-420/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-420/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-430\n",
      "Configuration saved in content/models/checkpoint-430/config.json\n",
      "Model weights saved in content/models/checkpoint-430/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-430/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-410] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-440\n",
      "Configuration saved in content/models/checkpoint-440/config.json\n",
      "Model weights saved in content/models/checkpoint-440/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-440/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-420] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-450\n",
      "Configuration saved in content/models/checkpoint-450/config.json\n",
      "Model weights saved in content/models/checkpoint-450/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-450/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-430] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-460\n",
      "Configuration saved in content/models/checkpoint-460/config.json\n",
      "Model weights saved in content/models/checkpoint-460/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-460/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-440] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-470\n",
      "Configuration saved in content/models/checkpoint-470/config.json\n",
      "Model weights saved in content/models/checkpoint-470/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-470/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-450] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-480\n",
      "Configuration saved in content/models/checkpoint-480/config.json\n",
      "Model weights saved in content/models/checkpoint-480/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-480/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-460] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-490\n",
      "Configuration saved in content/models/checkpoint-490/config.json\n",
      "Model weights saved in content/models/checkpoint-490/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-490/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-470] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-500\n",
      "Configuration saved in content/models/checkpoint-500/config.json\n",
      "Model weights saved in content/models/checkpoint-500/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-500/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-480] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-510\n",
      "Configuration saved in content/models/checkpoint-510/config.json\n",
      "Model weights saved in content/models/checkpoint-510/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-510/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-490] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-520\n",
      "Configuration saved in content/models/checkpoint-520/config.json\n",
      "Model weights saved in content/models/checkpoint-520/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-520/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-530\n",
      "Configuration saved in content/models/checkpoint-530/config.json\n",
      "Model weights saved in content/models/checkpoint-530/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-530/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-510] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-540\n",
      "Configuration saved in content/models/checkpoint-540/config.json\n",
      "Model weights saved in content/models/checkpoint-540/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-540/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-520] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-550\n",
      "Configuration saved in content/models/checkpoint-550/config.json\n",
      "Model weights saved in content/models/checkpoint-550/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-550/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-530] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-560\n",
      "Configuration saved in content/models/checkpoint-560/config.json\n",
      "Model weights saved in content/models/checkpoint-560/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-560/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-540] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-570\n",
      "Configuration saved in content/models/checkpoint-570/config.json\n",
      "Model weights saved in content/models/checkpoint-570/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-570/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-550] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-580\n",
      "Configuration saved in content/models/checkpoint-580/config.json\n",
      "Model weights saved in content/models/checkpoint-580/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-580/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-560] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-590\n",
      "Configuration saved in content/models/checkpoint-590/config.json\n",
      "Model weights saved in content/models/checkpoint-590/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-590/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-570] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-600\n",
      "Configuration saved in content/models/checkpoint-600/config.json\n",
      "Model weights saved in content/models/checkpoint-600/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-600/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-580] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-610\n",
      "Configuration saved in content/models/checkpoint-610/config.json\n",
      "Model weights saved in content/models/checkpoint-610/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-610/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-590] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-620\n",
      "Configuration saved in content/models/checkpoint-620/config.json\n",
      "Model weights saved in content/models/checkpoint-620/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-620/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-600] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-630\n",
      "Configuration saved in content/models/checkpoint-630/config.json\n",
      "Model weights saved in content/models/checkpoint-630/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-630/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-610] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-640\n",
      "Configuration saved in content/models/checkpoint-640/config.json\n",
      "Model weights saved in content/models/checkpoint-640/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-640/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-620] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-650\n",
      "Configuration saved in content/models/checkpoint-650/config.json\n",
      "Model weights saved in content/models/checkpoint-650/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-650/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-630] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-660\n",
      "Configuration saved in content/models/checkpoint-660/config.json\n",
      "Model weights saved in content/models/checkpoint-660/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-660/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-640] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-670\n",
      "Configuration saved in content/models/checkpoint-670/config.json\n",
      "Model weights saved in content/models/checkpoint-670/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-670/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-650] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-680\n",
      "Configuration saved in content/models/checkpoint-680/config.json\n",
      "Model weights saved in content/models/checkpoint-680/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-680/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-660] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-690\n",
      "Configuration saved in content/models/checkpoint-690/config.json\n",
      "Model weights saved in content/models/checkpoint-690/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-690/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-670] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-700\n",
      "Configuration saved in content/models/checkpoint-700/config.json\n",
      "Model weights saved in content/models/checkpoint-700/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-680] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-710\n",
      "Configuration saved in content/models/checkpoint-710/config.json\n",
      "Model weights saved in content/models/checkpoint-710/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-710/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-690] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-720\n",
      "Configuration saved in content/models/checkpoint-720/config.json\n",
      "Model weights saved in content/models/checkpoint-720/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-720/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-730\n",
      "Configuration saved in content/models/checkpoint-730/config.json\n",
      "Model weights saved in content/models/checkpoint-730/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-730/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-710] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-740\n",
      "Configuration saved in content/models/checkpoint-740/config.json\n",
      "Model weights saved in content/models/checkpoint-740/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-740/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-720] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-750\n",
      "Configuration saved in content/models/checkpoint-750/config.json\n",
      "Model weights saved in content/models/checkpoint-750/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-750/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-730] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-760\n",
      "Configuration saved in content/models/checkpoint-760/config.json\n",
      "Model weights saved in content/models/checkpoint-760/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-760/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-740] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: path, emotion. If path, emotion are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 154\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to content/models/checkpoint-770\n",
      "Configuration saved in content/models/checkpoint-770/config.json\n",
      "Model weights saved in content/models/checkpoint-770/pytorch_model.bin\n",
      "Feature extractor saved in content/models/checkpoint-770/preprocessor_config.json\n",
      "Deleting older checkpoint [content/models/checkpoint-750] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=770, training_loss=0.7784464161117356, metrics={'train_runtime': 878.1239, 'train_samples_per_second': 6.992, 'train_steps_per_second': 0.877, 'total_flos': 1.5241100481246083e+17, 'train_loss': 0.7784464161117356, 'epoch': 10.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.memory_allocated()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to content/model\n",
      "Configuration saved in content/model/config.json\n",
      "Model weights saved in content/model/pytorch_model.bin\n",
      "Feature extractor saved in content/model/preprocessor_config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(output_dir='content/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3prIN9eiMBHo"
   },
   "source": [
    "The training loss goes down and we can see that the Acurracy on the test set also improves nicely. Because this notebook is just for demonstration purposes, we can stop here.\n",
    "\n",
    "The resulting model of this notebook has been saved to [m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition](https://huggingface.co/m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition)\n",
    "\n",
    "As a final check, let's load the model and verify that it indeed has learned to recognize the emotion in the speech.\n",
    "\n",
    "Let's first load the pretrained checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsaOTx_FVm0i"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4tGNY7hRXO44"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "IYxg1Tfo2VUw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-92f8667effa50d69\n",
      "Found cached dataset csv (/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/cache/csv/default-92f8667effa50d69/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4779b875768447f8d83b56e4065c0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'emotion'],\n",
       "    num_rows: 154\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"csv\", data_files={\"validation\": \"content/data/test.csv\"}, delimiter=\"\\t\")[\"validation\"]\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "QgZFkMDHW_Um"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-ESFEXeaWgua"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file content/model/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"Wav2Vec2ProcessorWithLM\",\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file content/model/config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"content/model\",\n",
      "  \"activation_dropout\": 0.05,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"mean\",\n",
      "  \"ctc_zero_infinity\": true,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.05,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.05,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"angry\",\n",
      "    \"1\": \"disgust\",\n",
      "    \"2\": \"fear\",\n",
      "    \"3\": \"happy\",\n",
      "    \"4\": \"ps\",\n",
      "    \"5\": \"sad\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"angry\": 0,\n",
      "    \"disgust\": 1,\n",
      "    \"fear\": 2,\n",
      "    \"happy\": 3,\n",
      "    \"ps\": 4,\n",
      "    \"sad\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.05,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 38,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading configuration file content/model/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"processor_class\": \"Wav2Vec2ProcessorWithLM\",\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'content/model'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'content/model' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:51\u001b[0m, in \u001b[0;36mWav2Vec2Processor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/processing_utils.py:183\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mInstantiate a processor associated with a pretrained model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m        [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/processing_utils.py:227\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 227\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:662\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1785\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 1785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   1786\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1787\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1788\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1789\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1790\u001b[0m     )\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'content/model'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'content/model' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name_or_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent/model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#config = AutoConfig.from_pretrained(model_name_or_path)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mWav2Vec2Processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m KNNModel\u001b[38;5;241m.\u001b[39mWav2Vec2ForSpeechClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:63\u001b[0m, in \u001b[0;36mWav2Vec2Processor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a tokenizer inside \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from a config that does not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m include a `tokenizer_class` attribute is deprecated and will be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m Wav2Vec2FeatureExtractor\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 63\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mWav2Vec2CTCTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(feature_extractor\u001b[38;5;241m=\u001b[39mfeature_extractor, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1785\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1780\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1781\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1782\u001b[0m     )\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 1785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   1786\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1787\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1788\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1789\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1790\u001b[0m     )\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'content/model'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'content/model' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"content/model\"\n",
    "#config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path)\n",
    "model = KNNModel.Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "BkEd4w8IV7kZ"
   },
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    speech_array = speech_array.squeeze().numpy()\n",
    "    speech_array = librosa.resample(np.asarray(speech_array), sampling_rate, processor.feature_extractor.sampling_rate)\n",
    "\n",
    "    batch[\"speech\"] = speech_array\n",
    "    return batch\n",
    "\n",
    "\n",
    "def predict(batch):\n",
    "    features = processor(batch[\"speech\"], sampling_rate=processor.feature_extractor.sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = features.attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits \n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    batch[\"predicted\"] = pred_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "S4P6P6XwW85p"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd57dfb6ff3a43b0be9d5d6ddebe7b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48229/2184849335.py:4: FutureWarning: Pass orig_sr=44100, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  speech_array = librosa.resample(np.asarray(speech_array), sampling_rate, processor.feature_extractor.sampling_rate)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "K_oZJzHsXKHv"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb2d96d524a414ba776b302bb46fe4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = test_dataset.map(predict, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "BnfJLZvAaxTo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'ps', 'sad']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = [config.id2label[i] for i in range(config.num_labels)]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_50_70dB.wav',\n",
       " 'emotion': 'sad',\n",
       " 'speech': [1.4362941946899355e-08,\n",
       "  -2.2597133053636753e-08,\n",
       "  3.1742164452452926e-08,\n",
       "  -4.121974583881638e-08,\n",
       "  5.0132950235592943e-08,\n",
       "  -5.7397191000063685e-08,\n",
       "  6.135852004263143e-08,\n",
       "  -6.041211264573576e-08,\n",
       "  5.2473389189344743e-08,\n",
       "  -3.5618906935042105e-08,\n",
       "  7.522541700666352e-09,\n",
       "  3.3769627094670795e-08,\n",
       "  -9.030095782236458e-08,\n",
       "  1.6409683212259552e-07,\n",
       "  -2.584087610557617e-07,\n",
       "  3.789788536323613e-07,\n",
       "  -5.408544438978424e-07,\n",
       "  7.900629839241446e-07,\n",
       "  -1.3239421150501585e-06,\n",
       "  4.075676315551391e-06,\n",
       "  2.991001383634284e-05,\n",
       "  3.035163172171451e-05,\n",
       "  3.5935054256697185e-06,\n",
       "  -9.816906185733387e-07,\n",
       "  6.11801908689813e-07,\n",
       "  -5.792601314169588e-07,\n",
       "  7.009504656707577e-07,\n",
       "  -9.691298146208283e-07,\n",
       "  1.4927182974133757e-06,\n",
       "  -2.832466407198808e-06,\n",
       "  1.7455626220908016e-05,\n",
       "  5.6992186728166416e-05,\n",
       "  8.202600292861462e-05,\n",
       "  6.328233575914055e-05,\n",
       "  6.567654781974852e-05,\n",
       "  0.000118826879770495,\n",
       "  0.00013047833635937423,\n",
       "  0.00016740798309911042,\n",
       "  0.0001760569284670055,\n",
       "  0.00012715854973066598,\n",
       "  9.710707672638819e-05,\n",
       "  5.07210788782686e-05,\n",
       "  4.2509622289799154e-05,\n",
       "  7.54501816118136e-05,\n",
       "  4.221802009851672e-05,\n",
       "  -5.493168282555416e-05,\n",
       "  -0.0001090838632080704,\n",
       "  -0.00010413253039587289,\n",
       "  -4.1710718505783007e-05,\n",
       "  -2.0621539079002105e-05,\n",
       "  -0.00012037553824484348,\n",
       "  -0.00023999420227482915,\n",
       "  -0.000349800189724192,\n",
       "  -0.00046698469668626785,\n",
       "  -0.0006593434954993427,\n",
       "  -0.0008577195694670081,\n",
       "  -0.00091932388022542,\n",
       "  -0.0008332577417604625,\n",
       "  -0.0006337416125461459,\n",
       "  -0.0004534631734713912,\n",
       "  -0.00034384705941192806,\n",
       "  -0.0004779960145242512,\n",
       "  -0.0007396514411084354,\n",
       "  -0.0008297376334667206,\n",
       "  -0.0007774168043397367,\n",
       "  -0.0006380043341778219,\n",
       "  -0.0006269188597798347,\n",
       "  -0.0006994957802817225,\n",
       "  -0.0008502814453095198,\n",
       "  -0.0011895555071532726,\n",
       "  -0.0015921477461233735,\n",
       "  -0.001711853314191103,\n",
       "  -0.0015002017607912421,\n",
       "  -0.0012833855580538511,\n",
       "  -0.0012039195280522108,\n",
       "  -0.0011591683141887188,\n",
       "  -0.0009719652589410543,\n",
       "  -0.0007589051383547485,\n",
       "  -0.0004148914886172861,\n",
       "  9.625875827623531e-05,\n",
       "  0.0005619752919301391,\n",
       "  0.0008451575413346291,\n",
       "  0.0012124113272875547,\n",
       "  0.0015751783503219485,\n",
       "  0.0018957671709358692,\n",
       "  0.0024095915723592043,\n",
       "  0.0028811823576688766,\n",
       "  0.003686052281409502,\n",
       "  0.004695729352533817,\n",
       "  0.005491701420396566,\n",
       "  0.006051275879144669,\n",
       "  0.00628548813983798,\n",
       "  0.00635581323876977,\n",
       "  0.006738822907209396,\n",
       "  0.0074216388165950775,\n",
       "  0.007753830403089523,\n",
       "  0.007692969869822264,\n",
       "  0.007567209657281637,\n",
       "  0.0077503519132733345,\n",
       "  0.008295878767967224,\n",
       "  0.008758298121392727,\n",
       "  0.008852967992424965,\n",
       "  0.009008480235934258,\n",
       "  0.009480554610490799,\n",
       "  0.010194928385317326,\n",
       "  0.011182507500052452,\n",
       "  0.012046691961586475,\n",
       "  0.012678788043558598,\n",
       "  0.013213558122515678,\n",
       "  0.01413382776081562,\n",
       "  0.015305130742490292,\n",
       "  0.016314223408699036,\n",
       "  0.017197495326399803,\n",
       "  0.017877565696835518,\n",
       "  0.01835784502327442,\n",
       "  0.018322009593248367,\n",
       "  0.018329227343201637,\n",
       "  0.018683824688196182,\n",
       "  0.01940430887043476,\n",
       "  0.020170148462057114,\n",
       "  0.02051047421991825,\n",
       "  0.020225487649440765,\n",
       "  0.019157275557518005,\n",
       "  0.018029337748885155,\n",
       "  0.017139412462711334,\n",
       "  0.016799043864011765,\n",
       "  0.016268879175186157,\n",
       "  0.014878584071993828,\n",
       "  0.012989809736609459,\n",
       "  0.011026602238416672,\n",
       "  0.009528488852083683,\n",
       "  0.008401375263929367,\n",
       "  0.007213226519525051,\n",
       "  0.0058579216711223125,\n",
       "  0.004330378025770187,\n",
       "  0.0026982685085386038,\n",
       "  0.0013201157562434673,\n",
       "  -9.372867498314008e-05,\n",
       "  -0.001402165275067091,\n",
       "  -0.002478701528161764,\n",
       "  -0.003173799952492118,\n",
       "  -0.0036546066403388977,\n",
       "  -0.004626344423741102,\n",
       "  -0.006064604502171278,\n",
       "  -0.007490440737456083,\n",
       "  -0.008381056599318981,\n",
       "  -0.008863585069775581,\n",
       "  -0.008714006282389164,\n",
       "  -0.008428585715591908,\n",
       "  -0.008674995973706245,\n",
       "  -0.009182486683130264,\n",
       "  -0.009414006024599075,\n",
       "  -0.009236525744199753,\n",
       "  -0.008920649066567421,\n",
       "  -0.00840086955577135,\n",
       "  -0.00815847609192133,\n",
       "  -0.007980268448591232,\n",
       "  -0.007863793522119522,\n",
       "  -0.007725476752966642,\n",
       "  -0.0068432181142270565,\n",
       "  -0.005448751151561737,\n",
       "  -0.003819512203335762,\n",
       "  -0.0022089038975536823,\n",
       "  -0.0011407239362597466,\n",
       "  -0.0006650729919783771,\n",
       "  -0.00033479032572358847,\n",
       "  -3.0765975679969415e-05,\n",
       "  0.0008458353113383055,\n",
       "  0.0024066513869911432,\n",
       "  0.0038407084066420794,\n",
       "  0.004857379477471113,\n",
       "  0.0052995760925114155,\n",
       "  0.005085841286927462,\n",
       "  0.005048636347055435,\n",
       "  0.005496112629771233,\n",
       "  0.006153235677629709,\n",
       "  0.006986293010413647,\n",
       "  0.0076436917297542095,\n",
       "  0.008215954527258873,\n",
       "  0.00855847354978323,\n",
       "  0.008941441774368286,\n",
       "  0.009550477378070354,\n",
       "  0.01003536581993103,\n",
       "  0.010470263659954071,\n",
       "  0.01073467917740345,\n",
       "  0.011078129522502422,\n",
       "  0.011284939013421535,\n",
       "  0.011175614781677723,\n",
       "  0.011399936862289906,\n",
       "  0.01186662632972002,\n",
       "  0.01254887692630291,\n",
       "  0.013081650249660015,\n",
       "  0.013297471217811108,\n",
       "  0.013465535826981068,\n",
       "  0.013754420913755894,\n",
       "  0.014316001906991005,\n",
       "  0.014798729680478573,\n",
       "  0.015432962216436863,\n",
       "  0.015729280188679695,\n",
       "  0.015803338959813118,\n",
       "  0.01613130234181881,\n",
       "  0.016497045755386353,\n",
       "  0.01629425212740898,\n",
       "  0.015646055340766907,\n",
       "  0.015122301876544952,\n",
       "  0.014129768125712872,\n",
       "  0.01313089020550251,\n",
       "  0.012146483175456524,\n",
       "  0.011512239463627338,\n",
       "  0.0108731584623456,\n",
       "  0.00954598281532526,\n",
       "  0.008601855486631393,\n",
       "  0.008506624959409237,\n",
       "  0.00823928415775299,\n",
       "  0.007354419678449631,\n",
       "  0.006509540136903524,\n",
       "  0.005356005392968655,\n",
       "  0.004662693478167057,\n",
       "  0.00401820195838809,\n",
       "  0.0031150225549936295,\n",
       "  0.002064717933535576,\n",
       "  0.0002408671280136332,\n",
       "  -0.0013644446153193712,\n",
       "  -0.0021989885717630386,\n",
       "  -0.0020798826590180397,\n",
       "  -0.0023344631772488356,\n",
       "  -0.0032784556970000267,\n",
       "  -0.004272775258868933,\n",
       "  -0.00494915246963501,\n",
       "  -0.004939193371683359,\n",
       "  -0.004870282951742411,\n",
       "  -0.004780117888003588,\n",
       "  -0.005239279009401798,\n",
       "  -0.006342872511595488,\n",
       "  -0.0072431559674441814,\n",
       "  -0.007820558734238148,\n",
       "  -0.008462007157504559,\n",
       "  -0.009039782918989658,\n",
       "  -0.009682011790573597,\n",
       "  -0.010204188525676727,\n",
       "  -0.010341119952499866,\n",
       "  -0.01050083339214325,\n",
       "  -0.010787085629999638,\n",
       "  -0.011395550332963467,\n",
       "  -0.011868849396705627,\n",
       "  -0.011768217198550701,\n",
       "  -0.011188174597918987,\n",
       "  -0.010797034949064255,\n",
       "  -0.01115666888654232,\n",
       "  -0.011750747449696064,\n",
       "  -0.012209520675241947,\n",
       "  -0.012526260688900948,\n",
       "  -0.012617538683116436,\n",
       "  -0.01247444748878479,\n",
       "  -0.01242405828088522,\n",
       "  -0.013365210965275764,\n",
       "  -0.014334515668451786,\n",
       "  -0.014506451785564423,\n",
       "  -0.01399960182607174,\n",
       "  -0.012852937914431095,\n",
       "  -0.012305707670748234,\n",
       "  -0.012341543100774288,\n",
       "  -0.012662005610764027,\n",
       "  -0.012665867805480957,\n",
       "  -0.012256242334842682,\n",
       "  -0.011556419543921947,\n",
       "  -0.011186357587575912,\n",
       "  -0.011515920050442219,\n",
       "  -0.01175619661808014,\n",
       "  -0.011561117134988308,\n",
       "  -0.010529701597988605,\n",
       "  -0.009992898441851139,\n",
       "  -0.01034222450107336,\n",
       "  -0.01073344424366951,\n",
       "  -0.010345232672989368,\n",
       "  -0.009256985038518906,\n",
       "  -0.008639000356197357,\n",
       "  -0.009127194993197918,\n",
       "  -0.010127418674528599,\n",
       "  -0.010094881057739258,\n",
       "  -0.008851898834109306,\n",
       "  -0.007811266928911209,\n",
       "  -0.007975105196237564,\n",
       "  -0.008984005078673363,\n",
       "  -0.01031941082328558,\n",
       "  -0.010465363040566444,\n",
       "  -0.00929061695933342,\n",
       "  -0.007898284122347832,\n",
       "  -0.0074595194309949875,\n",
       "  -0.00867004506289959,\n",
       "  -0.009931865148246288,\n",
       "  -0.010067529045045376,\n",
       "  -0.009129437617957592,\n",
       "  -0.009028530679643154,\n",
       "  -0.010077765211462975,\n",
       "  -0.010918989777565002,\n",
       "  -0.011082710698246956,\n",
       "  -0.010427952744066715,\n",
       "  -0.009699001908302307,\n",
       "  -0.009486019611358643,\n",
       "  -0.009790251031517982,\n",
       "  -0.008249383419752121,\n",
       "  -0.002371458802372217,\n",
       "  0.007032687775790691,\n",
       "  0.016266021877527237,\n",
       "  0.02209959365427494,\n",
       "  0.024424057453870773,\n",
       "  0.025478754192590714,\n",
       "  0.028312887996435165,\n",
       "  0.033839862793684006,\n",
       "  0.04033088684082031,\n",
       "  0.045442380011081696,\n",
       "  0.04872922971844673,\n",
       "  0.050308480858802795,\n",
       "  0.05085325986146927,\n",
       "  0.05237250402569771,\n",
       "  0.053936734795570374,\n",
       "  0.05500391125679016,\n",
       "  0.05650221183896065,\n",
       "  0.05881105363368988,\n",
       "  0.061218615621328354,\n",
       "  0.0609392374753952,\n",
       "  0.05821869894862175,\n",
       "  0.055068489164114,\n",
       "  0.0538344569504261,\n",
       "  0.05426821857690811,\n",
       "  0.053587887436151505,\n",
       "  0.05077267065644264,\n",
       "  0.046036310493946075,\n",
       "  0.04162243381142616,\n",
       "  0.03825535625219345,\n",
       "  0.035834748297929764,\n",
       "  0.033830609172582626,\n",
       "  0.03083406761288643,\n",
       "  0.02663971297442913,\n",
       "  0.022282473742961884,\n",
       "  0.018982844427227974,\n",
       "  0.0163529384881258,\n",
       "  0.013653872534632683,\n",
       "  0.01129285991191864,\n",
       "  0.009566598571836948,\n",
       "  0.007376692723482847,\n",
       "  0.004264854826033115,\n",
       "  0.0008719125180505216,\n",
       "  -0.0019111339934170246,\n",
       "  -0.0038304352201521397,\n",
       "  -0.004940432030707598,\n",
       "  -0.006200624164193869,\n",
       "  -0.007976604625582695,\n",
       "  -0.010183549486100674,\n",
       "  -0.013214092701673508,\n",
       "  -0.015616807155311108,\n",
       "  -0.01708742044866085,\n",
       "  -0.017846766859292984,\n",
       "  -0.01809116080403328,\n",
       "  -0.01902516931295395,\n",
       "  -0.020306142047047615,\n",
       "  -0.021573763340711594,\n",
       "  -0.02316540852189064,\n",
       "  -0.02384491078555584,\n",
       "  -0.02326534502208233,\n",
       "  -0.022297972813248634,\n",
       "  -0.02215520292520523,\n",
       "  -0.02292078360915184,\n",
       "  -0.023602670058608055,\n",
       "  -0.0237986259162426,\n",
       "  -0.023595649749040604,\n",
       "  -0.023993123322725296,\n",
       "  -0.024727048352360725,\n",
       "  -0.025842037051916122,\n",
       "  -0.02681679278612137,\n",
       "  -0.02739572525024414,\n",
       "  -0.02779546193778515,\n",
       "  -0.027816444635391235,\n",
       "  -0.027942275628447533,\n",
       "  -0.028050007298588753,\n",
       "  -0.027984585613012314,\n",
       "  -0.02774854376912117,\n",
       "  -0.027791325002908707,\n",
       "  -0.027504146099090576,\n",
       "  -0.02641003578901291,\n",
       "  -0.02455647476017475,\n",
       "  -0.02321154810488224,\n",
       "  -0.02399078756570816,\n",
       "  -0.025941815227270126,\n",
       "  -0.027070697396993637,\n",
       "  -0.025827068835496902,\n",
       "  -0.022658342495560646,\n",
       "  -0.0198291577398777,\n",
       "  -0.019306287169456482,\n",
       "  -0.02066846936941147,\n",
       "  -0.022272426635026932,\n",
       "  -0.02232411690056324,\n",
       "  -0.019752681255340576,\n",
       "  -0.016488345339894295,\n",
       "  -0.014064990915358067,\n",
       "  -0.013016186654567719,\n",
       "  -0.013297153636813164,\n",
       "  -0.013745413161814213,\n",
       "  -0.01390238106250763,\n",
       "  -0.0127262519672513,\n",
       "  -0.010380684398114681,\n",
       "  -0.007990348152816296,\n",
       "  -0.006728229578584433,\n",
       "  -0.007122035138309002,\n",
       "  -0.008027247153222561,\n",
       "  -0.008378291502594948,\n",
       "  -0.007204741705209017,\n",
       "  -0.005282960832118988,\n",
       "  -0.003950399346649647,\n",
       "  -0.003942639566957951,\n",
       "  -0.005234002601355314,\n",
       "  -0.006447463762015104,\n",
       "  -0.006371409632265568,\n",
       "  -0.004804542753845453,\n",
       "  -0.0030982953030616045,\n",
       "  -0.0027386127039790154,\n",
       "  -0.0041203573346138,\n",
       "  -0.0057107871398329735,\n",
       "  -0.006428046151995659,\n",
       "  -0.005894944071769714,\n",
       "  -0.004370593931525946,\n",
       "  -0.004032952710986137,\n",
       "  -0.005548261571675539,\n",
       "  -0.008050739765167236,\n",
       "  -0.010220173746347427,\n",
       "  -0.010690962895751,\n",
       "  -0.009279132820665836,\n",
       "  -0.007615281268954277,\n",
       "  -0.007942109368741512,\n",
       "  -0.010573817417025566,\n",
       "  -0.01304204948246479,\n",
       "  -0.01449836790561676,\n",
       "  -0.014789199456572533,\n",
       "  -0.01319427601993084,\n",
       "  -0.01151812169700861,\n",
       "  -0.011760103516280651,\n",
       "  -0.014105312526226044,\n",
       "  -0.016172366216778755,\n",
       "  -0.016748519614338875,\n",
       "  -0.016962319612503052,\n",
       "  -0.016727499663829803,\n",
       "  -0.015101605094969273,\n",
       "  -0.014573742635548115,\n",
       "  -0.014683435671031475,\n",
       "  -0.009704574011266232,\n",
       "  0.0013774075778201222,\n",
       "  0.014694903045892715,\n",
       "  0.024016009643673897,\n",
       "  0.027158236131072044,\n",
       "  0.02679077535867691,\n",
       "  0.027603818103671074,\n",
       "  0.03455284237861633,\n",
       "  0.04565427079796791,\n",
       "  0.05439985170960426,\n",
       "  0.05765484273433685,\n",
       "  0.05708463117480278,\n",
       "  0.05636942386627197,\n",
       "  0.058664362877607346,\n",
       "  0.06273316591978073,\n",
       "  0.06624142825603485,\n",
       "  0.0687006264925003,\n",
       "  0.06958993524312973,\n",
       "  0.06864020973443985,\n",
       "  0.06642401963472366,\n",
       "  0.06506902724504471,\n",
       "  0.06510168313980103,\n",
       "  0.06567472964525223,\n",
       "  0.06553155928850174,\n",
       "  0.06437704712152481,\n",
       "  0.061310961842536926,\n",
       "  0.05575353279709816,\n",
       "  0.05066809803247452,\n",
       "  0.047130730003118515,\n",
       "  0.04474596679210663,\n",
       "  0.04209846630692482,\n",
       "  0.03784104064106941,\n",
       "  0.03233515843749046,\n",
       "  0.02701006643474102,\n",
       "  0.023766404017806053,\n",
       "  0.02192569710314274,\n",
       "  0.0199736338108778,\n",
       "  0.017183324322104454,\n",
       "  0.014296370558440685,\n",
       "  0.011616178788244724,\n",
       "  0.00907362811267376,\n",
       "  0.006682924926280975,\n",
       "  0.0034466495271772146,\n",
       "  7.710661884630099e-05,\n",
       "  -0.0019449226092547178,\n",
       "  -0.0022919541224837303,\n",
       "  -0.0026710976380854845,\n",
       "  -0.004496019333600998,\n",
       "  -0.008034289814531803,\n",
       "  -0.011660697869956493,\n",
       "  -0.013424376025795937,\n",
       "  -0.014375566504895687,\n",
       "  -0.01607174053788185,\n",
       "  -0.019230106845498085,\n",
       "  -0.022565841674804688,\n",
       "  -0.024477306753396988,\n",
       "  -0.025168534368276596,\n",
       "  -0.02608502469956875,\n",
       "  -0.02708892710506916,\n",
       "  -0.028105054050683975,\n",
       "  -0.029473617672920227,\n",
       "  -0.030146973207592964,\n",
       "  -0.030675319954752922,\n",
       "  -0.03139263391494751,\n",
       "  -0.032898783683776855,\n",
       "  -0.034988127648830414,\n",
       "  -0.0362548753619194,\n",
       "  -0.036435917019844055,\n",
       "  -0.03619915619492531,\n",
       "  -0.036761969327926636,\n",
       "  -0.03819071128964424,\n",
       "  -0.0398583710193634,\n",
       "  -0.040762849152088165,\n",
       "  -0.04090623930096626,\n",
       "  -0.040071528404951096,\n",
       "  -0.03847112879157066,\n",
       "  -0.03782014176249504,\n",
       "  -0.03793898969888687,\n",
       "  -0.037708576768636703,\n",
       "  -0.035939864814281464,\n",
       "  -0.033109862357378006,\n",
       "  -0.03107369691133499,\n",
       "  -0.03056030161678791,\n",
       "  -0.031047837808728218,\n",
       "  -0.0309887882322073,\n",
       "  -0.029549939557909966,\n",
       "  -0.02683120034635067,\n",
       "  -0.02408241294324398,\n",
       "  -0.02255995012819767,\n",
       "  -0.022417254745960236,\n",
       "  -0.02235773205757141,\n",
       "  -0.020664948970079422,\n",
       "  -0.0174860842525959,\n",
       "  -0.01394347008317709,\n",
       "  -0.011293210089206696,\n",
       "  -0.010201657190918922,\n",
       "  -0.010548923164606094,\n",
       "  -0.010746538639068604,\n",
       "  -0.009377013891935349,\n",
       "  -0.00671512121334672,\n",
       "  -0.004212547559291124,\n",
       "  -0.003607960185036063,\n",
       "  -0.004782538861036301,\n",
       "  -0.006442764308303595,\n",
       "  -0.006992385722696781,\n",
       "  -0.0059850481338799,\n",
       "  -0.003939089830964804,\n",
       "  -0.001977140549570322,\n",
       "  -0.001343967393040657,\n",
       "  -0.002072311006486416,\n",
       "  -0.004076803103089333,\n",
       "  -0.0054962667636573315,\n",
       "  -0.005477545782923698,\n",
       "  -0.004511644132435322,\n",
       "  -0.0029663043096661568,\n",
       "  -0.0026253818068653345,\n",
       "  -0.0045438362285494804,\n",
       "  -0.007841164246201515,\n",
       "  -0.009863581508398056,\n",
       "  -0.009503430686891079,\n",
       "  -0.007292094640433788,\n",
       "  -0.005581898149102926,\n",
       "  -0.00572754954919219,\n",
       "  -0.007918676361441612,\n",
       "  -0.011773064732551575,\n",
       "  -0.013900644145905972,\n",
       "  -0.013377287425100803,\n",
       "  -0.011262242682278156,\n",
       "  -0.009251194074749947,\n",
       "  -0.009218993596732616,\n",
       "  -0.011407658457756042,\n",
       "  -0.013867916539311409,\n",
       "  -0.01566241681575775,\n",
       "  -0.01705373078584671,\n",
       "  -0.017342591658234596,\n",
       "  -0.01711631380021572,\n",
       "  -0.015730202198028564,\n",
       "  -0.014481413178145885,\n",
       "  -0.015046822838485241,\n",
       "  -0.016709893941879272,\n",
       "  -0.019647743552923203,\n",
       "  -0.021297790110111237,\n",
       "  -0.020131144672632217,\n",
       "  -0.017053352668881416,\n",
       "  -0.015178864821791649,\n",
       "  -0.014898995868861675,\n",
       "  -0.007926525548100471,\n",
       "  0.007658307906240225,\n",
       "  0.02387530915439129,\n",
       "  0.032915838062763214,\n",
       "  0.03276703134179115,\n",
       "  0.028979146853089333,\n",
       "  0.030244002118706703,\n",
       "  0.04112939164042473,\n",
       "  0.057513199746608734,\n",
       "  0.06935670971870422,\n",
       "  0.07032661885023117,\n",
       "  0.06403644382953644,\n",
       "  0.058343518525362015,\n",
       "  0.05965639650821686,\n",
       "  0.06836968660354614,\n",
       "  0.07796237617731094,\n",
       "  0.08176864683628082,\n",
       "  0.07875701785087585,\n",
       "  0.07303887605667114,\n",
       "  0.0689784437417984,\n",
       "  0.06856782734394073,\n",
       "  0.07107977569103241,\n",
       "  0.07370861619710922,\n",
       "  0.07362590730190277,\n",
       "  0.06991467624902725,\n",
       "  0.06304077059030533,\n",
       "  0.054901592433452606,\n",
       "  0.04900792986154556,\n",
       "  0.04787911847233772,\n",
       "  0.04878338426351547,\n",
       "  0.04760389029979706,\n",
       "  0.0422869510948658,\n",
       "  0.033026061952114105,\n",
       "  0.02499515749514103,\n",
       "  0.022507112473249435,\n",
       "  0.025474879890680313,\n",
       "  0.02830999344587326,\n",
       "  0.025492681190371513,\n",
       "  0.017879493534564972,\n",
       "  0.00987145584076643,\n",
       "  0.005817166529595852,\n",
       "  0.0055924067273736,\n",
       "  0.006320137996226549,\n",
       "  0.006418348290026188,\n",
       "  0.005712341517210007,\n",
       "  0.0036564816255122423,\n",
       "  0.0011062014382332563,\n",
       "  -0.0012466482585296035,\n",
       "  -0.0034834330435842276,\n",
       "  -0.004680677782744169,\n",
       "  -0.005502485670149326,\n",
       "  -0.006772320251911879,\n",
       "  -0.008775697089731693,\n",
       "  -0.012305356562137604,\n",
       "  -0.016747508198022842,\n",
       "  -0.020035304129123688,\n",
       "  -0.022582056000828743,\n",
       "  -0.024796292185783386,\n",
       "  -0.026144998148083687,\n",
       "  -0.027269186452031136,\n",
       "  -0.027844490483403206,\n",
       "  -0.028873486444354057,\n",
       "  -0.03175728768110275,\n",
       "  -0.03500282019376755,\n",
       "  -0.03751197084784508,\n",
       "  -0.03942161425948143,\n",
       "  -0.04045218974351883,\n",
       "  -0.04139082133769989,\n",
       "  -0.0421040840446949,\n",
       "  -0.04312487691640854,\n",
       "  -0.04580635204911232,\n",
       "  -0.04896227642893791,\n",
       "  -0.051074545830488205,\n",
       "  -0.05103124678134918,\n",
       "  -0.04908032342791557,\n",
       "  -0.046611059457063675,\n",
       "  -0.045247845351696014,\n",
       "  -0.04665777087211609,\n",
       "  -0.04913703352212906,\n",
       "  -0.04872078076004982,\n",
       "  -0.044913556426763535,\n",
       "  -0.039751701056957245,\n",
       "  -0.035978417843580246,\n",
       "  -0.03547295928001404,\n",
       "  -0.03733748570084572,\n",
       "  -0.03910934552550316,\n",
       "  -0.0374431237578392,\n",
       "  -0.031908679753541946,\n",
       "  -0.02551208809018135,\n",
       "  -0.020833661779761314,\n",
       "  -0.01947305165231228,\n",
       "  -0.02043248899281025,\n",
       "  -0.019942544400691986,\n",
       "  -0.016500236466526985,\n",
       "  -0.011955776251852512,\n",
       "  -0.00899701938033104,\n",
       "  -0.008831888437271118,\n",
       "  -0.00943841878324747,\n",
       "  -0.008875534869730473,\n",
       "  -0.00724285701289773,\n",
       "  -0.005589076317846775,\n",
       "  -0.004971797578036785,\n",
       "  -0.005263511091470718,\n",
       "  -0.004997878335416317,\n",
       "  -0.003248790046200156,\n",
       "  -0.0015694856410846114,\n",
       "  -0.0014650772791355848,\n",
       "  -0.00237439782358706,\n",
       "  -0.003004421480000019,\n",
       "  -0.003099375870078802,\n",
       "  -0.0029809195548295975,\n",
       "  -0.0031350008212029934,\n",
       "  -0.0037645576521754265,\n",
       "  -0.004261964466422796,\n",
       "  -0.00446501886472106,\n",
       "  -0.004459715913981199,\n",
       "  -0.005892354529350996,\n",
       "  -0.008438188582658768,\n",
       "  -0.008838680572807789,\n",
       "  -0.006685062311589718,\n",
       "  -0.0034594826865941286,\n",
       "  -0.002382473321631551,\n",
       "  -0.005606946535408497,\n",
       "  -0.010272994637489319,\n",
       "  -0.012165961787104607,\n",
       "  -0.010098699480295181,\n",
       "  -0.0062937261536717415,\n",
       "  -0.00458805775269866,\n",
       "  -0.007097921799868345,\n",
       "  -0.011674955487251282,\n",
       "  -0.014841029420495033,\n",
       "  -0.014090778306126595,\n",
       "  -0.010814640671014786,\n",
       "  -0.008542219176888466,\n",
       "  -0.009260699152946472,\n",
       "  -0.012340668588876724,\n",
       "  -0.015165426768362522,\n",
       "  -0.016095779836177826,\n",
       "  -0.013892797753214836,\n",
       "  -0.011335312388837337,\n",
       "  -0.011545293033123016,\n",
       "  -0.014542915858328342,\n",
       "  -0.01782129891216755,\n",
       "  -0.0190911702811718,\n",
       "  -0.018860794603824615,\n",
       "  -0.01788974180817604,\n",
       "  -0.01818673498928547,\n",
       "  -0.01375710591673851,\n",
       "  0.0015359210083261132,\n",
       "  0.022812558338046074,\n",
       "  0.03838014230132103,\n",
       "  0.03987036645412445,\n",
       "  0.03194700554013252,\n",
       "  0.02699131891131401,\n",
       "  0.034715455025434494,\n",
       "  0.05302823707461357,\n",
       "  0.07156004011631012,\n",
       "  0.07850125432014465,\n",
       "  0.07175730168819427,\n",
       "  0.060774724930524826,\n",
       "  0.05745309218764305,\n",
       "  0.06551989912986755,\n",
       "  0.07905007898807526,\n",
       "  0.08928696066141129,\n",
       "  0.08967064321041107,\n",
       "  0.0822877511382103,\n",
       "  0.0722522884607315,\n",
       "  0.06581410020589828,\n",
       "  0.0659923404455185,\n",
       "  0.0714484378695488,\n",
       "  0.07780597358942032,\n",
       "  0.07871782034635544,\n",
       "  0.07041560113430023,\n",
       "  0.05516701564192772,\n",
       "  0.041666727513074875,\n",
       "  0.036655623465776443,\n",
       "  0.040848616510629654,\n",
       "  0.04649883136153221,\n",
       "  0.04528985545039177,\n",
       "  0.03548372909426689,\n",
       "  0.02264317125082016,\n",
       "  0.014325781725347042,\n",
       "  0.013229493983089924,\n",
       "  0.017682794481515884,\n",
       "  0.02181587740778923,\n",
       "  0.02004823088645935,\n",
       "  0.012111441232264042,\n",
       "  0.002937190467491746,\n",
       "  -0.0036904732696712017,\n",
       "  -0.006264509167522192,\n",
       "  -0.005145040340721607,\n",
       "  -0.0028326406609266996,\n",
       "  -0.0024572417605668306,\n",
       "  -0.005360608920454979,\n",
       "  -0.009390156716108322,\n",
       "  -0.012087889946997166,\n",
       "  -0.011984681710600853,\n",
       "  -0.010309692472219467,\n",
       "  -0.009568475186824799,\n",
       "  -0.010827149264514446,\n",
       "  -0.013188153505325317,\n",
       "  -0.015615695156157017,\n",
       "  -0.018298843875527382,\n",
       "  -0.02080644853413105,\n",
       "  -0.022356262430548668,\n",
       "  -0.023005541414022446,\n",
       "  -0.023296093568205833,\n",
       "  -0.02359519526362419,\n",
       "  -0.025564514100551605,\n",
       "  -0.029870983213186264,\n",
       "  -0.03433377668261528,\n",
       "  -0.03670854866504669,\n",
       "  -0.036537736654281616,\n",
       "  -0.03532950580120087,\n",
       "  -0.035794276744127274,\n",
       "  -0.0392150804400444,\n",
       "  -0.04363375902175903,\n",
       "  -0.04619487747550011,\n",
       "  -0.04581962898373604,\n",
       "  -0.04442685469985008,\n",
       "  -0.04451121389865875,\n",
       "  -0.04609980434179306,\n",
       "  -0.04739685356616974,\n",
       "  -0.04770297184586525,\n",
       "  -0.047626182436943054,\n",
       "  -0.04724675789475441,\n",
       "  -0.04681994765996933,\n",
       "  -0.04597083851695061,\n",
       "  -0.04356670007109642,\n",
       "  -0.04005271941423416,\n",
       "  -0.03667942062020302,\n",
       "  -0.03447691351175308,\n",
       "  -0.03381181135773659,\n",
       "  -0.03341226279735565,\n",
       "  -0.03215837851166725,\n",
       "  -0.030057983472943306,\n",
       "  -0.026854747906327248,\n",
       "  -0.022508831694722176,\n",
       "  -0.018033325672149658,\n",
       "  -0.014761275611817837,\n",
       "  -0.013932812958955765,\n",
       "  -0.01455171313136816,\n",
       "  -0.014139082282781601,\n",
       "  -0.011335127055644989,\n",
       "  -0.006843130569905043,\n",
       "  -0.0033903303556144238,\n",
       "  -0.0026557513047009706,\n",
       "  -0.004725937731564045,\n",
       "  -0.007239981554448605,\n",
       "  -0.007075812667608261,\n",
       "  -0.004295462276786566,\n",
       "  -0.0011114180088043213,\n",
       "  0.0004937277990393341,\n",
       "  -0.0003117277519777417,\n",
       "  -0.0028059142641723156,\n",
       "  -0.004549408331513405,\n",
       "  -0.004813524894416332,\n",
       "  -0.004603574518114328,\n",
       "  -0.00454039266332984,\n",
       "  -0.005050479434430599,\n",
       "  -0.005511583760380745,\n",
       "  -0.005442769732326269,\n",
       "  -0.004832681268453598,\n",
       "  -0.004501268267631531,\n",
       "  -0.005971258040517569,\n",
       "  -0.008552655577659607,\n",
       "  -0.01036512665450573,\n",
       "  -0.010361594147980213,\n",
       "  -0.008803540840744972,\n",
       "  -0.007852144539356232,\n",
       "  -0.00953989289700985,\n",
       "  -0.01287490501999855,\n",
       "  -0.014553721062839031,\n",
       "  -0.013121086172759533,\n",
       "  -0.009913555346429348,\n",
       "  -0.007789148949086666,\n",
       "  -0.008813058957457542,\n",
       "  -0.012063802219927311,\n",
       "  -0.015718283131718636,\n",
       "  -0.016825852915644646,\n",
       "  -0.01417776569724083,\n",
       "  -0.010928892530500889,\n",
       "  -0.010320214554667473,\n",
       "  -0.012864883989095688,\n",
       "  -0.01603725366294384,\n",
       "  -0.017557818442583084,\n",
       "  -0.016770582646131516,\n",
       "  -0.014752709306776524,\n",
       "  -0.01376039907336235,\n",
       "  -0.01468526292592287,\n",
       "  -0.016342539340257645,\n",
       "  -0.01837053708732128,\n",
       "  -0.019186673685908318,\n",
       "  -0.01935780979692936,\n",
       "  -0.018520278856158257,\n",
       "  -0.006582967471331358,\n",
       "  0.015912117436528206,\n",
       "  0.037075091153383255,\n",
       "  0.046115677803754807,\n",
       "  0.03929717838764191,\n",
       "  0.02842038683593273,\n",
       "  0.028770102187991142,\n",
       "  0.04497377946972847,\n",
       "  0.06892101466655731,\n",
       "  0.0857841819524765,\n",
       "  0.08552157133817673,\n",
       "  0.07357844710350037,\n",
       "  0.06327568739652634,\n",
       "  0.06535578519105911,\n",
       "  0.08010264486074448,\n",
       "  0.09551545232534409,\n",
       "  0.1006111279129982,\n",
       "  0.09307561069726944,\n",
       "  0.08046570420265198,\n",
       "  0.07262735068798065,\n",
       "  0.07317038625478745,\n",
       "  0.07947050034999847,\n",
       "  0.08538705855607986,\n",
       "  0.08481074124574661,\n",
       "  0.07551851868629456,\n",
       "  0.06178358942270279,\n",
       "  0.050957512110471725,\n",
       "  0.04748193547129631,\n",
       "  0.04972798377275467,\n",
       "  0.05110805109143257,\n",
       "  0.04627741500735283,\n",
       "  0.036081790924072266,\n",
       "  0.0253913551568985,\n",
       "  0.018966250121593475,\n",
       "  0.01862836256623268,\n",
       "  0.021199263632297516,\n",
       "  0.02148759923875332,\n",
       "  0.016793565824627876,\n",
       "  0.009182102978229523,\n",
       "  0.0030771426390856504,\n",
       "  -0.00037793838419020176,\n",
       "  -0.0028340346179902554,\n",
       "  -0.005715833976864815,\n",
       "  -0.008892213925719261,\n",
       "  -0.011339429765939713,\n",
       "  -0.012006392702460289,\n",
       "  -0.011273390613496304,\n",
       "  -0.011243165470659733,\n",
       "  -0.013692350126802921,\n",
       "  -0.017667170614004135,\n",
       "  -0.020416157320141792,\n",
       "  -0.020486682653427124,\n",
       "  -0.017535744234919548,\n",
       "  -0.01468630786985159,\n",
       "  -0.015453388914465904,\n",
       "  -0.020100858062505722,\n",
       "  -0.02584734372794628,\n",
       "  -0.029138045385479927,\n",
       "  -0.028972085565328598,\n",
       "  -0.026304487138986588,\n",
       "  -0.02426314726471901,\n",
       "  -0.025977276265621185,\n",
       "  -0.03203391283750534,\n",
       "  -0.03931649774312973,\n",
       "  -0.043154846876859665,\n",
       "  -0.042011287063360214,\n",
       "  -0.03843497484922409,\n",
       "  -0.036711085587739944,\n",
       "  -0.03954807296395302,\n",
       "  -0.045564256608486176,\n",
       "  -0.05080925673246384,\n",
       "  -0.05206923931837082,\n",
       "  -0.04960883781313896,\n",
       "  -0.046262480318546295,\n",
       "  -0.04510655626654625,\n",
       "  -0.046988487243652344,\n",
       "  -0.04979332163929939,\n",
       "  -0.051177702844142914,\n",
       "  -0.04962228611111641,\n",
       "  -0.04638109356164932,\n",
       "  -0.043452370911836624,\n",
       "  -0.04159662872552872,\n",
       "  -0.04067574068903923,\n",
       "  -0.039307985454797745,\n",
       "  -0.03704680874943733,\n",
       "  -0.034225765615701675,\n",
       "  -0.03130076453089714,\n",
       "  -0.028687387704849243,\n",
       "  -0.02620340883731842,\n",
       "  -0.023726027458906174,\n",
       "  -0.021248919889330864,\n",
       "  -0.018712623044848442,\n",
       "  -0.016140693798661232,\n",
       "  -0.014083965681493282,\n",
       "  -0.01202941033989191,\n",
       "  -0.010078639723360538,\n",
       "  -0.008485673926770687,\n",
       "  -0.0066466922871768475,\n",
       "  -0.004885034170001745,\n",
       "  -0.0031769077759236097,\n",
       "  -0.002478675451129675,\n",
       "  -0.002677775686606765,\n",
       "  -0.003354480257257819,\n",
       "  -0.003524010069668293,\n",
       "  -0.002408143598586321,\n",
       "  -0.0009911955567076802,\n",
       "  -0.0002880727988667786,\n",
       "  -0.0014340383931994438,\n",
       "  -0.003409114433452487,\n",
       "  -0.00502112228423357,\n",
       "  -0.005337494425475597,\n",
       "  -0.004497528541833162,\n",
       "  -0.0036394326016306877,\n",
       "  -0.004047286231070757,\n",
       "  ...],\n",
       " 'predicted': 5}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "vRtajzvTabeH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1, 1, 4, 5]\n",
      "[5, 1, 1, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "y_true = [config.label2id[name] for name in result[\"emotion\"]]\n",
    "\n",
    "\n",
    "y_pred = result[\"predicted\"]\n",
    "\n",
    "print(y_true[:5])\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1, 1, 4, 5, 2, 0, 3, 1, 5, 1, 3, 5, 0, 4, 0, 1, 2, 2, 5, 0, 0, 1, 5, 3, 0, 4, 4, 1, 0, 3, 3, 4, 5, 1, 5, 5, 0, 3, 1, 2, 3, 3, 0, 3, 0, 1, 2, 3, 5, 1, 5, 1, 3, 4, 1, 4, 1, 2, 1, 5, 3, 2, 0, 3, 4, 0, 1, 1, 2, 5, 2, 1, 2, 5, 5, 1, 0, 0, 4, 3, 3, 4, 2, 3, 0, 0, 4, 1, 1, 4, 1, 1, 4, 5, 5, 5, 1, 0, 1, 2, 4, 5, 3, 3, 4, 0, 2, 3, 2, 4, 4, 2, 5, 2, 4, 5, 5, 4, 0, 4, 4, 5, 4, 3, 2, 3, 5, 0, 3, 1, 1, 5, 0, 3, 2, 3, 0, 2, 4, 2, 3, 3, 3, 2, 4, 1, 3, 5, 3, 1, 3, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "print(result['predicted'])\n",
    "#config.label2id['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "tUt5rIppXrzl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.73      0.64      0.68        25\n",
      "     disgust       0.83      0.96      0.89        26\n",
      "        fear       0.90      0.73      0.81        26\n",
      "       happy       0.77      0.92      0.84        26\n",
      "          ps       0.96      0.88      0.92        26\n",
      "         sad       0.88      0.92      0.90        25\n",
      "\n",
      "    accuracy                           0.84       154\n",
      "   macro avg       0.85      0.84      0.84       154\n",
      "weighted avg       0.85      0.84      0.84       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ylb2Z6Xke2ro"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "EQzCioPhWIiX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from transformers import AutoConfig, Wav2Vec2Processor\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DocavTvQWIr_"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d2a13d35694d4ba8ab109664ce453a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file preprocessor_config.json from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef50f3d66c514dc199b19857609dc7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/398 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f35a36752fa4ccda8b3b693d0e8dd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/config.json\n",
      "/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"mean\",\n",
      "  \"ctc_zero_infinity\": true,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.0,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"disgust\",\n",
      "    \"2\": \"fear\",\n",
      "    \"3\": \"happiness\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"disgust\": 1,\n",
      "    \"fear\": 2,\n",
      "    \"happiness\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 54,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 55,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edede4aa9665466a85e57d6c07b24f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/535 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c016ad5c24934f6fa014377d703555ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a026e3eabd4410ea5ca2be42ace525e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/309 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/vocab.json\n",
      "loading file tokenizer_config.json from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/tokenizer_config.json\n",
      "loading file added_tokens.json from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/added_tokens.json\n",
      "loading file special_tokens_map.json from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/special_tokens_map.json\n",
      "loading configuration file config.json from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"mean\",\n",
      "  \"ctc_zero_infinity\": true,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.0,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"disgust\",\n",
      "    \"2\": \"fear\",\n",
      "    \"3\": \"happiness\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"disgust\": 1,\n",
      "    \"fear\": 2,\n",
      "    \"happiness\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 54,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 55,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "loading configuration file config.json from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"lighteternal/wav2vec2-large-xlsr-53-greek\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"mean\",\n",
      "  \"ctc_zero_infinity\": true,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.0,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"disgust\",\n",
      "    \"2\": \"fear\",\n",
      "    \"3\": \"happiness\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"disgust\": 1,\n",
      "    \"fear\": 2,\n",
      "    \"happiness\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 54,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 55,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415eb58385b046b385f3cd1da711aa18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at content/cache/models--m3hrdadfi--wav2vec2-xlsr-greek-speech-emotion-recognition/snapshots/ed9982a2c7a3fd79a918bac683a9e4cbfbad772e/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing Wav2Vec2ForSpeechClassification.\n",
      "\n",
      "All the weights of Wav2Vec2ForSpeechClassification were initialized from the model checkpoint at m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForSpeechClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name_or_path = \"m3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition\"\n",
    "# config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "model = KNNModel.Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "1SSs95o9WIvK"
   },
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "\n",
    "\n",
    "def predict(path, sampling_rate):\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    features = processor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = features.attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits\n",
    "\n",
    "    scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "    outputs = [{\"Emotion\": config.id2label[i], \"Score\": f\"{round(score * 100, 3):.1f}%\"} for i, score in enumerate(scores)]\n",
    "    return outputs\n",
    "\n",
    "\n",
    "STYLES = \"\"\"\n",
    "<style>\n",
    "div.display_data {\n",
    "    margin: 0 auto;\n",
    "    max-width: 500px;\n",
    "}\n",
    "table.xxx {\n",
    "    margin: 50px !important;\n",
    "    float: right !important;\n",
    "    clear: both !important;\n",
    "}\n",
    "table.xxx td {\n",
    "    min-width: 300px !important;\n",
    "    text-align: center !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\".strip()\n",
    "\n",
    "def prediction(df_row):\n",
    "    path, emotion = df_row[\"path\"], df_row[\"emotion\"]\n",
    "    df = pd.DataFrame([{\"Emotion\": emotion, \"Sentence\": \"    \"}])\n",
    "    setup = {\n",
    "        'border': 2,\n",
    "        'show_dimensions': True,\n",
    "        'justify': 'center',\n",
    "        'classes': 'xxx',\n",
    "        'escape': False,\n",
    "    }\n",
    "    ipd.display(ipd.HTML(STYLES + df.to_html(**setup) + \"<br />\"))\n",
    "    speech, sr = torchaudio.load(path)\n",
    "    speech = speech[0].numpy().squeeze()\n",
    "    speech = librosa.resample(np.asarray(speech), sr, sampling_rate)\n",
    "    ipd.display(ipd.Audio(data=np.asarray(speech), autoplay=True, rate=sampling_rate))\n",
    "\n",
    "    outputs = predict(path, sampling_rate)\n",
    "    r = pd.DataFrame(outputs)\n",
    "    ipd.display(ipd.HTML(STYLES + r.to_html(**setup) + \"<br />\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "UD7oUP20YwYT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_50...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_50...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_25...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_75...</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_10...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  emotion\n",
       "0  ../Stimuli_Intensitätsmorphs/nm04_sad_w02_c_50...      sad\n",
       "1  ../Stimuli_Intensitätsmorphs/nf01_dis_w01_o_50...  disgust\n",
       "2  ../Stimuli_Intensitätsmorphs/nm02_dis_w02_o_25...  disgust\n",
       "3  ../Stimuli_Intensitätsmorphs/nm04_sur_w05_o_75...       ps\n",
       "4  ../Stimuli_Intensitätsmorphs/nf03_sad_w03_o_10...      sad"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"content/data/test.csv\", sep=\"\\t\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "FlJO2LfVWIyT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.display_data {\n",
       "    margin: 0 auto;\n",
       "    max-width: 500px;\n",
       "}\n",
       "table.xxx {\n",
       "    margin: 50px !important;\n",
       "    float: right !important;\n",
       "    clear: both !important;\n",
       "}\n",
       "table.xxx td {\n",
       "    min-width: 300px !important;\n",
       "    text-align: center !important;\n",
       "}\n",
       "</style><table border=\"2\" class=\"dataframe xxx\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2 columns</p><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48229/3971349692.py:54: FutureWarning: Pass orig_sr=44100, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  speech = librosa.resample(np.asarray(speech), sr, sampling_rate)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.display_data {\n",
       "    margin: 0 auto;\n",
       "    max-width: 500px;\n",
       "}\n",
       "table.xxx {\n",
       "    margin: 50px !important;\n",
       "    float: right !important;\n",
       "    clear: both !important;\n",
       "}\n",
       "table.xxx td {\n",
       "    min-width: 300px !important;\n",
       "    text-align: center !important;\n",
       "}\n",
       "</style><table border=\"2\" class=\"dataframe xxx\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>10.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ps</td>\n",
       "      <td>89.1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2 columns</p><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction(test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "hzoKOgpoWI1K"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.display_data {\n",
       "    margin: 0 auto;\n",
       "    max-width: 500px;\n",
       "}\n",
       "table.xxx {\n",
       "    margin: 50px !important;\n",
       "    float: right !important;\n",
       "    clear: both !important;\n",
       "}\n",
       "table.xxx td {\n",
       "    min-width: 300px !important;\n",
       "    text-align: center !important;\n",
       "}\n",
       "</style><table border=\"2\" class=\"dataframe xxx\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2 columns</p><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48229/3211767695.py:54: FutureWarning: Pass orig_sr=44100, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  speech = librosa.resample(np.asarray(speech), sr, sampling_rate)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.display_data {\n",
       "    margin: 0 auto;\n",
       "    max-width: 500px;\n",
       "}\n",
       "table.xxx {\n",
       "    margin: 50px !important;\n",
       "    float: right !important;\n",
       "    clear: both !important;\n",
       "}\n",
       "table.xxx td {\n",
       "    min-width: 300px !important;\n",
       "    text-align: center !important;\n",
       "}\n",
       "</style><table border=\"2\" class=\"dataframe xxx\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>94.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ps</td>\n",
       "      <td>5.1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2 columns</p><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction(test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nqwbTTXSfMO"
   },
   "outputs": [],
   "source": [
    "prediction(test.iloc[2])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Emotion recognition in Greek speech using Wav2Vec2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

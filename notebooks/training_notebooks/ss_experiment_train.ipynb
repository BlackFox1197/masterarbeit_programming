{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 15:27:10.806463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 15:27:11.423117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 15:27:11.423176: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 15:27:11.423181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "from network_models.soundsream_models_and_utils.ss_wrapper_trainer_experiments import ExperimentsTrainer\n",
    "import torch\n",
    "from network_models.soundsream_models_and_utils.ss_encoded_dataset import ss_encoded_dataset_full\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 12\n",
    "models_dir = \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu\"\n",
    "trials_per_model_type = 3\n",
    "epochs_per_model = 1000\n",
    "save_highest_acc_min_acc = 0.5\n",
    "start_lr = 2e-4\n",
    "lr_quotient = 2\n",
    "gc.collect()\n",
    "data_set= ss_encoded_dataset_full(\n",
    "    csvPath=\"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/data/allEncodings_version0_12_1.pkl\", device=\"cuda\")\n",
    "\n",
    "exp_trainer = ExperimentsTrainer(dataset=data_set, device=device, models_dir=models_dir, batch_size=batch_size, trials_per_model_type=trials_per_model_type,\n",
    "                   epochs_per_model=epochs_per_model, start_lr=start_lr, lr_quotient=lr_quotient, save_highest_acc_min_acc=save_highest_acc_min_acc, regularize_dims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.985069; classification loss: 1.997574;  cosine similarity loss: 1.935050\n",
      "[ 1400/ 5482] total-loss: 1.921762; classification loss: 1.917645;  cosine similarity loss: 1.938229\n",
      "[ 2800/ 5482] total-loss: 1.916857; classification loss: 1.908353;  cosine similarity loss: 1.950875\n",
      "[ 4200/ 5482] total-loss: 1.898241; classification loss: 1.891841;  cosine similarity loss: 1.923843\n",
      "[ 5600/ 5482] total-loss: 1.867496; classification loss: 1.864671;  cosine similarity loss: 1.878793\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.226     0.208     0.670    106\n",
      " disgust     0.226     0.000     0.000    106\n",
      "    fear     0.226     0.000     0.000    106\n",
      "   happy     0.226     0.000     0.000    106\n",
      " neutral     0.226     0.242     0.915    106\n",
      "     sad     0.226     0.000     0.000    106\n",
      "surprise     0.226     0.000     0.000    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.226     0.064     0.226    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 22.4%, Avg loss: 1.890970 \n",
      "\n",
      "classification loss: 1.885656;  cosine similarity loss: 1.903369 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.871313; classification loss: 1.866015;  cosine similarity loss: 1.892505\n",
      "[ 1400/ 5482] total-loss: 1.886158; classification loss: 1.871273;  cosine similarity loss: 1.945699\n",
      "[ 2800/ 5482] total-loss: 1.869687; classification loss: 1.864312;  cosine similarity loss: 1.891188\n",
      "[ 4200/ 5482] total-loss: 1.844563; classification loss: 1.837538;  cosine similarity loss: 1.872662\n",
      "[ 5600/ 5482] total-loss: 1.843539; classification loss: 1.825124;  cosine similarity loss: 1.917194\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.228     0.217     0.660    106\n",
      " disgust     0.228     0.000     0.000    106\n",
      "    fear     0.228     0.000     0.000    106\n",
      "   happy     0.228     0.000     0.000    106\n",
      " neutral     0.228     0.236     0.934    106\n",
      "     sad     0.228     0.000     0.000    106\n",
      "surprise     0.228     0.000     0.000    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.228     0.065     0.228    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 22.6%, Avg loss: 1.869358 \n",
      "\n",
      "classification loss: 1.855692;  cosine similarity loss: 1.901247 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.876331; classification loss: 1.875543;  cosine similarity loss: 1.879484\n",
      "[ 1400/ 5482] total-loss: 1.855864; classification loss: 1.845290;  cosine similarity loss: 1.898160\n",
      "[ 2800/ 5482] total-loss: 1.895301; classification loss: 1.894126;  cosine similarity loss: 1.899998\n",
      "[ 4200/ 5482] total-loss: 1.852460; classification loss: 1.832084;  cosine similarity loss: 1.933962\n",
      "[ 5600/ 5482] total-loss: 1.806552; classification loss: 1.794427;  cosine similarity loss: 1.855054\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.240     0.219     0.755    106\n",
      " disgust     0.240     0.000     0.000    106\n",
      "    fear     0.240     0.000     0.000    106\n",
      "   happy     0.240     0.000     0.000    106\n",
      " neutral     0.240     0.260     0.925    106\n",
      "     sad     0.240     0.000     0.000    106\n",
      "surprise     0.240     0.000     0.000    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.240     0.068     0.240    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 23.8%, Avg loss: 1.851353 \n",
      "\n",
      "classification loss: 1.833126;  cosine similarity loss: 1.893883 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.863444; classification loss: 1.853309;  cosine similarity loss: 1.903985\n",
      "[ 1400/ 5482] total-loss: 1.825627; classification loss: 1.815112;  cosine similarity loss: 1.867687\n",
      "[ 2800/ 5482] total-loss: 1.857060; classification loss: 1.834894;  cosine similarity loss: 1.945722\n",
      "[ 4200/ 5482] total-loss: 1.856106; classification loss: 1.845139;  cosine similarity loss: 1.899973\n",
      "[ 5600/ 5482] total-loss: 1.790465; classification loss: 1.762210;  cosine similarity loss: 1.903487\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.252     0.207     0.877    106\n",
      " disgust     0.252     0.000     0.000    106\n",
      "    fear     0.252     0.000     0.000    106\n",
      "   happy     0.252     0.000     0.000    106\n",
      " neutral     0.252     0.321     0.887    106\n",
      "     sad     0.252     0.000     0.000    106\n",
      "surprise     0.252     0.000     0.000    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.252     0.075     0.252    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.828663 \n",
      "\n",
      "classification loss: 1.799451;  cosine similarity loss: 1.896824 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.791924; classification loss: 1.772374;  cosine similarity loss: 1.870122\n",
      "[ 1400/ 5482] total-loss: 1.830034; classification loss: 1.816515;  cosine similarity loss: 1.884108\n",
      "[ 2800/ 5482] total-loss: 1.836814; classification loss: 1.822358;  cosine similarity loss: 1.894635\n",
      "[ 4200/ 5482] total-loss: 1.761433; classification loss: 1.740638;  cosine similarity loss: 1.844616\n",
      "[ 5600/ 5482] total-loss: 1.746327; classification loss: 1.717612;  cosine similarity loss: 1.861187\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.252     0.209     0.925    106\n",
      " disgust     0.252     0.000     0.000    106\n",
      "    fear     0.252     0.000     0.000    106\n",
      "   happy     0.252     0.000     0.000    106\n",
      " neutral     0.252     0.326     0.840    106\n",
      "     sad     0.252     0.000     0.000    106\n",
      "surprise     0.252     0.000     0.000    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.252     0.076     0.252    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.813562 \n",
      "\n",
      "classification loss: 1.777222;  cosine similarity loss: 1.898355 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.732762; classification loss: 1.697838;  cosine similarity loss: 1.872460\n",
      "[ 1400/ 5482] total-loss: 1.831037; classification loss: 1.810767;  cosine similarity loss: 1.912116\n",
      "[ 2800/ 5482] total-loss: 1.746602; classification loss: 1.718171;  cosine similarity loss: 1.860326\n",
      "[ 4200/ 5482] total-loss: 1.753671; classification loss: 1.717676;  cosine similarity loss: 1.897650\n",
      "[ 5600/ 5482] total-loss: 1.852832; classification loss: 1.845684;  cosine similarity loss: 1.881424\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.268     0.228     0.906    106\n",
      " disgust     0.268     0.000     0.000    106\n",
      "    fear     0.268     1.000     0.094    106\n",
      "   happy     0.268     0.000     0.000    106\n",
      " neutral     0.268     0.317     0.877    106\n",
      "     sad     0.268     0.000     0.000    106\n",
      "surprise     0.268     0.000     0.000    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.268     0.221     0.268    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 26.6%, Avg loss: 1.787673 \n",
      "\n",
      "classification loss: 1.743679;  cosine similarity loss: 1.890326 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.750401; classification loss: 1.721202;  cosine similarity loss: 1.867199\n",
      "[ 1400/ 5482] total-loss: 1.810271; classification loss: 1.787063;  cosine similarity loss: 1.903101\n",
      "[ 2800/ 5482] total-loss: 1.796533; classification loss: 1.765193;  cosine similarity loss: 1.921889\n",
      "[ 4200/ 5482] total-loss: 1.756520; classification loss: 1.726091;  cosine similarity loss: 1.878236\n",
      "[ 5600/ 5482] total-loss: 1.718992; classification loss: 1.689425;  cosine similarity loss: 1.837256\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.272     0.153     0.358    106\n",
      " disgust     0.272     0.000     0.000    106\n",
      "    fear     0.272     0.765     0.123    106\n",
      "   happy     0.272     0.000     0.000    106\n",
      " neutral     0.272     0.320     0.906    106\n",
      "     sad     0.272     0.000     0.000    106\n",
      "surprise     0.272     0.312     0.519    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.272     0.221     0.272    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 27.0%, Avg loss: 1.768708 \n",
      "\n",
      "classification loss: 1.717384;  cosine similarity loss: 1.888464 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.723509; classification loss: 1.686888;  cosine similarity loss: 1.869995\n",
      "[ 1400/ 5482] total-loss: 1.776395; classification loss: 1.734734;  cosine similarity loss: 1.943037\n",
      "[ 2800/ 5482] total-loss: 1.672025; classification loss: 1.627253;  cosine similarity loss: 1.851116\n",
      "[ 4200/ 5482] total-loss: 1.786625; classification loss: 1.750999;  cosine similarity loss: 1.929125\n",
      "[ 5600/ 5482] total-loss: 1.802611; classification loss: 1.775488;  cosine similarity loss: 1.911100\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.286     0.129     0.255    106\n",
      " disgust     0.286     0.000     0.000    106\n",
      "    fear     0.286     0.583     0.066    106\n",
      "   happy     0.286     0.333     0.019    106\n",
      " neutral     0.286     0.363     0.858    106\n",
      "     sad     0.286     0.000     0.000    106\n",
      "surprise     0.286     0.323     0.802    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.286     0.247     0.286    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 28.3%, Avg loss: 1.751935 \n",
      "\n",
      "classification loss: 1.692722;  cosine similarity loss: 1.890098 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.680480; classification loss: 1.633142;  cosine similarity loss: 1.869830\n",
      "[ 1400/ 5482] total-loss: 1.699314; classification loss: 1.653800;  cosine similarity loss: 1.881372\n",
      "[ 2800/ 5482] total-loss: 1.693108; classification loss: 1.644340;  cosine similarity loss: 1.888182\n",
      "[ 4200/ 5482] total-loss: 1.645243; classification loss: 1.593003;  cosine similarity loss: 1.854206\n",
      "[ 5600/ 5482] total-loss: 1.805625; classification loss: 1.770579;  cosine similarity loss: 1.945810\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.284     0.114     0.226    106\n",
      " disgust     0.284     0.000     0.000    106\n",
      "    fear     0.284     0.471     0.075    106\n",
      "   happy     0.284     0.222     0.019    106\n",
      " neutral     0.284     0.388     0.868    106\n",
      "     sad     0.284     0.000     0.000    106\n",
      "surprise     0.284     0.323     0.802    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.284     0.217     0.284    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 28.2%, Avg loss: 1.730550 \n",
      "\n",
      "classification loss: 1.662862;  cosine similarity loss: 1.888487 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.675256; classification loss: 1.622793;  cosine similarity loss: 1.885108\n",
      "[ 1400/ 5482] total-loss: 1.632083; classification loss: 1.566029;  cosine similarity loss: 1.896299\n",
      "[ 2800/ 5482] total-loss: 1.805276; classification loss: 1.772109;  cosine similarity loss: 1.937943\n",
      "[ 4200/ 5482] total-loss: 1.649906; classification loss: 1.595559;  cosine similarity loss: 1.867295\n",
      "[ 5600/ 5482] total-loss: 1.763756; classification loss: 1.725201;  cosine similarity loss: 1.917975\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.333     0.062     0.047    106\n",
      " disgust     0.333     0.565     0.613    106\n",
      "    fear     0.333     0.312     0.047    106\n",
      "   happy     0.333     0.050     0.009    106\n",
      " neutral     0.333     0.389     0.811    106\n",
      "     sad     0.333     0.000     0.000    106\n",
      "surprise     0.333     0.293     0.802    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.333     0.239     0.333    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.0%, Avg loss: 1.720467 \n",
      "\n",
      "classification loss: 1.647725;  cosine similarity loss: 1.890197 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.783108; classification loss: 1.745510;  cosine similarity loss: 1.933501\n",
      "[ 1400/ 5482] total-loss: 1.686954; classification loss: 1.640350;  cosine similarity loss: 1.873373\n",
      "[ 2800/ 5482] total-loss: 1.612420; classification loss: 1.549023;  cosine similarity loss: 1.866009\n",
      "[ 4200/ 5482] total-loss: 1.727482; classification loss: 1.683022;  cosine similarity loss: 1.905322\n",
      "[ 5600/ 5482] total-loss: 1.763230; classification loss: 1.731642;  cosine similarity loss: 1.889582\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.334     0.040     0.028    106\n",
      " disgust     0.334     0.523     0.632    106\n",
      "    fear     0.334     0.125     0.019    106\n",
      "   happy     0.334     0.118     0.038    106\n",
      " neutral     0.334     0.441     0.811    106\n",
      "     sad     0.334     0.000     0.000    106\n",
      "surprise     0.334     0.293     0.811    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.334     0.220     0.334    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 1.706330 \n",
      "\n",
      "classification loss: 1.629890;  cosine similarity loss: 1.884690 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.549785; classification loss: 1.471957;  cosine similarity loss: 1.861096\n",
      "[ 1400/ 5482] total-loss: 1.544023; classification loss: 1.469572;  cosine similarity loss: 1.841826\n",
      "[ 2800/ 5482] total-loss: 1.668291; classification loss: 1.611139;  cosine similarity loss: 1.896898\n",
      "[ 4200/ 5482] total-loss: 1.586983; classification loss: 1.514521;  cosine similarity loss: 1.876832\n",
      "[ 5600/ 5482] total-loss: 1.547766; classification loss: 1.470704;  cosine similarity loss: 1.856013\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.367     0.044     0.019    106\n",
      " disgust     0.367     0.611     0.726    106\n",
      "    fear     0.367     0.390     0.151    106\n",
      "   happy     0.367     0.083     0.028    106\n",
      " neutral     0.367     0.420     0.840    106\n",
      "     sad     0.367     0.000     0.000    106\n",
      "surprise     0.367     0.301     0.802    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.367     0.264     0.367    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 1.680721 \n",
      "\n",
      "classification loss: 1.592943;  cosine similarity loss: 1.885539 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.524725; classification loss: 1.443863;  cosine similarity loss: 1.848171\n",
      "[ 1400/ 5482] total-loss: 1.702098; classification loss: 1.652797;  cosine similarity loss: 1.899302\n",
      "[ 2800/ 5482] total-loss: 1.554283; classification loss: 1.474613;  cosine similarity loss: 1.872962\n",
      "[ 4200/ 5482] total-loss: 1.507152; classification loss: 1.415243;  cosine similarity loss: 1.874788\n",
      "[ 5600/ 5482] total-loss: 1.631267; classification loss: 1.559654;  cosine similarity loss: 1.917720\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.377     0.047     0.019    106\n",
      " disgust     0.377     0.623     0.811    106\n",
      "    fear     0.377     0.472     0.160    106\n",
      "   happy     0.377     0.062     0.028    106\n",
      " neutral     0.377     0.396     0.877    106\n",
      "     sad     0.377     0.000     0.000    106\n",
      "surprise     0.377     0.326     0.745    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.377     0.275     0.377    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 37.4%, Avg loss: 1.660562 \n",
      "\n",
      "classification loss: 1.565108;  cosine similarity loss: 1.883287 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.486494; classification loss: 1.399606;  cosine similarity loss: 1.834046\n",
      "[ 1400/ 5482] total-loss: 1.559040; classification loss: 1.477368;  cosine similarity loss: 1.885726\n",
      "[ 2800/ 5482] total-loss: 1.500856; classification loss: 1.408188;  cosine similarity loss: 1.871529\n",
      "[ 4200/ 5482] total-loss: 1.588538; classification loss: 1.512694;  cosine similarity loss: 1.891917\n",
      "[ 5600/ 5482] total-loss: 1.576510; classification loss: 1.506662;  cosine similarity loss: 1.855898\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.399     0.111     0.038    106\n",
      " disgust     0.399     0.578     0.877    106\n",
      "    fear     0.399     0.617     0.274    106\n",
      "   happy     0.399     0.029     0.009    106\n",
      " neutral     0.399     0.385     0.887    106\n",
      "     sad     0.399     0.000     0.000    106\n",
      "surprise     0.399     0.342     0.708    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.399     0.295     0.399    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.655390 \n",
      "\n",
      "classification loss: 1.557340;  cosine similarity loss: 1.884175 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.551590; classification loss: 1.476045;  cosine similarity loss: 1.853773\n",
      "[ 1400/ 5482] total-loss: 1.579711; classification loss: 1.506280;  cosine similarity loss: 1.873436\n",
      "[ 2800/ 5482] total-loss: 1.565193; classification loss: 1.491785;  cosine similarity loss: 1.858824\n",
      "[ 4200/ 5482] total-loss: 1.444425; classification loss: 1.343555;  cosine similarity loss: 1.847902\n",
      "[ 5600/ 5482] total-loss: 1.462999; classification loss: 1.367530;  cosine similarity loss: 1.844872\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.406     0.125     0.038    106\n",
      " disgust     0.406     0.647     0.811    106\n",
      "    fear     0.406     0.519     0.377    106\n",
      "   happy     0.406     0.205     0.085    106\n",
      " neutral     0.406     0.369     0.887    106\n",
      "     sad     0.406     0.000     0.000    106\n",
      "surprise     0.406     0.338     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.406     0.315     0.406    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 1.646756 \n",
      "\n",
      "classification loss: 1.548116;  cosine similarity loss: 1.876916 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.587014; classification loss: 1.511116;  cosine similarity loss: 1.890605\n",
      "[ 1400/ 5482] total-loss: 1.547232; classification loss: 1.467162;  cosine similarity loss: 1.867512\n",
      "[ 2800/ 5482] total-loss: 1.475732; classification loss: 1.377739;  cosine similarity loss: 1.867703\n",
      "[ 4200/ 5482] total-loss: 1.544247; classification loss: 1.457694;  cosine similarity loss: 1.890460\n",
      "[ 5600/ 5482] total-loss: 1.424217; classification loss: 1.319929;  cosine similarity loss: 1.841372\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.403     0.068     0.038    106\n",
      " disgust     0.403     0.642     0.811    106\n",
      "    fear     0.403     0.552     0.349    106\n",
      "   happy     0.403     0.130     0.066    106\n",
      " neutral     0.403     0.432     0.840    106\n",
      "     sad     0.403     0.000     0.000    106\n",
      "surprise     0.403     0.342     0.717    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.403     0.309     0.403    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 1.633838 \n",
      "\n",
      "classification loss: 1.525012;  cosine similarity loss: 1.887767 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.454602; classification loss: 1.358872;  cosine similarity loss: 1.837520\n",
      "[ 1400/ 5482] total-loss: 1.659572; classification loss: 1.597351;  cosine similarity loss: 1.908456\n",
      "[ 2800/ 5482] total-loss: 1.438661; classification loss: 1.331105;  cosine similarity loss: 1.868886\n",
      "[ 4200/ 5482] total-loss: 1.416442; classification loss: 1.308828;  cosine similarity loss: 1.846897\n",
      "[ 5600/ 5482] total-loss: 1.458165; classification loss: 1.354260;  cosine similarity loss: 1.873782\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.439     0.163     0.066    106\n",
      " disgust     0.439     0.528     0.877    106\n",
      "    fear     0.439     0.692     0.425    106\n",
      "   happy     0.439     0.200     0.132    106\n",
      " neutral     0.439     0.458     0.830    106\n",
      "     sad     0.439     0.000     0.000    106\n",
      "surprise     0.439     0.405     0.745    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.439     0.350     0.439    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.626621 \n",
      "\n",
      "classification loss: 1.515271;  cosine similarity loss: 1.886439 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.419089; classification loss: 1.308101;  cosine similarity loss: 1.863043\n",
      "[ 1400/ 5482] total-loss: 1.562472; classification loss: 1.477167;  cosine similarity loss: 1.903692\n",
      "[ 2800/ 5482] total-loss: 1.414630; classification loss: 1.308137;  cosine similarity loss: 1.840603\n",
      "[ 4200/ 5482] total-loss: 1.432104; classification loss: 1.330754;  cosine similarity loss: 1.837502\n",
      "[ 5600/ 5482] total-loss: 1.415440; classification loss: 1.304291;  cosine similarity loss: 1.860034\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.427     0.071     0.028    106\n",
      " disgust     0.427     0.629     0.849    106\n",
      "    fear     0.427     0.612     0.387    106\n",
      "   happy     0.427     0.140     0.113    106\n",
      " neutral     0.427     0.450     0.811    106\n",
      "     sad     0.427     0.833     0.047    106\n",
      "surprise     0.427     0.386     0.755    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.427     0.446     0.427    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 1.615305 \n",
      "\n",
      "classification loss: 1.500216;  cosine similarity loss: 1.883846 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.403101; classification loss: 1.290168;  cosine similarity loss: 1.854833\n",
      "[ 1400/ 5482] total-loss: 1.522159; classification loss: 1.439160;  cosine similarity loss: 1.854154\n",
      "[ 2800/ 5482] total-loss: 1.590029; classification loss: 1.522307;  cosine similarity loss: 1.860916\n",
      "[ 4200/ 5482] total-loss: 1.370055; classification loss: 1.247284;  cosine similarity loss: 1.861139\n",
      "[ 5600/ 5482] total-loss: 1.458756; classification loss: 1.357473;  cosine similarity loss: 1.863884\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.418     0.119     0.047    106\n",
      " disgust     0.418     0.610     0.840    106\n",
      "    fear     0.418     0.634     0.491    106\n",
      "   happy     0.418     0.200     0.123    106\n",
      " neutral     0.418     0.378     0.877    106\n",
      "     sad     0.418     0.000     0.000    106\n",
      "surprise     0.418     0.365     0.547    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.418     0.329     0.418    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 1.627208 \n",
      "\n",
      "classification loss: 1.514999;  cosine similarity loss: 1.889031 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.767786; classification loss: 1.734810;  cosine similarity loss: 1.899689\n",
      "[ 1400/ 5482] total-loss: 1.330838; classification loss: 1.208136;  cosine similarity loss: 1.821643\n",
      "[ 2800/ 5482] total-loss: 1.356230; classification loss: 1.235609;  cosine similarity loss: 1.838714\n",
      "[ 4200/ 5482] total-loss: 1.337887; classification loss: 1.211269;  cosine similarity loss: 1.844360\n",
      "[ 5600/ 5482] total-loss: 1.405586; classification loss: 1.289426;  cosine similarity loss: 1.870225\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.406     0.132     0.047    106\n",
      " disgust     0.406     0.616     0.849    106\n",
      "    fear     0.406     0.630     0.481    106\n",
      "   happy     0.406     0.080     0.066    106\n",
      " neutral     0.406     0.402     0.887    106\n",
      "     sad     0.406     0.200     0.028    106\n",
      "surprise     0.406     0.362     0.481    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.406     0.346     0.406    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 1.617298 \n",
      "\n",
      "classification loss: 1.501007;  cosine similarity loss: 1.888645 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.348864; classification loss: 1.224235;  cosine similarity loss: 1.847380\n",
      "[ 1400/ 5482] total-loss: 1.380836; classification loss: 1.274812;  cosine similarity loss: 1.804935\n",
      "[ 2800/ 5482] total-loss: 1.369778; classification loss: 1.241010;  cosine similarity loss: 1.884850\n",
      "[ 4200/ 5482] total-loss: 1.454777; classification loss: 1.352286;  cosine similarity loss: 1.864742\n",
      "[ 5600/ 5482] total-loss: 1.296151; classification loss: 1.163184;  cosine similarity loss: 1.828016\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.439     0.190     0.075    106\n",
      " disgust     0.439     0.683     0.774    106\n",
      "    fear     0.439     0.482     0.500    106\n",
      "   happy     0.439     0.222     0.132    106\n",
      " neutral     0.439     0.467     0.868    106\n",
      "     sad     0.439     0.727     0.075    106\n",
      "surprise     0.439     0.347     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.439     0.446     0.439    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.586962 \n",
      "\n",
      "classification loss: 1.459652;  cosine similarity loss: 1.884019 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.301299; classification loss: 1.163441;  cosine similarity loss: 1.852731\n",
      "[ 1400/ 5482] total-loss: 1.403917; classification loss: 1.291110;  cosine similarity loss: 1.855141\n",
      "[ 2800/ 5482] total-loss: 1.335877; classification loss: 1.210601;  cosine similarity loss: 1.836982\n",
      "[ 4200/ 5482] total-loss: 1.283806; classification loss: 1.153178;  cosine similarity loss: 1.806316\n",
      "[ 5600/ 5482] total-loss: 1.369497; classification loss: 1.251470;  cosine similarity loss: 1.841603\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.474     0.216     0.075    106\n",
      " disgust     0.474     0.590     0.868    106\n",
      "    fear     0.474     0.566     0.528    106\n",
      "   happy     0.474     0.279     0.274    106\n",
      " neutral     0.474     0.511     0.840    106\n",
      "     sad     0.474     0.679     0.179    106\n",
      "surprise     0.474     0.410     0.557    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.474     0.464     0.474    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.583582 \n",
      "\n",
      "classification loss: 1.452764;  cosine similarity loss: 1.888823 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.342065; classification loss: 1.210912;  cosine similarity loss: 1.866677\n",
      "[ 1400/ 5482] total-loss: 1.299735; classification loss: 1.162971;  cosine similarity loss: 1.846791\n",
      "[ 2800/ 5482] total-loss: 1.276500; classification loss: 1.140167;  cosine similarity loss: 1.821832\n",
      "[ 4200/ 5482] total-loss: 1.511184; classification loss: 1.416266;  cosine similarity loss: 1.890856\n",
      "[ 5600/ 5482] total-loss: 1.384634; classification loss: 1.263309;  cosine similarity loss: 1.869936\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.469     0.200     0.057    106\n",
      " disgust     0.469     0.682     0.849    106\n",
      "    fear     0.469     0.616     0.575    106\n",
      "   happy     0.469     0.276     0.226    106\n",
      " neutral     0.469     0.416     0.858    106\n",
      "     sad     0.469     0.520     0.123    106\n",
      "surprise     0.469     0.420     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.469     0.447     0.469    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.586757 \n",
      "\n",
      "classification loss: 1.459030;  cosine similarity loss: 1.884788 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.329760; classification loss: 1.198975;  cosine similarity loss: 1.852900\n",
      "[ 1400/ 5482] total-loss: 1.245820; classification loss: 1.095664;  cosine similarity loss: 1.846443\n",
      "[ 2800/ 5482] total-loss: 1.343339; classification loss: 1.214416;  cosine similarity loss: 1.859034\n",
      "[ 4200/ 5482] total-loss: 1.303112; classification loss: 1.170802;  cosine similarity loss: 1.832349\n",
      "[ 5600/ 5482] total-loss: 1.262990; classification loss: 1.121398;  cosine similarity loss: 1.829361\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.493     0.241     0.066    106\n",
      " disgust     0.493     0.655     0.858    106\n",
      "    fear     0.493     0.613     0.538    106\n",
      "   happy     0.493     0.324     0.311    106\n",
      " neutral     0.493     0.484     0.868    106\n",
      "     sad     0.493     0.750     0.226    106\n",
      "surprise     0.493     0.395     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.493     0.495     0.493    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.584744 \n",
      "\n",
      "classification loss: 1.455046;  cosine similarity loss: 1.887373 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.292224; classification loss: 1.154079;  cosine similarity loss: 1.844803\n",
      "[ 1400/ 5482] total-loss: 1.332164; classification loss: 1.198243;  cosine similarity loss: 1.867849\n",
      "[ 2800/ 5482] total-loss: 1.274003; classification loss: 1.132399;  cosine similarity loss: 1.840420\n",
      "[ 4200/ 5482] total-loss: 1.193947; classification loss: 1.034725;  cosine similarity loss: 1.830833\n",
      "[ 5600/ 5482] total-loss: 1.336639; classification loss: 1.206339;  cosine similarity loss: 1.857840\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.519     0.316     0.113    106\n",
      " disgust     0.519     0.591     0.887    106\n",
      "    fear     0.519     0.530     0.585    106\n",
      "   happy     0.519     0.451     0.349    106\n",
      " neutral     0.519     0.529     0.783    106\n",
      "     sad     0.519     0.712     0.396    106\n",
      "surprise     0.519     0.423     0.519    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.519     0.507     0.519    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 1.569345 \n",
      "\n",
      "classification loss: 1.432664;  cosine similarity loss: 1.888269 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep24_acc_51.md \n",
      "\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep24_acc_51\"!  new accuracy: 51.4\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.247636; classification loss: 1.100281;  cosine similarity loss: 1.837055\n",
      "[ 1400/ 5482] total-loss: 1.243271; classification loss: 1.094351;  cosine similarity loss: 1.838948\n",
      "[ 2800/ 5482] total-loss: 1.166157; classification loss: 1.007247;  cosine similarity loss: 1.801795\n",
      "[ 4200/ 5482] total-loss: 1.330873; classification loss: 1.194968;  cosine similarity loss: 1.874496\n",
      "[ 5600/ 5482] total-loss: 1.402722; classification loss: 1.281036;  cosine similarity loss: 1.889463\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.489     0.417     0.047    106\n",
      " disgust     0.489     0.737     0.792    106\n",
      "    fear     0.489     0.489     0.651    106\n",
      "   happy     0.489     0.351     0.377    106\n",
      " neutral     0.489     0.503     0.906    106\n",
      "     sad     0.489     0.304     0.066    106\n",
      "surprise     0.489     0.422     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.489     0.460     0.489    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.570922 \n",
      "\n",
      "classification loss: 1.435250;  cosine similarity loss: 1.887489 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.213133; classification loss: 1.057494;  cosine similarity loss: 1.835690\n",
      "[ 1400/ 5482] total-loss: 1.217545; classification loss: 1.062438;  cosine similarity loss: 1.837976\n",
      "[ 2800/ 5482] total-loss: 1.154809; classification loss: 0.992418;  cosine similarity loss: 1.804374\n",
      "[ 4200/ 5482] total-loss: 1.114535; classification loss: 0.943755;  cosine similarity loss: 1.797656\n",
      "[ 5600/ 5482] total-loss: 1.155651; classification loss: 0.985459;  cosine similarity loss: 1.836419\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.512     0.458     0.104    106\n",
      " disgust     0.512     0.657     0.887    106\n",
      "    fear     0.512     0.531     0.642    106\n",
      "   happy     0.512     0.423     0.387    106\n",
      " neutral     0.512     0.545     0.849    106\n",
      "     sad     0.512     0.486     0.170    106\n",
      "surprise     0.512     0.392     0.547    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.512     0.499     0.512    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.537063 \n",
      "\n",
      "classification loss: 1.390442;  cosine similarity loss: 1.879178 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.343038; classification loss: 1.220531;  cosine similarity loss: 1.833066\n",
      "[ 1400/ 5482] total-loss: 1.215506; classification loss: 1.062751;  cosine similarity loss: 1.826529\n",
      "[ 2800/ 5482] total-loss: 1.136230; classification loss: 0.967803;  cosine similarity loss: 1.809935\n",
      "[ 4200/ 5482] total-loss: 1.125774; classification loss: 0.951549;  cosine similarity loss: 1.822676\n",
      "[ 5600/ 5482] total-loss: 1.269440; classification loss: 1.123692;  cosine similarity loss: 1.852433\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.513     0.333     0.057    106\n",
      " disgust     0.513     0.713     0.821    106\n",
      "    fear     0.513     0.497     0.708    106\n",
      "   happy     0.513     0.410     0.387    106\n",
      " neutral     0.513     0.564     0.868    106\n",
      "     sad     0.513     0.531     0.160    106\n",
      "surprise     0.513     0.404     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.513     0.493     0.513    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 1.516237 \n",
      "\n",
      "classification loss: 1.360782;  cosine similarity loss: 1.878966 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.131361; classification loss: 0.961628;  cosine similarity loss: 1.810290\n",
      "[ 1400/ 5482] total-loss: 1.179431; classification loss: 1.014733;  cosine similarity loss: 1.838223\n",
      "[ 2800/ 5482] total-loss: 1.179287; classification loss: 1.014627;  cosine similarity loss: 1.837930\n",
      "[ 4200/ 5482] total-loss: 1.361427; classification loss: 1.240381;  cosine similarity loss: 1.845608\n",
      "[ 5600/ 5482] total-loss: 1.111890; classification loss: 0.932141;  cosine similarity loss: 1.830884\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.550     0.407     0.104    106\n",
      " disgust     0.550     0.590     0.925    106\n",
      "    fear     0.550     0.721     0.585    106\n",
      "   happy     0.550     0.416     0.538    106\n",
      " neutral     0.550     0.617     0.868    106\n",
      "     sad     0.550     0.757     0.264    106\n",
      "surprise     0.550     0.429     0.566    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.550     0.563     0.550    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.535613 \n",
      "\n",
      "classification loss: 1.387965;  cosine similarity loss: 1.880125 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep28_acc_54.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep24_acc_51\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep28_acc_54\"! Old accuracy: 51.4, new accuracy: 54.5\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.186996; classification loss: 1.020229;  cosine similarity loss: 1.854066\n",
      "[ 1400/ 5482] total-loss: 1.154649; classification loss: 0.987201;  cosine similarity loss: 1.824440\n",
      "[ 2800/ 5482] total-loss: 1.068438; classification loss: 0.879847;  cosine similarity loss: 1.822801\n",
      "[ 4200/ 5482] total-loss: 1.102778; classification loss: 0.923021;  cosine similarity loss: 1.821808\n",
      "[ 5600/ 5482] total-loss: 1.224721; classification loss: 1.063912;  cosine similarity loss: 1.867955\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.554     0.316     0.113    106\n",
      " disgust     0.554     0.718     0.840    106\n",
      "    fear     0.554     0.570     0.613    106\n",
      "   happy     0.554     0.524     0.519    106\n",
      " neutral     0.554     0.677     0.792    106\n",
      "     sad     0.554     0.711     0.302    106\n",
      "surprise     0.554     0.385     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.554     0.557     0.554    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.518043 \n",
      "\n",
      "classification loss: 1.362947;  cosine similarity loss: 1.879935 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep29_acc_55.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep28_acc_54\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep29_acc_55\"! Old accuracy: 54.5, new accuracy: 54.9\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.060999; classification loss: 0.873156;  cosine similarity loss: 1.812373\n",
      "[ 1400/ 5482] total-loss: 1.095151; classification loss: 0.911430;  cosine similarity loss: 1.830038\n",
      "[ 2800/ 5482] total-loss: 1.065553; classification loss: 0.873254;  cosine similarity loss: 1.834753\n",
      "[ 4200/ 5482] total-loss: 1.078902; classification loss: 0.894352;  cosine similarity loss: 1.817100\n",
      "[ 5600/ 5482] total-loss: 1.272596; classification loss: 1.125440;  cosine similarity loss: 1.861217\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.601     0.744     0.547    106\n",
      " disgust     0.601     0.657     0.887    106\n",
      "    fear     0.601     0.629     0.623    106\n",
      "   happy     0.601     0.432     0.594    106\n",
      " neutral     0.601     0.610     0.840    106\n",
      "     sad     0.601     0.579     0.208    106\n",
      "surprise     0.601     0.628     0.509    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.601     0.611     0.601    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 1.517578 \n",
      "\n",
      "classification loss: 1.361303;  cosine similarity loss: 1.882218 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep30_acc_60.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep29_acc_55\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep30_acc_60\"! Old accuracy: 54.9, new accuracy: 59.5\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.986829; classification loss: 0.784428;  cosine similarity loss: 1.796436\n",
      "[ 1400/ 5482] total-loss: 1.044006; classification loss: 0.849872;  cosine similarity loss: 1.820542\n",
      "[ 2800/ 5482] total-loss: 0.981762; classification loss: 0.776385;  cosine similarity loss: 1.803271\n",
      "[ 4200/ 5482] total-loss: 1.163030; classification loss: 0.995850;  cosine similarity loss: 1.831752\n",
      "[ 5600/ 5482] total-loss: 1.039267; classification loss: 0.847512;  cosine similarity loss: 1.806287\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.602     0.617     0.472    106\n",
      " disgust     0.602     0.703     0.783    106\n",
      "    fear     0.602     0.535     0.651    106\n",
      "   happy     0.602     0.570     0.538    106\n",
      " neutral     0.602     0.669     0.802    106\n",
      "     sad     0.602     0.755     0.349    106\n",
      "surprise     0.602     0.478     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.602     0.618     0.602    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 1.499015 \n",
      "\n",
      "classification loss: 1.335323;  cosine similarity loss: 1.880961 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep31_acc_60.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep30_acc_60\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep31_acc_60\"! Old accuracy: 59.5, new accuracy: 59.7\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 1.177557; classification loss: 1.010843;  cosine similarity loss: 1.844411\n",
      "[ 1400/ 5482] total-loss: 0.967781; classification loss: 0.757631;  cosine similarity loss: 1.808380\n",
      "[ 2800/ 5482] total-loss: 0.999969; classification loss: 0.799272;  cosine similarity loss: 1.802757\n",
      "[ 4200/ 5482] total-loss: 1.071851; classification loss: 0.881568;  cosine similarity loss: 1.832987\n",
      "[ 5600/ 5482] total-loss: 1.236816; classification loss: 1.073551;  cosine similarity loss: 1.889878\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.643     0.698     0.632    106\n",
      " disgust     0.643     0.646     0.877    106\n",
      "    fear     0.643     0.596     0.613    106\n",
      "   happy     0.643     0.545     0.632    106\n",
      " neutral     0.643     0.656     0.811    106\n",
      "     sad     0.643     0.820     0.387    106\n",
      "surprise     0.643     0.652     0.547    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.643     0.659     0.643    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.463461 \n",
      "\n",
      "classification loss: 1.285375;  cosine similarity loss: 1.878994 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep32_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep31_acc_60\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep32_acc_64\"! Old accuracy: 59.7, new accuracy: 63.7\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.965812; classification loss: 0.751231;  cosine similarity loss: 1.824136\n",
      "[ 1400/ 5482] total-loss: 1.025357; classification loss: 0.824021;  cosine similarity loss: 1.830699\n",
      "[ 2800/ 5482] total-loss: 1.256643; classification loss: 1.106150;  cosine similarity loss: 1.858612\n",
      "[ 4200/ 5482] total-loss: 1.047859; classification loss: 0.850082;  cosine similarity loss: 1.838969\n",
      "[ 5600/ 5482] total-loss: 1.023458; classification loss: 0.826796;  cosine similarity loss: 1.810107\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.648     0.795     0.660    106\n",
      " disgust     0.648     0.586     0.934    106\n",
      "    fear     0.648     0.610     0.575    106\n",
      "   happy     0.648     0.546     0.557    106\n",
      " neutral     0.648     0.628     0.858    106\n",
      "     sad     0.648     0.886     0.368    106\n",
      "surprise     0.648     0.705     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.648     0.679     0.648    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.448372 \n",
      "\n",
      "classification loss: 1.265525;  cosine similarity loss: 1.875013 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep33_acc_64.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep32_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep33_acc_64\"! Old accuracy: 63.7, new accuracy: 64.2\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.936850; classification loss: 0.719308;  cosine similarity loss: 1.807017\n",
      "[ 1400/ 5482] total-loss: 1.026253; classification loss: 0.824484;  cosine similarity loss: 1.833329\n",
      "[ 2800/ 5482] total-loss: 0.974089; classification loss: 0.764383;  cosine similarity loss: 1.812913\n",
      "[ 4200/ 5482] total-loss: 1.155134; classification loss: 0.984149;  cosine similarity loss: 1.839076\n",
      "[ 5600/ 5482] total-loss: 0.898414; classification loss: 0.672398;  cosine similarity loss: 1.802477\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.660     0.690     0.651    106\n",
      " disgust     0.660     0.674     0.858    106\n",
      "    fear     0.660     0.589     0.594    106\n",
      "   happy     0.660     0.613     0.538    106\n",
      " neutral     0.660     0.708     0.802    106\n",
      "     sad     0.660     0.845     0.462    106\n",
      "surprise     0.660     0.589     0.717    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.660     0.673     0.660    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.455847 \n",
      "\n",
      "classification loss: 1.276316;  cosine similarity loss: 1.874752 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep34_acc_65.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep33_acc_64\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep34_acc_65\"! Old accuracy: 64.2, new accuracy: 65.4\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.917276; classification loss: 0.698547;  cosine similarity loss: 1.792188\n",
      "[ 1400/ 5482] total-loss: 0.954909; classification loss: 0.741441;  cosine similarity loss: 1.808781\n",
      "[ 2800/ 5482] total-loss: 1.011276; classification loss: 0.804008;  cosine similarity loss: 1.840345\n",
      "[ 4200/ 5482] total-loss: 1.050816; classification loss: 0.852144;  cosine similarity loss: 1.845505\n",
      "[ 5600/ 5482] total-loss: 0.865150; classification loss: 0.628902;  cosine similarity loss: 1.810138\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.659     0.679     0.679    106\n",
      " disgust     0.659     0.746     0.858    106\n",
      "    fear     0.659     0.569     0.547    106\n",
      "   happy     0.659     0.538     0.594    106\n",
      " neutral     0.659     0.721     0.830    106\n",
      "     sad     0.659     0.797     0.519    106\n",
      "surprise     0.659     0.596     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.659     0.664     0.659    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 1.451389 \n",
      "\n",
      "classification loss: 1.268643;  cosine similarity loss: 1.877796 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.901380; classification loss: 0.671464;  cosine similarity loss: 1.821041\n",
      "[ 1400/ 5482] total-loss: 0.862007; classification loss: 0.624253;  cosine similarity loss: 1.813026\n",
      "[ 2800/ 5482] total-loss: 1.137438; classification loss: 0.962883;  cosine similarity loss: 1.835659\n",
      "[ 4200/ 5482] total-loss: 0.854830; classification loss: 0.619763;  cosine similarity loss: 1.795095\n",
      "[ 5600/ 5482] total-loss: 0.828827; classification loss: 0.582758;  cosine similarity loss: 1.813104\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.674     0.685     0.717    106\n",
      " disgust     0.674     0.715     0.877    106\n",
      "    fear     0.674     0.609     0.632    106\n",
      "   happy     0.674     0.517     0.566    106\n",
      " neutral     0.674     0.705     0.811    106\n",
      "     sad     0.674     0.912     0.491    106\n",
      "surprise     0.674     0.688     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.674     0.690     0.674    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 1.428012 \n",
      "\n",
      "classification loss: 1.236519;  cosine similarity loss: 1.874830 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep36_acc_67.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep34_acc_65\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep36_acc_67\"! Old accuracy: 65.4, new accuracy: 66.8\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.814901; classification loss: 0.566059;  cosine similarity loss: 1.810270\n",
      "[ 1400/ 5482] total-loss: 0.795844; classification loss: 0.544903;  cosine similarity loss: 1.799608\n",
      "[ 2800/ 5482] total-loss: 0.809981; classification loss: 0.562895;  cosine similarity loss: 1.798322\n",
      "[ 4200/ 5482] total-loss: 0.847361; classification loss: 0.607371;  cosine similarity loss: 1.807322\n",
      "[ 5600/ 5482] total-loss: 0.830801; classification loss: 0.582602;  cosine similarity loss: 1.823594\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.660     0.644     0.717    106\n",
      " disgust     0.660     0.724     0.840    106\n",
      "    fear     0.660     0.513     0.575    106\n",
      "   happy     0.660     0.562     0.557    106\n",
      " neutral     0.660     0.702     0.802    106\n",
      "     sad     0.660     0.981     0.500    106\n",
      "surprise     0.660     0.657     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.660     0.683     0.660    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.417204 \n",
      "\n",
      "classification loss: 1.219277;  cosine similarity loss: 1.879035 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.831749; classification loss: 0.582044;  cosine similarity loss: 1.830569\n",
      "[ 1400/ 5482] total-loss: 0.810730; classification loss: 0.556875;  cosine similarity loss: 1.826148\n",
      "[ 2800/ 5482] total-loss: 0.853890; classification loss: 0.615211;  cosine similarity loss: 1.808607\n",
      "[ 4200/ 5482] total-loss: 0.846245; classification loss: 0.605146;  cosine similarity loss: 1.810639\n",
      "[ 5600/ 5482] total-loss: 0.787460; classification loss: 0.530779;  cosine similarity loss: 1.814181\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.662     0.747     0.698    106\n",
      " disgust     0.662     0.830     0.830    106\n",
      "    fear     0.662     0.570     0.651    106\n",
      "   happy     0.662     0.473     0.660    106\n",
      " neutral     0.662     0.630     0.821    106\n",
      "     sad     0.662     0.791     0.500    106\n",
      "surprise     0.662     0.794     0.472    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.662     0.691     0.662    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 1.487178 \n",
      "\n",
      "classification loss: 1.319419;  cosine similarity loss: 1.878615 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.765566; classification loss: 0.500147;  cosine similarity loss: 1.827243\n",
      "[ 1400/ 5482] total-loss: 0.858028; classification loss: 0.617242;  cosine similarity loss: 1.821172\n",
      "[ 2800/ 5482] total-loss: 0.791614; classification loss: 0.536145;  cosine similarity loss: 1.813492\n",
      "[ 4200/ 5482] total-loss: 0.904721; classification loss: 0.674965;  cosine similarity loss: 1.823745\n",
      "[ 5600/ 5482] total-loss: 0.862256; classification loss: 0.618443;  cosine similarity loss: 1.837508\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.670     0.742     0.679    106\n",
      " disgust     0.670     0.744     0.821    106\n",
      "    fear     0.670     0.583     0.632    106\n",
      "   happy     0.670     0.534     0.594    106\n",
      " neutral     0.670     0.649     0.821    106\n",
      "     sad     0.670     0.903     0.528    106\n",
      "surprise     0.670     0.657     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.670     0.687     0.670    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 1.464762 \n",
      "\n",
      "classification loss: 1.289546;  cosine similarity loss: 1.873601 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.889879; classification loss: 0.654060;  cosine similarity loss: 1.833154\n",
      "[ 1400/ 5482] total-loss: 0.731551; classification loss: 0.464780;  cosine similarity loss: 1.798635\n",
      "[ 2800/ 5482] total-loss: 0.857640; classification loss: 0.615452;  cosine similarity loss: 1.826389\n",
      "[ 4200/ 5482] total-loss: 0.864946; classification loss: 0.624232;  cosine similarity loss: 1.827801\n",
      "[ 5600/ 5482] total-loss: 0.825465; classification loss: 0.574214;  cosine similarity loss: 1.830467\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.683     0.709     0.736    106\n",
      " disgust     0.683     0.775     0.811    106\n",
      "    fear     0.683     0.562     0.689    106\n",
      "   happy     0.683     0.564     0.585    106\n",
      " neutral     0.683     0.720     0.849    106\n",
      "     sad     0.683     0.797     0.557    106\n",
      "surprise     0.683     0.720     0.557    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.683     0.692     0.683    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 1.460769 \n",
      "\n",
      "classification loss: 1.282365;  cosine similarity loss: 1.877044 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep40_acc_68.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep36_acc_67\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep40_acc_68\"! Old accuracy: 66.8, new accuracy: 67.7\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.730845; classification loss: 0.459894;  cosine similarity loss: 1.814646\n",
      "[ 1400/ 5482] total-loss: 0.724452; classification loss: 0.455260;  cosine similarity loss: 1.801219\n",
      "[ 2800/ 5482] total-loss: 0.676861; classification loss: 0.399015;  cosine similarity loss: 1.788244\n",
      "[ 4200/ 5482] total-loss: 0.698010; classification loss: 0.421616;  cosine similarity loss: 1.803586\n",
      "[ 5600/ 5482] total-loss: 0.701081; classification loss: 0.426805;  cosine similarity loss: 1.798185\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.685     0.638     0.783    106\n",
      " disgust     0.685     0.732     0.877    106\n",
      "    fear     0.685     0.641     0.557    106\n",
      "   happy     0.685     0.575     0.651    106\n",
      " neutral     0.685     0.757     0.821    106\n",
      "     sad     0.685     0.781     0.538    106\n",
      "surprise     0.685     0.706     0.566    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.685     0.690     0.685    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.428483 \n",
      "\n",
      "classification loss: 1.236701;  cosine similarity loss: 1.875974 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep41_acc_68.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep40_acc_68\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep41_acc_68\"! Old accuracy: 67.7, new accuracy: 67.8\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.786927; classification loss: 0.527493;  cosine similarity loss: 1.824663\n",
      "[ 1400/ 5482] total-loss: 1.159069; classification loss: 0.980058;  cosine similarity loss: 1.875111\n",
      "[ 2800/ 5482] total-loss: 0.804647; classification loss: 0.549905;  cosine similarity loss: 1.823617\n",
      "[ 4200/ 5482] total-loss: 0.726066; classification loss: 0.455865;  cosine similarity loss: 1.806869\n",
      "[ 5600/ 5482] total-loss: 0.689637; classification loss: 0.410588;  cosine similarity loss: 1.805831\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.671     0.636     0.708    106\n",
      " disgust     0.671     0.832     0.745    106\n",
      "    fear     0.671     0.518     0.679    106\n",
      "   happy     0.671     0.659     0.566    106\n",
      " neutral     0.671     0.677     0.811    106\n",
      "     sad     0.671     0.852     0.491    106\n",
      "surprise     0.671     0.667     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.671     0.692     0.671    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 1.459404 \n",
      "\n",
      "classification loss: 1.280359;  cosine similarity loss: 1.877178 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.811409; classification loss: 0.557031;  cosine similarity loss: 1.828921\n",
      "[ 1400/ 5482] total-loss: 0.864149; classification loss: 0.621024;  cosine similarity loss: 1.836646\n",
      "[ 2800/ 5482] total-loss: 0.671033; classification loss: 0.385196;  cosine similarity loss: 1.814383\n",
      "[ 4200/ 5482] total-loss: 0.657904; classification loss: 0.372370;  cosine similarity loss: 1.800041\n",
      "[ 5600/ 5482] total-loss: 0.804271; classification loss: 0.551255;  cosine similarity loss: 1.816333\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.689     0.683     0.774    106\n",
      " disgust     0.689     0.685     0.840    106\n",
      "    fear     0.689     0.619     0.566    106\n",
      "   happy     0.689     0.598     0.660    106\n",
      " neutral     0.689     0.744     0.821    106\n",
      "     sad     0.689     0.769     0.566    106\n",
      "surprise     0.689     0.759     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.689     0.694     0.689    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.438632 \n",
      "\n",
      "classification loss: 1.250809;  cosine similarity loss: 1.876887 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep43_acc_68.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep41_acc_68\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep43_acc_68\"! Old accuracy: 67.8, new accuracy: 68.2\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.694542; classification loss: 0.414176;  cosine similarity loss: 1.816003\n",
      "[ 1400/ 5482] total-loss: 0.747842; classification loss: 0.477502;  cosine similarity loss: 1.829201\n",
      "[ 2800/ 5482] total-loss: 0.630774; classification loss: 0.341038;  cosine similarity loss: 1.789722\n",
      "[ 4200/ 5482] total-loss: 0.688632; classification loss: 0.408835;  cosine similarity loss: 1.807822\n",
      "[ 5600/ 5482] total-loss: 0.673599; classification loss: 0.390310;  cosine similarity loss: 1.806753\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.690     0.705     0.745    106\n",
      " disgust     0.690     0.782     0.745    106\n",
      "    fear     0.690     0.608     0.689    106\n",
      "   happy     0.690     0.543     0.660    106\n",
      " neutral     0.690     0.667     0.830    106\n",
      "     sad     0.690     0.868     0.557    106\n",
      "surprise     0.690     0.800     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.690     0.710     0.690    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.441020 \n",
      "\n",
      "classification loss: 1.254454;  cosine similarity loss: 1.876340 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep44_acc_68.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep43_acc_68\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep44_acc_68\"! Old accuracy: 68.2, new accuracy: 68.4\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.621873; classification loss: 0.329134;  cosine similarity loss: 1.792828\n",
      "[ 1400/ 5482] total-loss: 0.816784; classification loss: 0.561198;  cosine similarity loss: 1.839126\n",
      "[ 2800/ 5482] total-loss: 0.663660; classification loss: 0.379922;  cosine similarity loss: 1.798612\n",
      "[ 4200/ 5482] total-loss: 0.663834; classification loss: 0.374482;  cosine similarity loss: 1.821243\n",
      "[ 5600/ 5482] total-loss: 0.727504; classification loss: 0.457428;  cosine similarity loss: 1.807811\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.690     0.678     0.736    106\n",
      " disgust     0.690     0.790     0.783    106\n",
      "    fear     0.690     0.692     0.594    106\n",
      "   happy     0.690     0.585     0.651    106\n",
      " neutral     0.690     0.650     0.840    106\n",
      "     sad     0.690     0.797     0.557    106\n",
      "surprise     0.690     0.696     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.690     0.698     0.690    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.478672 \n",
      "\n",
      "classification loss: 1.308226;  cosine similarity loss: 1.876379 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.698954; classification loss: 0.417311;  cosine similarity loss: 1.825525\n",
      "[ 1400/ 5482] total-loss: 0.700649; classification loss: 0.418410;  cosine similarity loss: 1.829605\n",
      "[ 2800/ 5482] total-loss: 0.700211; classification loss: 0.424598;  cosine similarity loss: 1.802665\n",
      "[ 4200/ 5482] total-loss: 0.668700; classification loss: 0.380190;  cosine similarity loss: 1.822740\n",
      "[ 5600/ 5482] total-loss: 0.660910; classification loss: 0.372831;  cosine similarity loss: 1.813225\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.681     0.686     0.679    106\n",
      " disgust     0.681     0.798     0.821    106\n",
      "    fear     0.681     0.592     0.698    106\n",
      "   happy     0.681     0.583     0.632    106\n",
      " neutral     0.681     0.669     0.840    106\n",
      "     sad     0.681     0.776     0.557    106\n",
      "surprise     0.681     0.722     0.538    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.681     0.689     0.681    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 1.491067 \n",
      "\n",
      "classification loss: 1.325983;  cosine similarity loss: 1.876265 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.634953; classification loss: 0.341906;  cosine similarity loss: 1.807143\n",
      "[ 1400/ 5482] total-loss: 0.690633; classification loss: 0.411830;  cosine similarity loss: 1.805845\n",
      "[ 2800/ 5482] total-loss: 0.721243; classification loss: 0.447464;  cosine similarity loss: 1.816360\n",
      "[ 4200/ 5482] total-loss: 0.624542; classification loss: 0.331544;  cosine similarity loss: 1.796535\n",
      "[ 5600/ 5482] total-loss: 0.773793; classification loss: 0.511403;  cosine similarity loss: 1.823350\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.689     0.640     0.840    106\n",
      " disgust     0.689     0.730     0.792    106\n",
      "    fear     0.689     0.674     0.604    106\n",
      "   happy     0.689     0.604     0.632    106\n",
      " neutral     0.689     0.755     0.783    106\n",
      "     sad     0.689     0.722     0.538    106\n",
      "surprise     0.689     0.720     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.689     0.692     0.689    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.459580 \n",
      "\n",
      "classification loss: 1.281463;  cosine similarity loss: 1.875185 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.702772; classification loss: 0.425508;  cosine similarity loss: 1.811831\n",
      "[ 1400/ 5482] total-loss: 0.616736; classification loss: 0.320355;  cosine similarity loss: 1.802259\n",
      "[ 2800/ 5482] total-loss: 1.004728; classification loss: 0.793629;  cosine similarity loss: 1.849123\n",
      "[ 4200/ 5482] total-loss: 0.597960; classification loss: 0.297437;  cosine similarity loss: 1.800051\n",
      "[ 5600/ 5482] total-loss: 0.578044; classification loss: 0.274485;  cosine similarity loss: 1.792281\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.679     0.621     0.774    106\n",
      " disgust     0.679     0.674     0.821    106\n",
      "    fear     0.679     0.692     0.594    106\n",
      "   happy     0.679     0.573     0.632    106\n",
      " neutral     0.679     0.728     0.783    106\n",
      "     sad     0.679     0.753     0.575    106\n",
      "surprise     0.679     0.782     0.575    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.679     0.689     0.679    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 1.480208 \n",
      "\n",
      "classification loss: 1.308618;  cosine similarity loss: 1.880585 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.602592; classification loss: 0.302529;  cosine similarity loss: 1.802845\n",
      "[ 1400/ 5482] total-loss: 0.672179; classification loss: 0.387111;  cosine similarity loss: 1.812450\n",
      "[ 2800/ 5482] total-loss: 0.579291; classification loss: 0.275114;  cosine similarity loss: 1.795998\n",
      "[ 4200/ 5482] total-loss: 0.590700; classification loss: 0.290188;  cosine similarity loss: 1.792746\n",
      "[ 5600/ 5482] total-loss: 0.877857; classification loss: 0.639377;  cosine similarity loss: 1.831777\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.712     0.745    106\n",
      " disgust     0.702     0.746     0.858    106\n",
      "    fear     0.702     0.634     0.604    106\n",
      "   happy     0.702     0.589     0.689    106\n",
      " neutral     0.702     0.723     0.811    106\n",
      "     sad     0.702     0.775     0.585    106\n",
      "surprise     0.702     0.776     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.708     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.454892 \n",
      "\n",
      "classification loss: 1.274346;  cosine similarity loss: 1.876168 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep49_acc_70.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep44_acc_68\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep49_acc_70\"! Old accuracy: 68.4, new accuracy: 69.6\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.572019; classification loss: 0.268176;  cosine similarity loss: 1.787392\n",
      "[ 1400/ 5482] total-loss: 0.629379; classification loss: 0.336401;  cosine similarity loss: 1.801291\n",
      "[ 2800/ 5482] total-loss: 0.552870; classification loss: 0.242855;  cosine similarity loss: 1.792932\n",
      "[ 4200/ 5482] total-loss: 0.718743; classification loss: 0.444587;  cosine similarity loss: 1.815365\n",
      "[ 5600/ 5482] total-loss: 0.698452; classification loss: 0.418236;  cosine similarity loss: 1.819318\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.685     0.681     0.764    106\n",
      " disgust     0.685     0.713     0.821    106\n",
      "    fear     0.685     0.610     0.604    106\n",
      "   happy     0.685     0.574     0.623    106\n",
      " neutral     0.685     0.737     0.792    106\n",
      "     sad     0.685     0.765     0.585    106\n",
      "surprise     0.685     0.744     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.685     0.689     0.685    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.486028 \n",
      "\n",
      "classification loss: 1.317219;  cosine similarity loss: 1.879916 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.728310; classification loss: 0.455026;  cosine similarity loss: 1.821446\n",
      "[ 1400/ 5482] total-loss: 0.596063; classification loss: 0.296150;  cosine similarity loss: 1.795717\n",
      "[ 2800/ 5482] total-loss: 0.550749; classification loss: 0.241092;  cosine similarity loss: 1.789377\n",
      "[ 4200/ 5482] total-loss: 0.552215; classification loss: 0.242619;  cosine similarity loss: 1.790596\n",
      "[ 5600/ 5482] total-loss: 0.565165; classification loss: 0.259174;  cosine similarity loss: 1.789132\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.697     0.733     0.802    106\n",
      " disgust     0.697     0.791     0.821    106\n",
      "    fear     0.697     0.613     0.613    106\n",
      "   happy     0.697     0.580     0.651    106\n",
      " neutral     0.697     0.709     0.783    106\n",
      "     sad     0.697     0.723     0.566    106\n",
      "surprise     0.697     0.747     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.697     0.699     0.697    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1.449232 \n",
      "\n",
      "classification loss: 1.267029;  cosine similarity loss: 1.874371 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.539745; classification loss: 0.226885;  cosine similarity loss: 1.791183\n",
      "[ 1400/ 5482] total-loss: 0.601045; classification loss: 0.302054;  cosine similarity loss: 1.797010\n",
      "[ 2800/ 5482] total-loss: 0.548202; classification loss: 0.238415;  cosine similarity loss: 1.787350\n",
      "[ 4200/ 5482] total-loss: 0.549478; classification loss: 0.237158;  cosine similarity loss: 1.798760\n",
      "[ 5600/ 5482] total-loss: 0.534064; classification loss: 0.220942;  cosine similarity loss: 1.786551\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.679     0.802     0.726    106\n",
      " disgust     0.679     0.687     0.868    106\n",
      "    fear     0.679     0.635     0.575    106\n",
      "   happy     0.679     0.587     0.604    106\n",
      " neutral     0.679     0.652     0.811    106\n",
      "     sad     0.679     0.660     0.604    106\n",
      "surprise     0.679     0.769     0.566    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.679     0.685     0.679    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 1.487062 \n",
      "\n",
      "classification loss: 1.321354;  cosine similarity loss: 1.873713 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.702321; classification loss: 0.422794;  cosine similarity loss: 1.820431\n",
      "[ 1400/ 5482] total-loss: 0.545062; classification loss: 0.232779;  cosine similarity loss: 1.794197\n",
      "[ 2800/ 5482] total-loss: 0.700977; classification loss: 0.418194;  cosine similarity loss: 1.832110\n",
      "[ 4200/ 5482] total-loss: 0.550208; classification loss: 0.238519;  cosine similarity loss: 1.796964\n",
      "[ 5600/ 5482] total-loss: 0.536445; classification loss: 0.222320;  cosine similarity loss: 1.792945\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.691     0.678     0.774    106\n",
      " disgust     0.691     0.779     0.830    106\n",
      "    fear     0.691     0.616     0.575    106\n",
      "   happy     0.691     0.600     0.651    106\n",
      " neutral     0.691     0.682     0.830    106\n",
      "     sad     0.691     0.744     0.604    106\n",
      "surprise     0.691     0.772     0.575    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.691     0.696     0.691    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.495054 \n",
      "\n",
      "classification loss: 1.331711;  cosine similarity loss: 1.876188 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.858820; classification loss: 0.616288;  cosine similarity loss: 1.828945\n",
      "[ 1400/ 5482] total-loss: 0.528692; classification loss: 0.212066;  cosine similarity loss: 1.795196\n",
      "[ 2800/ 5482] total-loss: 0.613038; classification loss: 0.311332;  cosine similarity loss: 1.819863\n",
      "[ 4200/ 5482] total-loss: 0.748952; classification loss: 0.475975;  cosine similarity loss: 1.840862\n",
      "[ 5600/ 5482] total-loss: 0.539834; classification loss: 0.227073;  cosine similarity loss: 1.790877\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.689     0.643     0.783    106\n",
      " disgust     0.689     0.700     0.858    106\n",
      "    fear     0.689     0.645     0.566    106\n",
      "   happy     0.689     0.571     0.604    106\n",
      " neutral     0.689     0.739     0.830    106\n",
      "     sad     0.689     0.795     0.585    106\n",
      "surprise     0.689     0.778     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.689     0.696     0.689    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.480262 \n",
      "\n",
      "classification loss: 1.312642;  cosine similarity loss: 1.871376 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.689695; classification loss: 0.403007;  cosine similarity loss: 1.836447\n",
      "[ 1400/ 5482] total-loss: 0.547591; classification loss: 0.234895;  cosine similarity loss: 1.798375\n",
      "[ 2800/ 5482] total-loss: 0.520287; classification loss: 0.201686;  cosine similarity loss: 1.794692\n",
      "[ 4200/ 5482] total-loss: 0.527602; classification loss: 0.211055;  cosine similarity loss: 1.793790\n",
      "[ 5600/ 5482] total-loss: 0.544266; classification loss: 0.229605;  cosine similarity loss: 1.802911\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.690     0.625     0.755    106\n",
      " disgust     0.690     0.779     0.830    106\n",
      "    fear     0.690     0.705     0.585    106\n",
      "   happy     0.690     0.600     0.651    106\n",
      " neutral     0.690     0.733     0.830    106\n",
      "     sad     0.690     0.646     0.585    106\n",
      "surprise     0.690     0.768     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.690     0.694     0.690    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.511311 \n",
      "\n",
      "classification loss: 1.354111;  cosine similarity loss: 1.878111 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.645715; classification loss: 0.356647;  cosine similarity loss: 1.801985\n",
      "[ 1400/ 5482] total-loss: 0.591564; classification loss: 0.290674;  cosine similarity loss: 1.795126\n",
      "[ 2800/ 5482] total-loss: 0.512406; classification loss: 0.191985;  cosine similarity loss: 1.794092\n",
      "[ 4200/ 5482] total-loss: 0.615544; classification loss: 0.320089;  cosine similarity loss: 1.797363\n",
      "[ 5600/ 5482] total-loss: 0.509507; classification loss: 0.189233;  cosine similarity loss: 1.790604\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.694     0.718     0.698    106\n",
      " disgust     0.694     0.730     0.868    106\n",
      "    fear     0.694     0.610     0.604    106\n",
      "   happy     0.694     0.598     0.689    106\n",
      " neutral     0.694     0.690     0.821    106\n",
      "     sad     0.694     0.747     0.585    106\n",
      "surprise     0.694     0.818     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.694     0.702     0.694    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.479950 \n",
      "\n",
      "classification loss: 1.310697;  cosine similarity loss: 1.874875 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.507435; classification loss: 0.186124;  cosine similarity loss: 1.792679\n",
      "[ 1400/ 5482] total-loss: 0.544198; classification loss: 0.227744;  cosine similarity loss: 1.810013\n",
      "[ 2800/ 5482] total-loss: 0.500076; classification loss: 0.177934;  cosine similarity loss: 1.788644\n",
      "[ 4200/ 5482] total-loss: 0.758680; classification loss: 0.492273;  cosine similarity loss: 1.824307\n",
      "[ 5600/ 5482] total-loss: 0.676270; classification loss: 0.389616;  cosine similarity loss: 1.822887\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.688     0.726    106\n",
      " disgust     0.701     0.706     0.840    106\n",
      "    fear     0.701     0.670     0.613    106\n",
      "   happy     0.701     0.562     0.642    106\n",
      " neutral     0.701     0.819     0.811    106\n",
      "     sad     0.701     0.712     0.698    106\n",
      "surprise     0.701     0.792     0.575    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.707     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.492388 \n",
      "\n",
      "classification loss: 1.328868;  cosine similarity loss: 1.873934 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.523850; classification loss: 0.205174;  cosine similarity loss: 1.798553\n",
      "[ 1400/ 5482] total-loss: 0.499113; classification loss: 0.175199;  cosine similarity loss: 1.794770\n",
      "[ 2800/ 5482] total-loss: 0.518276; classification loss: 0.198553;  cosine similarity loss: 1.797171\n",
      "[ 4200/ 5482] total-loss: 0.500976; classification loss: 0.177660;  cosine similarity loss: 1.794242\n",
      "[ 5600/ 5482] total-loss: 0.502566; classification loss: 0.181404;  cosine similarity loss: 1.787216\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.669     0.745    106\n",
      " disgust     0.702     0.725     0.821    106\n",
      "    fear     0.702     0.722     0.613    106\n",
      "   happy     0.702     0.687     0.642    106\n",
      " neutral     0.702     0.669     0.858    106\n",
      "     sad     0.702     0.771     0.604    106\n",
      "surprise     0.702     0.698     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.706     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.533254 \n",
      "\n",
      "classification loss: 1.388428;  cosine similarity loss: 1.871181 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.496353; classification loss: 0.174076;  cosine similarity loss: 1.785461\n",
      "[ 1400/ 5482] total-loss: 0.497599; classification loss: 0.174756;  cosine similarity loss: 1.788971\n",
      "[ 2800/ 5482] total-loss: 0.804566; classification loss: 0.544082;  cosine similarity loss: 1.846503\n",
      "[ 4200/ 5482] total-loss: 0.494490; classification loss: 0.170998;  cosine similarity loss: 1.788458\n",
      "[ 5600/ 5482] total-loss: 0.547649; classification loss: 0.233341;  cosine similarity loss: 1.804882\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.777     0.755    106\n",
      " disgust     0.702     0.724     0.840    106\n",
      "    fear     0.702     0.639     0.651    106\n",
      "   happy     0.702     0.619     0.566    106\n",
      " neutral     0.702     0.726     0.849    106\n",
      "     sad     0.702     0.677     0.632    106\n",
      "surprise     0.702     0.750     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.701     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.496985 \n",
      "\n",
      "classification loss: 1.335164;  cosine similarity loss: 1.874566 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.811973; classification loss: 0.557793;  cosine similarity loss: 1.828694\n",
      "[ 1400/ 5482] total-loss: 0.575887; classification loss: 0.266433;  cosine similarity loss: 1.813705\n",
      "[ 2800/ 5482] total-loss: 0.647470; classification loss: 0.358231;  cosine similarity loss: 1.804427\n",
      "[ 4200/ 5482] total-loss: 0.484778; classification loss: 0.158590;  cosine similarity loss: 1.789531\n",
      "[ 5600/ 5482] total-loss: 0.499820; classification loss: 0.177587;  cosine similarity loss: 1.788754\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.759     0.774    106\n",
      " disgust     0.710     0.728     0.858    106\n",
      "    fear     0.710     0.680     0.660    106\n",
      "   happy     0.710     0.650     0.632    106\n",
      " neutral     0.710     0.734     0.858    106\n",
      "     sad     0.710     0.653     0.585    106\n",
      "surprise     0.710     0.762     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.709     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.485599 \n",
      "\n",
      "classification loss: 1.322659;  cosine similarity loss: 1.865791 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep60_acc_70.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep49_acc_70\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep60_acc_70\"! Old accuracy: 69.6, new accuracy: 70.4\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.518743; classification loss: 0.199462;  cosine similarity loss: 1.795864\n",
      "[ 1400/ 5482] total-loss: 0.486949; classification loss: 0.160442;  cosine similarity loss: 1.792974\n",
      "[ 2800/ 5482] total-loss: 0.739187; classification loss: 0.468315;  cosine similarity loss: 1.822675\n",
      "[ 4200/ 5482] total-loss: 0.559306; classification loss: 0.248567;  cosine similarity loss: 1.802265\n",
      "[ 5600/ 5482] total-loss: 0.494884; classification loss: 0.170458;  cosine similarity loss: 1.792590\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.745     0.774    106\n",
      " disgust     0.705     0.736     0.840    106\n",
      "    fear     0.705     0.648     0.642    106\n",
      "   happy     0.705     0.609     0.632    106\n",
      " neutral     0.705     0.693     0.830    106\n",
      "     sad     0.705     0.744     0.604    106\n",
      "surprise     0.705     0.783     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.708     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.515578 \n",
      "\n",
      "classification loss: 1.363413;  cosine similarity loss: 1.870628 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.479366; classification loss: 0.151706;  cosine similarity loss: 1.790005\n",
      "[ 1400/ 5482] total-loss: 0.477108; classification loss: 0.148407;  cosine similarity loss: 1.791914\n",
      "[ 2800/ 5482] total-loss: 0.669143; classification loss: 0.380838;  cosine similarity loss: 1.822360\n",
      "[ 4200/ 5482] total-loss: 0.590227; classification loss: 0.284828;  cosine similarity loss: 1.811826\n",
      "[ 5600/ 5482] total-loss: 0.493262; classification loss: 0.167801;  cosine similarity loss: 1.795106\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.731     0.745    106\n",
      " disgust     0.712     0.739     0.830    106\n",
      "    fear     0.712     0.710     0.623    106\n",
      "   happy     0.712     0.607     0.670    106\n",
      " neutral     0.712     0.756     0.849    106\n",
      "     sad     0.712     0.694     0.642    106\n",
      "surprise     0.712     0.750     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.713     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.542953 \n",
      "\n",
      "classification loss: 1.401575;  cosine similarity loss: 1.872836 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep62_acc_70.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep60_acc_70\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep62_acc_70\"! Old accuracy: 70.4, new accuracy: 70.5\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.509980; classification loss: 0.189819;  cosine similarity loss: 1.790623\n",
      "[ 1400/ 5482] total-loss: 0.539192; classification loss: 0.226461;  cosine similarity loss: 1.790115\n",
      "[ 2800/ 5482] total-loss: 0.502543; classification loss: 0.179755;  cosine similarity loss: 1.793696\n",
      "[ 4200/ 5482] total-loss: 0.510117; classification loss: 0.186720;  cosine similarity loss: 1.803702\n",
      "[ 5600/ 5482] total-loss: 0.652456; classification loss: 0.359550;  cosine similarity loss: 1.824083\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.690     0.704     0.764    106\n",
      " disgust     0.690     0.773     0.802    106\n",
      "    fear     0.690     0.531     0.651    106\n",
      "   happy     0.690     0.692     0.594    106\n",
      " neutral     0.690     0.770     0.821    106\n",
      "     sad     0.690     0.741     0.566    106\n",
      "surprise     0.690     0.657     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.690     0.695     0.690    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.466736 \n",
      "\n",
      "classification loss: 1.294076;  cosine similarity loss: 1.869612 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.641759; classification loss: 0.341595;  cosine similarity loss: 1.842415\n",
      "[ 1400/ 5482] total-loss: 0.530524; classification loss: 0.212821;  cosine similarity loss: 1.801333\n",
      "[ 2800/ 5482] total-loss: 0.468948; classification loss: 0.138216;  cosine similarity loss: 1.791873\n",
      "[ 4200/ 5482] total-loss: 0.681513; classification loss: 0.398864;  cosine similarity loss: 1.812111\n",
      "[ 5600/ 5482] total-loss: 0.479844; classification loss: 0.151028;  cosine similarity loss: 1.795107\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.716     0.783    106\n",
      " disgust     0.705     0.739     0.830    106\n",
      "    fear     0.705     0.685     0.575    106\n",
      "   happy     0.705     0.663     0.594    106\n",
      " neutral     0.705     0.732     0.877    106\n",
      "     sad     0.705     0.688     0.604    106\n",
      "surprise     0.705     0.689     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.702     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.531804 \n",
      "\n",
      "classification loss: 1.387219;  cosine similarity loss: 1.869168 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.496947; classification loss: 0.174807;  cosine similarity loss: 1.785507\n",
      "[ 1400/ 5482] total-loss: 0.627600; classification loss: 0.332136;  cosine similarity loss: 1.809453\n",
      "[ 2800/ 5482] total-loss: 0.485580; classification loss: 0.158088;  cosine similarity loss: 1.795548\n",
      "[ 4200/ 5482] total-loss: 0.476179; classification loss: 0.146673;  cosine similarity loss: 1.794205\n",
      "[ 5600/ 5482] total-loss: 0.461834; classification loss: 0.129099;  cosine similarity loss: 1.792774\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.687     0.686     0.764    106\n",
      " disgust     0.687     0.704     0.830    106\n",
      "    fear     0.687     0.620     0.585    106\n",
      "   happy     0.687     0.644     0.613    106\n",
      " neutral     0.687     0.714     0.802    106\n",
      "     sad     0.687     0.736     0.604    106\n",
      "surprise     0.687     0.707     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.687     0.687     0.687    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.551555 \n",
      "\n",
      "classification loss: 1.414375;  cosine similarity loss: 1.871641 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.479201; classification loss: 0.150682;  cosine similarity loss: 1.793275\n",
      "[ 1400/ 5482] total-loss: 0.471365; classification loss: 0.140971;  cosine similarity loss: 1.792940\n",
      "[ 2800/ 5482] total-loss: 0.786907; classification loss: 0.530142;  cosine similarity loss: 1.813966\n",
      "[ 4200/ 5482] total-loss: 0.487902; classification loss: 0.161007;  cosine similarity loss: 1.795481\n",
      "[ 5600/ 5482] total-loss: 0.461083; classification loss: 0.128417;  cosine similarity loss: 1.791748\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.700     0.726    106\n",
      " disgust     0.702     0.717     0.858    106\n",
      "    fear     0.702     0.660     0.604    106\n",
      "   happy     0.702     0.579     0.660    106\n",
      " neutral     0.702     0.763     0.849    106\n",
      "     sad     0.702     0.713     0.632    106\n",
      "surprise     0.702     0.827     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.708     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.567825 \n",
      "\n",
      "classification loss: 1.436566;  cosine similarity loss: 1.874093 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.493876; classification loss: 0.168440;  cosine similarity loss: 1.795620\n",
      "[ 1400/ 5482] total-loss: 0.693816; classification loss: 0.412322;  cosine similarity loss: 1.819793\n",
      "[ 2800/ 5482] total-loss: 0.464832; classification loss: 0.132913;  cosine similarity loss: 1.792505\n",
      "[ 4200/ 5482] total-loss: 0.459622; classification loss: 0.127277;  cosine similarity loss: 1.789001\n",
      "[ 5600/ 5482] total-loss: 0.522280; classification loss: 0.200547;  cosine similarity loss: 1.809210\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.698     0.764    106\n",
      " disgust     0.705     0.740     0.858    106\n",
      "    fear     0.705     0.643     0.594    106\n",
      "   happy     0.705     0.589     0.623    106\n",
      " neutral     0.705     0.768     0.811    106\n",
      "     sad     0.705     0.731     0.642    106\n",
      "surprise     0.705     0.773     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.706     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.565412 \n",
      "\n",
      "classification loss: 1.433131;  cosine similarity loss: 1.874068 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.478668; classification loss: 0.150457;  cosine similarity loss: 1.791510\n",
      "[ 1400/ 5482] total-loss: 0.455070; classification loss: 0.121000;  cosine similarity loss: 1.791349\n",
      "[ 2800/ 5482] total-loss: 0.469419; classification loss: 0.136979;  cosine similarity loss: 1.799180\n",
      "[ 4200/ 5482] total-loss: 0.466977; classification loss: 0.135326;  cosine similarity loss: 1.793584\n",
      "[ 5600/ 5482] total-loss: 0.784411; classification loss: 0.524056;  cosine similarity loss: 1.825828\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.798     0.745    106\n",
      " disgust     0.721     0.776     0.849    106\n",
      "    fear     0.721     0.586     0.642    106\n",
      "   happy     0.721     0.595     0.679    106\n",
      " neutral     0.721     0.748     0.811    106\n",
      "     sad     0.721     0.768     0.689    106\n",
      "surprise     0.721     0.838     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.730     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.566296 \n",
      "\n",
      "classification loss: 1.435194;  cosine similarity loss: 1.872201 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep68_acc_71.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep62_acc_70\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep68_acc_71\"! Old accuracy: 70.5, new accuracy: 71.4\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.458188; classification loss: 0.124051;  cosine similarity loss: 1.794734\n",
      "[ 1400/ 5482] total-loss: 0.455745; classification loss: 0.122253;  cosine similarity loss: 1.789713\n",
      "[ 2800/ 5482] total-loss: 0.469213; classification loss: 0.138101;  cosine similarity loss: 1.793659\n",
      "[ 4200/ 5482] total-loss: 0.480546; classification loss: 0.147711;  cosine similarity loss: 1.811888\n",
      "[ 5600/ 5482] total-loss: 0.452931; classification loss: 0.119261;  cosine similarity loss: 1.787609\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.755     0.783    106\n",
      " disgust     0.705     0.782     0.811    106\n",
      "    fear     0.705     0.626     0.585    106\n",
      "   happy     0.705     0.595     0.623    106\n",
      " neutral     0.705     0.742     0.840    106\n",
      "     sad     0.705     0.719     0.651    106\n",
      "surprise     0.705     0.708     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.704     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.537123 \n",
      "\n",
      "classification loss: 1.395136;  cosine similarity loss: 1.868424 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.503083; classification loss: 0.178715;  cosine similarity loss: 1.800559\n",
      "[ 1400/ 5482] total-loss: 0.453074; classification loss: 0.119224;  cosine similarity loss: 1.788475\n",
      "[ 2800/ 5482] total-loss: 0.452725; classification loss: 0.117878;  cosine similarity loss: 1.792116\n",
      "[ 4200/ 5482] total-loss: 0.463771; classification loss: 0.131625;  cosine similarity loss: 1.792353\n",
      "[ 5600/ 5482] total-loss: 0.498129; classification loss: 0.173485;  cosine similarity loss: 1.796706\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.672     0.774    106\n",
      " disgust     0.701     0.755     0.783    106\n",
      "    fear     0.701     0.596     0.642    106\n",
      "   happy     0.701     0.673     0.660    106\n",
      " neutral     0.701     0.729     0.811    106\n",
      "     sad     0.701     0.818     0.594    106\n",
      "surprise     0.701     0.701     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.706     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.584539 \n",
      "\n",
      "classification loss: 1.460002;  cosine similarity loss: 1.875123 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.453634; classification loss: 0.119222;  cosine similarity loss: 1.791282\n",
      "[ 1400/ 5482] total-loss: 0.452054; classification loss: 0.117301;  cosine similarity loss: 1.791069\n",
      "[ 2800/ 5482] total-loss: 0.463102; classification loss: 0.129332;  cosine similarity loss: 1.798181\n",
      "[ 4200/ 5482] total-loss: 0.450175; classification loss: 0.115236;  cosine similarity loss: 1.789934\n",
      "[ 5600/ 5482] total-loss: 0.477458; classification loss: 0.148470;  cosine similarity loss: 1.793409\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.736     0.840    106\n",
      " disgust     0.722     0.698     0.849    106\n",
      "    fear     0.722     0.618     0.642    106\n",
      "   happy     0.722     0.707     0.613    106\n",
      " neutral     0.722     0.777     0.821    106\n",
      "     sad     0.722     0.758     0.651    106\n",
      "surprise     0.722     0.782     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.725     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.544510 \n",
      "\n",
      "classification loss: 1.405809;  cosine similarity loss: 1.868147 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep71_acc_72.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep68_acc_71\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep71_acc_72\"! Old accuracy: 71.4, new accuracy: 71.6\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.454247; classification loss: 0.119233;  cosine similarity loss: 1.794300\n",
      "[ 1400/ 5482] total-loss: 0.448430; classification loss: 0.112581;  cosine similarity loss: 1.791826\n",
      "[ 2800/ 5482] total-loss: 0.451835; classification loss: 0.117352;  cosine similarity loss: 1.789768\n",
      "[ 4200/ 5482] total-loss: 0.546378; classification loss: 0.232018;  cosine similarity loss: 1.803820\n",
      "[ 5600/ 5482] total-loss: 0.445388; classification loss: 0.108690;  cosine similarity loss: 1.792181\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.748     0.783    106\n",
      " disgust     0.706     0.736     0.840    106\n",
      "    fear     0.706     0.626     0.632    106\n",
      "   happy     0.706     0.606     0.623    106\n",
      " neutral     0.706     0.789     0.849    106\n",
      "     sad     0.706     0.684     0.632    106\n",
      "surprise     0.706     0.756     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.706     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.581417 \n",
      "\n",
      "classification loss: 1.457164;  cosine similarity loss: 1.871341 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.492811; classification loss: 0.165521;  cosine similarity loss: 1.801971\n",
      "[ 1400/ 5482] total-loss: 0.443654; classification loss: 0.107708;  cosine similarity loss: 1.787438\n",
      "[ 2800/ 5482] total-loss: 0.441914; classification loss: 0.104187;  cosine similarity loss: 1.792821\n",
      "[ 4200/ 5482] total-loss: 0.443483; classification loss: 0.106482;  cosine similarity loss: 1.791489\n",
      "[ 5600/ 5482] total-loss: 0.441173; classification loss: 0.103773;  cosine similarity loss: 1.790773\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.704     0.645     0.755    106\n",
      " disgust     0.704     0.720     0.849    106\n",
      "    fear     0.704     0.629     0.575    106\n",
      "   happy     0.704     0.645     0.651    106\n",
      " neutral     0.704     0.802     0.802    106\n",
      "     sad     0.704     0.745     0.660    106\n",
      "surprise     0.704     0.753     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.704     0.705     0.704    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.610453 \n",
      "\n",
      "classification loss: 1.497331;  cosine similarity loss: 1.874403 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.460198; classification loss: 0.125979;  cosine similarity loss: 1.797073\n",
      "[ 1400/ 5482] total-loss: 0.458573; classification loss: 0.124781;  cosine similarity loss: 1.793739\n",
      "[ 2800/ 5482] total-loss: 0.439663; classification loss: 0.101395;  cosine similarity loss: 1.792735\n",
      "[ 4200/ 5482] total-loss: 0.459333; classification loss: 0.124753;  cosine similarity loss: 1.797651\n",
      "[ 5600/ 5482] total-loss: 0.435832; classification loss: 0.096318;  cosine similarity loss: 1.793888\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.704     0.728     0.708    106\n",
      " disgust     0.704     0.701     0.840    106\n",
      "    fear     0.704     0.677     0.613    106\n",
      "   happy     0.704     0.644     0.632    106\n",
      " neutral     0.704     0.783     0.849    106\n",
      "     sad     0.704     0.657     0.670    106\n",
      "surprise     0.704     0.730     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.704     0.703     0.704    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.540135 \n",
      "\n",
      "classification loss: 1.399391;  cosine similarity loss: 1.868538 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.545699; classification loss: 0.226183;  cosine similarity loss: 1.823762\n",
      "[ 1400/ 5482] total-loss: 0.457563; classification loss: 0.123397;  cosine similarity loss: 1.794228\n",
      "[ 2800/ 5482] total-loss: 0.512914; classification loss: 0.189843;  cosine similarity loss: 1.805202\n",
      "[ 4200/ 5482] total-loss: 0.455744; classification loss: 0.121444;  cosine similarity loss: 1.792944\n",
      "[ 5600/ 5482] total-loss: 0.461649; classification loss: 0.127748;  cosine similarity loss: 1.797251\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.757     0.792    106\n",
      " disgust     0.720     0.730     0.868    106\n",
      "    fear     0.720     0.639     0.651    106\n",
      "   happy     0.720     0.620     0.632    106\n",
      " neutral     0.720     0.757     0.821    106\n",
      "     sad     0.720     0.742     0.679    106\n",
      "surprise     0.720     0.818     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.723     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.609003 \n",
      "\n",
      "classification loss: 1.496285;  cosine similarity loss: 1.872011 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.439753; classification loss: 0.102246;  cosine similarity loss: 1.789783\n",
      "[ 1400/ 5482] total-loss: 0.441042; classification loss: 0.103371;  cosine similarity loss: 1.791724\n",
      "[ 2800/ 5482] total-loss: 0.437158; classification loss: 0.098294;  cosine similarity loss: 1.792613\n",
      "[ 4200/ 5482] total-loss: 0.525898; classification loss: 0.206078;  cosine similarity loss: 1.805182\n",
      "[ 5600/ 5482] total-loss: 0.436741; classification loss: 0.097560;  cosine similarity loss: 1.793462\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.694     0.718     0.792    106\n",
      " disgust     0.694     0.641     0.877    106\n",
      "    fear     0.694     0.684     0.491    106\n",
      "   happy     0.694     0.629     0.623    106\n",
      " neutral     0.694     0.780     0.802    106\n",
      "     sad     0.694     0.673     0.660    106\n",
      "surprise     0.694     0.756     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.694     0.697     0.694    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.572407 \n",
      "\n",
      "classification loss: 1.444701;  cosine similarity loss: 1.870387 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.441771; classification loss: 0.103479;  cosine similarity loss: 1.794940\n",
      "[ 1400/ 5482] total-loss: 0.442861; classification loss: 0.104953;  cosine similarity loss: 1.794496\n",
      "[ 2800/ 5482] total-loss: 0.431613; classification loss: 0.092414;  cosine similarity loss: 1.788410\n",
      "[ 4200/ 5482] total-loss: 0.478505; classification loss: 0.148961;  cosine similarity loss: 1.796679\n",
      "[ 5600/ 5482] total-loss: 0.442473; classification loss: 0.104045;  cosine similarity loss: 1.796182\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.704     0.669     0.821    106\n",
      " disgust     0.704     0.682     0.849    106\n",
      "    fear     0.704     0.606     0.538    106\n",
      "   happy     0.704     0.765     0.613    106\n",
      " neutral     0.704     0.779     0.764    106\n",
      "     sad     0.704     0.761     0.660    106\n",
      "surprise     0.704     0.686     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.704     0.707     0.704    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.579969 \n",
      "\n",
      "classification loss: 1.454103;  cosine similarity loss: 1.873655 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.446717; classification loss: 0.110028;  cosine similarity loss: 1.793475\n",
      "[ 1400/ 5482] total-loss: 0.455066; classification loss: 0.119788;  cosine similarity loss: 1.796178\n",
      "[ 2800/ 5482] total-loss: 0.564457; classification loss: 0.254007;  cosine similarity loss: 1.806258\n",
      "[ 4200/ 5482] total-loss: 0.600341; classification loss: 0.296140;  cosine similarity loss: 1.817144\n",
      "[ 5600/ 5482] total-loss: 0.432871; classification loss: 0.090864;  cosine similarity loss: 1.800901\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.696     0.736    106\n",
      " disgust     0.701     0.770     0.821    106\n",
      "    fear     0.701     0.616     0.575    106\n",
      "   happy     0.701     0.593     0.660    106\n",
      " neutral     0.701     0.750     0.849    106\n",
      "     sad     0.701     0.784     0.651    106\n",
      "surprise     0.701     0.707     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.702     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.605281 \n",
      "\n",
      "classification loss: 1.491653;  cosine similarity loss: 1.870415 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.437710; classification loss: 0.098817;  cosine similarity loss: 1.793280\n",
      "[ 1400/ 5482] total-loss: 0.440781; classification loss: 0.102650;  cosine similarity loss: 1.793303\n",
      "[ 2800/ 5482] total-loss: 0.475921; classification loss: 0.143620;  cosine similarity loss: 1.805125\n",
      "[ 4200/ 5482] total-loss: 0.439316; classification loss: 0.100536;  cosine similarity loss: 1.794434\n",
      "[ 5600/ 5482] total-loss: 0.467814; classification loss: 0.136047;  cosine similarity loss: 1.794883\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.682     0.672     0.774    106\n",
      " disgust     0.682     0.706     0.792    106\n",
      "    fear     0.682     0.638     0.566    106\n",
      "   happy     0.682     0.708     0.594    106\n",
      " neutral     0.682     0.757     0.764    106\n",
      "     sad     0.682     0.657     0.670    106\n",
      "surprise     0.682     0.631     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.682     0.681     0.682    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 1.604213 \n",
      "\n",
      "classification loss: 1.489701;  cosine similarity loss: 1.871406 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.436974; classification loss: 0.098495;  cosine similarity loss: 1.790889\n",
      "[ 1400/ 5482] total-loss: 0.484555; classification loss: 0.156154;  cosine similarity loss: 1.798159\n",
      "[ 2800/ 5482] total-loss: 0.443559; classification loss: 0.106872;  cosine similarity loss: 1.790311\n",
      "[ 4200/ 5482] total-loss: 0.427562; classification loss: 0.086032;  cosine similarity loss: 1.793681\n",
      "[ 5600/ 5482] total-loss: 0.448391; classification loss: 0.114040;  cosine similarity loss: 1.785797\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.695     0.725     0.745    106\n",
      " disgust     0.695     0.674     0.858    106\n",
      "    fear     0.695     0.663     0.575    106\n",
      "   happy     0.695     0.617     0.623    106\n",
      " neutral     0.695     0.754     0.811    106\n",
      "     sad     0.695     0.726     0.651    106\n",
      "surprise     0.695     0.711     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.695     0.696     0.695    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 1.651307 \n",
      "\n",
      "classification loss: 1.556334;  cosine similarity loss: 1.872909 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.450215; classification loss: 0.113118;  cosine similarity loss: 1.798601\n",
      "[ 1400/ 5482] total-loss: 0.425273; classification loss: 0.084723;  cosine similarity loss: 1.787472\n",
      "[ 2800/ 5482] total-loss: 0.424596; classification loss: 0.085207;  cosine similarity loss: 1.782152\n",
      "[ 4200/ 5482] total-loss: 0.426718; classification loss: 0.086177;  cosine similarity loss: 1.788884\n",
      "[ 5600/ 5482] total-loss: 0.428536; classification loss: 0.088213;  cosine similarity loss: 1.789826\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.698     0.648     0.783    106\n",
      " disgust     0.698     0.720     0.849    106\n",
      "    fear     0.698     0.644     0.547    106\n",
      "   happy     0.698     0.632     0.632    106\n",
      " neutral     0.698     0.768     0.811    106\n",
      "     sad     0.698     0.750     0.651    106\n",
      "surprise     0.698     0.730     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.698     0.699     0.698    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.603612 \n",
      "\n",
      "classification loss: 1.489336;  cosine similarity loss: 1.870256 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.429531; classification loss: 0.089779;  cosine similarity loss: 1.788538\n",
      "[ 1400/ 5482] total-loss: 0.429230; classification loss: 0.088379;  cosine similarity loss: 1.792638\n",
      "[ 2800/ 5482] total-loss: 0.450713; classification loss: 0.115388;  cosine similarity loss: 1.792014\n",
      "[ 4200/ 5482] total-loss: 0.600131; classification loss: 0.299241;  cosine similarity loss: 1.803691\n",
      "[ 5600/ 5482] total-loss: 0.428342; classification loss: 0.087591;  cosine similarity loss: 1.791346\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.695     0.774    106\n",
      " disgust     0.705     0.759     0.802    106\n",
      "    fear     0.705     0.626     0.585    106\n",
      "   happy     0.705     0.617     0.623    106\n",
      " neutral     0.705     0.752     0.830    106\n",
      "     sad     0.705     0.791     0.679    106\n",
      "surprise     0.705     0.694     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.705     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.613043 \n",
      "\n",
      "classification loss: 1.502843;  cosine similarity loss: 1.870177 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.428004; classification loss: 0.084009;  cosine similarity loss: 1.803982\n",
      "[ 1400/ 5482] total-loss: 0.452634; classification loss: 0.115658;  cosine similarity loss: 1.800537\n",
      "[ 2800/ 5482] total-loss: 0.428058; classification loss: 0.087555;  cosine similarity loss: 1.790072\n",
      "[ 4200/ 5482] total-loss: 0.426529; classification loss: 0.085060;  cosine similarity loss: 1.792404\n",
      "[ 5600/ 5482] total-loss: 0.421012; classification loss: 0.078482;  cosine similarity loss: 1.791129\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.701     0.774    106\n",
      " disgust     0.712     0.754     0.840    106\n",
      "    fear     0.712     0.667     0.604    106\n",
      "   happy     0.712     0.736     0.604    106\n",
      " neutral     0.712     0.781     0.840    106\n",
      "     sad     0.712     0.695     0.689    106\n",
      "surprise     0.712     0.638     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.710     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.563720 \n",
      "\n",
      "classification loss: 1.433784;  cosine similarity loss: 1.866904 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.425171; classification loss: 0.083727;  cosine similarity loss: 1.790948\n",
      "[ 1400/ 5482] total-loss: 0.430058; classification loss: 0.090128;  cosine similarity loss: 1.789775\n",
      "[ 2800/ 5482] total-loss: 0.415923; classification loss: 0.074022;  cosine similarity loss: 1.783528\n",
      "[ 4200/ 5482] total-loss: 0.420961; classification loss: 0.079203;  cosine similarity loss: 1.787992\n",
      "[ 5600/ 5482] total-loss: 0.435180; classification loss: 0.096739;  cosine similarity loss: 1.788946\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.727     0.755    106\n",
      " disgust     0.709     0.730     0.868    106\n",
      "    fear     0.709     0.637     0.613    106\n",
      "   happy     0.709     0.676     0.651    106\n",
      " neutral     0.709     0.757     0.821    106\n",
      "     sad     0.709     0.676     0.670    106\n",
      "surprise     0.709     0.756     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.709     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.604491 \n",
      "\n",
      "classification loss: 1.491149;  cosine similarity loss: 1.868955 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.493319; classification loss: 0.167700;  cosine similarity loss: 1.795798\n",
      "[ 1400/ 5482] total-loss: 0.420493; classification loss: 0.079113;  cosine similarity loss: 1.786014\n",
      "[ 2800/ 5482] total-loss: 0.470056; classification loss: 0.138343;  cosine similarity loss: 1.796908\n",
      "[ 4200/ 5482] total-loss: 0.420408; classification loss: 0.079174;  cosine similarity loss: 1.785345\n",
      "[ 5600/ 5482] total-loss: 0.418713; classification loss: 0.077747;  cosine similarity loss: 1.782573\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.643     0.783    106\n",
      " disgust     0.710     0.765     0.830    106\n",
      "    fear     0.710     0.716     0.594    106\n",
      "   happy     0.710     0.644     0.632    106\n",
      " neutral     0.710     0.750     0.849    106\n",
      "     sad     0.710     0.763     0.698    106\n",
      "surprise     0.710     0.697     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.711     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.633512 \n",
      "\n",
      "classification loss: 1.531475;  cosine similarity loss: 1.871599 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.419406; classification loss: 0.078661;  cosine similarity loss: 1.782384\n",
      "[ 1400/ 5482] total-loss: 0.430617; classification loss: 0.090474;  cosine similarity loss: 1.791190\n",
      "[ 2800/ 5482] total-loss: 0.415307; classification loss: 0.072344;  cosine similarity loss: 1.787159\n",
      "[ 4200/ 5482] total-loss: 0.497323; classification loss: 0.171949;  cosine similarity loss: 1.798818\n",
      "[ 5600/ 5482] total-loss: 0.449553; classification loss: 0.111845;  cosine similarity loss: 1.800385\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.758     0.708    106\n",
      " disgust     0.710     0.736     0.840    106\n",
      "    fear     0.710     0.614     0.660    106\n",
      "   happy     0.710     0.603     0.717    106\n",
      " neutral     0.710     0.789     0.811    106\n",
      "     sad     0.710     0.740     0.670    106\n",
      "surprise     0.710     0.779     0.566    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.717     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.633675 \n",
      "\n",
      "classification loss: 1.533042;  cosine similarity loss: 1.868486 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.412794; classification loss: 0.069471;  cosine similarity loss: 1.786085\n",
      "[ 1400/ 5482] total-loss: 0.416129; classification loss: 0.072455;  cosine similarity loss: 1.790825\n",
      "[ 2800/ 5482] total-loss: 0.420419; classification loss: 0.078631;  cosine similarity loss: 1.787574\n",
      "[ 4200/ 5482] total-loss: 0.413328; classification loss: 0.070630;  cosine similarity loss: 1.784121\n",
      "[ 5600/ 5482] total-loss: 0.420854; classification loss: 0.079191;  cosine similarity loss: 1.787506\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.747     0.670    106\n",
      " disgust     0.717     0.721     0.877    106\n",
      "    fear     0.717     0.605     0.708    106\n",
      "   happy     0.717     0.624     0.594    106\n",
      " neutral     0.717     0.824     0.840    106\n",
      "     sad     0.717     0.735     0.708    106\n",
      "surprise     0.717     0.795     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.722     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 1.622407 \n",
      "\n",
      "classification loss: 1.515339;  cosine similarity loss: 1.872232 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.425745; classification loss: 0.086060;  cosine similarity loss: 1.784482\n",
      "[ 1400/ 5482] total-loss: 0.419619; classification loss: 0.077288;  cosine similarity loss: 1.788941\n",
      "[ 2800/ 5482] total-loss: 0.412851; classification loss: 0.071051;  cosine similarity loss: 1.780049\n",
      "[ 4200/ 5482] total-loss: 0.517031; classification loss: 0.195338;  cosine similarity loss: 1.803804\n",
      "[ 5600/ 5482] total-loss: 0.416841; classification loss: 0.075995;  cosine similarity loss: 1.780225\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.699     0.694     0.726    106\n",
      " disgust     0.699     0.727     0.830    106\n",
      "    fear     0.699     0.581     0.642    106\n",
      "   happy     0.699     0.646     0.604    106\n",
      " neutral     0.699     0.754     0.840    106\n",
      "     sad     0.699     0.730     0.689    106\n",
      "surprise     0.699     0.789     0.566    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.699     0.703     0.699    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.668342 \n",
      "\n",
      "classification loss: 1.580727;  cosine similarity loss: 1.872777 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.423499; classification loss: 0.081117;  cosine similarity loss: 1.793029\n",
      "[ 1400/ 5482] total-loss: 0.434523; classification loss: 0.095865;  cosine similarity loss: 1.789151\n",
      "[ 2800/ 5482] total-loss: 0.413593; classification loss: 0.070795;  cosine similarity loss: 1.784785\n",
      "[ 4200/ 5482] total-loss: 0.413754; classification loss: 0.069693;  cosine similarity loss: 1.789998\n",
      "[ 5600/ 5482] total-loss: 0.431015; classification loss: 0.091032;  cosine similarity loss: 1.790946\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.675     0.764    106\n",
      " disgust     0.714     0.726     0.849    106\n",
      "    fear     0.714     0.657     0.613    106\n",
      "   happy     0.714     0.633     0.651    106\n",
      " neutral     0.714     0.782     0.811    106\n",
      "     sad     0.714     0.705     0.698    106\n",
      "surprise     0.714     0.867     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.721     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 1.571397 \n",
      "\n",
      "classification loss: 1.444096;  cosine similarity loss: 1.868434 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.428936; classification loss: 0.088916;  cosine similarity loss: 1.789013\n",
      "[ 1400/ 5482] total-loss: 0.841791; classification loss: 0.598110;  cosine similarity loss: 1.816517\n",
      "[ 2800/ 5482] total-loss: 0.465836; classification loss: 0.131194;  cosine similarity loss: 1.804404\n",
      "[ 4200/ 5482] total-loss: 0.421980; classification loss: 0.078753;  cosine similarity loss: 1.794889\n",
      "[ 5600/ 5482] total-loss: 0.408470; classification loss: 0.064092;  cosine similarity loss: 1.785984\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.644     0.802    106\n",
      " disgust     0.710     0.763     0.821    106\n",
      "    fear     0.710     0.614     0.660    106\n",
      "   happy     0.710     0.594     0.566    106\n",
      " neutral     0.710     0.789     0.811    106\n",
      "     sad     0.710     0.829     0.642    106\n",
      "surprise     0.710     0.789     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.717     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.670014 \n",
      "\n",
      "classification loss: 1.583194;  cosine similarity loss: 1.872593 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.558831; classification loss: 0.248335;  cosine similarity loss: 1.800815\n",
      "[ 1400/ 5482] total-loss: 0.471938; classification loss: 0.139510;  cosine similarity loss: 1.801650\n",
      "[ 2800/ 5482] total-loss: 0.433736; classification loss: 0.094480;  cosine similarity loss: 1.790757\n",
      "[ 4200/ 5482] total-loss: 0.409713; classification loss: 0.066260;  cosine similarity loss: 1.783526\n",
      "[ 5600/ 5482] total-loss: 0.415630; classification loss: 0.072294;  cosine similarity loss: 1.788972\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.724     0.694     0.811    106\n",
      " disgust     0.724     0.789     0.811    106\n",
      "    fear     0.724     0.621     0.679    106\n",
      "   happy     0.724     0.625     0.613    106\n",
      " neutral     0.724     0.795     0.840    106\n",
      "     sad     0.724     0.778     0.660    106\n",
      "surprise     0.724     0.793     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.724     0.728     0.724    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 1.634980 \n",
      "\n",
      "classification loss: 1.535013;  cosine similarity loss: 1.868237 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep91_acc_72.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep71_acc_72\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep91_acc_72\"! Old accuracy: 71.6, new accuracy: 71.7\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.404840; classification loss: 0.061218;  cosine similarity loss: 1.779329\n",
      "[ 1400/ 5482] total-loss: 0.405162; classification loss: 0.060394;  cosine similarity loss: 1.784232\n",
      "[ 2800/ 5482] total-loss: 0.407248; classification loss: 0.064349;  cosine similarity loss: 1.778842\n",
      "[ 4200/ 5482] total-loss: 0.413002; classification loss: 0.069658;  cosine similarity loss: 1.786376\n",
      "[ 5600/ 5482] total-loss: 0.419822; classification loss: 0.076884;  cosine similarity loss: 1.791572\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.654     0.783    106\n",
      " disgust     0.713     0.712     0.840    106\n",
      "    fear     0.713     0.707     0.613    106\n",
      "   happy     0.713     0.711     0.604    106\n",
      " neutral     0.713     0.817     0.802    106\n",
      "     sad     0.713     0.696     0.670    106\n",
      "surprise     0.713     0.706     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.715     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.586865 \n",
      "\n",
      "classification loss: 1.466473;  cosine similarity loss: 1.867780 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.404697; classification loss: 0.060718;  cosine similarity loss: 1.780612\n",
      "[ 1400/ 5482] total-loss: 0.415000; classification loss: 0.070796;  cosine similarity loss: 1.791813\n",
      "[ 2800/ 5482] total-loss: 0.403396; classification loss: 0.058332;  cosine similarity loss: 1.783654\n",
      "[ 4200/ 5482] total-loss: 0.432363; classification loss: 0.091263;  cosine similarity loss: 1.796765\n",
      "[ 5600/ 5482] total-loss: 0.412286; classification loss: 0.068864;  cosine similarity loss: 1.785971\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.649     0.821    106\n",
      " disgust     0.714     0.772     0.830    106\n",
      "    fear     0.714     0.680     0.660    106\n",
      "   happy     0.714     0.674     0.585    106\n",
      " neutral     0.714     0.791     0.821    106\n",
      "     sad     0.714     0.729     0.660    106\n",
      "surprise     0.714     0.710     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.715     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 1.655436 \n",
      "\n",
      "classification loss: 1.564653;  cosine similarity loss: 1.867261 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.407253; classification loss: 0.062280;  cosine similarity loss: 1.787145\n",
      "[ 1400/ 5482] total-loss: 0.416392; classification loss: 0.072760;  cosine similarity loss: 1.790922\n",
      "[ 2800/ 5482] total-loss: 0.404364; classification loss: 0.059184;  cosine similarity loss: 1.785083\n",
      "[ 4200/ 5482] total-loss: 0.421114; classification loss: 0.077399;  cosine similarity loss: 1.795974\n",
      "[ 5600/ 5482] total-loss: 0.402246; classification loss: 0.057211;  cosine similarity loss: 1.782387\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.675     0.783    106\n",
      " disgust     0.702     0.677     0.849    106\n",
      "    fear     0.702     0.624     0.642    106\n",
      "   happy     0.702     0.621     0.604    106\n",
      " neutral     0.702     0.764     0.792    106\n",
      "     sad     0.702     0.825     0.623    106\n",
      "surprise     0.702     0.786     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.710     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.698237 \n",
      "\n",
      "classification loss: 1.624967;  cosine similarity loss: 1.869200 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.448207; classification loss: 0.111990;  cosine similarity loss: 1.793074\n",
      "[ 1400/ 5482] total-loss: 0.410811; classification loss: 0.066661;  cosine similarity loss: 1.787413\n",
      "[ 2800/ 5482] total-loss: 0.407050; classification loss: 0.061906;  cosine similarity loss: 1.787626\n",
      "[ 4200/ 5482] total-loss: 0.437245; classification loss: 0.097164;  cosine similarity loss: 1.797565\n",
      "[ 5600/ 5482] total-loss: 0.422074; classification loss: 0.079000;  cosine similarity loss: 1.794372\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.750     0.764    106\n",
      " disgust     0.714     0.655     0.858    106\n",
      "    fear     0.714     0.663     0.651    106\n",
      "   happy     0.714     0.667     0.604    106\n",
      " neutral     0.714     0.767     0.840    106\n",
      "     sad     0.714     0.753     0.660    106\n",
      "surprise     0.714     0.767     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.717     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 1.672971 \n",
      "\n",
      "classification loss: 1.588580;  cosine similarity loss: 1.869882 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.403960; classification loss: 0.059834;  cosine similarity loss: 1.780465\n",
      "[ 1400/ 5482] total-loss: 0.404193; classification loss: 0.058833;  cosine similarity loss: 1.785635\n",
      "[ 2800/ 5482] total-loss: 0.401002; classification loss: 0.056249;  cosine similarity loss: 1.780014\n",
      "[ 4200/ 5482] total-loss: 0.403364; classification loss: 0.058204;  cosine similarity loss: 1.784003\n",
      "[ 5600/ 5482] total-loss: 0.446025; classification loss: 0.108634;  cosine similarity loss: 1.795591\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.678     0.755    106\n",
      " disgust     0.716     0.724     0.840    106\n",
      "    fear     0.716     0.633     0.651    106\n",
      "   happy     0.716     0.656     0.594    106\n",
      " neutral     0.716     0.759     0.830    106\n",
      "     sad     0.716     0.812     0.651    106\n",
      "surprise     0.716     0.768     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.719     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.679484 \n",
      "\n",
      "classification loss: 1.599173;  cosine similarity loss: 1.866876 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.402967; classification loss: 0.057571;  cosine similarity loss: 1.784550\n",
      "[ 1400/ 5482] total-loss: 0.407468; classification loss: 0.063342;  cosine similarity loss: 1.783974\n",
      "[ 2800/ 5482] total-loss: 0.428816; classification loss: 0.088949;  cosine similarity loss: 1.788280\n",
      "[ 4200/ 5482] total-loss: 0.435741; classification loss: 0.096216;  cosine similarity loss: 1.793839\n",
      "[ 5600/ 5482] total-loss: 0.399548; classification loss: 0.053012;  cosine similarity loss: 1.785689\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.745     0.745    106\n",
      " disgust     0.721     0.748     0.840    106\n",
      "    fear     0.721     0.603     0.660    106\n",
      "   happy     0.721     0.657     0.651    106\n",
      " neutral     0.721     0.763     0.849    106\n",
      "     sad     0.721     0.805     0.660    106\n",
      "surprise     0.721     0.747     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.724     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.667312 \n",
      "\n",
      "classification loss: 1.579366;  cosine similarity loss: 1.872520 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.406562; classification loss: 0.062121;  cosine similarity loss: 1.784328\n",
      "[ 1400/ 5482] total-loss: 0.401015; classification loss: 0.055930;  cosine similarity loss: 1.781355\n",
      "[ 2800/ 5482] total-loss: 0.404166; classification loss: 0.058520;  cosine similarity loss: 1.786751\n",
      "[ 4200/ 5482] total-loss: 0.400711; classification loss: 0.054288;  cosine similarity loss: 1.786401\n",
      "[ 5600/ 5482] total-loss: 0.493785; classification loss: 0.164706;  cosine similarity loss: 1.810098\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.634     0.802    106\n",
      " disgust     0.712     0.756     0.849    106\n",
      "    fear     0.712     0.631     0.613    106\n",
      "   happy     0.712     0.657     0.613    106\n",
      " neutral     0.712     0.804     0.774    106\n",
      "     sad     0.712     0.760     0.717    106\n",
      "surprise     0.712     0.765     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.715     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.665033 \n",
      "\n",
      "classification loss: 1.576846;  cosine similarity loss: 1.870801 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.409633; classification loss: 0.065090;  cosine similarity loss: 1.787804\n",
      "[ 1400/ 5482] total-loss: 0.400142; classification loss: 0.053603;  cosine similarity loss: 1.786298\n",
      "[ 2800/ 5482] total-loss: 0.401165; classification loss: 0.055678;  cosine similarity loss: 1.783114\n",
      "[ 4200/ 5482] total-loss: 0.406784; classification loss: 0.060570;  cosine similarity loss: 1.791638\n",
      "[ 5600/ 5482] total-loss: 0.420782; classification loss: 0.076011;  cosine similarity loss: 1.799868\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.704     0.656     0.774    106\n",
      " disgust     0.704     0.723     0.811    106\n",
      "    fear     0.704     0.651     0.651    106\n",
      "   happy     0.704     0.644     0.632    106\n",
      " neutral     0.704     0.707     0.774    106\n",
      "     sad     0.704     0.774     0.679    106\n",
      "surprise     0.704     0.810     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.704     0.709     0.704    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.726120 \n",
      "\n",
      "classification loss: 1.662174;  cosine similarity loss: 1.875327 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.401247; classification loss: 0.054071;  cosine similarity loss: 1.789947\n",
      "[ 1400/ 5482] total-loss: 0.398222; classification loss: 0.052792;  cosine similarity loss: 1.779943\n",
      "[ 2800/ 5482] total-loss: 0.399427; classification loss: 0.052899;  cosine similarity loss: 1.785539\n",
      "[ 4200/ 5482] total-loss: 0.397016; classification loss: 0.050742;  cosine similarity loss: 1.782113\n",
      "[ 5600/ 5482] total-loss: 0.399754; classification loss: 0.053401;  cosine similarity loss: 1.785162\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.681     0.745    106\n",
      " disgust     0.710     0.752     0.802    106\n",
      "    fear     0.710     0.570     0.689    106\n",
      "   happy     0.710     0.657     0.613    106\n",
      " neutral     0.710     0.806     0.821    106\n",
      "     sad     0.710     0.765     0.708    106\n",
      "surprise     0.710     0.787     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.717     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.680868 \n",
      "\n",
      "classification loss: 1.599205;  cosine similarity loss: 1.871415 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.397138; classification loss: 0.052010;  cosine similarity loss: 1.777649\n",
      "[ 1400/ 5482] total-loss: 0.577288; classification loss: 0.271920;  cosine similarity loss: 1.798761\n",
      "[ 2800/ 5482] total-loss: 0.398272; classification loss: 0.052561;  cosine similarity loss: 1.781116\n",
      "[ 4200/ 5482] total-loss: 0.509876; classification loss: 0.186394;  cosine similarity loss: 1.803806\n",
      "[ 5600/ 5482] total-loss: 0.397733; classification loss: 0.051254;  cosine similarity loss: 1.783649\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.641     0.774    106\n",
      " disgust     0.716     0.721     0.830    106\n",
      "    fear     0.716     0.676     0.670    106\n",
      "   happy     0.716     0.687     0.642    106\n",
      " neutral     0.716     0.767     0.840    106\n",
      "     sad     0.716     0.758     0.651    106\n",
      "surprise     0.716     0.790     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.720     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.705881 \n",
      "\n",
      "classification loss: 1.634512;  cosine similarity loss: 1.872408 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.405894; classification loss: 0.059833;  cosine similarity loss: 1.790139\n",
      "[ 1400/ 5482] total-loss: 0.402960; classification loss: 0.057784;  cosine similarity loss: 1.783664\n",
      "[ 2800/ 5482] total-loss: 0.395953; classification loss: 0.049165;  cosine similarity loss: 1.783108\n",
      "[ 4200/ 5482] total-loss: 0.396658; classification loss: 0.051726;  cosine similarity loss: 1.776384\n",
      "[ 5600/ 5482] total-loss: 0.395947; classification loss: 0.048977;  cosine similarity loss: 1.783830\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.706     0.792    106\n",
      " disgust     0.713     0.755     0.783    106\n",
      "    fear     0.713     0.592     0.698    106\n",
      "   happy     0.713     0.678     0.575    106\n",
      " neutral     0.713     0.768     0.811    106\n",
      "     sad     0.713     0.742     0.679    106\n",
      "surprise     0.713     0.775     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.717     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.659093 \n",
      "\n",
      "classification loss: 1.568288;  cosine similarity loss: 1.870970 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.398011; classification loss: 0.051066;  cosine similarity loss: 1.785791\n",
      "[ 1400/ 5482] total-loss: 0.405656; classification loss: 0.059839;  cosine similarity loss: 1.788922\n",
      "[ 2800/ 5482] total-loss: 0.396497; classification loss: 0.049755;  cosine similarity loss: 1.783463\n",
      "[ 4200/ 5482] total-loss: 0.397243; classification loss: 0.051007;  cosine similarity loss: 1.782187\n",
      "[ 5600/ 5482] total-loss: 0.394896; classification loss: 0.048131;  cosine similarity loss: 1.781955\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.681     0.764    106\n",
      " disgust     0.720     0.734     0.858    106\n",
      "    fear     0.720     0.724     0.670    106\n",
      "   happy     0.720     0.639     0.651    106\n",
      " neutral     0.720     0.722     0.858    106\n",
      "     sad     0.720     0.802     0.651    106\n",
      "surprise     0.720     0.765     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.724     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.720563 \n",
      "\n",
      "classification loss: 1.657588;  cosine similarity loss: 1.867506 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.493174; classification loss: 0.168416;  cosine similarity loss: 1.792207\n",
      "[ 1400/ 5482] total-loss: 0.397881; classification loss: 0.051053;  cosine similarity loss: 1.785192\n",
      "[ 2800/ 5482] total-loss: 0.436772; classification loss: 0.097891;  cosine similarity loss: 1.792295\n",
      "[ 4200/ 5482] total-loss: 0.400087; classification loss: 0.053994;  cosine similarity loss: 1.784459\n",
      "[ 5600/ 5482] total-loss: 0.395471; classification loss: 0.049620;  cosine similarity loss: 1.778876\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.733     0.726    106\n",
      " disgust     0.705     0.752     0.858    106\n",
      "    fear     0.705     0.683     0.651    106\n",
      "   happy     0.705     0.613     0.613    106\n",
      " neutral     0.705     0.733     0.802    106\n",
      "     sad     0.705     0.670     0.670    106\n",
      "surprise     0.705     0.747     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.704     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.712075 \n",
      "\n",
      "classification loss: 1.644163;  cosine similarity loss: 1.870536 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.394325; classification loss: 0.047382;  cosine similarity loss: 1.782098\n",
      "[ 1400/ 5482] total-loss: 0.397220; classification loss: 0.049874;  cosine similarity loss: 1.786605\n",
      "[ 2800/ 5482] total-loss: 0.402825; classification loss: 0.057175;  cosine similarity loss: 1.785424\n",
      "[ 4200/ 5482] total-loss: 0.401975; classification loss: 0.054514;  cosine similarity loss: 1.791819\n",
      "[ 5600/ 5482] total-loss: 0.398068; classification loss: 0.051998;  cosine similarity loss: 1.782348\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.654     0.821    106\n",
      " disgust     0.716     0.693     0.830    106\n",
      "    fear     0.716     0.717     0.670    106\n",
      "   happy     0.716     0.653     0.604    106\n",
      " neutral     0.716     0.806     0.821    106\n",
      "     sad     0.716     0.750     0.679    106\n",
      "surprise     0.716     0.765     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.720     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.695386 \n",
      "\n",
      "classification loss: 1.622050;  cosine similarity loss: 1.866502 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.407350; classification loss: 0.061878;  cosine similarity loss: 1.789236\n",
      "[ 1400/ 5482] total-loss: 0.433098; classification loss: 0.092712;  cosine similarity loss: 1.794641\n",
      "[ 2800/ 5482] total-loss: 0.393167; classification loss: 0.044997;  cosine similarity loss: 1.785847\n",
      "[ 4200/ 5482] total-loss: 0.513251; classification loss: 0.193064;  cosine similarity loss: 1.793998\n",
      "[ 5600/ 5482] total-loss: 0.393600; classification loss: 0.045583;  cosine similarity loss: 1.785671\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.705     0.811    106\n",
      " disgust     0.701     0.706     0.840    106\n",
      "    fear     0.701     0.667     0.604    106\n",
      "   happy     0.701     0.593     0.632    106\n",
      " neutral     0.701     0.719     0.774    106\n",
      "     sad     0.701     0.761     0.632    106\n",
      "surprise     0.701     0.783     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.705     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.781595 \n",
      "\n",
      "classification loss: 1.743564;  cosine similarity loss: 1.870336 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.406114; classification loss: 0.059958;  cosine similarity loss: 1.790737\n",
      "[ 1400/ 5482] total-loss: 0.425077; classification loss: 0.083047;  cosine similarity loss: 1.793197\n",
      "[ 2800/ 5482] total-loss: 0.402022; classification loss: 0.056262;  cosine similarity loss: 1.785059\n",
      "[ 4200/ 5482] total-loss: 0.431278; classification loss: 0.092858;  cosine similarity loss: 1.784959\n",
      "[ 5600/ 5482] total-loss: 0.393433; classification loss: 0.046137;  cosine similarity loss: 1.782618\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.724     0.792    106\n",
      " disgust     0.713     0.722     0.858    106\n",
      "    fear     0.713     0.667     0.698    106\n",
      "   happy     0.713     0.569     0.585    106\n",
      " neutral     0.713     0.739     0.830    106\n",
      "     sad     0.713     0.810     0.642    106\n",
      "surprise     0.713     0.805     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.719     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.773367 \n",
      "\n",
      "classification loss: 1.731312;  cosine similarity loss: 1.871497 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.398668; classification loss: 0.051039;  cosine similarity loss: 1.789183\n",
      "[ 1400/ 5482] total-loss: 0.436544; classification loss: 0.096831;  cosine similarity loss: 1.795395\n",
      "[ 2800/ 5482] total-loss: 0.392189; classification loss: 0.045082;  cosine similarity loss: 1.780614\n",
      "[ 4200/ 5482] total-loss: 0.395556; classification loss: 0.047094;  cosine similarity loss: 1.789400\n",
      "[ 5600/ 5482] total-loss: 0.392301; classification loss: 0.045281;  cosine similarity loss: 1.780382\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.652     0.849    106\n",
      " disgust     0.705     0.825     0.802    106\n",
      "    fear     0.705     0.640     0.670    106\n",
      "   happy     0.705     0.628     0.557    106\n",
      " neutral     0.705     0.776     0.783    106\n",
      "     sad     0.705     0.651     0.651    106\n",
      "surprise     0.705     0.795     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.710     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.665238 \n",
      "\n",
      "classification loss: 1.578118;  cosine similarity loss: 1.868516 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.398727; classification loss: 0.051284;  cosine similarity loss: 1.788499\n",
      "[ 1400/ 5482] total-loss: 0.393418; classification loss: 0.046938;  cosine similarity loss: 1.779337\n",
      "[ 2800/ 5482] total-loss: 0.394830; classification loss: 0.047758;  cosine similarity loss: 1.783114\n",
      "[ 4200/ 5482] total-loss: 0.405040; classification loss: 0.059872;  cosine similarity loss: 1.785711\n",
      "[ 5600/ 5482] total-loss: 0.391424; classification loss: 0.044282;  cosine similarity loss: 1.779995\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.758     0.708    106\n",
      " disgust     0.712     0.752     0.802    106\n",
      "    fear     0.712     0.608     0.717    106\n",
      "   happy     0.712     0.627     0.604    106\n",
      " neutral     0.712     0.727     0.830    106\n",
      "     sad     0.712     0.706     0.679    106\n",
      "surprise     0.712     0.850     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.718     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.751957 \n",
      "\n",
      "classification loss: 1.700623;  cosine similarity loss: 1.871737 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.409155; classification loss: 0.061548;  cosine similarity loss: 1.799583\n",
      "[ 1400/ 5482] total-loss: 0.394281; classification loss: 0.046771;  cosine similarity loss: 1.784320\n",
      "[ 2800/ 5482] total-loss: 0.425354; classification loss: 0.084064;  cosine similarity loss: 1.790512\n",
      "[ 4200/ 5482] total-loss: 0.394457; classification loss: 0.048034;  cosine similarity loss: 1.780150\n",
      "[ 5600/ 5482] total-loss: 0.404452; classification loss: 0.057855;  cosine similarity loss: 1.790839\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.787     0.698    106\n",
      " disgust     0.721     0.730     0.868    106\n",
      "    fear     0.721     0.639     0.717    106\n",
      "   happy     0.721     0.600     0.623    106\n",
      " neutral     0.721     0.761     0.840    106\n",
      "     sad     0.721     0.761     0.660    106\n",
      "surprise     0.721     0.810     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.727     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.732463 \n",
      "\n",
      "classification loss: 1.674310;  cosine similarity loss: 1.868154 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.550379; classification loss: 0.239361;  cosine similarity loss: 1.794449\n",
      "[ 1400/ 5482] total-loss: 0.395554; classification loss: 0.049429;  cosine similarity loss: 1.780051\n",
      "[ 2800/ 5482] total-loss: 0.394925; classification loss: 0.046501;  cosine similarity loss: 1.788621\n",
      "[ 4200/ 5482] total-loss: 0.398377; classification loss: 0.050644;  cosine similarity loss: 1.789312\n",
      "[ 5600/ 5482] total-loss: 0.401447; classification loss: 0.053889;  cosine similarity loss: 1.791680\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.618     0.792    106\n",
      " disgust     0.706     0.737     0.821    106\n",
      "    fear     0.706     0.753     0.604    106\n",
      "   happy     0.706     0.657     0.632    106\n",
      " neutral     0.706     0.800     0.792    106\n",
      "     sad     0.706     0.778     0.660    106\n",
      "surprise     0.706     0.642     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.712     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.815466 \n",
      "\n",
      "classification loss: 1.792728;  cosine similarity loss: 1.868522 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.391496; classification loss: 0.043658;  cosine similarity loss: 1.782848\n",
      "[ 1400/ 5482] total-loss: 0.454425; classification loss: 0.117842;  cosine similarity loss: 1.800753\n",
      "[ 2800/ 5482] total-loss: 0.402706; classification loss: 0.056018;  cosine similarity loss: 1.789460\n",
      "[ 4200/ 5482] total-loss: 0.398028; classification loss: 0.052850;  cosine similarity loss: 1.778741\n",
      "[ 5600/ 5482] total-loss: 0.434027; classification loss: 0.093355;  cosine similarity loss: 1.796715\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.723     0.764    106\n",
      " disgust     0.705     0.786     0.830    106\n",
      "    fear     0.705     0.576     0.679    106\n",
      "   happy     0.705     0.547     0.604    106\n",
      " neutral     0.705     0.767     0.840    106\n",
      "     sad     0.705     0.795     0.623    106\n",
      "surprise     0.705     0.818     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.716     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.758592 \n",
      "\n",
      "classification loss: 1.709845;  cosine similarity loss: 1.872334 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.436315; classification loss: 0.097203;  cosine similarity loss: 1.792761\n",
      "[ 1400/ 5482] total-loss: 0.392469; classification loss: 0.044770;  cosine similarity loss: 1.783263\n",
      "[ 2800/ 5482] total-loss: 0.399104; classification loss: 0.053061;  cosine similarity loss: 1.783275\n",
      "[ 4200/ 5482] total-loss: 0.391629; classification loss: 0.042704;  cosine similarity loss: 1.787331\n",
      "[ 5600/ 5482] total-loss: 0.389563; classification loss: 0.041024;  cosine similarity loss: 1.783721\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.696     0.755    106\n",
      " disgust     0.712     0.730     0.840    106\n",
      "    fear     0.712     0.670     0.689    106\n",
      "   happy     0.712     0.612     0.594    106\n",
      " neutral     0.712     0.791     0.821    106\n",
      "     sad     0.712     0.735     0.679    106\n",
      "surprise     0.712     0.753     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.712     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.758047 \n",
      "\n",
      "classification loss: 1.710075;  cosine similarity loss: 1.869982 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.396885; classification loss: 0.049647;  cosine similarity loss: 1.785838\n",
      "[ 1400/ 5482] total-loss: 0.390127; classification loss: 0.041594;  cosine similarity loss: 1.784256\n",
      "[ 2800/ 5482] total-loss: 0.388565; classification loss: 0.040225;  cosine similarity loss: 1.781924\n",
      "[ 4200/ 5482] total-loss: 0.400383; classification loss: 0.053496;  cosine similarity loss: 1.787930\n",
      "[ 5600/ 5482] total-loss: 0.389281; classification loss: 0.040573;  cosine similarity loss: 1.784110\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.699     0.745    106\n",
      " disgust     0.720     0.769     0.849    106\n",
      "    fear     0.720     0.660     0.604    106\n",
      "   happy     0.720     0.673     0.642    106\n",
      " neutral     0.720     0.742     0.840    106\n",
      "     sad     0.720     0.738     0.717    106\n",
      "surprise     0.720     0.747     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.718     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.727062 \n",
      "\n",
      "classification loss: 1.668501;  cosine similarity loss: 1.863704 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.387526; classification loss: 0.039391;  cosine similarity loss: 1.780068\n",
      "[ 1400/ 5482] total-loss: 0.439083; classification loss: 0.098567;  cosine similarity loss: 1.801148\n",
      "[ 2800/ 5482] total-loss: 0.387930; classification loss: 0.039741;  cosine similarity loss: 1.780683\n",
      "[ 4200/ 5482] total-loss: 0.387274; classification loss: 0.038962;  cosine similarity loss: 1.780524\n",
      "[ 5600/ 5482] total-loss: 0.388917; classification loss: 0.040987;  cosine similarity loss: 1.780636\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.631     0.840    106\n",
      " disgust     0.710     0.832     0.792    106\n",
      "    fear     0.710     0.626     0.632    106\n",
      "   happy     0.710     0.681     0.585    106\n",
      " neutral     0.710     0.800     0.830    106\n",
      "     sad     0.710     0.745     0.660    106\n",
      "surprise     0.710     0.684     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.714     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.769053 \n",
      "\n",
      "classification loss: 1.725426;  cosine similarity loss: 1.870852 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.391303; classification loss: 0.042126;  cosine similarity loss: 1.788012\n",
      "[ 1400/ 5482] total-loss: 0.585891; classification loss: 0.283462;  cosine similarity loss: 1.795607\n",
      "[ 2800/ 5482] total-loss: 0.388268; classification loss: 0.039021;  cosine similarity loss: 1.785257\n",
      "[ 4200/ 5482] total-loss: 0.389405; classification loss: 0.040250;  cosine similarity loss: 1.786026\n",
      "[ 5600/ 5482] total-loss: 0.388403; classification loss: 0.040164;  cosine similarity loss: 1.781359\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.733     0.697     0.783    106\n",
      " disgust     0.733     0.773     0.802    106\n",
      "    fear     0.733     0.703     0.670    106\n",
      "   happy     0.733     0.628     0.670    106\n",
      " neutral     0.733     0.764     0.887    106\n",
      "     sad     0.733     0.789     0.708    106\n",
      "surprise     0.733     0.802     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.733     0.737     0.733    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 1.742607 \n",
      "\n",
      "classification loss: 1.690776;  cosine similarity loss: 1.863547 \n",
      "\n",
      "Generating Report... \n",
      "\n",
      "Report saved to: /home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep116_acc_73.md \n",
      "\n",
      "Old best model deleted from \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep91_acc_72\"\n",
      "New best model saved to \"/home/ckwdani/Programming/Projects/masterarbeit/Jupyter/mainProject/notebooks/content/soundstream/experiments/experiment_v_12_1_NR4_relu/Run_Nr_0/conv/emo_reco_best_ep116_acc_73\"! Old accuracy: 71.7, new accuracy: 72.6\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.394473; classification loss: 0.046756;  cosine similarity loss: 1.785340\n",
      "[ 1400/ 5482] total-loss: 0.392346; classification loss: 0.043613;  cosine similarity loss: 1.787278\n",
      "[ 2800/ 5482] total-loss: 0.386987; classification loss: 0.038516;  cosine similarity loss: 1.780871\n",
      "[ 4200/ 5482] total-loss: 0.386698; classification loss: 0.037972;  cosine similarity loss: 1.781602\n",
      "[ 5600/ 5482] total-loss: 0.387233; classification loss: 0.039019;  cosine similarity loss: 1.780087\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.632     0.792    106\n",
      " disgust     0.714     0.824     0.792    106\n",
      "    fear     0.714     0.706     0.679    106\n",
      "   happy     0.714     0.575     0.651    106\n",
      " neutral     0.714     0.717     0.858    106\n",
      "     sad     0.714     0.802     0.651    106\n",
      "surprise     0.714     0.847     0.575    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.729     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 1.787840 \n",
      "\n",
      "classification loss: 1.751857;  cosine similarity loss: 1.871802 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.387215; classification loss: 0.038846;  cosine similarity loss: 1.780692\n",
      "[ 1400/ 5482] total-loss: 0.391575; classification loss: 0.041469;  cosine similarity loss: 1.791999\n",
      "[ 2800/ 5482] total-loss: 0.386353; classification loss: 0.037614;  cosine similarity loss: 1.781311\n",
      "[ 4200/ 5482] total-loss: 0.386592; classification loss: 0.037131;  cosine similarity loss: 1.784439\n",
      "[ 5600/ 5482] total-loss: 0.425319; classification loss: 0.083974;  cosine similarity loss: 1.790698\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.733     0.696     0.821    106\n",
      " disgust     0.733     0.739     0.830    106\n",
      "    fear     0.733     0.682     0.689    106\n",
      "   happy     0.733     0.667     0.623    106\n",
      " neutral     0.733     0.778     0.858    106\n",
      "     sad     0.733     0.802     0.689    106\n",
      "surprise     0.733     0.786     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.733     0.736     0.733    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 1.700196 \n",
      "\n",
      "classification loss: 1.630534;  cosine similarity loss: 1.862741 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.395634; classification loss: 0.048559;  cosine similarity loss: 1.783933\n",
      "[ 1400/ 5482] total-loss: 0.391413; classification loss: 0.043481;  cosine similarity loss: 1.783140\n",
      "[ 2800/ 5482] total-loss: 0.385930; classification loss: 0.037446;  cosine similarity loss: 1.779865\n",
      "[ 4200/ 5482] total-loss: 0.390396; classification loss: 0.040342;  cosine similarity loss: 1.790613\n",
      "[ 5600/ 5482] total-loss: 0.386903; classification loss: 0.038444;  cosine similarity loss: 1.780740\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.697     0.802    106\n",
      " disgust     0.716     0.725     0.821    106\n",
      "    fear     0.716     0.683     0.651    106\n",
      "   happy     0.716     0.653     0.585    106\n",
      " neutral     0.716     0.756     0.849    106\n",
      "     sad     0.716     0.769     0.660    106\n",
      "surprise     0.716     0.723     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.715     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.766074 \n",
      "\n",
      "classification loss: 1.723120;  cosine similarity loss: 1.866302 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.385935; classification loss: 0.037431;  cosine similarity loss: 1.779951\n",
      "[ 1400/ 5482] total-loss: 0.385313; classification loss: 0.036885;  cosine similarity loss: 1.779028\n",
      "[ 2800/ 5482] total-loss: 0.390244; classification loss: 0.041783;  cosine similarity loss: 1.784087\n",
      "[ 4200/ 5482] total-loss: 0.387117; classification loss: 0.039405;  cosine similarity loss: 1.777965\n",
      "[ 5600/ 5482] total-loss: 0.384975; classification loss: 0.036601;  cosine similarity loss: 1.778473\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.713     0.774    106\n",
      " disgust     0.712     0.725     0.821    106\n",
      "    fear     0.712     0.676     0.651    106\n",
      "   happy     0.712     0.618     0.594    106\n",
      " neutral     0.712     0.781     0.840    106\n",
      "     sad     0.712     0.742     0.651    106\n",
      "surprise     0.712     0.719     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.711     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.767998 \n",
      "\n",
      "classification loss: 1.724488;  cosine similarity loss: 1.869521 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.385046; classification loss: 0.035660;  cosine similarity loss: 1.782588\n",
      "[ 1400/ 5482] total-loss: 0.388762; classification loss: 0.038922;  cosine similarity loss: 1.788122\n",
      "[ 2800/ 5482] total-loss: 0.387676; classification loss: 0.038637;  cosine similarity loss: 1.783831\n",
      "[ 4200/ 5482] total-loss: 0.384665; classification loss: 0.036375;  cosine similarity loss: 1.777824\n",
      "[ 5600/ 5482] total-loss: 0.387384; classification loss: 0.038334;  cosine similarity loss: 1.783584\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.677     0.811    106\n",
      " disgust     0.721     0.750     0.821    106\n",
      "    fear     0.721     0.614     0.660    106\n",
      "   happy     0.721     0.696     0.604    106\n",
      " neutral     0.721     0.798     0.821    106\n",
      "     sad     0.721     0.774     0.679    106\n",
      "surprise     0.721     0.758     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.724     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.808087 \n",
      "\n",
      "classification loss: 1.782473;  cosine similarity loss: 1.867855 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.390494; classification loss: 0.043208;  cosine similarity loss: 1.779636\n",
      "[ 1400/ 5482] total-loss: 0.386372; classification loss: 0.037836;  cosine similarity loss: 1.780518\n",
      "[ 2800/ 5482] total-loss: 0.384661; classification loss: 0.036775;  cosine similarity loss: 1.776205\n",
      "[ 4200/ 5482] total-loss: 0.389075; classification loss: 0.041433;  cosine similarity loss: 1.779645\n",
      "[ 5600/ 5482] total-loss: 0.386535; classification loss: 0.037684;  cosine similarity loss: 1.781943\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.686     0.783    106\n",
      " disgust     0.718     0.807     0.830    106\n",
      "    fear     0.718     0.623     0.670    106\n",
      "   happy     0.718     0.621     0.604    106\n",
      " neutral     0.718     0.813     0.821    106\n",
      "     sad     0.718     0.716     0.689    106\n",
      "surprise     0.718     0.779     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.721     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.753883 \n",
      "\n",
      "classification loss: 1.705564;  cosine similarity loss: 1.866629 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.384122; classification loss: 0.034954;  cosine similarity loss: 1.780792\n",
      "[ 1400/ 5482] total-loss: 0.384759; classification loss: 0.035778;  cosine similarity loss: 1.780686\n",
      "[ 2800/ 5482] total-loss: 0.387186; classification loss: 0.039398;  cosine similarity loss: 1.778337\n",
      "[ 4200/ 5482] total-loss: 0.385710; classification loss: 0.036670;  cosine similarity loss: 1.781871\n",
      "[ 5600/ 5482] total-loss: 0.383791; classification loss: 0.034605;  cosine similarity loss: 1.780534\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.683     0.792    106\n",
      " disgust     0.718     0.795     0.840    106\n",
      "    fear     0.718     0.680     0.642    106\n",
      "   happy     0.718     0.696     0.604    106\n",
      " neutral     0.718     0.781     0.840    106\n",
      "     sad     0.718     0.680     0.642    106\n",
      "surprise     0.718     0.703     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.717     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.739345 \n",
      "\n",
      "classification loss: 1.684339;  cosine similarity loss: 1.867692 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.391456; classification loss: 0.043568;  cosine similarity loss: 1.783006\n",
      "[ 1400/ 5482] total-loss: 0.390581; classification loss: 0.040144;  cosine similarity loss: 1.792330\n",
      "[ 2800/ 5482] total-loss: 0.383352; classification loss: 0.034517;  cosine similarity loss: 1.778691\n",
      "[ 4200/ 5482] total-loss: 0.386813; classification loss: 0.037098;  cosine similarity loss: 1.785670\n",
      "[ 5600/ 5482] total-loss: 0.385180; classification loss: 0.037034;  cosine similarity loss: 1.777766\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.711     0.811    106\n",
      " disgust     0.716     0.740     0.858    106\n",
      "    fear     0.716     0.650     0.632    106\n",
      "   happy     0.716     0.629     0.623    106\n",
      " neutral     0.716     0.744     0.849    106\n",
      "     sad     0.716     0.750     0.623    106\n",
      "surprise     0.716     0.802     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.718     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.702215 \n",
      "\n",
      "classification loss: 1.630661;  cosine similarity loss: 1.869174 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.386181; classification loss: 0.037239;  cosine similarity loss: 1.781947\n",
      "[ 1400/ 5482] total-loss: 0.384380; classification loss: 0.036043;  cosine similarity loss: 1.777728\n",
      "[ 2800/ 5482] total-loss: 0.385470; classification loss: 0.036774;  cosine similarity loss: 1.780251\n",
      "[ 4200/ 5482] total-loss: 0.385460; classification loss: 0.036247;  cosine similarity loss: 1.782310\n",
      "[ 5600/ 5482] total-loss: 0.383491; classification loss: 0.034529;  cosine similarity loss: 1.779340\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.727     0.755    106\n",
      " disgust     0.713     0.737     0.821    106\n",
      "    fear     0.713     0.651     0.670    106\n",
      "   happy     0.713     0.663     0.594    106\n",
      " neutral     0.713     0.771     0.858    106\n",
      "     sad     0.713     0.740     0.670    106\n",
      "surprise     0.713     0.688     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.711     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.796422 \n",
      "\n",
      "classification loss: 1.764941;  cosine similarity loss: 1.869880 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.386588; classification loss: 0.037455;  cosine similarity loss: 1.783118\n",
      "[ 1400/ 5482] total-loss: 0.385703; classification loss: 0.038060;  cosine similarity loss: 1.776275\n",
      "[ 2800/ 5482] total-loss: 0.383702; classification loss: 0.033974;  cosine similarity loss: 1.782617\n",
      "[ 4200/ 5482] total-loss: 0.383579; classification loss: 0.034185;  cosine similarity loss: 1.781154\n",
      "[ 5600/ 5482] total-loss: 0.386442; classification loss: 0.038026;  cosine similarity loss: 1.780107\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.643     0.783    106\n",
      " disgust     0.717     0.723     0.811    106\n",
      "    fear     0.717     0.700     0.660    106\n",
      "   happy     0.717     0.688     0.623    106\n",
      " neutral     0.717     0.802     0.802    106\n",
      "     sad     0.717     0.692     0.698    106\n",
      "surprise     0.717     0.800     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.721     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 1.779865 \n",
      "\n",
      "classification loss: 1.742199;  cosine similarity loss: 1.867751 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.382532; classification loss: 0.033324;  cosine similarity loss: 1.779365\n",
      "[ 1400/ 5482] total-loss: 0.383966; classification loss: 0.035419;  cosine similarity loss: 1.778155\n",
      "[ 2800/ 5482] total-loss: 0.386994; classification loss: 0.037721;  cosine similarity loss: 1.784088\n",
      "[ 4200/ 5482] total-loss: 0.395600; classification loss: 0.048285;  cosine similarity loss: 1.784863\n",
      "[ 5600/ 5482] total-loss: 0.388037; classification loss: 0.040524;  cosine similarity loss: 1.778087\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.694     0.643     0.783    106\n",
      " disgust     0.694     0.718     0.792    106\n",
      "    fear     0.694     0.607     0.642    106\n",
      "   happy     0.694     0.636     0.594    106\n",
      " neutral     0.694     0.776     0.783    106\n",
      "     sad     0.694     0.729     0.660    106\n",
      "surprise     0.694     0.780     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.694     0.699     0.694    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.808961 \n",
      "\n",
      "classification loss: 1.781527;  cosine similarity loss: 1.872971 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.382825; classification loss: 0.033715;  cosine similarity loss: 1.779266\n",
      "[ 1400/ 5482] total-loss: 0.420142; classification loss: 0.074246;  cosine similarity loss: 1.803725\n",
      "[ 2800/ 5482] total-loss: 0.397948; classification loss: 0.052178;  cosine similarity loss: 1.781028\n",
      "[ 4200/ 5482] total-loss: 0.383904; classification loss: 0.035683;  cosine similarity loss: 1.776789\n",
      "[ 5600/ 5482] total-loss: 0.387405; classification loss: 0.038149;  cosine similarity loss: 1.784427\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.697     0.653     0.726    106\n",
      " disgust     0.697     0.778     0.792    106\n",
      "    fear     0.697     0.603     0.660    106\n",
      "   happy     0.697     0.602     0.642    106\n",
      " neutral     0.697     0.737     0.821    106\n",
      "     sad     0.697     0.782     0.642    106\n",
      "surprise     0.697     0.768     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.697     0.703     0.697    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1.784333 \n",
      "\n",
      "classification loss: 1.745232;  cosine similarity loss: 1.875569 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.390214; classification loss: 0.040328;  cosine similarity loss: 1.789757\n",
      "[ 1400/ 5482] total-loss: 0.385117; classification loss: 0.035537;  cosine similarity loss: 1.783437\n",
      "[ 2800/ 5482] total-loss: 0.382439; classification loss: 0.033696;  cosine similarity loss: 1.777412\n",
      "[ 4200/ 5482] total-loss: 0.382244; classification loss: 0.033596;  cosine similarity loss: 1.776839\n",
      "[ 5600/ 5482] total-loss: 0.500671; classification loss: 0.174971;  cosine similarity loss: 1.803471\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.689     0.647     0.811    106\n",
      " disgust     0.689     0.685     0.821    106\n",
      "    fear     0.689     0.594     0.538    106\n",
      "   happy     0.689     0.699     0.547    106\n",
      " neutral     0.689     0.800     0.792    106\n",
      "     sad     0.689     0.778     0.660    106\n",
      "surprise     0.689     0.639     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.689     0.692     0.689    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.934049 \n",
      "\n",
      "classification loss: 1.960950;  cosine similarity loss: 1.871282 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.414323; classification loss: 0.069831;  cosine similarity loss: 1.792292\n",
      "[ 1400/ 5482] total-loss: 0.382845; classification loss: 0.033098;  cosine similarity loss: 1.781833\n",
      "[ 2800/ 5482] total-loss: 0.381566; classification loss: 0.032057;  cosine similarity loss: 1.779600\n",
      "[ 4200/ 5482] total-loss: 0.391396; classification loss: 0.042964;  cosine similarity loss: 1.785121\n",
      "[ 5600/ 5482] total-loss: 0.386318; classification loss: 0.036439;  cosine similarity loss: 1.785834\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.697     0.723     0.764    106\n",
      " disgust     0.697     0.685     0.840    106\n",
      "    fear     0.697     0.684     0.613    106\n",
      "   happy     0.697     0.546     0.613    106\n",
      " neutral     0.697     0.788     0.774    106\n",
      "     sad     0.697     0.716     0.689    106\n",
      "surprise     0.697     0.775     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.697     0.702     0.697    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1.840243 \n",
      "\n",
      "classification loss: 1.828487;  cosine similarity loss: 1.867672 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.381373; classification loss: 0.031804;  cosine similarity loss: 1.779650\n",
      "[ 1400/ 5482] total-loss: 0.386929; classification loss: 0.039210;  cosine similarity loss: 1.777806\n",
      "[ 2800/ 5482] total-loss: 0.385811; classification loss: 0.037370;  cosine similarity loss: 1.779574\n",
      "[ 4200/ 5482] total-loss: 0.380738; classification loss: 0.031442;  cosine similarity loss: 1.777923\n",
      "[ 5600/ 5482] total-loss: 0.409493; classification loss: 0.066371;  cosine similarity loss: 1.781983\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.697     0.788     0.774    106\n",
      " disgust     0.697     0.677     0.792    106\n",
      "    fear     0.697     0.636     0.660    106\n",
      "   happy     0.697     0.619     0.566    106\n",
      " neutral     0.697     0.746     0.830    106\n",
      "     sad     0.697     0.642     0.660    106\n",
      "surprise     0.697     0.787     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.697     0.699     0.697    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1.772085 \n",
      "\n",
      "classification loss: 1.729345;  cosine similarity loss: 1.871810 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.383365; classification loss: 0.035479;  cosine similarity loss: 1.774912\n",
      "[ 1400/ 5482] total-loss: 0.381119; classification loss: 0.032260;  cosine similarity loss: 1.776557\n",
      "[ 2800/ 5482] total-loss: 0.390036; classification loss: 0.043184;  cosine similarity loss: 1.777442\n",
      "[ 4200/ 5482] total-loss: 0.388459; classification loss: 0.039959;  cosine similarity loss: 1.782458\n",
      "[ 5600/ 5482] total-loss: 0.387378; classification loss: 0.038957;  cosine similarity loss: 1.781062\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.760     0.717    106\n",
      " disgust     0.701     0.712     0.840    106\n",
      "    fear     0.701     0.619     0.613    106\n",
      "   happy     0.701     0.616     0.651    106\n",
      " neutral     0.701     0.718     0.840    106\n",
      "     sad     0.701     0.724     0.670    106\n",
      "surprise     0.701     0.782     0.575    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.704     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.866712 \n",
      "\n",
      "classification loss: 1.865575;  cosine similarity loss: 1.869365 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.383738; classification loss: 0.034023;  cosine similarity loss: 1.782602\n",
      "[ 1400/ 5482] total-loss: 0.380929; classification loss: 0.032650;  cosine similarity loss: 1.774042\n",
      "[ 2800/ 5482] total-loss: 0.382532; classification loss: 0.033006;  cosine similarity loss: 1.780639\n",
      "[ 4200/ 5482] total-loss: 0.380512; classification loss: 0.031697;  cosine similarity loss: 1.775770\n",
      "[ 5600/ 5482] total-loss: 0.382574; classification loss: 0.033330;  cosine similarity loss: 1.779546\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.679     0.619     0.783    106\n",
      " disgust     0.679     0.685     0.802    106\n",
      "    fear     0.679     0.652     0.566    106\n",
      "   happy     0.679     0.629     0.575    106\n",
      " neutral     0.679     0.816     0.792    106\n",
      "     sad     0.679     0.667     0.642    106\n",
      "surprise     0.679     0.700     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.679     0.681     0.679    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 1.932491 \n",
      "\n",
      "classification loss: 1.958866;  cosine similarity loss: 1.870951 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.393982; classification loss: 0.045516;  cosine similarity loss: 1.787843\n",
      "[ 1400/ 5482] total-loss: 0.381496; classification loss: 0.032717;  cosine similarity loss: 1.776614\n",
      "[ 2800/ 5482] total-loss: 0.381821; classification loss: 0.033245;  cosine similarity loss: 1.776123\n",
      "[ 4200/ 5482] total-loss: 0.382324; classification loss: 0.033434;  cosine similarity loss: 1.777883\n",
      "[ 5600/ 5482] total-loss: 0.390422; classification loss: 0.041632;  cosine similarity loss: 1.785582\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.695     0.669     0.745    106\n",
      " disgust     0.695     0.783     0.783    106\n",
      "    fear     0.695     0.636     0.642    106\n",
      "   happy     0.695     0.583     0.566    106\n",
      " neutral     0.695     0.727     0.830    106\n",
      "     sad     0.695     0.760     0.689    106\n",
      "surprise     0.695     0.714     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.695     0.696     0.695    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 1.869359 \n",
      "\n",
      "classification loss: 1.869436;  cosine similarity loss: 1.869178 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.438267; classification loss: 0.102623;  cosine similarity loss: 1.780840\n",
      "[ 1400/ 5482] total-loss: 0.380655; classification loss: 0.030501;  cosine similarity loss: 1.781274\n",
      "[ 2800/ 5482] total-loss: 0.380779; classification loss: 0.030920;  cosine similarity loss: 1.780216\n",
      "[ 4200/ 5482] total-loss: 0.383882; classification loss: 0.034658;  cosine similarity loss: 1.780781\n",
      "[ 5600/ 5482] total-loss: 0.381012; classification loss: 0.031650;  cosine similarity loss: 1.778459\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.698     0.650     0.755    106\n",
      " disgust     0.698     0.674     0.858    106\n",
      "    fear     0.698     0.740     0.538    106\n",
      "   happy     0.698     0.613     0.613    106\n",
      " neutral     0.698     0.752     0.830    106\n",
      "     sad     0.698     0.777     0.689    106\n",
      "surprise     0.698     0.711     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.698     0.703     0.698    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.960191 \n",
      "\n",
      "classification loss: 1.999401;  cosine similarity loss: 1.868700 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.380030; classification loss: 0.030381;  cosine similarity loss: 1.778626\n",
      "[ 1400/ 5482] total-loss: 0.380963; classification loss: 0.031621;  cosine similarity loss: 1.778331\n",
      "[ 2800/ 5482] total-loss: 0.382248; classification loss: 0.033104;  cosine similarity loss: 1.778828\n",
      "[ 4200/ 5482] total-loss: 0.388883; classification loss: 0.040587;  cosine similarity loss: 1.782063\n",
      "[ 5600/ 5482] total-loss: 0.379479; classification loss: 0.029902;  cosine similarity loss: 1.777788\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.701     0.774    106\n",
      " disgust     0.717     0.708     0.868    106\n",
      "    fear     0.717     0.685     0.594    106\n",
      "   happy     0.717     0.629     0.623    106\n",
      " neutral     0.717     0.718     0.840    106\n",
      "     sad     0.717     0.824     0.708    106\n",
      "surprise     0.717     0.783     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.721     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 1.859908 \n",
      "\n",
      "classification loss: 1.856509;  cosine similarity loss: 1.867838 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.379711; classification loss: 0.030307;  cosine similarity loss: 1.777329\n",
      "[ 1400/ 5482] total-loss: 0.379232; classification loss: 0.029508;  cosine similarity loss: 1.778127\n",
      "[ 2800/ 5482] total-loss: 0.387554; classification loss: 0.039884;  cosine similarity loss: 1.778234\n",
      "[ 4200/ 5482] total-loss: 0.379215; classification loss: 0.029639;  cosine similarity loss: 1.777517\n",
      "[ 5600/ 5482] total-loss: 0.380952; classification loss: 0.031063;  cosine similarity loss: 1.780505\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.698     0.620     0.755    106\n",
      " disgust     0.698     0.733     0.802    106\n",
      "    fear     0.698     0.587     0.575    106\n",
      "   happy     0.698     0.729     0.585    106\n",
      " neutral     0.698     0.820     0.774    106\n",
      "     sad     0.698     0.726     0.726    106\n",
      "surprise     0.698     0.696     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.698     0.702     0.698    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.811141 \n",
      "\n",
      "classification loss: 1.785517;  cosine similarity loss: 1.870930 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.384411; classification loss: 0.033592;  cosine similarity loss: 1.787686\n",
      "[ 1400/ 5482] total-loss: 0.380885; classification loss: 0.031868;  cosine similarity loss: 1.776953\n",
      "[ 2800/ 5482] total-loss: 0.379711; classification loss: 0.029081;  cosine similarity loss: 1.782232\n",
      "[ 4200/ 5482] total-loss: 0.378800; classification loss: 0.029400;  cosine similarity loss: 1.776402\n",
      "[ 5600/ 5482] total-loss: 0.380805; classification loss: 0.030909;  cosine similarity loss: 1.780389\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.698     0.764    106\n",
      " disgust     0.718     0.690     0.840    106\n",
      "    fear     0.718     0.729     0.585    106\n",
      "   happy     0.718     0.653     0.623    106\n",
      " neutral     0.718     0.720     0.849    106\n",
      "     sad     0.718     0.796     0.698    106\n",
      "surprise     0.718     0.763     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.721     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.885164 \n",
      "\n",
      "classification loss: 1.891883;  cosine similarity loss: 1.869487 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.380810; classification loss: 0.030777;  cosine similarity loss: 1.780941\n",
      "[ 1400/ 5482] total-loss: 0.384049; classification loss: 0.033035;  cosine similarity loss: 1.788103\n",
      "[ 2800/ 5482] total-loss: 0.380242; classification loss: 0.030532;  cosine similarity loss: 1.779081\n",
      "[ 4200/ 5482] total-loss: 0.377982; classification loss: 0.028037;  cosine similarity loss: 1.777761\n",
      "[ 5600/ 5482] total-loss: 0.379444; classification loss: 0.030580;  cosine similarity loss: 1.774900\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.644     0.821    106\n",
      " disgust     0.709     0.731     0.821    106\n",
      "    fear     0.709     0.721     0.585    106\n",
      "   happy     0.709     0.656     0.557    106\n",
      " neutral     0.709     0.736     0.840    106\n",
      "     sad     0.709     0.732     0.670    106\n",
      "surprise     0.709     0.755     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.711     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.865275 \n",
      "\n",
      "classification loss: 1.863201;  cosine similarity loss: 1.870114 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.381072; classification loss: 0.031636;  cosine similarity loss: 1.778817\n",
      "[ 1400/ 5482] total-loss: 0.380839; classification loss: 0.031166;  cosine similarity loss: 1.779531\n",
      "[ 2800/ 5482] total-loss: 0.380237; classification loss: 0.029669;  cosine similarity loss: 1.782509\n",
      "[ 4200/ 5482] total-loss: 0.379630; classification loss: 0.029518;  cosine similarity loss: 1.780079\n",
      "[ 5600/ 5482] total-loss: 0.379296; classification loss: 0.028509;  cosine similarity loss: 1.782446\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.659     0.802    106\n",
      " disgust     0.708     0.698     0.830    106\n",
      "    fear     0.708     0.768     0.594    106\n",
      "   happy     0.708     0.586     0.613    106\n",
      " neutral     0.708     0.748     0.840    106\n",
      "     sad     0.708     0.778     0.660    106\n",
      "surprise     0.708     0.765     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.715     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 1.970098 \n",
      "\n",
      "classification loss: 2.011647;  cosine similarity loss: 1.873150 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.386343; classification loss: 0.037938;  cosine similarity loss: 1.779964\n",
      "[ 1400/ 5482] total-loss: 0.382934; classification loss: 0.033364;  cosine similarity loss: 1.781217\n",
      "[ 2800/ 5482] total-loss: 0.380520; classification loss: 0.030839;  cosine similarity loss: 1.779246\n",
      "[ 4200/ 5482] total-loss: 0.378810; classification loss: 0.029295;  cosine similarity loss: 1.776869\n",
      "[ 5600/ 5482] total-loss: 0.377709; classification loss: 0.027729;  cosine similarity loss: 1.777631\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.697     0.653     0.764    106\n",
      " disgust     0.697     0.766     0.802    106\n",
      "    fear     0.697     0.617     0.623    106\n",
      "   happy     0.697     0.626     0.585    106\n",
      " neutral     0.697     0.769     0.783    106\n",
      "     sad     0.697     0.740     0.698    106\n",
      "surprise     0.697     0.710     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.697     0.697     0.697    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1.868813 \n",
      "\n",
      "classification loss: 1.869462;  cosine similarity loss: 1.867298 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.378474; classification loss: 0.029266;  cosine similarity loss: 1.775308\n",
      "[ 1400/ 5482] total-loss: 0.377716; classification loss: 0.027768;  cosine similarity loss: 1.777508\n",
      "[ 2800/ 5482] total-loss: 0.378190; classification loss: 0.027781;  cosine similarity loss: 1.779828\n",
      "[ 4200/ 5482] total-loss: 0.378714; classification loss: 0.028908;  cosine similarity loss: 1.777936\n",
      "[ 5600/ 5482] total-loss: 0.383658; classification loss: 0.034942;  cosine similarity loss: 1.778523\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.698     0.684     0.755    106\n",
      " disgust     0.698     0.768     0.811    106\n",
      "    fear     0.698     0.657     0.613    106\n",
      "   happy     0.698     0.546     0.613    106\n",
      " neutral     0.698     0.674     0.858    106\n",
      "     sad     0.698     0.827     0.632    106\n",
      "surprise     0.698     0.810     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.698     0.709     0.698    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.917395 \n",
      "\n",
      "classification loss: 1.938053;  cosine similarity loss: 1.869192 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.385003; classification loss: 0.036371;  cosine similarity loss: 1.779532\n",
      "[ 1400/ 5482] total-loss: 0.379394; classification loss: 0.029297;  cosine similarity loss: 1.779780\n",
      "[ 2800/ 5482] total-loss: 0.959308; classification loss: 0.745526;  cosine similarity loss: 1.814436\n",
      "[ 4200/ 5482] total-loss: 0.379312; classification loss: 0.027982;  cosine similarity loss: 1.784630\n",
      "[ 5600/ 5482] total-loss: 0.381435; classification loss: 0.030054;  cosine similarity loss: 1.786959\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.694     0.726    106\n",
      " disgust     0.705     0.804     0.774    106\n",
      "    fear     0.705     0.585     0.651    106\n",
      "   happy     0.705     0.633     0.585    106\n",
      " neutral     0.705     0.800     0.792    106\n",
      "     sad     0.705     0.748     0.726    106\n",
      "surprise     0.705     0.686     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.707     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.860193 \n",
      "\n",
      "classification loss: 1.856187;  cosine similarity loss: 1.869539 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.387701; classification loss: 0.039549;  cosine similarity loss: 1.780308\n",
      "[ 1400/ 5482] total-loss: 0.380068; classification loss: 0.031015;  cosine similarity loss: 1.776283\n",
      "[ 2800/ 5482] total-loss: 0.402134; classification loss: 0.057536;  cosine similarity loss: 1.780528\n",
      "[ 4200/ 5482] total-loss: 0.377756; classification loss: 0.028511;  cosine similarity loss: 1.774737\n",
      "[ 5600/ 5482] total-loss: 0.379600; classification loss: 0.030115;  cosine similarity loss: 1.777541\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.682     0.648     0.783    106\n",
      " disgust     0.682     0.702     0.755    106\n",
      "    fear     0.682     0.608     0.585    106\n",
      "   happy     0.682     0.648     0.557    106\n",
      " neutral     0.682     0.796     0.774    106\n",
      "     sad     0.682     0.634     0.670    106\n",
      "surprise     0.682     0.750     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.682     0.684     0.682    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 1.789258 \n",
      "\n",
      "classification loss: 1.752242;  cosine similarity loss: 1.875629 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.378911; classification loss: 0.029552;  cosine similarity loss: 1.776350\n",
      "[ 1400/ 5482] total-loss: 0.377343; classification loss: 0.028056;  cosine similarity loss: 1.774491\n",
      "[ 2800/ 5482] total-loss: 0.377926; classification loss: 0.028592;  cosine similarity loss: 1.775264\n",
      "[ 4200/ 5482] total-loss: 0.378540; classification loss: 0.029267;  cosine similarity loss: 1.775632\n",
      "[ 5600/ 5482] total-loss: 0.376262; classification loss: 0.026186;  cosine similarity loss: 1.776563\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.691     0.686     0.764    106\n",
      " disgust     0.691     0.772     0.736    106\n",
      "    fear     0.691     0.687     0.642    106\n",
      "   happy     0.691     0.555     0.623    106\n",
      " neutral     0.691     0.761     0.783    106\n",
      "     sad     0.691     0.667     0.660    106\n",
      "surprise     0.691     0.736     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.691     0.695     0.691    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.802622 \n",
      "\n",
      "classification loss: 1.772935;  cosine similarity loss: 1.871890 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.495327; classification loss: 0.170836;  cosine similarity loss: 1.793294\n",
      "[ 1400/ 5482] total-loss: 0.377316; classification loss: 0.027762;  cosine similarity loss: 1.775535\n",
      "[ 2800/ 5482] total-loss: 0.380892; classification loss: 0.031772;  cosine similarity loss: 1.777371\n",
      "[ 4200/ 5482] total-loss: 0.380000; classification loss: 0.029726;  cosine similarity loss: 1.781097\n",
      "[ 5600/ 5482] total-loss: 0.376448; classification loss: 0.027488;  cosine similarity loss: 1.772290\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.719     0.774    106\n",
      " disgust     0.709     0.757     0.821    106\n",
      "    fear     0.709     0.705     0.632    106\n",
      "   happy     0.709     0.588     0.632    106\n",
      " neutral     0.709     0.742     0.840    106\n",
      "     sad     0.709     0.704     0.651    106\n",
      "surprise     0.709     0.756     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.710     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.811110 \n",
      "\n",
      "classification loss: 1.786308;  cosine similarity loss: 1.868982 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.385457; classification loss: 0.036017;  cosine similarity loss: 1.783219\n",
      "[ 1400/ 5482] total-loss: 0.381291; classification loss: 0.033251;  cosine similarity loss: 1.773454\n",
      "[ 2800/ 5482] total-loss: 0.378821; classification loss: 0.029482;  cosine similarity loss: 1.776179\n",
      "[ 4200/ 5482] total-loss: 0.377880; classification loss: 0.028405;  cosine similarity loss: 1.775783\n",
      "[ 5600/ 5482] total-loss: 0.377483; classification loss: 0.027137;  cosine similarity loss: 1.778868\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.667     0.774    106\n",
      " disgust     0.710     0.775     0.811    106\n",
      "    fear     0.710     0.620     0.632    106\n",
      "   happy     0.710     0.663     0.613    106\n",
      " neutral     0.710     0.750     0.849    106\n",
      "     sad     0.710     0.774     0.679    106\n",
      "surprise     0.710     0.730     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.711     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.833667 \n",
      "\n",
      "classification loss: 1.820243;  cosine similarity loss: 1.864990 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.376894; classification loss: 0.027414;  cosine similarity loss: 1.774817\n",
      "[ 1400/ 5482] total-loss: 0.376182; classification loss: 0.026643;  cosine similarity loss: 1.774342\n",
      "[ 2800/ 5482] total-loss: 0.378901; classification loss: 0.027169;  cosine similarity loss: 1.785827\n",
      "[ 4200/ 5482] total-loss: 0.377825; classification loss: 0.028580;  cosine similarity loss: 1.774802\n",
      "[ 5600/ 5482] total-loss: 0.376778; classification loss: 0.026808;  cosine similarity loss: 1.776657\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.643     0.783    106\n",
      " disgust     0.712     0.766     0.802    106\n",
      "    fear     0.712     0.641     0.623    106\n",
      "   happy     0.712     0.725     0.623    106\n",
      " neutral     0.712     0.784     0.821    106\n",
      "     sad     0.712     0.667     0.679    106\n",
      "surprise     0.712     0.775     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.714     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.793235 \n",
      "\n",
      "classification loss: 1.760634;  cosine similarity loss: 1.869304 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.381169; classification loss: 0.030747;  cosine similarity loss: 1.782857\n",
      "[ 1400/ 5482] total-loss: 0.376143; classification loss: 0.025756;  cosine similarity loss: 1.777693\n",
      "[ 2800/ 5482] total-loss: 0.378767; classification loss: 0.027869;  cosine similarity loss: 1.782357\n",
      "[ 4200/ 5482] total-loss: 0.376096; classification loss: 0.025146;  cosine similarity loss: 1.779896\n",
      "[ 5600/ 5482] total-loss: 0.646217; classification loss: 0.358898;  cosine similarity loss: 1.795495\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.697     0.706     0.792    106\n",
      " disgust     0.697     0.705     0.811    106\n",
      "    fear     0.697     0.707     0.613    106\n",
      "   happy     0.697     0.549     0.632    106\n",
      " neutral     0.697     0.774     0.774    106\n",
      "     sad     0.697     0.663     0.632    106\n",
      "surprise     0.697     0.825     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.697     0.704     0.697    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1.851702 \n",
      "\n",
      "classification loss: 1.843759;  cosine similarity loss: 1.870236 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.541208; classification loss: 0.229225;  cosine similarity loss: 1.789140\n",
      "[ 1400/ 5482] total-loss: 0.377341; classification loss: 0.027299;  cosine similarity loss: 1.777509\n",
      "[ 2800/ 5482] total-loss: 0.378136; classification loss: 0.027800;  cosine similarity loss: 1.779479\n",
      "[ 4200/ 5482] total-loss: 0.379006; classification loss: 0.029216;  cosine similarity loss: 1.778164\n",
      "[ 5600/ 5482] total-loss: 0.377022; classification loss: 0.027559;  cosine similarity loss: 1.774871\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.688     0.811    106\n",
      " disgust     0.720     0.769     0.783    106\n",
      "    fear     0.720     0.698     0.698    106\n",
      "   happy     0.720     0.660     0.623    106\n",
      " neutral     0.720     0.724     0.792    106\n",
      "     sad     0.720     0.783     0.679    106\n",
      "surprise     0.720     0.726     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.721     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.820115 \n",
      "\n",
      "classification loss: 1.798160;  cosine similarity loss: 1.871342 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.378167; classification loss: 0.026942;  cosine similarity loss: 1.783067\n",
      "[ 1400/ 5482] total-loss: 0.499600; classification loss: 0.179088;  cosine similarity loss: 1.781648\n",
      "[ 2800/ 5482] total-loss: 0.377954; classification loss: 0.029161;  cosine similarity loss: 1.773126\n",
      "[ 4200/ 5482] total-loss: 0.377942; classification loss: 0.027253;  cosine similarity loss: 1.780698\n",
      "[ 5600/ 5482] total-loss: 0.377431; classification loss: 0.026148;  cosine similarity loss: 1.782562\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.690     0.821    106\n",
      " disgust     0.701     0.706     0.792    106\n",
      "    fear     0.701     0.674     0.566    106\n",
      "   happy     0.701     0.663     0.613    106\n",
      " neutral     0.701     0.769     0.755    106\n",
      "     sad     0.701     0.682     0.708    106\n",
      "surprise     0.701     0.719     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.701     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.812540 \n",
      "\n",
      "classification loss: 1.787381;  cosine similarity loss: 1.871243 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.377076; classification loss: 0.026414;  cosine similarity loss: 1.779723\n",
      "[ 1400/ 5482] total-loss: 0.375847; classification loss: 0.025313;  cosine similarity loss: 1.777982\n",
      "[ 2800/ 5482] total-loss: 0.378677; classification loss: 0.027783;  cosine similarity loss: 1.782252\n",
      "[ 4200/ 5482] total-loss: 0.377003; classification loss: 0.026114;  cosine similarity loss: 1.780560\n",
      "[ 5600/ 5482] total-loss: 0.376515; classification loss: 0.024857;  cosine similarity loss: 1.783146\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.685     0.802    106\n",
      " disgust     0.701     0.733     0.802    106\n",
      "    fear     0.701     0.689     0.585    106\n",
      "   happy     0.701     0.566     0.651    106\n",
      " neutral     0.701     0.739     0.802    106\n",
      "     sad     0.701     0.750     0.651    106\n",
      "surprise     0.701     0.783     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.706     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.874559 \n",
      "\n",
      "classification loss: 1.876628;  cosine similarity loss: 1.869731 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.375886; classification loss: 0.025289;  cosine similarity loss: 1.778275\n",
      "[ 1400/ 5482] total-loss: 0.376088; classification loss: 0.025831;  cosine similarity loss: 1.777116\n",
      "[ 2800/ 5482] total-loss: 0.377764; classification loss: 0.027412;  cosine similarity loss: 1.779170\n",
      "[ 4200/ 5482] total-loss: 0.374947; classification loss: 0.024935;  cosine similarity loss: 1.774991\n",
      "[ 5600/ 5482] total-loss: 0.376448; classification loss: 0.024653;  cosine similarity loss: 1.783624\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.738     0.745    106\n",
      " disgust     0.708     0.754     0.811    106\n",
      "    fear     0.708     0.677     0.613    106\n",
      "   happy     0.708     0.552     0.651    106\n",
      " neutral     0.708     0.730     0.840    106\n",
      "     sad     0.708     0.742     0.679    106\n",
      "surprise     0.708     0.802     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.714     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 1.906443 \n",
      "\n",
      "classification loss: 1.922047;  cosine similarity loss: 1.870034 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.374883; classification loss: 0.025103;  cosine similarity loss: 1.774007\n",
      "[ 1400/ 5482] total-loss: 0.375387; classification loss: 0.025894;  cosine similarity loss: 1.773360\n",
      "[ 2800/ 5482] total-loss: 0.375391; classification loss: 0.024919;  cosine similarity loss: 1.777278\n",
      "[ 4200/ 5482] total-loss: 0.375026; classification loss: 0.024808;  cosine similarity loss: 1.775900\n",
      "[ 5600/ 5482] total-loss: 0.375218; classification loss: 0.024895;  cosine similarity loss: 1.776512\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.697     0.802    106\n",
      " disgust     0.720     0.738     0.849    106\n",
      "    fear     0.720     0.747     0.613    106\n",
      "   happy     0.720     0.606     0.623    106\n",
      " neutral     0.720     0.770     0.821    106\n",
      "     sad     0.720     0.727     0.679    106\n",
      "surprise     0.720     0.767     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.722     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.958656 \n",
      "\n",
      "classification loss: 1.996153;  cosine similarity loss: 1.871161 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.404552; classification loss: 0.058173;  cosine similarity loss: 1.790068\n",
      "[ 1400/ 5482] total-loss: 0.376656; classification loss: 0.025911;  cosine similarity loss: 1.779639\n",
      "[ 2800/ 5482] total-loss: 0.374286; classification loss: 0.023361;  cosine similarity loss: 1.777986\n",
      "[ 4200/ 5482] total-loss: 0.380194; classification loss: 0.030691;  cosine similarity loss: 1.778203\n",
      "[ 5600/ 5482] total-loss: 0.376085; classification loss: 0.025291;  cosine similarity loss: 1.779264\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.736     0.736    106\n",
      " disgust     0.708     0.729     0.811    106\n",
      "    fear     0.708     0.623     0.623    106\n",
      "   happy     0.708     0.618     0.594    106\n",
      " neutral     0.708     0.746     0.887    106\n",
      "     sad     0.708     0.787     0.660    106\n",
      "surprise     0.708     0.716     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.708     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 1.912613 \n",
      "\n",
      "classification loss: 1.930874;  cosine similarity loss: 1.870004 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.376116; classification loss: 0.026381;  cosine similarity loss: 1.775054\n",
      "[ 1400/ 5482] total-loss: 0.558832; classification loss: 0.247959;  cosine similarity loss: 1.802326\n",
      "[ 2800/ 5482] total-loss: 0.383056; classification loss: 0.034605;  cosine similarity loss: 1.776861\n",
      "[ 4200/ 5482] total-loss: 0.374722; classification loss: 0.025319;  cosine similarity loss: 1.772332\n",
      "[ 5600/ 5482] total-loss: 0.382519; classification loss: 0.031813;  cosine similarity loss: 1.785344\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.714     0.755    106\n",
      " disgust     0.706     0.711     0.811    106\n",
      "    fear     0.706     0.644     0.632    106\n",
      "   happy     0.706     0.595     0.623    106\n",
      " neutral     0.706     0.784     0.821    106\n",
      "     sad     0.706     0.725     0.698    106\n",
      "surprise     0.706     0.790     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.709     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.807266 \n",
      "\n",
      "classification loss: 1.782473;  cosine similarity loss: 1.865115 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.376916; classification loss: 0.025586;  cosine similarity loss: 1.782234\n",
      "[ 1400/ 5482] total-loss: 0.374856; classification loss: 0.024356;  cosine similarity loss: 1.776855\n",
      "[ 2800/ 5482] total-loss: 0.374894; classification loss: 0.024732;  cosine similarity loss: 1.775543\n",
      "[ 4200/ 5482] total-loss: 0.376981; classification loss: 0.026963;  cosine similarity loss: 1.777054\n",
      "[ 5600/ 5482] total-loss: 0.386999; classification loss: 0.037149;  cosine similarity loss: 1.786399\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.695     0.774    106\n",
      " disgust     0.720     0.832     0.745    106\n",
      "    fear     0.720     0.605     0.679    106\n",
      "   happy     0.720     0.725     0.623    106\n",
      " neutral     0.720     0.774     0.840    106\n",
      "     sad     0.720     0.705     0.745    106\n",
      "surprise     0.720     0.728     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.723     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.798543 \n",
      "\n",
      "classification loss: 1.769476;  cosine similarity loss: 1.866366 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.377695; classification loss: 0.027976;  cosine similarity loss: 1.776571\n",
      "[ 1400/ 5482] total-loss: 1.726191; classification loss: 1.703156;  cosine similarity loss: 1.818332\n",
      "[ 2800/ 5482] total-loss: 0.374543; classification loss: 0.024744;  cosine similarity loss: 1.773740\n",
      "[ 4200/ 5482] total-loss: 0.386797; classification loss: 0.038781;  cosine similarity loss: 1.778865\n",
      "[ 5600/ 5482] total-loss: 0.374508; classification loss: 0.023619;  cosine similarity loss: 1.778064\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.713     0.821    106\n",
      " disgust     0.716     0.744     0.821    106\n",
      "    fear     0.716     0.667     0.623    106\n",
      "   happy     0.716     0.627     0.604    106\n",
      " neutral     0.716     0.754     0.840    106\n",
      "     sad     0.716     0.732     0.670    106\n",
      "surprise     0.716     0.770     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.715     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.858781 \n",
      "\n",
      "classification loss: 1.854750;  cosine similarity loss: 1.868186 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.374188; classification loss: 0.024485;  cosine similarity loss: 1.773001\n",
      "[ 1400/ 5482] total-loss: 0.374174; classification loss: 0.023594;  cosine similarity loss: 1.776494\n",
      "[ 2800/ 5482] total-loss: 0.378462; classification loss: 0.027677;  cosine similarity loss: 1.781600\n",
      "[ 4200/ 5482] total-loss: 0.374455; classification loss: 0.023844;  cosine similarity loss: 1.776900\n",
      "[ 5600/ 5482] total-loss: 0.373557; classification loss: 0.022621;  cosine similarity loss: 1.777302\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.614     0.811    106\n",
      " disgust     0.705     0.733     0.802    106\n",
      "    fear     0.705     0.726     0.575    106\n",
      "   happy     0.705     0.673     0.642    106\n",
      " neutral     0.705     0.754     0.811    106\n",
      "     sad     0.705     0.706     0.679    106\n",
      "surprise     0.705     0.765     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.710     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.845200 \n",
      "\n",
      "classification loss: 1.835086;  cosine similarity loss: 1.868798 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.374590; classification loss: 0.024461;  cosine similarity loss: 1.775107\n",
      "[ 1400/ 5482] total-loss: 0.384737; classification loss: 0.034933;  cosine similarity loss: 1.783951\n",
      "[ 2800/ 5482] total-loss: 0.375218; classification loss: 0.024714;  cosine similarity loss: 1.777234\n",
      "[ 4200/ 5482] total-loss: 0.374715; classification loss: 0.023710;  cosine similarity loss: 1.778738\n",
      "[ 5600/ 5482] total-loss: 0.372969; classification loss: 0.023006;  cosine similarity loss: 1.772821\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.699     0.675     0.745    106\n",
      " disgust     0.699     0.769     0.783    106\n",
      "    fear     0.699     0.650     0.613    106\n",
      "   happy     0.699     0.619     0.689    106\n",
      " neutral     0.699     0.703     0.849    106\n",
      "     sad     0.699     0.758     0.651    106\n",
      "surprise     0.699     0.750     0.566    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.699     0.703     0.699    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.989701 \n",
      "\n",
      "classification loss: 2.039270;  cosine similarity loss: 1.874040 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.377928; classification loss: 0.027394;  cosine similarity loss: 1.780060\n",
      "[ 1400/ 5482] total-loss: 0.377643; classification loss: 0.027345;  cosine similarity loss: 1.778838\n",
      "[ 2800/ 5482] total-loss: 0.377649; classification loss: 0.027496;  cosine similarity loss: 1.778264\n",
      "[ 4200/ 5482] total-loss: 0.373593; classification loss: 0.023001;  cosine similarity loss: 1.775961\n",
      "[ 5600/ 5482] total-loss: 0.372912; classification loss: 0.023379;  cosine similarity loss: 1.771043\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.659     0.764    106\n",
      " disgust     0.710     0.794     0.802    106\n",
      "    fear     0.710     0.667     0.585    106\n",
      "   happy     0.710     0.680     0.660    106\n",
      " neutral     0.710     0.768     0.811    106\n",
      "     sad     0.710     0.667     0.698    106\n",
      "surprise     0.710     0.742     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.711     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.808061 \n",
      "\n",
      "classification loss: 1.780232;  cosine similarity loss: 1.872994 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.374954; classification loss: 0.024399;  cosine similarity loss: 1.777175\n",
      "[ 1400/ 5482] total-loss: 0.375518; classification loss: 0.024432;  cosine similarity loss: 1.779861\n",
      "[ 2800/ 5482] total-loss: 0.373032; classification loss: 0.022839;  cosine similarity loss: 1.773804\n",
      "[ 4200/ 5482] total-loss: 0.374275; classification loss: 0.022231;  cosine similarity loss: 1.782448\n",
      "[ 5600/ 5482] total-loss: 0.374214; classification loss: 0.023419;  cosine similarity loss: 1.777395\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.698     0.764    106\n",
      " disgust     0.713     0.733     0.830    106\n",
      "    fear     0.713     0.690     0.566    106\n",
      "   happy     0.713     0.639     0.651    106\n",
      " neutral     0.713     0.754     0.840    106\n",
      "     sad     0.713     0.702     0.689    106\n",
      "surprise     0.713     0.775     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.713     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.864653 \n",
      "\n",
      "classification loss: 1.864559;  cosine similarity loss: 1.864874 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.373200; classification loss: 0.021954;  cosine similarity loss: 1.778185\n",
      "[ 1400/ 5482] total-loss: 0.372725; classification loss: 0.022251;  cosine similarity loss: 1.774620\n",
      "[ 2800/ 5482] total-loss: 0.372712; classification loss: 0.022379;  cosine similarity loss: 1.774043\n",
      "[ 4200/ 5482] total-loss: 0.374526; classification loss: 0.024721;  cosine similarity loss: 1.773746\n",
      "[ 5600/ 5482] total-loss: 0.374135; classification loss: 0.022744;  cosine similarity loss: 1.779700\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.699     0.656     0.755    106\n",
      " disgust     0.699     0.634     0.849    106\n",
      "    fear     0.699     0.744     0.575    106\n",
      "   happy     0.699     0.660     0.623    106\n",
      " neutral     0.699     0.744     0.821    106\n",
      "     sad     0.699     0.726     0.651    106\n",
      "surprise     0.699     0.786     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.699     0.707     0.699    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.929217 \n",
      "\n",
      "classification loss: 1.954515;  cosine similarity loss: 1.870188 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.375894; classification loss: 0.025702;  cosine similarity loss: 1.776664\n",
      "[ 1400/ 5482] total-loss: 0.382070; classification loss: 0.033069;  cosine similarity loss: 1.778073\n",
      "[ 2800/ 5482] total-loss: 0.378113; classification loss: 0.028807;  cosine similarity loss: 1.775337\n",
      "[ 4200/ 5482] total-loss: 0.372924; classification loss: 0.022849;  cosine similarity loss: 1.773225\n",
      "[ 5600/ 5482] total-loss: 0.372560; classification loss: 0.022091;  cosine similarity loss: 1.774436\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.750     0.792    106\n",
      " disgust     0.718     0.680     0.821    106\n",
      "    fear     0.718     0.670     0.594    106\n",
      "   happy     0.718     0.673     0.642    106\n",
      " neutral     0.718     0.770     0.821    106\n",
      "     sad     0.718     0.737     0.689    106\n",
      "surprise     0.718     0.747     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.718     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.899866 \n",
      "\n",
      "classification loss: 1.915119;  cosine similarity loss: 1.864275 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.445655; classification loss: 0.107241;  cosine similarity loss: 1.799312\n",
      "[ 1400/ 5482] total-loss: 0.373654; classification loss: 0.023369;  cosine similarity loss: 1.774793\n",
      "[ 2800/ 5482] total-loss: 0.396540; classification loss: 0.048930;  cosine similarity loss: 1.786980\n",
      "[ 4200/ 5482] total-loss: 0.372377; classification loss: 0.022067;  cosine similarity loss: 1.773618\n",
      "[ 5600/ 5482] total-loss: 0.373613; classification loss: 0.022818;  cosine similarity loss: 1.776793\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.699     0.679    106\n",
      " disgust     0.708     0.759     0.774    106\n",
      "    fear     0.708     0.650     0.613    106\n",
      "   happy     0.708     0.613     0.642    106\n",
      " neutral     0.708     0.734     0.858    106\n",
      "     sad     0.708     0.784     0.717    106\n",
      "surprise     0.708     0.717     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.708     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 1.875654 \n",
      "\n",
      "classification loss: 1.879197;  cosine similarity loss: 1.867385 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.372309; classification loss: 0.021914;  cosine similarity loss: 1.773889\n",
      "[ 1400/ 5482] total-loss: 0.372556; classification loss: 0.022438;  cosine similarity loss: 1.773026\n",
      "[ 2800/ 5482] total-loss: 0.415983; classification loss: 0.070927;  cosine similarity loss: 1.796206\n",
      "[ 4200/ 5482] total-loss: 0.373464; classification loss: 0.022712;  cosine similarity loss: 1.776470\n",
      "[ 5600/ 5482] total-loss: 0.372237; classification loss: 0.022277;  cosine similarity loss: 1.772076\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.694     0.722     0.783    106\n",
      " disgust     0.694     0.716     0.783    106\n",
      "    fear     0.694     0.577     0.604    106\n",
      "   happy     0.694     0.692     0.594    106\n",
      " neutral     0.694     0.723     0.811    106\n",
      "     sad     0.694     0.703     0.670    106\n",
      "surprise     0.694     0.730     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.694     0.695     0.694    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.962163 \n",
      "\n",
      "classification loss: 1.999813;  cosine similarity loss: 1.874314 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.373158; classification loss: 0.022443;  cosine similarity loss: 1.776014\n",
      "[ 1400/ 5482] total-loss: 0.372471; classification loss: 0.020929;  cosine similarity loss: 1.778638\n",
      "[ 2800/ 5482] total-loss: 0.372714; classification loss: 0.022922;  cosine similarity loss: 1.771879\n",
      "[ 4200/ 5482] total-loss: 0.372516; classification loss: 0.021441;  cosine similarity loss: 1.776820\n",
      "[ 5600/ 5482] total-loss: 0.375326; classification loss: 0.024532;  cosine similarity loss: 1.778502\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.699     0.745    106\n",
      " disgust     0.702     0.689     0.792    106\n",
      "    fear     0.702     0.667     0.566    106\n",
      "   happy     0.702     0.623     0.623    106\n",
      " neutral     0.702     0.746     0.830    106\n",
      "     sad     0.702     0.705     0.698    106\n",
      "surprise     0.702     0.795     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.703     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.947013 \n",
      "\n",
      "classification loss: 1.979073;  cosine similarity loss: 1.872205 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.373062; classification loss: 0.022323;  cosine similarity loss: 1.776015\n",
      "[ 1400/ 5482] total-loss: 0.374394; classification loss: 0.023027;  cosine similarity loss: 1.779860\n",
      "[ 2800/ 5482] total-loss: 0.371956; classification loss: 0.021664;  cosine similarity loss: 1.773124\n",
      "[ 4200/ 5482] total-loss: 0.372122; classification loss: 0.021502;  cosine similarity loss: 1.774604\n",
      "[ 5600/ 5482] total-loss: 0.381508; classification loss: 0.027437;  cosine similarity loss: 1.797793\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.688     0.811    106\n",
      " disgust     0.717     0.743     0.764    106\n",
      "    fear     0.717     0.670     0.651    106\n",
      "   happy     0.717     0.670     0.632    106\n",
      " neutral     0.717     0.761     0.811    106\n",
      "     sad     0.717     0.763     0.698    106\n",
      "surprise     0.717     0.726     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.717     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 1.941580 \n",
      "\n",
      "classification loss: 1.972097;  cosine similarity loss: 1.870374 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.374250; classification loss: 0.023790;  cosine similarity loss: 1.776094\n",
      "[ 1400/ 5482] total-loss: 0.376331; classification loss: 0.026105;  cosine similarity loss: 1.777233\n",
      "[ 2800/ 5482] total-loss: 0.371867; classification loss: 0.021800;  cosine similarity loss: 1.772138\n",
      "[ 4200/ 5482] total-loss: 0.372354; classification loss: 0.021947;  cosine similarity loss: 1.773982\n",
      "[ 5600/ 5482] total-loss: 0.371291; classification loss: 0.021106;  cosine similarity loss: 1.772030\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.735     0.783    106\n",
      " disgust     0.721     0.702     0.821    106\n",
      "    fear     0.721     0.676     0.651    106\n",
      "   happy     0.721     0.699     0.613    106\n",
      " neutral     0.721     0.770     0.821    106\n",
      "     sad     0.721     0.690     0.736    106\n",
      "surprise     0.721     0.786     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.722     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.893096 \n",
      "\n",
      "classification loss: 1.903013;  cosine similarity loss: 1.869957 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.372047; classification loss: 0.021087;  cosine similarity loss: 1.775888\n",
      "[ 1400/ 5482] total-loss: 0.372237; classification loss: 0.021765;  cosine similarity loss: 1.774127\n",
      "[ 2800/ 5482] total-loss: 0.371808; classification loss: 0.021645;  cosine similarity loss: 1.772461\n",
      "[ 4200/ 5482] total-loss: 0.374283; classification loss: 0.022632;  cosine similarity loss: 1.780884\n",
      "[ 5600/ 5482] total-loss: 0.372533; classification loss: 0.021324;  cosine similarity loss: 1.777371\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.726     0.750     0.764    106\n",
      " disgust     0.726     0.719     0.821    106\n",
      "    fear     0.726     0.663     0.613    106\n",
      "   happy     0.726     0.635     0.689    106\n",
      " neutral     0.726     0.742     0.840    106\n",
      "     sad     0.726     0.802     0.689    106\n",
      "surprise     0.726     0.798     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.726     0.730     0.726    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 1.993358 \n",
      "\n",
      "classification loss: 2.048173;  cosine similarity loss: 1.865457 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.373454; classification loss: 0.023462;  cosine similarity loss: 1.773425\n",
      "[ 1400/ 5482] total-loss: 0.375238; classification loss: 0.023630;  cosine similarity loss: 1.781668\n",
      "[ 2800/ 5482] total-loss: 0.373206; classification loss: 0.022465;  cosine similarity loss: 1.776168\n",
      "[ 4200/ 5482] total-loss: 0.371908; classification loss: 0.021035;  cosine similarity loss: 1.775403\n",
      "[ 5600/ 5482] total-loss: 0.373901; classification loss: 0.021860;  cosine similarity loss: 1.782069\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.755     0.755    106\n",
      " disgust     0.722     0.712     0.792    106\n",
      "    fear     0.722     0.667     0.642    106\n",
      "   happy     0.722     0.581     0.642    106\n",
      " neutral     0.722     0.850     0.802    106\n",
      "     sad     0.722     0.732     0.774    106\n",
      "surprise     0.722     0.793     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.727     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.791123 \n",
      "\n",
      "classification loss: 1.758991;  cosine similarity loss: 1.866098 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.371806; classification loss: 0.020604;  cosine similarity loss: 1.776612\n",
      "[ 1400/ 5482] total-loss: 0.371137; classification loss: 0.020623;  cosine similarity loss: 1.773194\n",
      "[ 2800/ 5482] total-loss: 0.376664; classification loss: 0.026173;  cosine similarity loss: 1.778626\n",
      "[ 4200/ 5482] total-loss: 0.371395; classification loss: 0.021063;  cosine similarity loss: 1.772724\n",
      "[ 5600/ 5482] total-loss: 0.371616; classification loss: 0.021170;  cosine similarity loss: 1.773402\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.722     0.783    106\n",
      " disgust     0.713     0.677     0.792    106\n",
      "    fear     0.713     0.653     0.585    106\n",
      "   happy     0.713     0.663     0.613    106\n",
      " neutral     0.713     0.772     0.830    106\n",
      "     sad     0.713     0.740     0.726    106\n",
      "surprise     0.713     0.761     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.713     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.894786 \n",
      "\n",
      "classification loss: 1.905524;  cosine similarity loss: 1.869731 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.373708; classification loss: 0.021910;  cosine similarity loss: 1.780897\n",
      "[ 1400/ 5482] total-loss: 0.371450; classification loss: 0.020695;  cosine similarity loss: 1.774469\n",
      "[ 2800/ 5482] total-loss: 0.371359; classification loss: 0.020790;  cosine similarity loss: 1.773634\n",
      "[ 4200/ 5482] total-loss: 0.371102; classification loss: 0.020310;  cosine similarity loss: 1.774268\n",
      "[ 5600/ 5482] total-loss: 0.370560; classification loss: 0.020414;  cosine similarity loss: 1.771146\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.694     0.792    106\n",
      " disgust     0.710     0.796     0.774    106\n",
      "    fear     0.710     0.583     0.594    106\n",
      "   happy     0.710     0.632     0.632    106\n",
      " neutral     0.710     0.763     0.849    106\n",
      "     sad     0.710     0.771     0.698    106\n",
      "surprise     0.710     0.744     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.712     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.921794 \n",
      "\n",
      "classification loss: 1.945011;  cosine similarity loss: 1.867620 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.371957; classification loss: 0.020698;  cosine similarity loss: 1.776992\n",
      "[ 1400/ 5482] total-loss: 0.371173; classification loss: 0.020036;  cosine similarity loss: 1.775719\n",
      "[ 2800/ 5482] total-loss: 0.373565; classification loss: 0.023868;  cosine similarity loss: 1.772349\n",
      "[ 4200/ 5482] total-loss: 0.371255; classification loss: 0.020621;  cosine similarity loss: 1.773789\n",
      "[ 5600/ 5482] total-loss: 0.370668; classification loss: 0.019973;  cosine similarity loss: 1.773449\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.694     0.656     0.774    106\n",
      " disgust     0.694     0.705     0.858    106\n",
      "    fear     0.694     0.641     0.557    106\n",
      "   happy     0.694     0.555     0.623    106\n",
      " neutral     0.694     0.798     0.821    106\n",
      "     sad     0.694     0.723     0.689    106\n",
      "surprise     0.694     0.851     0.538    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.694     0.704     0.694    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.933195 \n",
      "\n",
      "classification loss: 1.958410;  cosine similarity loss: 1.874360 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.379667; classification loss: 0.025723;  cosine similarity loss: 1.795443\n",
      "[ 1400/ 5482] total-loss: 0.370580; classification loss: 0.019952;  cosine similarity loss: 1.773093\n",
      "[ 2800/ 5482] total-loss: 0.374636; classification loss: 0.023584;  cosine similarity loss: 1.778841\n",
      "[ 4200/ 5482] total-loss: 0.371656; classification loss: 0.021182;  cosine similarity loss: 1.773554\n",
      "[ 5600/ 5482] total-loss: 0.372339; classification loss: 0.020291;  cosine similarity loss: 1.780531\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.683     0.774    106\n",
      " disgust     0.716     0.677     0.811    106\n",
      "    fear     0.716     0.635     0.623    106\n",
      "   happy     0.716     0.707     0.613    106\n",
      " neutral     0.716     0.763     0.849    106\n",
      "     sad     0.716     0.809     0.717    106\n",
      "surprise     0.716     0.759     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.719     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.970315 \n",
      "\n",
      "classification loss: 2.014866;  cosine similarity loss: 1.866364 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.373007; classification loss: 0.023032;  cosine similarity loss: 1.772906\n",
      "[ 1400/ 5482] total-loss: 0.370362; classification loss: 0.020282;  cosine similarity loss: 1.770678\n",
      "[ 2800/ 5482] total-loss: 0.370865; classification loss: 0.020166;  cosine similarity loss: 1.773664\n",
      "[ 4200/ 5482] total-loss: 0.373273; classification loss: 0.020490;  cosine similarity loss: 1.784408\n",
      "[ 5600/ 5482] total-loss: 0.370460; classification loss: 0.019829;  cosine similarity loss: 1.772981\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.696     0.755    106\n",
      " disgust     0.717     0.707     0.821    106\n",
      "    fear     0.717     0.677     0.632    106\n",
      "   happy     0.717     0.663     0.613    106\n",
      " neutral     0.717     0.726     0.849    106\n",
      "     sad     0.717     0.831     0.698    106\n",
      "surprise     0.717     0.734     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.719     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 1.908472 \n",
      "\n",
      "classification loss: 1.926170;  cosine similarity loss: 1.867177 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.373383; classification loss: 0.022228;  cosine similarity loss: 1.778002\n",
      "[ 1400/ 5482] total-loss: 0.371840; classification loss: 0.020809;  cosine similarity loss: 1.775967\n",
      "[ 2800/ 5482] total-loss: 0.370822; classification loss: 0.020899;  cosine similarity loss: 1.770517\n",
      "[ 4200/ 5482] total-loss: 0.370413; classification loss: 0.020967;  cosine similarity loss: 1.768198\n",
      "[ 5600/ 5482] total-loss: 0.373614; classification loss: 0.022455;  cosine similarity loss: 1.778250\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.713     0.774    106\n",
      " disgust     0.713     0.650     0.858    106\n",
      "    fear     0.713     0.700     0.594    106\n",
      "   happy     0.713     0.670     0.613    106\n",
      " neutral     0.713     0.731     0.821    106\n",
      "     sad     0.713     0.785     0.689    106\n",
      "surprise     0.713     0.773     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.717     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.942888 \n",
      "\n",
      "classification loss: 1.975453;  cosine similarity loss: 1.866903 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.370481; classification loss: 0.020574;  cosine similarity loss: 1.770110\n",
      "[ 1400/ 5482] total-loss: 0.675501; classification loss: 0.398016;  cosine similarity loss: 1.785441\n",
      "[ 2800/ 5482] total-loss: 0.373520; classification loss: 0.021910;  cosine similarity loss: 1.779958\n",
      "[ 4200/ 5482] total-loss: 0.370508; classification loss: 0.019516;  cosine similarity loss: 1.774480\n",
      "[ 5600/ 5482] total-loss: 0.379323; classification loss: 0.029181;  cosine similarity loss: 1.779891\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.757     0.792    106\n",
      " disgust     0.716     0.679     0.858    106\n",
      "    fear     0.716     0.709     0.575    106\n",
      "   happy     0.716     0.613     0.613    106\n",
      " neutral     0.716     0.789     0.811    106\n",
      "     sad     0.716     0.701     0.708    106\n",
      "surprise     0.716     0.775     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.718     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.872793 \n",
      "\n",
      "classification loss: 1.876097;  cosine similarity loss: 1.865082 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.371935; classification loss: 0.021247;  cosine similarity loss: 1.774689\n",
      "[ 1400/ 5482] total-loss: 0.370372; classification loss: 0.019711;  cosine similarity loss: 1.773019\n",
      "[ 2800/ 5482] total-loss: 0.369765; classification loss: 0.019197;  cosine similarity loss: 1.772033\n",
      "[ 4200/ 5482] total-loss: 0.375043; classification loss: 0.024202;  cosine similarity loss: 1.778410\n",
      "[ 5600/ 5482] total-loss: 0.370887; classification loss: 0.020621;  cosine similarity loss: 1.771947\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.748     0.783    106\n",
      " disgust     0.702     0.645     0.840    106\n",
      "    fear     0.702     0.659     0.566    106\n",
      "   happy     0.702     0.705     0.585    106\n",
      " neutral     0.702     0.764     0.792    106\n",
      "     sad     0.702     0.699     0.679    106\n",
      "surprise     0.702     0.703     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.703     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.872907 \n",
      "\n",
      "classification loss: 1.878926;  cosine similarity loss: 1.858862 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.373116; classification loss: 0.023324;  cosine similarity loss: 1.772286\n",
      "[ 1400/ 5482] total-loss: 0.370248; classification loss: 0.019755;  cosine similarity loss: 1.772220\n",
      "[ 2800/ 5482] total-loss: 0.378878; classification loss: 0.028416;  cosine similarity loss: 1.780725\n",
      "[ 4200/ 5482] total-loss: 0.377194; classification loss: 0.027146;  cosine similarity loss: 1.777384\n",
      "[ 5600/ 5482] total-loss: 0.369595; classification loss: 0.019146;  cosine similarity loss: 1.771388\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.757     0.792    106\n",
      " disgust     0.706     0.794     0.802    106\n",
      "    fear     0.706     0.631     0.613    106\n",
      "   happy     0.706     0.627     0.604    106\n",
      " neutral     0.706     0.720     0.849    106\n",
      "     sad     0.706     0.649     0.679    106\n",
      "surprise     0.706     0.771     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.707     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.908830 \n",
      "\n",
      "classification loss: 1.926309;  cosine similarity loss: 1.868046 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.371395; classification loss: 0.021405;  cosine similarity loss: 1.771353\n",
      "[ 1400/ 5482] total-loss: 0.369937; classification loss: 0.019441;  cosine similarity loss: 1.771921\n",
      "[ 2800/ 5482] total-loss: 0.382226; classification loss: 0.030636;  cosine similarity loss: 1.788582\n",
      "[ 4200/ 5482] total-loss: 0.369390; classification loss: 0.019117;  cosine similarity loss: 1.770482\n",
      "[ 5600/ 5482] total-loss: 0.372804; classification loss: 0.022598;  cosine similarity loss: 1.773627\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.695     0.643     0.783    106\n",
      " disgust     0.695     0.735     0.811    106\n",
      "    fear     0.695     0.681     0.585    106\n",
      "   happy     0.695     0.527     0.651    106\n",
      " neutral     0.695     0.830     0.830    106\n",
      "     sad     0.695     0.725     0.698    106\n",
      "surprise     0.695     0.818     0.509    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.695     0.709     0.695    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 1.887309 \n",
      "\n",
      "classification loss: 1.894219;  cosine similarity loss: 1.871184 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.370644; classification loss: 0.019217;  cosine similarity loss: 1.776352\n",
      "[ 1400/ 5482] total-loss: 0.369269; classification loss: 0.018739;  cosine similarity loss: 1.771391\n",
      "[ 2800/ 5482] total-loss: 0.370636; classification loss: 0.019626;  cosine similarity loss: 1.774676\n",
      "[ 4200/ 5482] total-loss: 0.377777; classification loss: 0.026206;  cosine similarity loss: 1.784057\n",
      "[ 5600/ 5482] total-loss: 0.369380; classification loss: 0.019496;  cosine similarity loss: 1.768916\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.726     0.664     0.783    106\n",
      " disgust     0.726     0.757     0.792    106\n",
      "    fear     0.726     0.701     0.642    106\n",
      "   happy     0.726     0.647     0.623    106\n",
      " neutral     0.726     0.814     0.868    106\n",
      "     sad     0.726     0.745     0.717    106\n",
      "surprise     0.726     0.761     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.726     0.727     0.726    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 1.859136 \n",
      "\n",
      "classification loss: 1.855692;  cosine similarity loss: 1.867172 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369955; classification loss: 0.018779;  cosine similarity loss: 1.774658\n",
      "[ 1400/ 5482] total-loss: 0.371057; classification loss: 0.021486;  cosine similarity loss: 1.769341\n",
      "[ 2800/ 5482] total-loss: 0.369679; classification loss: 0.018411;  cosine similarity loss: 1.774750\n",
      "[ 4200/ 5482] total-loss: 0.369351; classification loss: 0.018481;  cosine similarity loss: 1.772831\n",
      "[ 5600/ 5482] total-loss: 0.370904; classification loss: 0.018966;  cosine similarity loss: 1.778653\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.780     0.736    106\n",
      " disgust     0.709     0.794     0.802    106\n",
      "    fear     0.709     0.620     0.632    106\n",
      "   happy     0.709     0.537     0.689    106\n",
      " neutral     0.709     0.760     0.868    106\n",
      "     sad     0.709     0.761     0.660    106\n",
      "surprise     0.709     0.782     0.575    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.719     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.002410 \n",
      "\n",
      "classification loss: 2.060239;  cosine similarity loss: 1.867477 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369224; classification loss: 0.018401;  cosine similarity loss: 1.772519\n",
      "[ 1400/ 5482] total-loss: 0.370024; classification loss: 0.018536;  cosine similarity loss: 1.775974\n",
      "[ 2800/ 5482] total-loss: 0.376649; classification loss: 0.025535;  cosine similarity loss: 1.781105\n",
      "[ 4200/ 5482] total-loss: 0.369306; classification loss: 0.019308;  cosine similarity loss: 1.769298\n",
      "[ 5600/ 5482] total-loss: 0.370717; classification loss: 0.018998;  cosine similarity loss: 1.777595\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.703     0.783    106\n",
      " disgust     0.718     0.737     0.792    106\n",
      "    fear     0.718     0.637     0.613    106\n",
      "   happy     0.718     0.645     0.651    106\n",
      " neutral     0.718     0.778     0.858    106\n",
      "     sad     0.718     0.857     0.679    106\n",
      "surprise     0.718     0.690     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.721     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.967486 \n",
      "\n",
      "classification loss: 2.010174;  cosine similarity loss: 1.867881 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369252; classification loss: 0.018620;  cosine similarity loss: 1.771780\n",
      "[ 1400/ 5482] total-loss: 0.371073; classification loss: 0.020236;  cosine similarity loss: 1.774420\n",
      "[ 2800/ 5482] total-loss: 0.368750; classification loss: 0.018396;  cosine similarity loss: 1.770168\n",
      "[ 4200/ 5482] total-loss: 0.369197; classification loss: 0.019052;  cosine similarity loss: 1.769775\n",
      "[ 5600/ 5482] total-loss: 0.369306; classification loss: 0.017892;  cosine similarity loss: 1.774959\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.724     0.755     0.755    106\n",
      " disgust     0.724     0.702     0.821    106\n",
      "    fear     0.724     0.688     0.604    106\n",
      "   happy     0.724     0.632     0.632    106\n",
      " neutral     0.724     0.744     0.849    106\n",
      "     sad     0.724     0.758     0.708    106\n",
      "surprise     0.724     0.796     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.724     0.725     0.724    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 1.904232 \n",
      "\n",
      "classification loss: 1.919961;  cosine similarity loss: 1.867529 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369338; classification loss: 0.018867;  cosine similarity loss: 1.771221\n",
      "[ 1400/ 5482] total-loss: 0.370120; classification loss: 0.019095;  cosine similarity loss: 1.774218\n",
      "[ 2800/ 5482] total-loss: 0.371027; classification loss: 0.019876;  cosine similarity loss: 1.775628\n",
      "[ 4200/ 5482] total-loss: 0.369419; classification loss: 0.017846;  cosine similarity loss: 1.775711\n",
      "[ 5600/ 5482] total-loss: 0.369751; classification loss: 0.019091;  cosine similarity loss: 1.772392\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.638     0.783    106\n",
      " disgust     0.716     0.755     0.783    106\n",
      "    fear     0.716     0.690     0.651    106\n",
      "   happy     0.716     0.626     0.632    106\n",
      " neutral     0.716     0.774     0.840    106\n",
      "     sad     0.716     0.772     0.670    106\n",
      "surprise     0.716     0.784     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.720     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.945855 \n",
      "\n",
      "classification loss: 1.978329;  cosine similarity loss: 1.870081 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369456; classification loss: 0.019687;  cosine similarity loss: 1.768528\n",
      "[ 1400/ 5482] total-loss: 0.369741; classification loss: 0.018690;  cosine similarity loss: 1.773946\n",
      "[ 2800/ 5482] total-loss: 0.370736; classification loss: 0.020518;  cosine similarity loss: 1.771608\n",
      "[ 4200/ 5482] total-loss: 0.377425; classification loss: 0.024331;  cosine similarity loss: 1.789799\n",
      "[ 5600/ 5482] total-loss: 0.391188; classification loss: 0.043677;  cosine similarity loss: 1.781231\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.750     0.736    106\n",
      " disgust     0.714     0.782     0.811    106\n",
      "    fear     0.714     0.664     0.689    106\n",
      "   happy     0.714     0.570     0.651    106\n",
      " neutral     0.714     0.739     0.802    106\n",
      "     sad     0.714     0.747     0.670    106\n",
      "surprise     0.714     0.782     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.719     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 2.000634 \n",
      "\n",
      "classification loss: 2.057779;  cosine similarity loss: 1.867295 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.368868; classification loss: 0.018393;  cosine similarity loss: 1.770768\n",
      "[ 1400/ 5482] total-loss: 0.377979; classification loss: 0.026031;  cosine similarity loss: 1.785773\n",
      "[ 2800/ 5482] total-loss: 0.368855; classification loss: 0.018378;  cosine similarity loss: 1.770764\n",
      "[ 4200/ 5482] total-loss: 0.370344; classification loss: 0.019960;  cosine similarity loss: 1.771878\n",
      "[ 5600/ 5482] total-loss: 0.370713; classification loss: 0.019551;  cosine similarity loss: 1.775359\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.683     0.792    106\n",
      " disgust     0.721     0.739     0.830    106\n",
      "    fear     0.721     0.667     0.642    106\n",
      "   happy     0.721     0.705     0.632    106\n",
      " neutral     0.721     0.789     0.811    106\n",
      "     sad     0.721     0.735     0.679    106\n",
      "surprise     0.721     0.729     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.721     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.878553 \n",
      "\n",
      "classification loss: 1.885105;  cosine similarity loss: 1.863264 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369828; classification loss: 0.019554;  cosine similarity loss: 1.770926\n",
      "[ 1400/ 5482] total-loss: 0.368793; classification loss: 0.017886;  cosine similarity loss: 1.772420\n",
      "[ 2800/ 5482] total-loss: 0.369067; classification loss: 0.018960;  cosine similarity loss: 1.769491\n",
      "[ 4200/ 5482] total-loss: 0.368797; classification loss: 0.018075;  cosine similarity loss: 1.771688\n",
      "[ 5600/ 5482] total-loss: 0.370096; classification loss: 0.018990;  cosine similarity loss: 1.774519\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.698     0.764    106\n",
      " disgust     0.718     0.713     0.821    106\n",
      "    fear     0.718     0.612     0.670    106\n",
      "   happy     0.718     0.719     0.604    106\n",
      " neutral     0.718     0.810     0.802    106\n",
      "     sad     0.718     0.758     0.708    106\n",
      "surprise     0.718     0.737     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.721     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.837212 \n",
      "\n",
      "classification loss: 1.826930;  cosine similarity loss: 1.861202 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.374658; classification loss: 0.021522;  cosine similarity loss: 1.787200\n",
      "[ 1400/ 5482] total-loss: 0.369271; classification loss: 0.019785;  cosine similarity loss: 1.767214\n",
      "[ 2800/ 5482] total-loss: 0.368842; classification loss: 0.017575;  cosine similarity loss: 1.773910\n",
      "[ 4200/ 5482] total-loss: 0.369328; classification loss: 0.017319;  cosine similarity loss: 1.777365\n",
      "[ 5600/ 5482] total-loss: 0.392042; classification loss: 0.044329;  cosine similarity loss: 1.782892\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.734     0.755    106\n",
      " disgust     0.712     0.833     0.755    106\n",
      "    fear     0.712     0.557     0.689    106\n",
      "   happy     0.712     0.677     0.594    106\n",
      " neutral     0.712     0.820     0.774    106\n",
      "     sad     0.712     0.748     0.726    106\n",
      "surprise     0.712     0.664     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.719     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.965496 \n",
      "\n",
      "classification loss: 2.006647;  cosine similarity loss: 1.869475 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369833; classification loss: 0.017943;  cosine similarity loss: 1.777391\n",
      "[ 1400/ 5482] total-loss: 0.368693; classification loss: 0.018027;  cosine similarity loss: 1.771357\n",
      "[ 2800/ 5482] total-loss: 0.396209; classification loss: 0.048002;  cosine similarity loss: 1.789037\n",
      "[ 4200/ 5482] total-loss: 0.369312; classification loss: 0.017617;  cosine similarity loss: 1.776091\n",
      "[ 5600/ 5482] total-loss: 0.370816; classification loss: 0.018108;  cosine similarity loss: 1.781648\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.698     0.764    106\n",
      " disgust     0.713     0.757     0.792    106\n",
      "    fear     0.713     0.664     0.670    106\n",
      "   happy     0.713     0.567     0.642    106\n",
      " neutral     0.713     0.759     0.774    106\n",
      "     sad     0.713     0.813     0.698    106\n",
      "surprise     0.713     0.775     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.719     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.914242 \n",
      "\n",
      "classification loss: 1.933634;  cosine similarity loss: 1.868994 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.375780; classification loss: 0.022369;  cosine similarity loss: 1.789423\n",
      "[ 1400/ 5482] total-loss: 0.368585; classification loss: 0.017226;  cosine similarity loss: 1.774021\n",
      "[ 2800/ 5482] total-loss: 0.402235; classification loss: 0.058319;  cosine similarity loss: 1.777898\n",
      "[ 4200/ 5482] total-loss: 0.369069; classification loss: 0.018433;  cosine similarity loss: 1.771610\n",
      "[ 5600/ 5482] total-loss: 0.374131; classification loss: 0.023616;  cosine similarity loss: 1.776191\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.741     0.755    106\n",
      " disgust     0.722     0.725     0.821    106\n",
      "    fear     0.722     0.631     0.660    106\n",
      "   happy     0.722     0.627     0.604    106\n",
      " neutral     0.722     0.811     0.811    106\n",
      "     sad     0.722     0.729     0.736    106\n",
      "surprise     0.722     0.807     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.724     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.877143 \n",
      "\n",
      "classification loss: 1.884133;  cosine similarity loss: 1.860834 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.368381; classification loss: 0.018091;  cosine similarity loss: 1.769539\n",
      "[ 1400/ 5482] total-loss: 0.368524; classification loss: 0.016900;  cosine similarity loss: 1.775019\n",
      "[ 2800/ 5482] total-loss: 0.367808; classification loss: 0.017472;  cosine similarity loss: 1.769150\n",
      "[ 4200/ 5482] total-loss: 0.369176; classification loss: 0.018519;  cosine similarity loss: 1.771805\n",
      "[ 5600/ 5482] total-loss: 0.370701; classification loss: 0.019613;  cosine similarity loss: 1.775054\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.732     0.774    106\n",
      " disgust     0.720     0.729     0.811    106\n",
      "    fear     0.720     0.616     0.651    106\n",
      "   happy     0.720     0.631     0.660    106\n",
      " neutral     0.720     0.787     0.802    106\n",
      "     sad     0.720     0.789     0.670    106\n",
      "surprise     0.720     0.780     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.723     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.834022 \n",
      "\n",
      "classification loss: 1.821284;  cosine similarity loss: 1.863744 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.368616; classification loss: 0.017989;  cosine similarity loss: 1.771124\n",
      "[ 1400/ 5482] total-loss: 0.367993; classification loss: 0.017690;  cosine similarity loss: 1.769205\n",
      "[ 2800/ 5482] total-loss: 0.367753; classification loss: 0.017488;  cosine similarity loss: 1.768812\n",
      "[ 4200/ 5482] total-loss: 0.368500; classification loss: 0.018529;  cosine similarity loss: 1.768386\n",
      "[ 5600/ 5482] total-loss: 0.367823; classification loss: 0.017424;  cosine similarity loss: 1.769417\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.719     0.774    106\n",
      " disgust     0.718     0.789     0.811    106\n",
      "    fear     0.718     0.622     0.651    106\n",
      "   happy     0.718     0.597     0.670    106\n",
      " neutral     0.718     0.806     0.783    106\n",
      "     sad     0.718     0.740     0.670    106\n",
      "surprise     0.718     0.789     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.723     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.852283 \n",
      "\n",
      "classification loss: 1.846805;  cosine similarity loss: 1.865064 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.368651; classification loss: 0.017151;  cosine similarity loss: 1.774650\n",
      "[ 1400/ 5482] total-loss: 0.370193; classification loss: 0.018817;  cosine similarity loss: 1.775698\n",
      "[ 2800/ 5482] total-loss: 0.372602; classification loss: 0.021978;  cosine similarity loss: 1.775098\n",
      "[ 4200/ 5482] total-loss: 0.368980; classification loss: 0.017417;  cosine similarity loss: 1.775231\n",
      "[ 5600/ 5482] total-loss: 0.368382; classification loss: 0.018327;  cosine similarity loss: 1.768603\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.718     0.745    106\n",
      " disgust     0.710     0.752     0.830    106\n",
      "    fear     0.710     0.589     0.623    106\n",
      "   happy     0.710     0.575     0.689    106\n",
      " neutral     0.710     0.763     0.821    106\n",
      "     sad     0.710     0.791     0.679    106\n",
      "surprise     0.710     0.873     0.585    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.723     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.858048 \n",
      "\n",
      "classification loss: 1.854496;  cosine similarity loss: 1.866337 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367430; classification loss: 0.017222;  cosine similarity loss: 1.768261\n",
      "[ 1400/ 5482] total-loss: 0.370579; classification loss: 0.019024;  cosine similarity loss: 1.776801\n",
      "[ 2800/ 5482] total-loss: 0.368812; classification loss: 0.017205;  cosine similarity loss: 1.775239\n",
      "[ 4200/ 5482] total-loss: 0.368843; classification loss: 0.017872;  cosine similarity loss: 1.772724\n",
      "[ 5600/ 5482] total-loss: 0.371429; classification loss: 0.020316;  cosine similarity loss: 1.775881\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.716     0.783    106\n",
      " disgust     0.716     0.817     0.802    106\n",
      "    fear     0.716     0.576     0.642    106\n",
      "   happy     0.716     0.626     0.632    106\n",
      " neutral     0.716     0.810     0.802    106\n",
      "     sad     0.716     0.752     0.717    106\n",
      "surprise     0.716     0.736     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.719     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.852333 \n",
      "\n",
      "classification loss: 1.844761;  cosine similarity loss: 1.869999 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.368721; classification loss: 0.017016;  cosine similarity loss: 1.775541\n",
      "[ 1400/ 5482] total-loss: 0.367718; classification loss: 0.016379;  cosine similarity loss: 1.773073\n",
      "[ 2800/ 5482] total-loss: 0.368002; classification loss: 0.017531;  cosine similarity loss: 1.769887\n",
      "[ 4200/ 5482] total-loss: 0.379795; classification loss: 0.029619;  cosine similarity loss: 1.780499\n",
      "[ 5600/ 5482] total-loss: 0.368019; classification loss: 0.017699;  cosine similarity loss: 1.769299\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.686     0.764    106\n",
      " disgust     0.712     0.745     0.774    106\n",
      "    fear     0.712     0.593     0.632    106\n",
      "   happy     0.712     0.691     0.613    106\n",
      " neutral     0.712     0.794     0.802    106\n",
      "     sad     0.712     0.725     0.745    106\n",
      "surprise     0.712     0.758     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.713     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.834249 \n",
      "\n",
      "classification loss: 1.823171;  cosine similarity loss: 1.860098 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.390921; classification loss: 0.043185;  cosine similarity loss: 1.781864\n",
      "[ 1400/ 5482] total-loss: 0.368113; classification loss: 0.017747;  cosine similarity loss: 1.769578\n",
      "[ 2800/ 5482] total-loss: 0.368133; classification loss: 0.016880;  cosine similarity loss: 1.773141\n",
      "[ 4200/ 5482] total-loss: 0.368401; classification loss: 0.017066;  cosine similarity loss: 1.773740\n",
      "[ 5600/ 5482] total-loss: 0.367514; classification loss: 0.016968;  cosine similarity loss: 1.769698\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.726     0.726    106\n",
      " disgust     0.706     0.696     0.821    106\n",
      "    fear     0.706     0.624     0.642    106\n",
      "   happy     0.706     0.688     0.604    106\n",
      " neutral     0.706     0.723     0.811    106\n",
      "     sad     0.706     0.735     0.708    106\n",
      "surprise     0.706     0.761     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.708     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.894937 \n",
      "\n",
      "classification loss: 1.907875;  cosine similarity loss: 1.864748 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367207; classification loss: 0.016963;  cosine similarity loss: 1.768184\n",
      "[ 1400/ 5482] total-loss: 0.367173; classification loss: 0.016443;  cosine similarity loss: 1.770093\n",
      "[ 2800/ 5482] total-loss: 0.368018; classification loss: 0.016791;  cosine similarity loss: 1.772925\n",
      "[ 4200/ 5482] total-loss: 0.367950; classification loss: 0.017096;  cosine similarity loss: 1.771368\n",
      "[ 5600/ 5482] total-loss: 0.367580; classification loss: 0.016444;  cosine similarity loss: 1.772126\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.626     0.774    106\n",
      " disgust     0.713     0.719     0.821    106\n",
      "    fear     0.713     0.605     0.651    106\n",
      "   happy     0.713     0.795     0.585    106\n",
      " neutral     0.713     0.794     0.764    106\n",
      "     sad     0.713     0.776     0.717    106\n",
      "surprise     0.713     0.735     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.721     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.849177 \n",
      "\n",
      "classification loss: 1.843228;  cosine similarity loss: 1.863058 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.429052; classification loss: 0.086314;  cosine similarity loss: 1.800005\n",
      "[ 1400/ 5482] total-loss: 0.367045; classification loss: 0.016516;  cosine similarity loss: 1.769162\n",
      "[ 2800/ 5482] total-loss: 0.368382; classification loss: 0.016952;  cosine similarity loss: 1.774100\n",
      "[ 4200/ 5482] total-loss: 0.368453; classification loss: 0.017046;  cosine similarity loss: 1.774081\n",
      "[ 5600/ 5482] total-loss: 0.367727; classification loss: 0.016889;  cosine similarity loss: 1.771075\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.690     0.736    106\n",
      " disgust     0.713     0.705     0.811    106\n",
      "    fear     0.713     0.600     0.679    106\n",
      "   happy     0.713     0.727     0.604    106\n",
      " neutral     0.713     0.759     0.802    106\n",
      "     sad     0.713     0.758     0.679    106\n",
      "surprise     0.713     0.783     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.717     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.905533 \n",
      "\n",
      "classification loss: 1.922761;  cosine similarity loss: 1.865335 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367492; classification loss: 0.016785;  cosine similarity loss: 1.770321\n",
      "[ 1400/ 5482] total-loss: 0.367932; classification loss: 0.017034;  cosine similarity loss: 1.771524\n",
      "[ 2800/ 5482] total-loss: 0.367905; classification loss: 0.017743;  cosine similarity loss: 1.768552\n",
      "[ 4200/ 5482] total-loss: 0.368435; classification loss: 0.018284;  cosine similarity loss: 1.769042\n",
      "[ 5600/ 5482] total-loss: 0.367260; classification loss: 0.016852;  cosine similarity loss: 1.768893\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.642     0.745    106\n",
      " disgust     0.705     0.723     0.764    106\n",
      "    fear     0.705     0.602     0.642    106\n",
      "   happy     0.705     0.710     0.623    106\n",
      " neutral     0.705     0.742     0.840    106\n",
      "     sad     0.705     0.783     0.679    106\n",
      "surprise     0.705     0.764     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.709     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.981752 \n",
      "\n",
      "classification loss: 2.031834;  cosine similarity loss: 1.864893 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367177; classification loss: 0.016989;  cosine similarity loss: 1.767932\n",
      "[ 1400/ 5482] total-loss: 0.377164; classification loss: 0.026074;  cosine similarity loss: 1.781526\n",
      "[ 2800/ 5482] total-loss: 0.368197; classification loss: 0.017059;  cosine similarity loss: 1.772752\n",
      "[ 4200/ 5482] total-loss: 0.367324; classification loss: 0.018017;  cosine similarity loss: 1.764554\n",
      "[ 5600/ 5482] total-loss: 0.371339; classification loss: 0.021207;  cosine similarity loss: 1.771870\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.699     0.752     0.717    106\n",
      " disgust     0.699     0.718     0.792    106\n",
      "    fear     0.699     0.594     0.594    106\n",
      "   happy     0.699     0.597     0.670    106\n",
      " neutral     0.699     0.748     0.811    106\n",
      "     sad     0.699     0.785     0.689    106\n",
      "surprise     0.699     0.725     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.699     0.703     0.699    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.977370 \n",
      "\n",
      "classification loss: 2.023130;  cosine similarity loss: 1.870597 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367551; classification loss: 0.016080;  cosine similarity loss: 1.773433\n",
      "[ 1400/ 5482] total-loss: 0.379745; classification loss: 0.030771;  cosine similarity loss: 1.775637\n",
      "[ 2800/ 5482] total-loss: 0.367462; classification loss: 0.015501;  cosine similarity loss: 1.775302\n",
      "[ 4200/ 5482] total-loss: 0.367291; classification loss: 0.017244;  cosine similarity loss: 1.767478\n",
      "[ 5600/ 5482] total-loss: 0.367356; classification loss: 0.017057;  cosine similarity loss: 1.768552\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.694     0.709     0.736    106\n",
      " disgust     0.694     0.636     0.858    106\n",
      "    fear     0.694     0.764     0.519    106\n",
      "   happy     0.694     0.552     0.651    106\n",
      " neutral     0.694     0.764     0.792    106\n",
      "     sad     0.694     0.711     0.651    106\n",
      "surprise     0.694     0.812     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.694     0.707     0.694    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 2.038744 \n",
      "\n",
      "classification loss: 2.111648;  cosine similarity loss: 1.868635 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367183; classification loss: 0.015594;  cosine similarity loss: 1.773537\n",
      "[ 1400/ 5482] total-loss: 0.367075; classification loss: 0.016559;  cosine similarity loss: 1.769141\n",
      "[ 2800/ 5482] total-loss: 0.368057; classification loss: 0.016856;  cosine similarity loss: 1.772861\n",
      "[ 4200/ 5482] total-loss: 0.366588; classification loss: 0.016320;  cosine similarity loss: 1.767662\n",
      "[ 5600/ 5482] total-loss: 0.398014; classification loss: 0.053419;  cosine similarity loss: 1.776392\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.697     0.802    106\n",
      " disgust     0.712     0.737     0.821    106\n",
      "    fear     0.712     0.624     0.642    106\n",
      "   happy     0.712     0.641     0.623    106\n",
      " neutral     0.712     0.812     0.774    106\n",
      "     sad     0.712     0.703     0.670    106\n",
      "surprise     0.712     0.784     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.714     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.951521 \n",
      "\n",
      "classification loss: 1.986460;  cosine similarity loss: 1.869996 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.366887; classification loss: 0.016977;  cosine similarity loss: 1.766530\n",
      "[ 1400/ 5482] total-loss: 0.370322; classification loss: 0.019198;  cosine similarity loss: 1.774817\n",
      "[ 2800/ 5482] total-loss: 0.368960; classification loss: 0.018152;  cosine similarity loss: 1.772193\n",
      "[ 4200/ 5482] total-loss: 0.367109; classification loss: 0.016257;  cosine similarity loss: 1.770518\n",
      "[ 5600/ 5482] total-loss: 0.369266; classification loss: 0.017915;  cosine similarity loss: 1.774670\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.730     0.764    106\n",
      " disgust     0.710     0.733     0.802    106\n",
      "    fear     0.710     0.681     0.585    106\n",
      "   happy     0.710     0.597     0.670    106\n",
      " neutral     0.710     0.795     0.840    106\n",
      "     sad     0.710     0.692     0.698    106\n",
      "surprise     0.710     0.756     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.712     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.027492 \n",
      "\n",
      "classification loss: 2.093843;  cosine similarity loss: 1.872673 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367999; classification loss: 0.016290;  cosine similarity loss: 1.774837\n",
      "[ 1400/ 5482] total-loss: 0.367331; classification loss: 0.016474;  cosine similarity loss: 1.770758\n",
      "[ 2800/ 5482] total-loss: 0.366508; classification loss: 0.015919;  cosine similarity loss: 1.768865\n",
      "[ 4200/ 5482] total-loss: 0.367321; classification loss: 0.015875;  cosine similarity loss: 1.773107\n",
      "[ 5600/ 5482] total-loss: 0.367315; classification loss: 0.017038;  cosine similarity loss: 1.768423\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.788     0.736    106\n",
      " disgust     0.721     0.726     0.802    106\n",
      "    fear     0.721     0.657     0.632    106\n",
      "   happy     0.721     0.645     0.651    106\n",
      " neutral     0.721     0.800     0.830    106\n",
      "     sad     0.721     0.687     0.745    106\n",
      "surprise     0.721     0.750     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.722     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.916627 \n",
      "\n",
      "classification loss: 1.938697;  cosine similarity loss: 1.865129 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.366720; classification loss: 0.016187;  cosine similarity loss: 1.768855\n",
      "[ 1400/ 5482] total-loss: 0.368824; classification loss: 0.017182;  cosine similarity loss: 1.775390\n",
      "[ 2800/ 5482] total-loss: 0.376822; classification loss: 0.026820;  cosine similarity loss: 1.776830\n",
      "[ 4200/ 5482] total-loss: 0.369397; classification loss: 0.017906;  cosine similarity loss: 1.775362\n",
      "[ 5600/ 5482] total-loss: 0.368927; classification loss: 0.016237;  cosine similarity loss: 1.779687\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.679     0.690     0.736    106\n",
      " disgust     0.679     0.575     0.830    106\n",
      "    fear     0.679     0.725     0.547    106\n",
      "   happy     0.679     0.585     0.651    106\n",
      " neutral     0.679     0.785     0.689    106\n",
      "     sad     0.679     0.713     0.679    106\n",
      "surprise     0.679     0.786     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.679     0.694     0.679    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 2.159278 \n",
      "\n",
      "classification loss: 2.282111;  cosine similarity loss: 1.872669 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.593562; classification loss: 0.295544;  cosine similarity loss: 1.785634\n",
      "[ 1400/ 5482] total-loss: 0.367926; classification loss: 0.016258;  cosine similarity loss: 1.774598\n",
      "[ 2800/ 5482] total-loss: 0.366445; classification loss: 0.015660;  cosine similarity loss: 1.769585\n",
      "[ 4200/ 5482] total-loss: 0.367653; classification loss: 0.016305;  cosine similarity loss: 1.773044\n",
      "[ 5600/ 5482] total-loss: 0.367665; classification loss: 0.016689;  cosine similarity loss: 1.771572\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.694     0.792    106\n",
      " disgust     0.721     0.739     0.802    106\n",
      "    fear     0.721     0.618     0.642    106\n",
      "   happy     0.721     0.765     0.585    106\n",
      " neutral     0.721     0.812     0.774    106\n",
      "     sad     0.721     0.743     0.708    106\n",
      "surprise     0.721     0.699     0.745    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.724     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.855012 \n",
      "\n",
      "classification loss: 1.852423;  cosine similarity loss: 1.861053 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367236; classification loss: 0.016523;  cosine similarity loss: 1.770085\n",
      "[ 1400/ 5482] total-loss: 0.366776; classification loss: 0.015324;  cosine similarity loss: 1.772583\n",
      "[ 2800/ 5482] total-loss: 0.366655; classification loss: 0.015916;  cosine similarity loss: 1.769613\n",
      "[ 4200/ 5482] total-loss: 0.367053; classification loss: 0.016333;  cosine similarity loss: 1.769930\n",
      "[ 5600/ 5482] total-loss: 0.366416; classification loss: 0.015394;  cosine similarity loss: 1.770502\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.725     0.712     0.792    106\n",
      " disgust     0.725     0.816     0.755    106\n",
      "    fear     0.725     0.643     0.679    106\n",
      "   happy     0.725     0.545     0.689    106\n",
      " neutral     0.725     0.812     0.774    106\n",
      "     sad     0.725     0.785     0.689    106\n",
      "surprise     0.725     0.860     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.725     0.739     0.725    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.956958 \n",
      "\n",
      "classification loss: 1.994565;  cosine similarity loss: 1.869209 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369422; classification loss: 0.017645;  cosine similarity loss: 1.776533\n",
      "[ 1400/ 5482] total-loss: 0.366007; classification loss: 0.015550;  cosine similarity loss: 1.767838\n",
      "[ 2800/ 5482] total-loss: 0.373992; classification loss: 0.022296;  cosine similarity loss: 1.780774\n",
      "[ 4200/ 5482] total-loss: 0.367971; classification loss: 0.016653;  cosine similarity loss: 1.773244\n",
      "[ 5600/ 5482] total-loss: 0.368126; classification loss: 0.016743;  cosine similarity loss: 1.773658\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.693     0.830    106\n",
      " disgust     0.722     0.748     0.811    106\n",
      "    fear     0.722     0.650     0.632    106\n",
      "   happy     0.722     0.646     0.604    106\n",
      " neutral     0.722     0.827     0.811    106\n",
      "     sad     0.722     0.753     0.689    106\n",
      "surprise     0.722     0.742     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.723     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.913306 \n",
      "\n",
      "classification loss: 1.934390;  cosine similarity loss: 1.864109 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367132; classification loss: 0.016613;  cosine similarity loss: 1.769205\n",
      "[ 1400/ 5482] total-loss: 0.387297; classification loss: 0.040060;  cosine similarity loss: 1.776243\n",
      "[ 2800/ 5482] total-loss: 0.365862; classification loss: 0.016010;  cosine similarity loss: 1.765271\n",
      "[ 4200/ 5482] total-loss: 0.365933; classification loss: 0.015829;  cosine similarity loss: 1.766350\n",
      "[ 5600/ 5482] total-loss: 0.366445; classification loss: 0.015289;  cosine similarity loss: 1.771070\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.790     0.745    106\n",
      " disgust     0.714     0.701     0.840    106\n",
      "    fear     0.714     0.697     0.651    106\n",
      "   happy     0.714     0.602     0.642    106\n",
      " neutral     0.714     0.685     0.821    106\n",
      "     sad     0.714     0.763     0.670    106\n",
      "surprise     0.714     0.807     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.721     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 2.026745 \n",
      "\n",
      "classification loss: 2.097074;  cosine similarity loss: 1.862643 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367152; classification loss: 0.016791;  cosine similarity loss: 1.768600\n",
      "[ 1400/ 5482] total-loss: 0.366173; classification loss: 0.015162;  cosine similarity loss: 1.770219\n",
      "[ 2800/ 5482] total-loss: 0.366226; classification loss: 0.014790;  cosine similarity loss: 1.771967\n",
      "[ 4200/ 5482] total-loss: 0.366576; classification loss: 0.015337;  cosine similarity loss: 1.771532\n",
      "[ 5600/ 5482] total-loss: 0.366059; classification loss: 0.015213;  cosine similarity loss: 1.769445\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.743     0.736    106\n",
      " disgust     0.712     0.715     0.830    106\n",
      "    fear     0.712     0.747     0.642    106\n",
      "   happy     0.712     0.557     0.604    106\n",
      " neutral     0.712     0.757     0.821    106\n",
      "     sad     0.712     0.695     0.689    106\n",
      "surprise     0.712     0.795     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.716     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.988507 \n",
      "\n",
      "classification loss: 2.040162;  cosine similarity loss: 1.867978 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.411229; classification loss: 0.068233;  cosine similarity loss: 1.783214\n",
      "[ 1400/ 5482] total-loss: 0.367890; classification loss: 0.015882;  cosine similarity loss: 1.775922\n",
      "[ 2800/ 5482] total-loss: 0.365611; classification loss: 0.015379;  cosine similarity loss: 1.766538\n",
      "[ 4200/ 5482] total-loss: 0.366009; classification loss: 0.015253;  cosine similarity loss: 1.769032\n",
      "[ 5600/ 5482] total-loss: 0.366017; classification loss: 0.014930;  cosine similarity loss: 1.770364\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.802     0.764    106\n",
      " disgust     0.717     0.680     0.821    106\n",
      "    fear     0.717     0.616     0.651    106\n",
      "   happy     0.717     0.676     0.651    106\n",
      " neutral     0.717     0.800     0.792    106\n",
      "     sad     0.717     0.734     0.651    106\n",
      "surprise     0.717     0.730     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.720     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.005433 \n",
      "\n",
      "classification loss: 2.067532;  cosine similarity loss: 1.860534 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367386; classification loss: 0.017112;  cosine similarity loss: 1.768482\n",
      "[ 1400/ 5482] total-loss: 0.366971; classification loss: 0.016801;  cosine similarity loss: 1.767650\n",
      "[ 2800/ 5482] total-loss: 0.365919; classification loss: 0.014818;  cosine similarity loss: 1.770324\n",
      "[ 4200/ 5482] total-loss: 0.368048; classification loss: 0.015470;  cosine similarity loss: 1.778360\n",
      "[ 5600/ 5482] total-loss: 0.368057; classification loss: 0.017156;  cosine similarity loss: 1.771663\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.816     0.755    106\n",
      " disgust     0.716     0.737     0.792    106\n",
      "    fear     0.716     0.597     0.698    106\n",
      "   happy     0.716     0.648     0.642    106\n",
      " neutral     0.716     0.838     0.830    106\n",
      "     sad     0.716     0.652     0.689    106\n",
      "surprise     0.716     0.762     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.721     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.902597 \n",
      "\n",
      "classification loss: 1.917103;  cosine similarity loss: 1.868747 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365699; classification loss: 0.014987;  cosine similarity loss: 1.768548\n",
      "[ 1400/ 5482] total-loss: 0.366421; classification loss: 0.015886;  cosine similarity loss: 1.768560\n",
      "[ 2800/ 5482] total-loss: 0.365748; classification loss: 0.015160;  cosine similarity loss: 1.768102\n",
      "[ 4200/ 5482] total-loss: 0.367689; classification loss: 0.016153;  cosine similarity loss: 1.773835\n",
      "[ 5600/ 5482] total-loss: 0.365527; classification loss: 0.015124;  cosine similarity loss: 1.767140\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.700     0.726    106\n",
      " disgust     0.705     0.759     0.802    106\n",
      "    fear     0.705     0.626     0.632    106\n",
      "   happy     0.705     0.660     0.585    106\n",
      " neutral     0.705     0.767     0.840    106\n",
      "     sad     0.705     0.670     0.689    106\n",
      "surprise     0.705     0.745     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.704     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.932553 \n",
      "\n",
      "classification loss: 1.962639;  cosine similarity loss: 1.862354 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365870; classification loss: 0.015355;  cosine similarity loss: 1.767930\n",
      "[ 1400/ 5482] total-loss: 0.367548; classification loss: 0.016462;  cosine similarity loss: 1.771891\n",
      "[ 2800/ 5482] total-loss: 0.365728; classification loss: 0.015217;  cosine similarity loss: 1.767774\n",
      "[ 4200/ 5482] total-loss: 0.366173; classification loss: 0.015606;  cosine similarity loss: 1.768442\n",
      "[ 5600/ 5482] total-loss: 0.367799; classification loss: 0.016660;  cosine similarity loss: 1.772352\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.731     0.717    106\n",
      " disgust     0.706     0.735     0.811    106\n",
      "    fear     0.706     0.648     0.642    106\n",
      "   happy     0.706     0.595     0.623    106\n",
      " neutral     0.706     0.763     0.821    106\n",
      "     sad     0.706     0.702     0.689    106\n",
      "surprise     0.706     0.782     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.708     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.959954 \n",
      "\n",
      "classification loss: 1.998455;  cosine similarity loss: 1.870118 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365998; classification loss: 0.014810;  cosine similarity loss: 1.770751\n",
      "[ 1400/ 5482] total-loss: 0.365709; classification loss: 0.015539;  cosine similarity loss: 1.766388\n",
      "[ 2800/ 5482] total-loss: 0.365888; classification loss: 0.015042;  cosine similarity loss: 1.769270\n",
      "[ 4200/ 5482] total-loss: 0.365514; classification loss: 0.014925;  cosine similarity loss: 1.767872\n",
      "[ 5600/ 5482] total-loss: 0.365906; classification loss: 0.014348;  cosine similarity loss: 1.772139\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.775     0.745    106\n",
      " disgust     0.716     0.741     0.783    106\n",
      "    fear     0.716     0.642     0.642    106\n",
      "   happy     0.716     0.600     0.651    106\n",
      " neutral     0.716     0.779     0.830    106\n",
      "     sad     0.716     0.698     0.698    106\n",
      "surprise     0.716     0.795     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.718     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.965904 \n",
      "\n",
      "classification loss: 2.008096;  cosine similarity loss: 1.867456 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365598; classification loss: 0.014570;  cosine similarity loss: 1.769710\n",
      "[ 1400/ 5482] total-loss: 0.365671; classification loss: 0.015286;  cosine similarity loss: 1.767209\n",
      "[ 2800/ 5482] total-loss: 0.403465; classification loss: 0.060681;  cosine similarity loss: 1.774597\n",
      "[ 4200/ 5482] total-loss: 0.365189; classification loss: 0.014760;  cosine similarity loss: 1.766905\n",
      "[ 5600/ 5482] total-loss: 0.365759; classification loss: 0.015454;  cosine similarity loss: 1.766978\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.711     0.764    106\n",
      " disgust     0.708     0.741     0.783    106\n",
      "    fear     0.708     0.667     0.623    106\n",
      "   happy     0.708     0.586     0.613    106\n",
      " neutral     0.708     0.763     0.821    106\n",
      "     sad     0.708     0.730     0.689    106\n",
      "surprise     0.708     0.761     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.708     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.027556 \n",
      "\n",
      "classification loss: 2.097892;  cosine similarity loss: 1.863436 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.366266; classification loss: 0.014863;  cosine similarity loss: 1.771878\n",
      "[ 1400/ 5482] total-loss: 0.368707; classification loss: 0.017547;  cosine similarity loss: 1.773345\n",
      "[ 2800/ 5482] total-loss: 0.365011; classification loss: 0.014989;  cosine similarity loss: 1.765098\n",
      "[ 4200/ 5482] total-loss: 0.365486; classification loss: 0.014307;  cosine similarity loss: 1.770205\n",
      "[ 5600/ 5482] total-loss: 0.367139; classification loss: 0.016234;  cosine similarity loss: 1.770759\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.725     0.745    106\n",
      " disgust     0.716     0.748     0.840    106\n",
      "    fear     0.716     0.616     0.651    106\n",
      "   happy     0.716     0.625     0.566    106\n",
      " neutral     0.716     0.826     0.849    106\n",
      "     sad     0.716     0.682     0.708    106\n",
      "surprise     0.716     0.793     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.716     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 2.042985 \n",
      "\n",
      "classification loss: 2.118396;  cosine similarity loss: 1.867027 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.368256; classification loss: 0.015781;  cosine similarity loss: 1.778155\n",
      "[ 1400/ 5482] total-loss: 0.365994; classification loss: 0.014628;  cosine similarity loss: 1.771456\n",
      "[ 2800/ 5482] total-loss: 0.366071; classification loss: 0.015480;  cosine similarity loss: 1.768438\n",
      "[ 4200/ 5482] total-loss: 0.366198; classification loss: 0.013772;  cosine similarity loss: 1.775904\n",
      "[ 5600/ 5482] total-loss: 0.365037; classification loss: 0.014262;  cosine similarity loss: 1.768137\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.704     0.709     0.736    106\n",
      " disgust     0.704     0.720     0.802    106\n",
      "    fear     0.704     0.632     0.632    106\n",
      "   happy     0.704     0.595     0.623    106\n",
      " neutral     0.704     0.733     0.830    106\n",
      "     sad     0.704     0.761     0.660    106\n",
      "surprise     0.704     0.800     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.704     0.707     0.704    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 2.063516 \n",
      "\n",
      "classification loss: 2.149088;  cosine similarity loss: 1.863849 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365403; classification loss: 0.014910;  cosine similarity loss: 1.767376\n",
      "[ 1400/ 5482] total-loss: 0.405060; classification loss: 0.061162;  cosine similarity loss: 1.780650\n",
      "[ 2800/ 5482] total-loss: 0.367539; classification loss: 0.015784;  cosine similarity loss: 1.774562\n",
      "[ 4200/ 5482] total-loss: 0.365005; classification loss: 0.014235;  cosine similarity loss: 1.768085\n",
      "[ 5600/ 5482] total-loss: 0.540430; classification loss: 0.226864;  cosine similarity loss: 1.794693\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.695     0.774    106\n",
      " disgust     0.708     0.739     0.802    106\n",
      "    fear     0.708     0.635     0.575    106\n",
      "   happy     0.708     0.670     0.651    106\n",
      " neutral     0.708     0.770     0.821    106\n",
      "     sad     0.708     0.699     0.679    106\n",
      "surprise     0.708     0.734     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.706     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.004007 \n",
      "\n",
      "classification loss: 2.064402;  cosine similarity loss: 1.863086 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365099; classification loss: 0.014683;  cosine similarity loss: 1.766760\n",
      "[ 1400/ 5482] total-loss: 0.366422; classification loss: 0.016729;  cosine similarity loss: 1.765192\n",
      "[ 2800/ 5482] total-loss: 0.365982; classification loss: 0.015603;  cosine similarity loss: 1.767495\n",
      "[ 4200/ 5482] total-loss: 0.365847; classification loss: 0.014060;  cosine similarity loss: 1.772995\n",
      "[ 5600/ 5482] total-loss: 0.366262; classification loss: 0.015480;  cosine similarity loss: 1.769389\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.757     0.764    106\n",
      " disgust     0.712     0.731     0.821    106\n",
      "    fear     0.712     0.573     0.594    106\n",
      "   happy     0.712     0.633     0.651    106\n",
      " neutral     0.712     0.761     0.840    106\n",
      "     sad     0.712     0.717     0.670    106\n",
      "surprise     0.712     0.840     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.716     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.966943 \n",
      "\n",
      "classification loss: 2.009714;  cosine similarity loss: 1.867144 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364850; classification loss: 0.014480;  cosine similarity loss: 1.766333\n",
      "[ 1400/ 5482] total-loss: 0.364795; classification loss: 0.014483;  cosine similarity loss: 1.766040\n",
      "[ 2800/ 5482] total-loss: 0.365012; classification loss: 0.015039;  cosine similarity loss: 1.764906\n",
      "[ 4200/ 5482] total-loss: 0.365023; classification loss: 0.014293;  cosine similarity loss: 1.767944\n",
      "[ 5600/ 5482] total-loss: 0.365684; classification loss: 0.014048;  cosine similarity loss: 1.772230\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.689     0.774    106\n",
      " disgust     0.708     0.741     0.811    106\n",
      "    fear     0.708     0.568     0.594    106\n",
      "   happy     0.708     0.644     0.613    106\n",
      " neutral     0.708     0.789     0.811    106\n",
      "     sad     0.708     0.773     0.708    106\n",
      "surprise     0.708     0.764     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.710     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 1.949659 \n",
      "\n",
      "classification loss: 1.985796;  cosine similarity loss: 1.865340 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365155; classification loss: 0.014572;  cosine similarity loss: 1.767488\n",
      "[ 1400/ 5482] total-loss: 0.366281; classification loss: 0.016323;  cosine similarity loss: 1.766114\n",
      "[ 2800/ 5482] total-loss: 0.366017; classification loss: 0.015096;  cosine similarity loss: 1.769704\n",
      "[ 4200/ 5482] total-loss: 0.365039; classification loss: 0.014441;  cosine similarity loss: 1.767429\n",
      "[ 5600/ 5482] total-loss: 0.364610; classification loss: 0.014156;  cosine similarity loss: 1.766428\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.699     0.645     0.755    106\n",
      " disgust     0.699     0.766     0.802    106\n",
      "    fear     0.699     0.602     0.585    106\n",
      "   happy     0.699     0.558     0.632    106\n",
      " neutral     0.699     0.806     0.821    106\n",
      "     sad     0.699     0.787     0.660    106\n",
      "surprise     0.699     0.782     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.699     0.706     0.699    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.946400 \n",
      "\n",
      "classification loss: 1.980059;  cosine similarity loss: 1.867864 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.369695; classification loss: 0.016594;  cosine similarity loss: 1.782100\n",
      "[ 1400/ 5482] total-loss: 0.365826; classification loss: 0.015254;  cosine similarity loss: 1.768113\n",
      "[ 2800/ 5482] total-loss: 0.368526; classification loss: 0.016532;  cosine similarity loss: 1.776502\n",
      "[ 4200/ 5482] total-loss: 0.365934; classification loss: 0.015843;  cosine similarity loss: 1.766299\n",
      "[ 5600/ 5482] total-loss: 0.365048; classification loss: 0.014013;  cosine similarity loss: 1.769188\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.684     0.736    106\n",
      " disgust     0.705     0.698     0.830    106\n",
      "    fear     0.705     0.667     0.585    106\n",
      "   happy     0.705     0.613     0.642    106\n",
      " neutral     0.705     0.784     0.821    106\n",
      "     sad     0.705     0.699     0.679    106\n",
      "surprise     0.705     0.810     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.708     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.969441 \n",
      "\n",
      "classification loss: 2.012491;  cosine similarity loss: 1.868989 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364684; classification loss: 0.014149;  cosine similarity loss: 1.766824\n",
      "[ 1400/ 5482] total-loss: 0.364579; classification loss: 0.014153;  cosine similarity loss: 1.766285\n",
      "[ 2800/ 5482] total-loss: 0.364978; classification loss: 0.013422;  cosine similarity loss: 1.771203\n",
      "[ 4200/ 5482] total-loss: 0.366097; classification loss: 0.014209;  cosine similarity loss: 1.773648\n",
      "[ 5600/ 5482] total-loss: 0.364913; classification loss: 0.013617;  cosine similarity loss: 1.770098\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.669     0.783    106\n",
      " disgust     0.712     0.727     0.830    106\n",
      "    fear     0.712     0.613     0.642    106\n",
      "   happy     0.712     0.736     0.632    106\n",
      " neutral     0.712     0.777     0.821    106\n",
      "     sad     0.712     0.684     0.632    106\n",
      "surprise     0.712     0.800     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.715     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 2.011963 \n",
      "\n",
      "classification loss: 2.073573;  cosine similarity loss: 1.868207 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364654; classification loss: 0.014312;  cosine similarity loss: 1.766018\n",
      "[ 1400/ 5482] total-loss: 0.364996; classification loss: 0.013910;  cosine similarity loss: 1.769340\n",
      "[ 2800/ 5482] total-loss: 0.562132; classification loss: 0.255687;  cosine similarity loss: 1.787910\n",
      "[ 4200/ 5482] total-loss: 0.367390; classification loss: 0.015417;  cosine similarity loss: 1.775284\n",
      "[ 5600/ 5482] total-loss: 0.366502; classification loss: 0.015209;  cosine similarity loss: 1.771671\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.688     0.726    106\n",
      " disgust     0.706     0.728     0.783    106\n",
      "    fear     0.706     0.641     0.623    106\n",
      "   happy     0.706     0.627     0.651    106\n",
      " neutral     0.706     0.733     0.830    106\n",
      "     sad     0.706     0.724     0.670    106\n",
      "surprise     0.706     0.824     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.709     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.987239 \n",
      "\n",
      "classification loss: 2.038055;  cosine similarity loss: 1.868668 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364802; classification loss: 0.013903;  cosine similarity loss: 1.768400\n",
      "[ 1400/ 5482] total-loss: 0.364647; classification loss: 0.014277;  cosine similarity loss: 1.766124\n",
      "[ 2800/ 5482] total-loss: 0.365381; classification loss: 0.015044;  cosine similarity loss: 1.766730\n",
      "[ 4200/ 5482] total-loss: 0.364812; classification loss: 0.013374;  cosine similarity loss: 1.770565\n",
      "[ 5600/ 5482] total-loss: 0.392025; classification loss: 0.047728;  cosine similarity loss: 1.769214\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.718     0.698    106\n",
      " disgust     0.701     0.781     0.774    106\n",
      "    fear     0.701     0.584     0.623    106\n",
      "   happy     0.701     0.592     0.726    106\n",
      " neutral     0.701     0.708     0.802    106\n",
      "     sad     0.701     0.761     0.660    106\n",
      "surprise     0.701     0.835     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.711     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 2.073276 \n",
      "\n",
      "classification loss: 2.160515;  cosine similarity loss: 1.869721 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365447; classification loss: 0.014468;  cosine similarity loss: 1.769365\n",
      "[ 1400/ 5482] total-loss: 0.364355; classification loss: 0.013579;  cosine similarity loss: 1.767463\n",
      "[ 2800/ 5482] total-loss: 0.364576; classification loss: 0.014358;  cosine similarity loss: 1.765447\n",
      "[ 4200/ 5482] total-loss: 0.364467; classification loss: 0.013538;  cosine similarity loss: 1.768180\n",
      "[ 5600/ 5482] total-loss: 0.365559; classification loss: 0.014167;  cosine similarity loss: 1.771129\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.695     0.774    106\n",
      " disgust     0.718     0.794     0.802    106\n",
      "    fear     0.718     0.611     0.623    106\n",
      "   happy     0.718     0.660     0.623    106\n",
      " neutral     0.718     0.730     0.792    106\n",
      "     sad     0.718     0.740     0.726    106\n",
      "surprise     0.718     0.811     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.720     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 2.060055 \n",
      "\n",
      "classification loss: 2.143046;  cosine similarity loss: 1.866410 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364403; classification loss: 0.013751;  cosine similarity loss: 1.767015\n",
      "[ 1400/ 5482] total-loss: 0.364898; classification loss: 0.013693;  cosine similarity loss: 1.769719\n",
      "[ 2800/ 5482] total-loss: 0.364287; classification loss: 0.013292;  cosine similarity loss: 1.768270\n",
      "[ 4200/ 5482] total-loss: 0.364503; classification loss: 0.013662;  cosine similarity loss: 1.767868\n",
      "[ 5600/ 5482] total-loss: 0.371353; classification loss: 0.020659;  cosine similarity loss: 1.774129\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.680     0.783    106\n",
      " disgust     0.706     0.819     0.811    106\n",
      "    fear     0.706     0.610     0.604    106\n",
      "   happy     0.706     0.635     0.623    106\n",
      " neutral     0.706     0.726     0.802    106\n",
      "     sad     0.706     0.710     0.670    106\n",
      "surprise     0.706     0.775     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.708     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.071169 \n",
      "\n",
      "classification loss: 2.156143;  cosine similarity loss: 1.872896 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364414; classification loss: 0.013416;  cosine similarity loss: 1.768407\n",
      "[ 1400/ 5482] total-loss: 0.368149; classification loss: 0.017576;  cosine similarity loss: 1.770445\n",
      "[ 2800/ 5482] total-loss: 0.364703; classification loss: 0.013909;  cosine similarity loss: 1.767878\n",
      "[ 4200/ 5482] total-loss: 0.364262; classification loss: 0.013778;  cosine similarity loss: 1.766199\n",
      "[ 5600/ 5482] total-loss: 0.365225; classification loss: 0.014262;  cosine similarity loss: 1.769077\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.698     0.703     0.736    106\n",
      " disgust     0.698     0.727     0.830    106\n",
      "    fear     0.698     0.620     0.538    106\n",
      "   happy     0.698     0.647     0.623    106\n",
      " neutral     0.698     0.746     0.802    106\n",
      "     sad     0.698     0.679     0.698    106\n",
      "surprise     0.698     0.753     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.698     0.696     0.698    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 2.055030 \n",
      "\n",
      "classification loss: 2.134413;  cosine similarity loss: 1.869802 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.370233; classification loss: 0.020206;  cosine similarity loss: 1.770339\n",
      "[ 1400/ 5482] total-loss: 0.364898; classification loss: 0.014927;  cosine similarity loss: 1.764781\n",
      "[ 2800/ 5482] total-loss: 0.364712; classification loss: 0.013764;  cosine similarity loss: 1.768504\n",
      "[ 4200/ 5482] total-loss: 0.364805; classification loss: 0.014406;  cosine similarity loss: 1.766401\n",
      "[ 5600/ 5482] total-loss: 0.364271; classification loss: 0.013303;  cosine similarity loss: 1.768142\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.697     0.783    106\n",
      " disgust     0.702     0.731     0.821    106\n",
      "    fear     0.702     0.634     0.557    106\n",
      "   happy     0.702     0.617     0.623    106\n",
      " neutral     0.702     0.718     0.840    106\n",
      "     sad     0.702     0.729     0.660    106\n",
      "surprise     0.702     0.798     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.703     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 2.050401 \n",
      "\n",
      "classification loss: 2.129689;  cosine similarity loss: 1.865395 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364054; classification loss: 0.012989;  cosine similarity loss: 1.768313\n",
      "[ 1400/ 5482] total-loss: 0.365061; classification loss: 0.013958;  cosine similarity loss: 1.769475\n",
      "[ 2800/ 5482] total-loss: 0.364047; classification loss: 0.013590;  cosine similarity loss: 1.765873\n",
      "[ 4200/ 5482] total-loss: 0.365130; classification loss: 0.013867;  cosine similarity loss: 1.770183\n",
      "[ 5600/ 5482] total-loss: 0.364115; classification loss: 0.014077;  cosine similarity loss: 1.764265\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.651     0.774    106\n",
      " disgust     0.709     0.796     0.811    106\n",
      "    fear     0.709     0.594     0.594    106\n",
      "   happy     0.709     0.615     0.632    106\n",
      " neutral     0.709     0.780     0.802    106\n",
      "     sad     0.709     0.725     0.698    106\n",
      "surprise     0.709     0.841     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.715     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.943981 \n",
      "\n",
      "classification loss: 1.977778;  cosine similarity loss: 1.865121 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364169; classification loss: 0.013244;  cosine similarity loss: 1.767870\n",
      "[ 1400/ 5482] total-loss: 0.366083; classification loss: 0.013225;  cosine similarity loss: 1.777513\n",
      "[ 2800/ 5482] total-loss: 0.364433; classification loss: 0.013798;  cosine similarity loss: 1.766971\n",
      "[ 4200/ 5482] total-loss: 0.364571; classification loss: 0.013740;  cosine similarity loss: 1.767895\n",
      "[ 5600/ 5482] total-loss: 0.364546; classification loss: 0.014136;  cosine similarity loss: 1.766183\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.672     0.774    106\n",
      " disgust     0.706     0.669     0.821    106\n",
      "    fear     0.706     0.660     0.585    106\n",
      "   happy     0.706     0.670     0.594    106\n",
      " neutral     0.706     0.806     0.783    106\n",
      "     sad     0.706     0.706     0.726    106\n",
      "surprise     0.706     0.778     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.709     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.975253 \n",
      "\n",
      "classification loss: 2.024102;  cosine similarity loss: 1.861272 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364138; classification loss: 0.013952;  cosine similarity loss: 1.764882\n",
      "[ 1400/ 5482] total-loss: 0.363835; classification loss: 0.013861;  cosine similarity loss: 1.763730\n",
      "[ 2800/ 5482] total-loss: 0.433004; classification loss: 0.092721;  cosine similarity loss: 1.794137\n",
      "[ 4200/ 5482] total-loss: 0.364024; classification loss: 0.012625;  cosine similarity loss: 1.769622\n",
      "[ 5600/ 5482] total-loss: 0.371236; classification loss: 0.020335;  cosine similarity loss: 1.774840\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.684     0.736    106\n",
      " disgust     0.710     0.694     0.792    106\n",
      "    fear     0.710     0.646     0.689    106\n",
      "   happy     0.710     0.684     0.613    106\n",
      " neutral     0.710     0.798     0.783    106\n",
      "     sad     0.710     0.670     0.708    106\n",
      "surprise     0.710     0.831     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.715     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.952723 \n",
      "\n",
      "classification loss: 1.991222;  cosine similarity loss: 1.862891 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364516; classification loss: 0.013320;  cosine similarity loss: 1.769299\n",
      "[ 1400/ 5482] total-loss: 0.389998; classification loss: 0.042995;  cosine similarity loss: 1.778011\n",
      "[ 2800/ 5482] total-loss: 0.391046; classification loss: 0.045588;  cosine similarity loss: 1.772879\n",
      "[ 4200/ 5482] total-loss: 0.366608; classification loss: 0.015793;  cosine similarity loss: 1.769869\n",
      "[ 5600/ 5482] total-loss: 0.364083; classification loss: 0.013297;  cosine similarity loss: 1.767228\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.664     0.764    106\n",
      " disgust     0.706     0.700     0.792    106\n",
      "    fear     0.706     0.634     0.670    106\n",
      "   happy     0.706     0.673     0.623    106\n",
      " neutral     0.706     0.842     0.755    106\n",
      "     sad     0.706     0.701     0.708    106\n",
      "surprise     0.706     0.761     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.711     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.927747 \n",
      "\n",
      "classification loss: 1.953761;  cosine similarity loss: 1.867048 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.368061; classification loss: 0.018175;  cosine similarity loss: 1.767602\n",
      "[ 1400/ 5482] total-loss: 0.364085; classification loss: 0.012906;  cosine similarity loss: 1.768800\n",
      "[ 2800/ 5482] total-loss: 0.374411; classification loss: 0.023378;  cosine similarity loss: 1.778543\n",
      "[ 4200/ 5482] total-loss: 0.373932; classification loss: 0.021789;  cosine similarity loss: 1.782503\n",
      "[ 5600/ 5482] total-loss: 0.363994; classification loss: 0.013830;  cosine similarity loss: 1.764652\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.703     0.783    106\n",
      " disgust     0.716     0.750     0.821    106\n",
      "    fear     0.716     0.582     0.670    106\n",
      "   happy     0.716     0.663     0.594    106\n",
      " neutral     0.716     0.832     0.792    106\n",
      "     sad     0.716     0.750     0.708    106\n",
      "surprise     0.716     0.756     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.719     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.878532 \n",
      "\n",
      "classification loss: 1.883073;  cosine similarity loss: 1.867934 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364785; classification loss: 0.013087;  cosine similarity loss: 1.771579\n",
      "[ 1400/ 5482] total-loss: 0.364498; classification loss: 0.013701;  cosine similarity loss: 1.767684\n",
      "[ 2800/ 5482] total-loss: 0.365456; classification loss: 0.013733;  cosine similarity loss: 1.772351\n",
      "[ 4200/ 5482] total-loss: 0.364254; classification loss: 0.012518;  cosine similarity loss: 1.771194\n",
      "[ 5600/ 5482] total-loss: 0.363625; classification loss: 0.012886;  cosine similarity loss: 1.766580\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.725     0.745    106\n",
      " disgust     0.716     0.710     0.830    106\n",
      "    fear     0.716     0.635     0.623    106\n",
      "   happy     0.716     0.624     0.642    106\n",
      " neutral     0.716     0.817     0.840    106\n",
      "     sad     0.716     0.716     0.689    106\n",
      "surprise     0.716     0.800     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.718     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.898397 \n",
      "\n",
      "classification loss: 1.913517;  cosine similarity loss: 1.863119 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363524; classification loss: 0.013136;  cosine similarity loss: 1.765073\n",
      "[ 1400/ 5482] total-loss: 0.363962; classification loss: 0.013256;  cosine similarity loss: 1.766789\n",
      "[ 2800/ 5482] total-loss: 0.364030; classification loss: 0.013518;  cosine similarity loss: 1.766080\n",
      "[ 4200/ 5482] total-loss: 0.364649; classification loss: 0.013254;  cosine similarity loss: 1.770231\n",
      "[ 5600/ 5482] total-loss: 0.366149; classification loss: 0.014855;  cosine similarity loss: 1.771329\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.678     0.755    106\n",
      " disgust     0.716     0.759     0.802    106\n",
      "    fear     0.716     0.595     0.651    106\n",
      "   happy     0.716     0.651     0.670    106\n",
      " neutral     0.716     0.819     0.811    106\n",
      "     sad     0.716     0.727     0.679    106\n",
      "surprise     0.716     0.819     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.721     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.903087 \n",
      "\n",
      "classification loss: 1.917493;  cosine similarity loss: 1.869472 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363856; classification loss: 0.012822;  cosine similarity loss: 1.767993\n",
      "[ 1400/ 5482] total-loss: 0.363835; classification loss: 0.012495;  cosine similarity loss: 1.769197\n",
      "[ 2800/ 5482] total-loss: 0.363561; classification loss: 0.012589;  cosine similarity loss: 1.767446\n",
      "[ 4200/ 5482] total-loss: 0.364201; classification loss: 0.013002;  cosine similarity loss: 1.768997\n",
      "[ 5600/ 5482] total-loss: 0.367456; classification loss: 0.013746;  cosine similarity loss: 1.782297\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.643     0.764    106\n",
      " disgust     0.714     0.763     0.821    106\n",
      "    fear     0.714     0.633     0.585    106\n",
      "   happy     0.714     0.598     0.660    106\n",
      " neutral     0.714     0.808     0.792    106\n",
      "     sad     0.714     0.755     0.726    106\n",
      "surprise     0.714     0.852     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.722     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 1.942152 \n",
      "\n",
      "classification loss: 1.974524;  cosine similarity loss: 1.866618 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364736; classification loss: 0.013009;  cosine similarity loss: 1.771643\n",
      "[ 1400/ 5482] total-loss: 0.363636; classification loss: 0.013229;  cosine similarity loss: 1.765263\n",
      "[ 2800/ 5482] total-loss: 0.364089; classification loss: 0.013181;  cosine similarity loss: 1.767723\n",
      "[ 4200/ 5482] total-loss: 0.363571; classification loss: 0.013357;  cosine similarity loss: 1.764427\n",
      "[ 5600/ 5482] total-loss: 0.364671; classification loss: 0.012733;  cosine similarity loss: 1.772422\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.651     0.774    106\n",
      " disgust     0.705     0.724     0.792    106\n",
      "    fear     0.705     0.646     0.585    106\n",
      "   happy     0.705     0.639     0.651    106\n",
      " neutral     0.705     0.755     0.783    106\n",
      "     sad     0.705     0.743     0.708    106\n",
      "surprise     0.705     0.800     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.708     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.956870 \n",
      "\n",
      "classification loss: 1.995386;  cosine similarity loss: 1.866999 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364608; classification loss: 0.013362;  cosine similarity loss: 1.769589\n",
      "[ 1400/ 5482] total-loss: 0.363703; classification loss: 0.013297;  cosine similarity loss: 1.765326\n",
      "[ 2800/ 5482] total-loss: 0.364094; classification loss: 0.013247;  cosine similarity loss: 1.767484\n",
      "[ 4200/ 5482] total-loss: 0.363494; classification loss: 0.012552;  cosine similarity loss: 1.767266\n",
      "[ 5600/ 5482] total-loss: 0.364971; classification loss: 0.014125;  cosine similarity loss: 1.768358\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.726     0.690     0.755    106\n",
      " disgust     0.726     0.701     0.840    106\n",
      "    fear     0.726     0.681     0.585    106\n",
      "   happy     0.726     0.687     0.642    106\n",
      " neutral     0.726     0.859     0.802    106\n",
      "     sad     0.726     0.717     0.764    106\n",
      "surprise     0.726     0.763     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.726     0.728     0.726    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 1.861443 \n",
      "\n",
      "classification loss: 1.860819;  cosine similarity loss: 1.862898 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363589; classification loss: 0.012935;  cosine similarity loss: 1.766202\n",
      "[ 1400/ 5482] total-loss: 0.364624; classification loss: 0.012833;  cosine similarity loss: 1.771788\n",
      "[ 2800/ 5482] total-loss: 0.363737; classification loss: 0.013293;  cosine similarity loss: 1.765516\n",
      "[ 4200/ 5482] total-loss: 0.363810; classification loss: 0.013095;  cosine similarity loss: 1.766670\n",
      "[ 5600/ 5482] total-loss: 0.363378; classification loss: 0.012842;  cosine similarity loss: 1.765521\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.686     0.783    106\n",
      " disgust     0.722     0.723     0.811    106\n",
      "    fear     0.722     0.631     0.613    106\n",
      "   happy     0.722     0.620     0.632    106\n",
      " neutral     0.722     0.827     0.811    106\n",
      "     sad     0.722     0.802     0.726    106\n",
      "surprise     0.722     0.791     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.726     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.975954 \n",
      "\n",
      "classification loss: 2.024240;  cosine similarity loss: 1.863288 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363344; classification loss: 0.012985;  cosine similarity loss: 1.764777\n",
      "[ 1400/ 5482] total-loss: 0.363621; classification loss: 0.013044;  cosine similarity loss: 1.765926\n",
      "[ 2800/ 5482] total-loss: 0.365349; classification loss: 0.014710;  cosine similarity loss: 1.767905\n",
      "[ 4200/ 5482] total-loss: 0.363748; classification loss: 0.012626;  cosine similarity loss: 1.768235\n",
      "[ 5600/ 5482] total-loss: 0.363997; classification loss: 0.013070;  cosine similarity loss: 1.767705\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.684     0.736    106\n",
      " disgust     0.709     0.704     0.830    106\n",
      "    fear     0.709     0.590     0.585    106\n",
      "   happy     0.709     0.636     0.594    106\n",
      " neutral     0.709     0.789     0.811    106\n",
      "     sad     0.709     0.800     0.717    106\n",
      "surprise     0.709     0.768     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.710     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.986931 \n",
      "\n",
      "classification loss: 2.037777;  cosine similarity loss: 1.868288 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363110; classification loss: 0.012603;  cosine similarity loss: 1.765138\n",
      "[ 1400/ 5482] total-loss: 0.363318; classification loss: 0.012776;  cosine similarity loss: 1.765488\n",
      "[ 2800/ 5482] total-loss: 0.363306; classification loss: 0.012812;  cosine similarity loss: 1.765283\n",
      "[ 4200/ 5482] total-loss: 0.364525; classification loss: 0.012715;  cosine similarity loss: 1.771767\n",
      "[ 5600/ 5482] total-loss: 0.370687; classification loss: 0.020006;  cosine similarity loss: 1.773411\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.684     0.755    106\n",
      " disgust     0.712     0.699     0.811    106\n",
      "    fear     0.712     0.653     0.604    106\n",
      "   happy     0.712     0.610     0.604    106\n",
      " neutral     0.712     0.793     0.830    106\n",
      "     sad     0.712     0.793     0.689    106\n",
      "surprise     0.712     0.760     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.713     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 2.063460 \n",
      "\n",
      "classification loss: 2.148752;  cosine similarity loss: 1.864447 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363155; classification loss: 0.012427;  cosine similarity loss: 1.766068\n",
      "[ 1400/ 5482] total-loss: 0.363248; classification loss: 0.012150;  cosine similarity loss: 1.767641\n",
      "[ 2800/ 5482] total-loss: 0.363656; classification loss: 0.012773;  cosine similarity loss: 1.767188\n",
      "[ 4200/ 5482] total-loss: 0.363411; classification loss: 0.012599;  cosine similarity loss: 1.766661\n",
      "[ 5600/ 5482] total-loss: 0.363386; classification loss: 0.012487;  cosine similarity loss: 1.766983\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.677     0.792    106\n",
      " disgust     0.710     0.680     0.821    106\n",
      "    fear     0.710     0.699     0.613    106\n",
      "   happy     0.710     0.629     0.623    106\n",
      " neutral     0.710     0.766     0.774    106\n",
      "     sad     0.710     0.779     0.698    106\n",
      "surprise     0.710     0.767     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.714     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.064251 \n",
      "\n",
      "classification loss: 2.148935;  cosine similarity loss: 1.866656 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363661; classification loss: 0.012924;  cosine similarity loss: 1.766609\n",
      "[ 1400/ 5482] total-loss: 0.363892; classification loss: 0.013088;  cosine similarity loss: 1.767110\n",
      "[ 2800/ 5482] total-loss: 0.363767; classification loss: 0.013050;  cosine similarity loss: 1.766634\n",
      "[ 4200/ 5482] total-loss: 0.371528; classification loss: 0.022038;  cosine similarity loss: 1.769491\n",
      "[ 5600/ 5482] total-loss: 0.363539; classification loss: 0.012077;  cosine similarity loss: 1.769386\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.755     0.726    106\n",
      " disgust     0.713     0.729     0.811    106\n",
      "    fear     0.713     0.691     0.613    106\n",
      "   happy     0.713     0.631     0.660    106\n",
      " neutral     0.713     0.759     0.830    106\n",
      "     sad     0.713     0.702     0.689    106\n",
      "surprise     0.713     0.722     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.713     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 2.027848 \n",
      "\n",
      "classification loss: 2.095611;  cosine similarity loss: 1.869735 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363900; classification loss: 0.013072;  cosine similarity loss: 1.767213\n",
      "[ 1400/ 5482] total-loss: 0.364203; classification loss: 0.013516;  cosine similarity loss: 1.766951\n",
      "[ 2800/ 5482] total-loss: 0.364273; classification loss: 0.012148;  cosine similarity loss: 1.772776\n",
      "[ 4200/ 5482] total-loss: 0.362976; classification loss: 0.012276;  cosine similarity loss: 1.765777\n",
      "[ 5600/ 5482] total-loss: 0.364368; classification loss: 0.013460;  cosine similarity loss: 1.768003\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.752     0.717    106\n",
      " disgust     0.712     0.702     0.802    106\n",
      "    fear     0.712     0.625     0.708    106\n",
      "   happy     0.712     0.604     0.632    106\n",
      " neutral     0.712     0.774     0.840    106\n",
      "     sad     0.712     0.760     0.689    106\n",
      "surprise     0.712     0.808     0.594    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.718     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 2.007383 \n",
      "\n",
      "classification loss: 2.067680;  cosine similarity loss: 1.866688 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.366270; classification loss: 0.015761;  cosine similarity loss: 1.768307\n",
      "[ 1400/ 5482] total-loss: 0.364115; classification loss: 0.013374;  cosine similarity loss: 1.767078\n",
      "[ 2800/ 5482] total-loss: 0.365713; classification loss: 0.015702;  cosine similarity loss: 1.765759\n",
      "[ 4200/ 5482] total-loss: 0.362816; classification loss: 0.012374;  cosine similarity loss: 1.764585\n",
      "[ 5600/ 5482] total-loss: 0.363416; classification loss: 0.012688;  cosine similarity loss: 1.766326\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.681     0.816     0.585    106\n",
      " disgust     0.681     0.777     0.755    106\n",
      "    fear     0.681     0.510     0.698    106\n",
      "   happy     0.681     0.533     0.679    106\n",
      " neutral     0.681     0.750     0.821    106\n",
      "     sad     0.681     0.726     0.726    106\n",
      "surprise     0.681     0.869     0.500    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.681     0.712     0.681    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 2.101925 \n",
      "\n",
      "classification loss: 2.200741;  cosine similarity loss: 1.871354 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365144; classification loss: 0.013797;  cosine similarity loss: 1.770533\n",
      "[ 1400/ 5482] total-loss: 0.363248; classification loss: 0.012877;  cosine similarity loss: 1.764732\n",
      "[ 2800/ 5482] total-loss: 0.372025; classification loss: 0.022457;  cosine similarity loss: 1.770297\n",
      "[ 4200/ 5482] total-loss: 0.363569; classification loss: 0.013235;  cosine similarity loss: 1.764906\n",
      "[ 5600/ 5482] total-loss: 0.364827; classification loss: 0.012455;  cosine similarity loss: 1.774313\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.712     0.745    106\n",
      " disgust     0.702     0.674     0.821    106\n",
      "    fear     0.702     0.653     0.623    106\n",
      "   happy     0.702     0.634     0.604    106\n",
      " neutral     0.702     0.754     0.840    106\n",
      "     sad     0.702     0.795     0.660    106\n",
      "surprise     0.702     0.702     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.704     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 2.050221 \n",
      "\n",
      "classification loss: 2.128859;  cosine similarity loss: 1.866731 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363717; classification loss: 0.012948;  cosine similarity loss: 1.766792\n",
      "[ 1400/ 5482] total-loss: 0.363218; classification loss: 0.012088;  cosine similarity loss: 1.767738\n",
      "[ 2800/ 5482] total-loss: 0.362905; classification loss: 0.011835;  cosine similarity loss: 1.767183\n",
      "[ 4200/ 5482] total-loss: 0.362776; classification loss: 0.011949;  cosine similarity loss: 1.766085\n",
      "[ 5600/ 5482] total-loss: 0.466343; classification loss: 0.135270;  cosine similarity loss: 1.790633\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.729     0.736    106\n",
      " disgust     0.710     0.697     0.802    106\n",
      "    fear     0.710     0.657     0.632    106\n",
      "   happy     0.710     0.607     0.613    106\n",
      " neutral     0.710     0.754     0.840    106\n",
      "     sad     0.710     0.789     0.708    106\n",
      "surprise     0.710     0.747     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.712     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.030858 \n",
      "\n",
      "classification loss: 2.101168;  cosine similarity loss: 1.866801 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364359; classification loss: 0.012896;  cosine similarity loss: 1.770208\n",
      "[ 1400/ 5482] total-loss: 0.363025; classification loss: 0.012404;  cosine similarity loss: 1.765511\n",
      "[ 2800/ 5482] total-loss: 0.364700; classification loss: 0.014101;  cosine similarity loss: 1.767095\n",
      "[ 4200/ 5482] total-loss: 0.363776; classification loss: 0.012555;  cosine similarity loss: 1.768661\n",
      "[ 5600/ 5482] total-loss: 0.363067; classification loss: 0.012350;  cosine similarity loss: 1.765938\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.736     0.736    106\n",
      " disgust     0.705     0.688     0.811    106\n",
      "    fear     0.705     0.674     0.604    106\n",
      "   happy     0.705     0.609     0.632    106\n",
      " neutral     0.705     0.703     0.849    106\n",
      "     sad     0.705     0.778     0.660    106\n",
      "surprise     0.705     0.773     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.709     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.020004 \n",
      "\n",
      "classification loss: 2.085161;  cosine similarity loss: 1.867970 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363163; classification loss: 0.012125;  cosine similarity loss: 1.767315\n",
      "[ 1400/ 5482] total-loss: 0.362893; classification loss: 0.012244;  cosine similarity loss: 1.765489\n",
      "[ 2800/ 5482] total-loss: 0.363683; classification loss: 0.013291;  cosine similarity loss: 1.765249\n",
      "[ 4200/ 5482] total-loss: 0.365228; classification loss: 0.012811;  cosine similarity loss: 1.774897\n",
      "[ 5600/ 5482] total-loss: 0.362718; classification loss: 0.012062;  cosine similarity loss: 1.765338\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.716     0.783    106\n",
      " disgust     0.705     0.667     0.736    106\n",
      "    fear     0.705     0.636     0.642    106\n",
      "   happy     0.705     0.711     0.604    106\n",
      " neutral     0.705     0.763     0.849    106\n",
      "     sad     0.705     0.735     0.679    106\n",
      "surprise     0.705     0.708     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.705     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.084721 \n",
      "\n",
      "classification loss: 2.177676;  cosine similarity loss: 1.867825 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362561; classification loss: 0.011917;  cosine similarity loss: 1.765137\n",
      "[ 1400/ 5482] total-loss: 0.362769; classification loss: 0.012246;  cosine similarity loss: 1.764862\n",
      "[ 2800/ 5482] total-loss: 0.362835; classification loss: 0.012377;  cosine similarity loss: 1.764666\n",
      "[ 4200/ 5482] total-loss: 0.363568; classification loss: 0.012034;  cosine similarity loss: 1.769705\n",
      "[ 5600/ 5482] total-loss: 0.424232; classification loss: 0.086460;  cosine similarity loss: 1.775320\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.690     0.672     0.755    106\n",
      " disgust     0.690     0.694     0.811    106\n",
      "    fear     0.690     0.632     0.566    106\n",
      "   happy     0.690     0.624     0.594    106\n",
      " neutral     0.690     0.731     0.821    106\n",
      "     sad     0.690     0.755     0.670    106\n",
      "surprise     0.690     0.722     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.690     0.690     0.690    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.147160 \n",
      "\n",
      "classification loss: 2.266116;  cosine similarity loss: 1.869595 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362994; classification loss: 0.012140;  cosine similarity loss: 1.766410\n",
      "[ 1400/ 5482] total-loss: 0.363575; classification loss: 0.012012;  cosine similarity loss: 1.769828\n",
      "[ 2800/ 5482] total-loss: 0.363456; classification loss: 0.011334;  cosine similarity loss: 1.771946\n",
      "[ 4200/ 5482] total-loss: 0.363376; classification loss: 0.012934;  cosine similarity loss: 1.765144\n",
      "[ 5600/ 5482] total-loss: 0.362960; classification loss: 0.012524;  cosine similarity loss: 1.764706\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.685     0.717    106\n",
      " disgust     0.702     0.713     0.821    106\n",
      "    fear     0.702     0.635     0.623    106\n",
      "   happy     0.702     0.688     0.623    106\n",
      " neutral     0.702     0.733     0.830    106\n",
      "     sad     0.702     0.679     0.698    106\n",
      "surprise     0.702     0.800     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.705     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 2.038603 \n",
      "\n",
      "classification loss: 2.111578;  cosine similarity loss: 1.868327 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364789; classification loss: 0.012014;  cosine similarity loss: 1.775888\n",
      "[ 1400/ 5482] total-loss: 0.362547; classification loss: 0.011543;  cosine similarity loss: 1.766561\n",
      "[ 2800/ 5482] total-loss: 0.362865; classification loss: 0.011824;  cosine similarity loss: 1.767030\n",
      "[ 4200/ 5482] total-loss: 0.364278; classification loss: 0.012160;  cosine similarity loss: 1.772751\n",
      "[ 5600/ 5482] total-loss: 0.363797; classification loss: 0.012101;  cosine similarity loss: 1.770581\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.806     0.708    106\n",
      " disgust     0.710     0.816     0.792    106\n",
      "    fear     0.710     0.646     0.689    106\n",
      "   happy     0.710     0.589     0.623    106\n",
      " neutral     0.710     0.698     0.830    106\n",
      "     sad     0.710     0.692     0.679    106\n",
      "surprise     0.710     0.758     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.715     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.091234 \n",
      "\n",
      "classification loss: 2.186755;  cosine similarity loss: 1.868351 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363622; classification loss: 0.012979;  cosine similarity loss: 1.766192\n",
      "[ 1400/ 5482] total-loss: 0.362723; classification loss: 0.012236;  cosine similarity loss: 1.764674\n",
      "[ 2800/ 5482] total-loss: 0.362901; classification loss: 0.011882;  cosine similarity loss: 1.766976\n",
      "[ 4200/ 5482] total-loss: 0.364358; classification loss: 0.012522;  cosine similarity loss: 1.771700\n",
      "[ 5600/ 5482] total-loss: 0.364346; classification loss: 0.013895;  cosine similarity loss: 1.766150\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.695     0.698     0.764    106\n",
      " disgust     0.695     0.688     0.811    106\n",
      "    fear     0.695     0.610     0.575    106\n",
      "   happy     0.695     0.727     0.528    106\n",
      " neutral     0.695     0.741     0.811    106\n",
      "     sad     0.695     0.687     0.745    106\n",
      "surprise     0.695     0.720     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.695     0.696     0.695    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 2.054643 \n",
      "\n",
      "classification loss: 2.137549;  cosine similarity loss: 1.861195 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362667; classification loss: 0.011929;  cosine similarity loss: 1.765618\n",
      "[ 1400/ 5482] total-loss: 0.363216; classification loss: 0.012058;  cosine similarity loss: 1.767848\n",
      "[ 2800/ 5482] total-loss: 0.362661; classification loss: 0.011244;  cosine similarity loss: 1.768329\n",
      "[ 4200/ 5482] total-loss: 0.365729; classification loss: 0.013038;  cosine similarity loss: 1.776494\n",
      "[ 5600/ 5482] total-loss: 0.490041; classification loss: 0.167802;  cosine similarity loss: 1.778993\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.699     0.685     0.717    106\n",
      " disgust     0.699     0.696     0.821    106\n",
      "    fear     0.699     0.600     0.623    106\n",
      "   happy     0.699     0.680     0.623    106\n",
      " neutral     0.699     0.798     0.783    106\n",
      "     sad     0.699     0.747     0.670    106\n",
      "surprise     0.699     0.700     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.699     0.701     0.699    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.910750 \n",
      "\n",
      "classification loss: 1.931384;  cosine similarity loss: 1.862603 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.374179; classification loss: 0.024639;  cosine similarity loss: 1.772340\n",
      "[ 1400/ 5482] total-loss: 0.362452; classification loss: 0.011663;  cosine similarity loss: 1.765612\n",
      "[ 2800/ 5482] total-loss: 0.363412; classification loss: 0.011444;  cosine similarity loss: 1.771282\n",
      "[ 4200/ 5482] total-loss: 0.362586; classification loss: 0.011703;  cosine similarity loss: 1.766119\n",
      "[ 5600/ 5482] total-loss: 0.363669; classification loss: 0.012140;  cosine similarity loss: 1.769784\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.669     0.745    106\n",
      " disgust     0.710     0.718     0.792    106\n",
      "    fear     0.710     0.643     0.594    106\n",
      "   happy     0.710     0.729     0.585    106\n",
      " neutral     0.710     0.748     0.868    106\n",
      "     sad     0.710     0.762     0.726    106\n",
      "surprise     0.710     0.700     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.710     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.990504 \n",
      "\n",
      "classification loss: 2.044408;  cosine similarity loss: 1.864727 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362539; classification loss: 0.012017;  cosine similarity loss: 1.764624\n",
      "[ 1400/ 5482] total-loss: 0.362439; classification loss: 0.011982;  cosine similarity loss: 1.764267\n",
      "[ 2800/ 5482] total-loss: 0.369724; classification loss: 0.017877;  cosine similarity loss: 1.777109\n",
      "[ 4200/ 5482] total-loss: 0.362351; classification loss: 0.011434;  cosine similarity loss: 1.766019\n",
      "[ 5600/ 5482] total-loss: 0.362343; classification loss: 0.011915;  cosine similarity loss: 1.764056\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.695     0.623     0.717    106\n",
      " disgust     0.695     0.691     0.802    106\n",
      "    fear     0.695     0.663     0.557    106\n",
      "   happy     0.695     0.617     0.623    106\n",
      " neutral     0.695     0.717     0.858    106\n",
      "     sad     0.695     0.826     0.670    106\n",
      "surprise     0.695     0.773     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.695     0.701     0.695    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 2.088862 \n",
      "\n",
      "classification loss: 2.185445;  cosine similarity loss: 1.863502 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363178; classification loss: 0.011491;  cosine similarity loss: 1.769929\n",
      "[ 1400/ 5482] total-loss: 0.362237; classification loss: 0.011283;  cosine similarity loss: 1.766052\n",
      "[ 2800/ 5482] total-loss: 0.362382; classification loss: 0.011808;  cosine similarity loss: 1.764678\n",
      "[ 4200/ 5482] total-loss: 0.366427; classification loss: 0.015768;  cosine similarity loss: 1.769062\n",
      "[ 5600/ 5482] total-loss: 0.477387; classification loss: 0.148791;  cosine similarity loss: 1.791772\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.713     0.726    106\n",
      " disgust     0.706     0.754     0.811    106\n",
      "    fear     0.706     0.650     0.632    106\n",
      "   happy     0.706     0.593     0.632    106\n",
      " neutral     0.706     0.717     0.858    106\n",
      "     sad     0.706     0.726     0.651    106\n",
      "surprise     0.706     0.817     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.710     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.040225 \n",
      "\n",
      "classification loss: 2.115152;  cosine similarity loss: 1.865396 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.374427; classification loss: 0.025603;  cosine similarity loss: 1.769721\n",
      "[ 1400/ 5482] total-loss: 0.362625; classification loss: 0.012230;  cosine similarity loss: 1.764207\n",
      "[ 2800/ 5482] total-loss: 0.362876; classification loss: 0.012223;  cosine similarity loss: 1.765489\n",
      "[ 4200/ 5482] total-loss: 0.362458; classification loss: 0.012177;  cosine similarity loss: 1.763579\n",
      "[ 5600/ 5482] total-loss: 0.362700; classification loss: 0.011475;  cosine similarity loss: 1.767601\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.717     0.717    106\n",
      " disgust     0.717     0.746     0.830    106\n",
      "    fear     0.717     0.657     0.651    106\n",
      "   happy     0.717     0.632     0.632    106\n",
      " neutral     0.717     0.740     0.858    106\n",
      "     sad     0.717     0.778     0.660    106\n",
      "surprise     0.717     0.755     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.718     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 1.965632 \n",
      "\n",
      "classification loss: 2.008282;  cosine similarity loss: 1.866114 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362205; classification loss: 0.011248;  cosine similarity loss: 1.766032\n",
      "[ 1400/ 5482] total-loss: 0.362148; classification loss: 0.011388;  cosine similarity loss: 1.765187\n",
      "[ 2800/ 5482] total-loss: 0.362789; classification loss: 0.011573;  cosine similarity loss: 1.767653\n",
      "[ 4200/ 5482] total-loss: 0.362846; classification loss: 0.011857;  cosine similarity loss: 1.766803\n",
      "[ 5600/ 5482] total-loss: 0.363130; classification loss: 0.012126;  cosine similarity loss: 1.767143\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.714     0.708    106\n",
      " disgust     0.718     0.748     0.840    106\n",
      "    fear     0.718     0.648     0.660    106\n",
      "   happy     0.718     0.650     0.632    106\n",
      " neutral     0.718     0.817     0.840    106\n",
      "     sad     0.718     0.679     0.717    106\n",
      "surprise     0.718     0.779     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.719     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.973950 \n",
      "\n",
      "classification loss: 2.022366;  cosine similarity loss: 1.860977 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361995; classification loss: 0.011562;  cosine similarity loss: 1.763731\n",
      "[ 1400/ 5482] total-loss: 0.362732; classification loss: 0.012080;  cosine similarity loss: 1.765340\n",
      "[ 2800/ 5482] total-loss: 0.364842; classification loss: 0.013816;  cosine similarity loss: 1.768948\n",
      "[ 4200/ 5482] total-loss: 0.363152; classification loss: 0.011098;  cosine similarity loss: 1.771365\n",
      "[ 5600/ 5482] total-loss: 0.362413; classification loss: 0.011728;  cosine similarity loss: 1.765156\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.692     0.764    106\n",
      " disgust     0.722     0.694     0.792    106\n",
      "    fear     0.722     0.653     0.623    106\n",
      "   happy     0.722     0.701     0.642    106\n",
      " neutral     0.722     0.769     0.849    106\n",
      "     sad     0.722     0.768     0.689    106\n",
      "surprise     0.722     0.787     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.724     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.924547 \n",
      "\n",
      "classification loss: 1.950504;  cosine similarity loss: 1.863981 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362013; classification loss: 0.011212;  cosine similarity loss: 1.765217\n",
      "[ 1400/ 5482] total-loss: 0.362073; classification loss: 0.011394;  cosine similarity loss: 1.764791\n",
      "[ 2800/ 5482] total-loss: 0.363722; classification loss: 0.011480;  cosine similarity loss: 1.772690\n",
      "[ 4200/ 5482] total-loss: 0.361958; classification loss: 0.011219;  cosine similarity loss: 1.764915\n",
      "[ 5600/ 5482] total-loss: 0.362248; classification loss: 0.010783;  cosine similarity loss: 1.768108\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.730     0.730     0.764    106\n",
      " disgust     0.730     0.748     0.811    106\n",
      "    fear     0.730     0.667     0.660    106\n",
      "   happy     0.730     0.673     0.642    106\n",
      " neutral     0.730     0.748     0.868    106\n",
      "     sad     0.730     0.755     0.670    106\n",
      "surprise     0.730     0.796     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.730     0.731     0.730    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 1.987325 \n",
      "\n",
      "classification loss: 2.040526;  cosine similarity loss: 1.863190 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362213; classification loss: 0.011019;  cosine similarity loss: 1.766990\n",
      "[ 1400/ 5482] total-loss: 0.364039; classification loss: 0.012443;  cosine similarity loss: 1.770423\n",
      "[ 2800/ 5482] total-loss: 0.379216; classification loss: 0.030510;  cosine similarity loss: 1.774043\n",
      "[ 4200/ 5482] total-loss: 0.362739; classification loss: 0.011101;  cosine similarity loss: 1.769291\n",
      "[ 5600/ 5482] total-loss: 0.362327; classification loss: 0.011703;  cosine similarity loss: 1.764825\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.730     0.757     0.792    106\n",
      " disgust     0.730     0.727     0.830    106\n",
      "    fear     0.730     0.622     0.651    106\n",
      "   happy     0.730     0.722     0.613    106\n",
      " neutral     0.730     0.817     0.840    106\n",
      "     sad     0.730     0.747     0.698    106\n",
      "surprise     0.730     0.723     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.730     0.731     0.730    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 1.894313 \n",
      "\n",
      "classification loss: 1.910382;  cosine similarity loss: 1.856820 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361985; classification loss: 0.011583;  cosine similarity loss: 1.763595\n",
      "[ 1400/ 5482] total-loss: 0.366510; classification loss: 0.014625;  cosine similarity loss: 1.774048\n",
      "[ 2800/ 5482] total-loss: 0.362003; classification loss: 0.010978;  cosine similarity loss: 1.766105\n",
      "[ 4200/ 5482] total-loss: 0.363714; classification loss: 0.012505;  cosine similarity loss: 1.768550\n",
      "[ 5600/ 5482] total-loss: 0.361910; classification loss: 0.011160;  cosine similarity loss: 1.764909\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.745     0.717    106\n",
      " disgust     0.714     0.718     0.840    106\n",
      "    fear     0.714     0.555     0.670    106\n",
      "   happy     0.714     0.730     0.613    106\n",
      " neutral     0.714     0.800     0.792    106\n",
      "     sad     0.714     0.755     0.698    106\n",
      "surprise     0.714     0.740     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.720     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 1.943038 \n",
      "\n",
      "classification loss: 1.975457;  cosine similarity loss: 1.867392 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362330; classification loss: 0.011656;  cosine similarity loss: 1.765024\n",
      "[ 1400/ 5482] total-loss: 0.362088; classification loss: 0.011592;  cosine similarity loss: 1.764073\n",
      "[ 2800/ 5482] total-loss: 0.362484; classification loss: 0.011162;  cosine similarity loss: 1.767773\n",
      "[ 4200/ 5482] total-loss: 0.363062; classification loss: 0.012303;  cosine similarity loss: 1.766096\n",
      "[ 5600/ 5482] total-loss: 0.361952; classification loss: 0.011731;  cosine similarity loss: 1.762836\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.713     0.726    106\n",
      " disgust     0.716     0.737     0.792    106\n",
      "    fear     0.716     0.661     0.679    106\n",
      "   happy     0.716     0.687     0.642    106\n",
      " neutral     0.716     0.763     0.849    106\n",
      "     sad     0.716     0.710     0.670    106\n",
      "surprise     0.716     0.734     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.715     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.963034 \n",
      "\n",
      "classification loss: 2.004706;  cosine similarity loss: 1.865798 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363527; classification loss: 0.011891;  cosine similarity loss: 1.770067\n",
      "[ 1400/ 5482] total-loss: 0.361810; classification loss: 0.011423;  cosine similarity loss: 1.763355\n",
      "[ 2800/ 5482] total-loss: 0.363594; classification loss: 0.011732;  cosine similarity loss: 1.771043\n",
      "[ 4200/ 5482] total-loss: 0.362444; classification loss: 0.011497;  cosine similarity loss: 1.766232\n",
      "[ 5600/ 5482] total-loss: 0.361906; classification loss: 0.011007;  cosine similarity loss: 1.765499\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.699     0.745    106\n",
      " disgust     0.718     0.705     0.811    106\n",
      "    fear     0.718     0.643     0.679    106\n",
      "   happy     0.718     0.703     0.604    106\n",
      " neutral     0.718     0.837     0.821    106\n",
      "     sad     0.718     0.713     0.679    106\n",
      "surprise     0.718     0.737     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.720     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.958042 \n",
      "\n",
      "classification loss: 2.001235;  cosine similarity loss: 1.857259 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361807; classification loss: 0.011264;  cosine similarity loss: 1.763981\n",
      "[ 1400/ 5482] total-loss: 0.362074; classification loss: 0.011488;  cosine similarity loss: 1.764418\n",
      "[ 2800/ 5482] total-loss: 0.362381; classification loss: 0.011914;  cosine similarity loss: 1.764250\n",
      "[ 4200/ 5482] total-loss: 0.362316; classification loss: 0.011202;  cosine similarity loss: 1.766770\n",
      "[ 5600/ 5482] total-loss: 0.362843; classification loss: 0.011331;  cosine similarity loss: 1.768894\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.710     0.717    106\n",
      " disgust     0.722     0.717     0.811    106\n",
      "    fear     0.722     0.713     0.679    106\n",
      "   happy     0.722     0.660     0.623    106\n",
      " neutral     0.722     0.715     0.877    106\n",
      "     sad     0.722     0.831     0.698    106\n",
      "surprise     0.722     0.726     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.725     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 2.102849 \n",
      "\n",
      "classification loss: 2.204858;  cosine similarity loss: 1.864829 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363006; classification loss: 0.010743;  cosine similarity loss: 1.772060\n",
      "[ 1400/ 5482] total-loss: 0.362363; classification loss: 0.011506;  cosine similarity loss: 1.765794\n",
      "[ 2800/ 5482] total-loss: 0.362055; classification loss: 0.010704;  cosine similarity loss: 1.767458\n",
      "[ 4200/ 5482] total-loss: 0.362451; classification loss: 0.011984;  cosine similarity loss: 1.764320\n",
      "[ 5600/ 5482] total-loss: 0.361870; classification loss: 0.011370;  cosine similarity loss: 1.763870\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.718     0.716     0.783    106\n",
      " disgust     0.718     0.683     0.792    106\n",
      "    fear     0.718     0.681     0.604    106\n",
      "   happy     0.718     0.649     0.594    106\n",
      " neutral     0.718     0.807     0.868    106\n",
      "     sad     0.718     0.745     0.717    106\n",
      "surprise     0.718     0.740     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.718     0.717     0.718    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 2.019762 \n",
      "\n",
      "classification loss: 2.085517;  cosine similarity loss: 1.866334 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361995; classification loss: 0.011207;  cosine similarity loss: 1.765146\n",
      "[ 1400/ 5482] total-loss: 0.363679; classification loss: 0.010998;  cosine similarity loss: 1.774400\n",
      "[ 2800/ 5482] total-loss: 0.361817; classification loss: 0.011429;  cosine similarity loss: 1.763372\n",
      "[ 4200/ 5482] total-loss: 0.362403; classification loss: 0.010909;  cosine similarity loss: 1.768379\n",
      "[ 5600/ 5482] total-loss: 0.362037; classification loss: 0.011111;  cosine similarity loss: 1.765745\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.694     0.726    106\n",
      " disgust     0.721     0.743     0.792    106\n",
      "    fear     0.721     0.664     0.689    106\n",
      "   happy     0.721     0.677     0.632    106\n",
      " neutral     0.721     0.746     0.830    106\n",
      "     sad     0.721     0.794     0.726    106\n",
      "surprise     0.721     0.734     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.722     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 2.008033 \n",
      "\n",
      "classification loss: 2.070868;  cosine similarity loss: 1.861416 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362209; classification loss: 0.010999;  cosine similarity loss: 1.767047\n",
      "[ 1400/ 5482] total-loss: 0.363822; classification loss: 0.012444;  cosine similarity loss: 1.769333\n",
      "[ 2800/ 5482] total-loss: 0.362000; classification loss: 0.011509;  cosine similarity loss: 1.763968\n",
      "[ 4200/ 5482] total-loss: 0.361735; classification loss: 0.011266;  cosine similarity loss: 1.763613\n",
      "[ 5600/ 5482] total-loss: 0.361991; classification loss: 0.011312;  cosine similarity loss: 1.764708\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.685     0.698    106\n",
      " disgust     0.721     0.740     0.858    106\n",
      "    fear     0.721     0.689     0.670    106\n",
      "   happy     0.721     0.660     0.660    106\n",
      " neutral     0.721     0.804     0.849    106\n",
      "     sad     0.721     0.732     0.670    106\n",
      "surprise     0.721     0.731     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.720     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 2.075287 \n",
      "\n",
      "classification loss: 2.163170;  cosine similarity loss: 1.870225 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.365597; classification loss: 0.014331;  cosine similarity loss: 1.770657\n",
      "[ 1400/ 5482] total-loss: 0.362188; classification loss: 0.011526;  cosine similarity loss: 1.764834\n",
      "[ 2800/ 5482] total-loss: 0.362438; classification loss: 0.011737;  cosine similarity loss: 1.765242\n",
      "[ 4200/ 5482] total-loss: 0.370080; classification loss: 0.018774;  cosine similarity loss: 1.775301\n",
      "[ 5600/ 5482] total-loss: 0.362068; classification loss: 0.010669;  cosine similarity loss: 1.767663\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.652     0.689    106\n",
      " disgust     0.705     0.667     0.849    106\n",
      "    fear     0.705     0.708     0.594    106\n",
      "   happy     0.705     0.602     0.613    106\n",
      " neutral     0.705     0.786     0.830    106\n",
      "     sad     0.705     0.776     0.717    106\n",
      "surprise     0.705     0.773     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.709     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.105912 \n",
      "\n",
      "classification loss: 2.207262;  cosine similarity loss: 1.869430 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.364701; classification loss: 0.013521;  cosine similarity loss: 1.769417\n",
      "[ 1400/ 5482] total-loss: 0.362188; classification loss: 0.011105;  cosine similarity loss: 1.766522\n",
      "[ 2800/ 5482] total-loss: 0.383734; classification loss: 0.037889;  cosine similarity loss: 1.767112\n",
      "[ 4200/ 5482] total-loss: 0.361672; classification loss: 0.011077;  cosine similarity loss: 1.764053\n",
      "[ 5600/ 5482] total-loss: 0.362800; classification loss: 0.012204;  cosine similarity loss: 1.765188\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.681     0.726    106\n",
      " disgust     0.720     0.712     0.840    106\n",
      "    fear     0.720     0.707     0.660    106\n",
      "   happy     0.720     0.708     0.594    106\n",
      " neutral     0.720     0.788     0.840    106\n",
      "     sad     0.720     0.740     0.726    106\n",
      "surprise     0.720     0.697     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.719     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 2.062129 \n",
      "\n",
      "classification loss: 2.146225;  cosine similarity loss: 1.865905 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361992; classification loss: 0.010781;  cosine similarity loss: 1.766834\n",
      "[ 1400/ 5482] total-loss: 0.361947; classification loss: 0.010586;  cosine similarity loss: 1.767388\n",
      "[ 2800/ 5482] total-loss: 0.361488; classification loss: 0.010657;  cosine similarity loss: 1.764811\n",
      "[ 4200/ 5482] total-loss: 0.361729; classification loss: 0.011093;  cosine similarity loss: 1.764272\n",
      "[ 5600/ 5482] total-loss: 0.361741; classification loss: 0.011050;  cosine similarity loss: 1.764505\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.681     0.726    106\n",
      " disgust     0.717     0.723     0.764    106\n",
      "    fear     0.717     0.649     0.679    106\n",
      "   happy     0.717     0.703     0.604    106\n",
      " neutral     0.717     0.756     0.877    106\n",
      "     sad     0.717     0.800     0.717    106\n",
      "surprise     0.717     0.711     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.718     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.123823 \n",
      "\n",
      "classification loss: 2.232818;  cosine similarity loss: 1.869502 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362544; classification loss: 0.010372;  cosine similarity loss: 1.771235\n",
      "[ 1400/ 5482] total-loss: 0.361571; classification loss: 0.011089;  cosine similarity loss: 1.763499\n",
      "[ 2800/ 5482] total-loss: 0.361445; classification loss: 0.010746;  cosine similarity loss: 1.764239\n",
      "[ 4200/ 5482] total-loss: 0.363296; classification loss: 0.011627;  cosine similarity loss: 1.769974\n",
      "[ 5600/ 5482] total-loss: 0.432079; classification loss: 0.092960;  cosine similarity loss: 1.788552\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.678     0.774    106\n",
      " disgust     0.717     0.702     0.821    106\n",
      "    fear     0.717     0.654     0.642    106\n",
      "   happy     0.717     0.660     0.604    106\n",
      " neutral     0.717     0.774     0.840    106\n",
      "     sad     0.717     0.802     0.689    106\n",
      "surprise     0.717     0.767     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.719     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.136220 \n",
      "\n",
      "classification loss: 2.252000;  cosine similarity loss: 1.866068 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363218; classification loss: 0.010619;  cosine similarity loss: 1.773612\n",
      "[ 1400/ 5482] total-loss: 0.361811; classification loss: 0.010983;  cosine similarity loss: 1.765123\n",
      "[ 2800/ 5482] total-loss: 0.361399; classification loss: 0.010592;  cosine similarity loss: 1.764627\n",
      "[ 4200/ 5482] total-loss: 0.362135; classification loss: 0.011304;  cosine similarity loss: 1.765458\n",
      "[ 5600/ 5482] total-loss: 0.362959; classification loss: 0.010714;  cosine similarity loss: 1.771942\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.707     0.774    106\n",
      " disgust     0.720     0.688     0.830    106\n",
      "    fear     0.720     0.673     0.642    106\n",
      "   happy     0.720     0.708     0.594    106\n",
      " neutral     0.720     0.821     0.821    106\n",
      "     sad     0.720     0.753     0.689    106\n",
      "surprise     0.720     0.695     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.721     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 2.086278 \n",
      "\n",
      "classification loss: 2.182098;  cosine similarity loss: 1.862698 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361766; classification loss: 0.010468;  cosine similarity loss: 1.766959\n",
      "[ 1400/ 5482] total-loss: 0.361801; classification loss: 0.011207;  cosine similarity loss: 1.764176\n",
      "[ 2800/ 5482] total-loss: 0.362237; classification loss: 0.009976;  cosine similarity loss: 1.771284\n",
      "[ 4200/ 5482] total-loss: 0.361597; classification loss: 0.011112;  cosine similarity loss: 1.763538\n",
      "[ 5600/ 5482] total-loss: 0.363973; classification loss: 0.011527;  cosine similarity loss: 1.773755\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.723     0.764    106\n",
      " disgust     0.714     0.706     0.792    106\n",
      "    fear     0.714     0.633     0.651    106\n",
      "   happy     0.714     0.714     0.613    106\n",
      " neutral     0.714     0.798     0.858    106\n",
      "     sad     0.714     0.753     0.660    106\n",
      "surprise     0.714     0.673     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.714     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 2.092935 \n",
      "\n",
      "classification loss: 2.192384;  cosine similarity loss: 1.860886 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361957; classification loss: 0.010242;  cosine similarity loss: 1.768818\n",
      "[ 1400/ 5482] total-loss: 0.361437; classification loss: 0.010861;  cosine similarity loss: 1.763743\n",
      "[ 2800/ 5482] total-loss: 0.362354; classification loss: 0.011128;  cosine similarity loss: 1.767258\n",
      "[ 4200/ 5482] total-loss: 0.379113; classification loss: 0.032366;  cosine similarity loss: 1.766098\n",
      "[ 5600/ 5482] total-loss: 0.361823; classification loss: 0.010437;  cosine similarity loss: 1.767368\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.690     0.755    106\n",
      " disgust     0.720     0.719     0.821    106\n",
      "    fear     0.720     0.663     0.632    106\n",
      "   happy     0.720     0.713     0.632    106\n",
      " neutral     0.720     0.763     0.849    106\n",
      "     sad     0.720     0.747     0.698    106\n",
      "surprise     0.720     0.742     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.720     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 2.085167 \n",
      "\n",
      "classification loss: 2.181347;  cosine similarity loss: 1.860748 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362096; classification loss: 0.010452;  cosine similarity loss: 1.768671\n",
      "[ 1400/ 5482] total-loss: 0.361438; classification loss: 0.010846;  cosine similarity loss: 1.763806\n",
      "[ 2800/ 5482] total-loss: 0.361311; classification loss: 0.010820;  cosine similarity loss: 1.763277\n",
      "[ 4200/ 5482] total-loss: 0.362699; classification loss: 0.011990;  cosine similarity loss: 1.765537\n",
      "[ 5600/ 5482] total-loss: 0.374421; classification loss: 0.023412;  cosine similarity loss: 1.778459\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.698     0.771     0.698    106\n",
      " disgust     0.698     0.714     0.802    106\n",
      "    fear     0.698     0.639     0.585    106\n",
      "   happy     0.698     0.622     0.651    106\n",
      " neutral     0.698     0.705     0.858    106\n",
      "     sad     0.698     0.676     0.670    106\n",
      "surprise     0.698     0.776     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.698     0.701     0.698    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 2.195900 \n",
      "\n",
      "classification loss: 2.335750;  cosine similarity loss: 1.869584 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362245; classification loss: 0.010790;  cosine similarity loss: 1.768067\n",
      "[ 1400/ 5482] total-loss: 0.366136; classification loss: 0.014493;  cosine similarity loss: 1.772711\n",
      "[ 2800/ 5482] total-loss: 0.361431; classification loss: 0.010179;  cosine similarity loss: 1.766441\n",
      "[ 4200/ 5482] total-loss: 0.361197; classification loss: 0.010682;  cosine similarity loss: 1.763257\n",
      "[ 5600/ 5482] total-loss: 0.361199; classification loss: 0.010332;  cosine similarity loss: 1.764664\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.721     0.755    106\n",
      " disgust     0.722     0.731     0.821    106\n",
      "    fear     0.722     0.651     0.670    106\n",
      "   happy     0.722     0.717     0.623    106\n",
      " neutral     0.722     0.746     0.858    106\n",
      "     sad     0.722     0.774     0.679    106\n",
      "surprise     0.722     0.719     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.723     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 2.131473 \n",
      "\n",
      "classification loss: 2.245734;  cosine similarity loss: 1.864864 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361322; classification loss: 0.010317;  cosine similarity loss: 1.765342\n",
      "[ 1400/ 5482] total-loss: 0.361106; classification loss: 0.010431;  cosine similarity loss: 1.763807\n",
      "[ 2800/ 5482] total-loss: 0.361723; classification loss: 0.010950;  cosine similarity loss: 1.764816\n",
      "[ 4200/ 5482] total-loss: 0.361516; classification loss: 0.010532;  cosine similarity loss: 1.765451\n",
      "[ 5600/ 5482] total-loss: 0.362389; classification loss: 0.011383;  cosine similarity loss: 1.766414\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.718     0.745    106\n",
      " disgust     0.705     0.696     0.821    106\n",
      "    fear     0.705     0.634     0.604    106\n",
      "   happy     0.705     0.705     0.585    106\n",
      " neutral     0.705     0.727     0.830    106\n",
      "     sad     0.705     0.718     0.698    106\n",
      "surprise     0.705     0.734     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.705     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.176934 \n",
      "\n",
      "classification loss: 2.311063;  cosine similarity loss: 1.863964 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361054; classification loss: 0.010219;  cosine similarity loss: 1.764394\n",
      "[ 1400/ 5482] total-loss: 0.361044; classification loss: 0.010299;  cosine similarity loss: 1.764023\n",
      "[ 2800/ 5482] total-loss: 0.361074; classification loss: 0.010346;  cosine similarity loss: 1.763986\n",
      "[ 4200/ 5482] total-loss: 0.719413; classification loss: 0.452145;  cosine similarity loss: 1.788487\n",
      "[ 5600/ 5482] total-loss: 0.361383; classification loss: 0.010623;  cosine similarity loss: 1.764425\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.714     0.708    106\n",
      " disgust     0.708     0.748     0.783    106\n",
      "    fear     0.708     0.660     0.660    106\n",
      "   happy     0.708     0.619     0.613    106\n",
      " neutral     0.708     0.766     0.802    106\n",
      "     sad     0.708     0.670     0.726    106\n",
      "surprise     0.708     0.787     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.709     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.054550 \n",
      "\n",
      "classification loss: 2.136292;  cosine similarity loss: 1.863820 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363706; classification loss: 0.012094;  cosine similarity loss: 1.770154\n",
      "[ 1400/ 5482] total-loss: 0.361156; classification loss: 0.010686;  cosine similarity loss: 1.763037\n",
      "[ 2800/ 5482] total-loss: 0.361576; classification loss: 0.009760;  cosine similarity loss: 1.768842\n",
      "[ 4200/ 5482] total-loss: 0.361572; classification loss: 0.010817;  cosine similarity loss: 1.764591\n",
      "[ 5600/ 5482] total-loss: 0.362538; classification loss: 0.010317;  cosine similarity loss: 1.771423\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.729     0.736    106\n",
      " disgust     0.709     0.722     0.783    106\n",
      "    fear     0.709     0.654     0.642    106\n",
      "   happy     0.709     0.637     0.613    106\n",
      " neutral     0.709     0.759     0.802    106\n",
      "     sad     0.709     0.752     0.717    106\n",
      "surprise     0.709     0.703     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.708     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.069757 \n",
      "\n",
      "classification loss: 2.158189;  cosine similarity loss: 1.863416 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363205; classification loss: 0.011467;  cosine similarity loss: 1.770160\n",
      "[ 1400/ 5482] total-loss: 0.361271; classification loss: 0.010526;  cosine similarity loss: 1.764252\n",
      "[ 2800/ 5482] total-loss: 0.361163; classification loss: 0.010347;  cosine similarity loss: 1.764425\n",
      "[ 4200/ 5482] total-loss: 0.361139; classification loss: 0.010538;  cosine similarity loss: 1.763544\n",
      "[ 5600/ 5482] total-loss: 0.361752; classification loss: 0.011317;  cosine similarity loss: 1.763491\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.725     0.745    106\n",
      " disgust     0.714     0.677     0.792    106\n",
      "    fear     0.714     0.704     0.651    106\n",
      "   happy     0.714     0.688     0.604    106\n",
      " neutral     0.714     0.750     0.792    106\n",
      "     sad     0.714     0.727     0.755    106\n",
      "surprise     0.714     0.729     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.714     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 2.059957 \n",
      "\n",
      "classification loss: 2.144277;  cosine similarity loss: 1.863212 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361537; classification loss: 0.010341;  cosine similarity loss: 1.766322\n",
      "[ 1400/ 5482] total-loss: 0.361124; classification loss: 0.010385;  cosine similarity loss: 1.764080\n",
      "[ 2800/ 5482] total-loss: 0.372721; classification loss: 0.023015;  cosine similarity loss: 1.771545\n",
      "[ 4200/ 5482] total-loss: 0.361409; classification loss: 0.010203;  cosine similarity loss: 1.766235\n",
      "[ 5600/ 5482] total-loss: 0.361388; classification loss: 0.010069;  cosine similarity loss: 1.766667\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.712     0.792    106\n",
      " disgust     0.714     0.729     0.811    106\n",
      "    fear     0.714     0.617     0.623    106\n",
      "   happy     0.714     0.663     0.613    106\n",
      " neutral     0.714     0.759     0.830    106\n",
      "     sad     0.714     0.742     0.679    106\n",
      "surprise     0.714     0.784     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.715     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 2.101694 \n",
      "\n",
      "classification loss: 2.202564;  cosine similarity loss: 1.866332 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361556; classification loss: 0.010722;  cosine similarity loss: 1.764889\n",
      "[ 1400/ 5482] total-loss: 0.361742; classification loss: 0.010573;  cosine similarity loss: 1.766415\n",
      "[ 2800/ 5482] total-loss: 0.362968; classification loss: 0.011530;  cosine similarity loss: 1.768717\n",
      "[ 4200/ 5482] total-loss: 0.363352; classification loss: 0.011853;  cosine similarity loss: 1.769349\n",
      "[ 5600/ 5482] total-loss: 0.361528; classification loss: 0.011131;  cosine similarity loss: 1.763114\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.755     0.783    106\n",
      " disgust     0.716     0.725     0.821    106\n",
      "    fear     0.716     0.570     0.613    106\n",
      "   happy     0.716     0.716     0.594    106\n",
      " neutral     0.716     0.748     0.840    106\n",
      "     sad     0.716     0.731     0.717    106\n",
      "surprise     0.716     0.782     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.718     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 2.045706 \n",
      "\n",
      "classification loss: 2.122484;  cosine similarity loss: 1.866556 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361175; classification loss: 0.010645;  cosine similarity loss: 1.763294\n",
      "[ 1400/ 5482] total-loss: 0.361815; classification loss: 0.011042;  cosine similarity loss: 1.764907\n",
      "[ 2800/ 5482] total-loss: 0.362440; classification loss: 0.010146;  cosine similarity loss: 1.771615\n",
      "[ 4200/ 5482] total-loss: 0.361048; classification loss: 0.010154;  cosine similarity loss: 1.764624\n",
      "[ 5600/ 5482] total-loss: 0.365800; classification loss: 0.013374;  cosine similarity loss: 1.775506\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.706     0.792    106\n",
      " disgust     0.722     0.729     0.811    106\n",
      "    fear     0.722     0.613     0.613    106\n",
      "   happy     0.722     0.694     0.642    106\n",
      " neutral     0.722     0.759     0.830    106\n",
      "     sad     0.722     0.755     0.726    106\n",
      "surprise     0.722     0.819     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.725     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 2.086871 \n",
      "\n",
      "classification loss: 2.180734;  cosine similarity loss: 1.867858 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362012; classification loss: 0.011137;  cosine similarity loss: 1.765514\n",
      "[ 1400/ 5482] total-loss: 0.361334; classification loss: 0.009923;  cosine similarity loss: 1.766977\n",
      "[ 2800/ 5482] total-loss: 0.361279; classification loss: 0.010189;  cosine similarity loss: 1.765637\n",
      "[ 4200/ 5482] total-loss: 0.361266; classification loss: 0.010179;  cosine similarity loss: 1.765616\n",
      "[ 5600/ 5482] total-loss: 0.360997; classification loss: 0.010484;  cosine similarity loss: 1.763045\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.695     0.774    106\n",
      " disgust     0.713     0.701     0.774    106\n",
      "    fear     0.713     0.591     0.613    106\n",
      "   happy     0.713     0.707     0.613    106\n",
      " neutral     0.713     0.783     0.849    106\n",
      "     sad     0.713     0.760     0.717    106\n",
      "surprise     0.713     0.767     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.715     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 2.080724 \n",
      "\n",
      "classification loss: 2.172382;  cosine similarity loss: 1.866855 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362252; classification loss: 0.011096;  cosine similarity loss: 1.766874\n",
      "[ 1400/ 5482] total-loss: 0.361599; classification loss: 0.010235;  cosine similarity loss: 1.767053\n",
      "[ 2800/ 5482] total-loss: 0.360896; classification loss: 0.009886;  cosine similarity loss: 1.764939\n",
      "[ 4200/ 5482] total-loss: 0.361539; classification loss: 0.010659;  cosine similarity loss: 1.765058\n",
      "[ 5600/ 5482] total-loss: 0.361929; classification loss: 0.010027;  cosine similarity loss: 1.769538\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.794     0.726    106\n",
      " disgust     0.705     0.678     0.774    106\n",
      "    fear     0.705     0.623     0.623    106\n",
      "   happy     0.705     0.685     0.594    106\n",
      " neutral     0.705     0.793     0.830    106\n",
      "     sad     0.705     0.632     0.745    106\n",
      "surprise     0.705     0.756     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.708     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.973191 \n",
      "\n",
      "classification loss: 2.020121;  cosine similarity loss: 1.863690 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360699; classification loss: 0.010024;  cosine similarity loss: 1.763400\n",
      "[ 1400/ 5482] total-loss: 0.361447; classification loss: 0.010784;  cosine similarity loss: 1.764101\n",
      "[ 2800/ 5482] total-loss: 0.361523; classification loss: 0.010255;  cosine similarity loss: 1.766596\n",
      "[ 4200/ 5482] total-loss: 0.363188; classification loss: 0.011842;  cosine similarity loss: 1.768573\n",
      "[ 5600/ 5482] total-loss: 0.362622; classification loss: 0.010120;  cosine similarity loss: 1.772629\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.720     0.703     0.783    106\n",
      " disgust     0.720     0.688     0.830    106\n",
      "    fear     0.720     0.688     0.604    106\n",
      "   happy     0.720     0.744     0.575    106\n",
      " neutral     0.720     0.796     0.811    106\n",
      "     sad     0.720     0.724     0.717    106\n",
      "surprise     0.720     0.704     0.717    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.720     0.721     0.720    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 2.037505 \n",
      "\n",
      "classification loss: 2.111910;  cosine similarity loss: 1.863892 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360938; classification loss: 0.010184;  cosine similarity loss: 1.763953\n",
      "[ 1400/ 5482] total-loss: 0.362601; classification loss: 0.010979;  cosine similarity loss: 1.769090\n",
      "[ 2800/ 5482] total-loss: 0.361603; classification loss: 0.009772;  cosine similarity loss: 1.768929\n",
      "[ 4200/ 5482] total-loss: 0.361634; classification loss: 0.010171;  cosine similarity loss: 1.767486\n",
      "[ 5600/ 5482] total-loss: 0.361360; classification loss: 0.010325;  cosine similarity loss: 1.765501\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.725     0.757     0.764    106\n",
      " disgust     0.725     0.731     0.821    106\n",
      "    fear     0.725     0.673     0.623    106\n",
      "   happy     0.725     0.667     0.604    106\n",
      " neutral     0.725     0.807     0.830    106\n",
      "     sad     0.725     0.693     0.745    106\n",
      "surprise     0.725     0.737     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.725     0.724     0.725    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 2.005530 \n",
      "\n",
      "classification loss: 2.064762;  cosine similarity loss: 1.867321 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361850; classification loss: 0.010023;  cosine similarity loss: 1.769157\n",
      "[ 1400/ 5482] total-loss: 0.365294; classification loss: 0.013593;  cosine similarity loss: 1.772098\n",
      "[ 2800/ 5482] total-loss: 0.365467; classification loss: 0.014136;  cosine similarity loss: 1.770793\n",
      "[ 4200/ 5482] total-loss: 0.360869; classification loss: 0.009611;  cosine similarity loss: 1.765901\n",
      "[ 5600/ 5482] total-loss: 0.372140; classification loss: 0.022035;  cosine similarity loss: 1.772560\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.730     0.750     0.792    106\n",
      " disgust     0.730     0.732     0.849    106\n",
      "    fear     0.730     0.611     0.623    106\n",
      "   happy     0.730     0.761     0.632    106\n",
      " neutral     0.730     0.763     0.849    106\n",
      "     sad     0.730     0.747     0.698    106\n",
      "surprise     0.730     0.755     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.730     0.731     0.730    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 1.971945 \n",
      "\n",
      "classification loss: 2.018785;  cosine similarity loss: 1.862651 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360806; classification loss: 0.009669;  cosine similarity loss: 1.765354\n",
      "[ 1400/ 5482] total-loss: 0.360865; classification loss: 0.009972;  cosine similarity loss: 1.764440\n",
      "[ 2800/ 5482] total-loss: 0.360880; classification loss: 0.009791;  cosine similarity loss: 1.765239\n",
      "[ 4200/ 5482] total-loss: 0.361075; classification loss: 0.009970;  cosine similarity loss: 1.765495\n",
      "[ 5600/ 5482] total-loss: 0.362619; classification loss: 0.010451;  cosine similarity loss: 1.771289\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.773     0.708    106\n",
      " disgust     0.721     0.690     0.840    106\n",
      "    fear     0.721     0.691     0.632    106\n",
      "   happy     0.721     0.595     0.651    106\n",
      " neutral     0.721     0.756     0.849    106\n",
      "     sad     0.721     0.780     0.736    106\n",
      "surprise     0.721     0.798     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.726     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 2.098392 \n",
      "\n",
      "classification loss: 2.198413;  cosine similarity loss: 1.865010 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360902; classification loss: 0.009961;  cosine similarity loss: 1.764668\n",
      "[ 1400/ 5482] total-loss: 0.360494; classification loss: 0.009745;  cosine similarity loss: 1.763489\n",
      "[ 2800/ 5482] total-loss: 0.360645; classification loss: 0.009708;  cosine similarity loss: 1.764393\n",
      "[ 4200/ 5482] total-loss: 0.360729; classification loss: 0.010075;  cosine similarity loss: 1.763341\n",
      "[ 5600/ 5482] total-loss: 0.360618; classification loss: 0.009814;  cosine similarity loss: 1.763830\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.699     0.694     0.726    106\n",
      " disgust     0.699     0.662     0.811    106\n",
      "    fear     0.699     0.630     0.642    106\n",
      "   happy     0.699     0.641     0.623    106\n",
      " neutral     0.699     0.808     0.792    106\n",
      "     sad     0.699     0.706     0.679    106\n",
      "surprise     0.699     0.786     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.699     0.704     0.699    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 2.009299 \n",
      "\n",
      "classification loss: 2.070154;  cosine similarity loss: 1.867303 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360637; classification loss: 0.009432;  cosine similarity loss: 1.765457\n",
      "[ 1400/ 5482] total-loss: 0.360723; classification loss: 0.009694;  cosine similarity loss: 1.764839\n",
      "[ 2800/ 5482] total-loss: 0.361122; classification loss: 0.010274;  cosine similarity loss: 1.764512\n",
      "[ 4200/ 5482] total-loss: 0.362466; classification loss: 0.010536;  cosine similarity loss: 1.770187\n",
      "[ 5600/ 5482] total-loss: 0.361986; classification loss: 0.010255;  cosine similarity loss: 1.768911\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.726     0.726    106\n",
      " disgust     0.716     0.690     0.821    106\n",
      "    fear     0.716     0.654     0.660    106\n",
      "   happy     0.716     0.623     0.623    106\n",
      " neutral     0.716     0.761     0.840    106\n",
      "     sad     0.716     0.725     0.698    106\n",
      "surprise     0.716     0.872     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.722     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 2.089776 \n",
      "\n",
      "classification loss: 2.186540;  cosine similarity loss: 1.863995 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363529; classification loss: 0.010072;  cosine similarity loss: 1.777356\n",
      "[ 1400/ 5482] total-loss: 0.361127; classification loss: 0.010266;  cosine similarity loss: 1.764571\n",
      "[ 2800/ 5482] total-loss: 0.360757; classification loss: 0.009960;  cosine similarity loss: 1.763945\n",
      "[ 4200/ 5482] total-loss: 0.361026; classification loss: 0.010152;  cosine similarity loss: 1.764522\n",
      "[ 5600/ 5482] total-loss: 0.361530; classification loss: 0.009951;  cosine similarity loss: 1.767848\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.651     0.774    106\n",
      " disgust     0.713     0.741     0.783    106\n",
      "    fear     0.713     0.634     0.604    106\n",
      "   happy     0.713     0.677     0.613    106\n",
      " neutral     0.713     0.795     0.840    106\n",
      "     sad     0.713     0.748     0.726    106\n",
      "surprise     0.713     0.750     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.714     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 2.016896 \n",
      "\n",
      "classification loss: 2.082357;  cosine similarity loss: 1.864153 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361007; classification loss: 0.010101;  cosine similarity loss: 1.764632\n",
      "[ 1400/ 5482] total-loss: 0.360925; classification loss: 0.010035;  cosine similarity loss: 1.764486\n",
      "[ 2800/ 5482] total-loss: 0.379379; classification loss: 0.032543;  cosine similarity loss: 1.766725\n",
      "[ 4200/ 5482] total-loss: 0.363020; classification loss: 0.010379;  cosine similarity loss: 1.773584\n",
      "[ 5600/ 5482] total-loss: 0.360727; classification loss: 0.009633;  cosine similarity loss: 1.765102\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.724     0.691     0.802    106\n",
      " disgust     0.724     0.720     0.802    106\n",
      "    fear     0.724     0.654     0.642    106\n",
      "   happy     0.724     0.750     0.623    106\n",
      " neutral     0.724     0.802     0.802    106\n",
      "     sad     0.724     0.776     0.717    106\n",
      "surprise     0.724     0.686     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.724     0.725     0.724    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 2.039952 \n",
      "\n",
      "classification loss: 2.116923;  cosine similarity loss: 1.860352 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360412; classification loss: 0.009545;  cosine similarity loss: 1.763877\n",
      "[ 1400/ 5482] total-loss: 0.360742; classification loss: 0.009676;  cosine similarity loss: 1.765007\n",
      "[ 2800/ 5482] total-loss: 0.367838; classification loss: 0.016919;  cosine similarity loss: 1.771512\n",
      "[ 4200/ 5482] total-loss: 0.362244; classification loss: 0.011748;  cosine similarity loss: 1.764228\n",
      "[ 5600/ 5482] total-loss: 0.361111; classification loss: 0.009707;  cosine similarity loss: 1.766726\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.703     0.736    106\n",
      " disgust     0.702     0.685     0.802    106\n",
      "    fear     0.702     0.626     0.585    106\n",
      "   happy     0.702     0.610     0.604    106\n",
      " neutral     0.702     0.830     0.830    106\n",
      "     sad     0.702     0.688     0.708    106\n",
      "surprise     0.702     0.784     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.704     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.994930 \n",
      "\n",
      "classification loss: 2.050959;  cosine similarity loss: 1.864195 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362266; classification loss: 0.009092;  cosine similarity loss: 1.774964\n",
      "[ 1400/ 5482] total-loss: 0.361516; classification loss: 0.009812;  cosine similarity loss: 1.768335\n",
      "[ 2800/ 5482] total-loss: 0.361471; classification loss: 0.010424;  cosine similarity loss: 1.765656\n",
      "[ 4200/ 5482] total-loss: 0.360357; classification loss: 0.009764;  cosine similarity loss: 1.762732\n",
      "[ 5600/ 5482] total-loss: 0.361335; classification loss: 0.010049;  cosine similarity loss: 1.766479\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.729     0.736    106\n",
      " disgust     0.709     0.654     0.802    106\n",
      "    fear     0.709     0.640     0.604    106\n",
      "   happy     0.709     0.584     0.623    106\n",
      " neutral     0.709     0.885     0.802    106\n",
      "     sad     0.709     0.729     0.736    106\n",
      "surprise     0.709     0.787     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.715     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.034821 \n",
      "\n",
      "classification loss: 2.108404;  cosine similarity loss: 1.863130 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361074; classification loss: 0.010174;  cosine similarity loss: 1.764675\n",
      "[ 1400/ 5482] total-loss: 0.361321; classification loss: 0.010141;  cosine similarity loss: 1.766040\n",
      "[ 2800/ 5482] total-loss: 0.360707; classification loss: 0.010099;  cosine similarity loss: 1.763138\n",
      "[ 4200/ 5482] total-loss: 0.360808; classification loss: 0.010255;  cosine similarity loss: 1.763019\n",
      "[ 5600/ 5482] total-loss: 0.364137; classification loss: 0.013589;  cosine similarity loss: 1.766326\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.687     0.745    106\n",
      " disgust     0.713     0.672     0.811    106\n",
      "    fear     0.713     0.653     0.604    106\n",
      "   happy     0.713     0.614     0.660    106\n",
      " neutral     0.713     0.859     0.802    106\n",
      "     sad     0.713     0.837     0.679    106\n",
      "surprise     0.713     0.716     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.720     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 2.035159 \n",
      "\n",
      "classification loss: 2.109367;  cosine similarity loss: 1.862006 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.379085; classification loss: 0.028665;  cosine similarity loss: 1.780767\n",
      "[ 1400/ 5482] total-loss: 0.362911; classification loss: 0.011863;  cosine similarity loss: 1.767104\n",
      "[ 2800/ 5482] total-loss: 0.360604; classification loss: 0.009980;  cosine similarity loss: 1.763098\n",
      "[ 4200/ 5482] total-loss: 0.514351; classification loss: 0.198355;  cosine similarity loss: 1.778333\n",
      "[ 5600/ 5482] total-loss: 0.369304; classification loss: 0.018856;  cosine similarity loss: 1.771096\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.695     0.687     0.745    106\n",
      " disgust     0.695     0.630     0.868    106\n",
      "    fear     0.695     0.656     0.557    106\n",
      "   happy     0.695     0.681     0.585    106\n",
      " neutral     0.695     0.842     0.802    106\n",
      "     sad     0.695     0.710     0.670    106\n",
      "surprise     0.695     0.687     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.695     0.699     0.695    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 2.087893 \n",
      "\n",
      "classification loss: 2.184470;  cosine similarity loss: 1.862548 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361016; classification loss: 0.010318;  cosine similarity loss: 1.763807\n",
      "[ 1400/ 5482] total-loss: 0.360680; classification loss: 0.009545;  cosine similarity loss: 1.765221\n",
      "[ 2800/ 5482] total-loss: 0.360559; classification loss: 0.009597;  cosine similarity loss: 1.764407\n",
      "[ 4200/ 5482] total-loss: 0.360491; classification loss: 0.009659;  cosine similarity loss: 1.763817\n",
      "[ 5600/ 5482] total-loss: 0.361334; classification loss: 0.009279;  cosine similarity loss: 1.769557\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.704     0.661     0.755    106\n",
      " disgust     0.704     0.652     0.830    106\n",
      "    fear     0.704     0.639     0.585    106\n",
      "   happy     0.704     0.674     0.585    106\n",
      " neutral     0.704     0.826     0.849    106\n",
      "     sad     0.704     0.710     0.670    106\n",
      "surprise     0.704     0.784     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.704     0.707     0.704    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 2.051764 \n",
      "\n",
      "classification loss: 2.133855;  cosine similarity loss: 1.860218 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360388; classification loss: 0.009550;  cosine similarity loss: 1.763736\n",
      "[ 1400/ 5482] total-loss: 0.360232; classification loss: 0.009347;  cosine similarity loss: 1.763774\n",
      "[ 2800/ 5482] total-loss: 0.360522; classification loss: 0.009553;  cosine similarity loss: 1.764398\n",
      "[ 4200/ 5482] total-loss: 0.360605; classification loss: 0.009645;  cosine similarity loss: 1.764443\n",
      "[ 5600/ 5482] total-loss: 0.362293; classification loss: 0.010899;  cosine similarity loss: 1.767870\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.661     0.755    106\n",
      " disgust     0.716     0.672     0.792    106\n",
      "    fear     0.716     0.593     0.632    106\n",
      "   happy     0.716     0.711     0.604    106\n",
      " neutral     0.716     0.832     0.840    106\n",
      "     sad     0.716     0.780     0.736    106\n",
      "surprise     0.716     0.802     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.722     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.973943 \n",
      "\n",
      "classification loss: 2.020741;  cosine similarity loss: 1.864747 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360994; classification loss: 0.009393;  cosine similarity loss: 1.767398\n",
      "[ 1400/ 5482] total-loss: 0.360382; classification loss: 0.009089;  cosine similarity loss: 1.765553\n",
      "[ 2800/ 5482] total-loss: 0.361410; classification loss: 0.010065;  cosine similarity loss: 1.766789\n",
      "[ 4200/ 5482] total-loss: 0.365109; classification loss: 0.013252;  cosine similarity loss: 1.772535\n",
      "[ 5600/ 5482] total-loss: 0.361025; classification loss: 0.010235;  cosine similarity loss: 1.764183\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.688     0.726    106\n",
      " disgust     0.710     0.649     0.821    106\n",
      "    fear     0.710     0.779     0.566    106\n",
      "   happy     0.710     0.646     0.604    106\n",
      " neutral     0.710     0.827     0.811    106\n",
      "     sad     0.710     0.675     0.726    106\n",
      "surprise     0.710     0.745     0.717    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.716     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.071582 \n",
      "\n",
      "classification loss: 2.160459;  cosine similarity loss: 1.864204 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360266; classification loss: 0.009660;  cosine similarity loss: 1.762690\n",
      "[ 1400/ 5482] total-loss: 0.362379; classification loss: 0.010853;  cosine similarity loss: 1.768485\n",
      "[ 2800/ 5482] total-loss: 0.360494; classification loss: 0.009385;  cosine similarity loss: 1.764928\n",
      "[ 4200/ 5482] total-loss: 0.363025; classification loss: 0.012558;  cosine similarity loss: 1.764892\n",
      "[ 5600/ 5482] total-loss: 0.361636; classification loss: 0.010991;  cosine similarity loss: 1.764215\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.745     0.717    106\n",
      " disgust     0.708     0.677     0.811    106\n",
      "    fear     0.708     0.623     0.623    106\n",
      "   happy     0.708     0.688     0.623    106\n",
      " neutral     0.708     0.827     0.811    106\n",
      "     sad     0.708     0.682     0.708    106\n",
      "surprise     0.708     0.722     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.709     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 1.974923 \n",
      "\n",
      "classification loss: 2.023357;  cosine similarity loss: 1.861911 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360235; classification loss: 0.009314;  cosine similarity loss: 1.763919\n",
      "[ 1400/ 5482] total-loss: 0.360376; classification loss: 0.009424;  cosine similarity loss: 1.764183\n",
      "[ 2800/ 5482] total-loss: 0.361428; classification loss: 0.009345;  cosine similarity loss: 1.769760\n",
      "[ 4200/ 5482] total-loss: 0.360699; classification loss: 0.008971;  cosine similarity loss: 1.767611\n",
      "[ 5600/ 5482] total-loss: 0.360338; classification loss: 0.009256;  cosine similarity loss: 1.764666\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.718     0.745    106\n",
      " disgust     0.714     0.714     0.802    106\n",
      "    fear     0.714     0.607     0.642    106\n",
      "   happy     0.714     0.695     0.623    106\n",
      " neutral     0.714     0.774     0.840    106\n",
      "     sad     0.714     0.774     0.679    106\n",
      "surprise     0.714     0.724     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.715     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 2.055443 \n",
      "\n",
      "classification loss: 2.137299;  cosine similarity loss: 1.864445 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360254; classification loss: 0.009194;  cosine similarity loss: 1.764493\n",
      "[ 1400/ 5482] total-loss: 0.360467; classification loss: 0.009493;  cosine similarity loss: 1.764362\n",
      "[ 2800/ 5482] total-loss: 0.360550; classification loss: 0.008870;  cosine similarity loss: 1.767272\n",
      "[ 4200/ 5482] total-loss: 0.361276; classification loss: 0.009436;  cosine similarity loss: 1.768636\n",
      "[ 5600/ 5482] total-loss: 0.360201; classification loss: 0.009395;  cosine similarity loss: 1.763426\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.701     0.664     0.726    106\n",
      " disgust     0.701     0.685     0.821    106\n",
      "    fear     0.701     0.699     0.613    106\n",
      "   happy     0.701     0.613     0.613    106\n",
      " neutral     0.701     0.824     0.792    106\n",
      "     sad     0.701     0.750     0.679    106\n",
      "surprise     0.701     0.686     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.701     0.703     0.701    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 2.154256 \n",
      "\n",
      "classification loss: 2.278779;  cosine similarity loss: 1.863702 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.362010; classification loss: 0.009560;  cosine similarity loss: 1.771810\n",
      "[ 1400/ 5482] total-loss: 0.360380; classification loss: 0.009053;  cosine similarity loss: 1.765689\n",
      "[ 2800/ 5482] total-loss: 0.361477; classification loss: 0.009265;  cosine similarity loss: 1.770329\n",
      "[ 4200/ 5482] total-loss: 0.360135; classification loss: 0.009190;  cosine similarity loss: 1.763915\n",
      "[ 5600/ 5482] total-loss: 0.360371; classification loss: 0.009320;  cosine similarity loss: 1.764575\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.712     0.736     0.736    106\n",
      " disgust     0.712     0.728     0.783    106\n",
      "    fear     0.712     0.631     0.660    106\n",
      "   happy     0.712     0.667     0.585    106\n",
      " neutral     0.712     0.840     0.840    106\n",
      "     sad     0.712     0.670     0.708    106\n",
      "surprise     0.712     0.710     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.712     0.711     0.712    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 2.060530 \n",
      "\n",
      "classification loss: 2.144386;  cosine similarity loss: 1.864866 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.367917; classification loss: 0.016033;  cosine similarity loss: 1.775453\n",
      "[ 1400/ 5482] total-loss: 0.360335; classification loss: 0.009009;  cosine similarity loss: 1.765641\n",
      "[ 2800/ 5482] total-loss: 0.361125; classification loss: 0.010177;  cosine similarity loss: 1.764920\n",
      "[ 4200/ 5482] total-loss: 0.360109; classification loss: 0.009179;  cosine similarity loss: 1.763831\n",
      "[ 5600/ 5482] total-loss: 0.361936; classification loss: 0.010885;  cosine similarity loss: 1.766143\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.702     0.713     0.726    106\n",
      " disgust     0.702     0.743     0.792    106\n",
      "    fear     0.702     0.596     0.613    106\n",
      "   happy     0.702     0.590     0.651    106\n",
      " neutral     0.702     0.827     0.811    106\n",
      "     sad     0.702     0.730     0.689    106\n",
      "surprise     0.702     0.736     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.702     0.705     0.702    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 2.139257 \n",
      "\n",
      "classification loss: 2.256423;  cosine similarity loss: 1.865869 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360378; classification loss: 0.009079;  cosine similarity loss: 1.765576\n",
      "[ 1400/ 5482] total-loss: 0.360591; classification loss: 0.009354;  cosine similarity loss: 1.765541\n",
      "[ 2800/ 5482] total-loss: 0.360523; classification loss: 0.009665;  cosine similarity loss: 1.763957\n",
      "[ 4200/ 5482] total-loss: 0.366178; classification loss: 0.015992;  cosine similarity loss: 1.766922\n",
      "[ 5600/ 5482] total-loss: 0.360300; classification loss: 0.009539;  cosine similarity loss: 1.763344\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.670     0.708    106\n",
      " disgust     0.705     0.706     0.792    106\n",
      "    fear     0.705     0.623     0.623    106\n",
      "   happy     0.705     0.674     0.585    106\n",
      " neutral     0.705     0.857     0.792    106\n",
      "     sad     0.705     0.706     0.726    106\n",
      "surprise     0.705     0.708     0.708    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.706     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.086912 \n",
      "\n",
      "classification loss: 2.181421;  cosine similarity loss: 1.866390 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.372742; classification loss: 0.023326;  cosine similarity loss: 1.770408\n",
      "[ 1400/ 5482] total-loss: 0.360352; classification loss: 0.009025;  cosine similarity loss: 1.765658\n",
      "[ 2800/ 5482] total-loss: 0.360284; classification loss: 0.009572;  cosine similarity loss: 1.763135\n",
      "[ 4200/ 5482] total-loss: 0.360100; classification loss: 0.009012;  cosine similarity loss: 1.764453\n",
      "[ 5600/ 5482] total-loss: 0.589588; classification loss: 0.291235;  cosine similarity loss: 1.783000\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.755     0.698    106\n",
      " disgust     0.708     0.728     0.783    106\n",
      "    fear     0.708     0.602     0.613    106\n",
      "   happy     0.708     0.653     0.623    106\n",
      " neutral     0.708     0.819     0.811    106\n",
      "     sad     0.708     0.655     0.717    106\n",
      "surprise     0.708     0.750     0.708    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.709     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.021886 \n",
      "\n",
      "classification loss: 2.090000;  cosine similarity loss: 1.862954 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360550; classification loss: 0.009629;  cosine similarity loss: 1.764230\n",
      "[ 1400/ 5482] total-loss: 0.359887; classification loss: 0.009017;  cosine similarity loss: 1.763365\n",
      "[ 2800/ 5482] total-loss: 0.360240; classification loss: 0.009340;  cosine similarity loss: 1.763839\n",
      "[ 4200/ 5482] total-loss: 0.363294; classification loss: 0.009629;  cosine similarity loss: 1.777952\n",
      "[ 5600/ 5482] total-loss: 0.360700; classification loss: 0.009783;  cosine similarity loss: 1.764367\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.704     0.636     0.774    106\n",
      " disgust     0.704     0.746     0.802    106\n",
      "    fear     0.704     0.656     0.575    106\n",
      "   happy     0.704     0.677     0.594    106\n",
      " neutral     0.704     0.811     0.811    106\n",
      "     sad     0.704     0.730     0.689    106\n",
      "surprise     0.704     0.673     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.704     0.704     0.704    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 2.077301 \n",
      "\n",
      "classification loss: 2.168851;  cosine similarity loss: 1.863684 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360811; classification loss: 0.009835;  cosine similarity loss: 1.764715\n",
      "[ 1400/ 5482] total-loss: 0.360243; classification loss: 0.009197;  cosine similarity loss: 1.764428\n",
      "[ 2800/ 5482] total-loss: 0.360658; classification loss: 0.009471;  cosine similarity loss: 1.765406\n",
      "[ 4200/ 5482] total-loss: 0.360267; classification loss: 0.008835;  cosine similarity loss: 1.765997\n",
      "[ 5600/ 5482] total-loss: 0.360006; classification loss: 0.008972;  cosine similarity loss: 1.764144\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.755     0.698    106\n",
      " disgust     0.710     0.730     0.764    106\n",
      "    fear     0.710     0.613     0.642    106\n",
      "   happy     0.710     0.637     0.679    106\n",
      " neutral     0.710     0.786     0.830    106\n",
      "     sad     0.710     0.696     0.670    106\n",
      "surprise     0.710     0.768     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.712     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.001717 \n",
      "\n",
      "classification loss: 2.060536;  cosine similarity loss: 1.864473 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360856; classification loss: 0.009650;  cosine similarity loss: 1.765679\n",
      "[ 1400/ 5482] total-loss: 0.361850; classification loss: 0.010028;  cosine similarity loss: 1.769139\n",
      "[ 2800/ 5482] total-loss: 0.360060; classification loss: 0.009033;  cosine similarity loss: 1.764167\n",
      "[ 4200/ 5482] total-loss: 0.360079; classification loss: 0.009053;  cosine similarity loss: 1.764185\n",
      "[ 5600/ 5482] total-loss: 0.361254; classification loss: 0.008872;  cosine similarity loss: 1.770780\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.704     0.672     0.736    106\n",
      " disgust     0.704     0.707     0.774    106\n",
      "    fear     0.704     0.673     0.660    106\n",
      "   happy     0.704     0.606     0.623    106\n",
      " neutral     0.704     0.757     0.821    106\n",
      "     sad     0.704     0.758     0.679    106\n",
      "surprise     0.704     0.770     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.704     0.706     0.704    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 2.053478 \n",
      "\n",
      "classification loss: 2.133742;  cosine similarity loss: 1.866196 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360595; classification loss: 0.009055;  cosine similarity loss: 1.766756\n",
      "[ 1400/ 5482] total-loss: 0.360279; classification loss: 0.009486;  cosine similarity loss: 1.763447\n",
      "[ 2800/ 5482] total-loss: 0.359911; classification loss: 0.008887;  cosine similarity loss: 1.764006\n",
      "[ 4200/ 5482] total-loss: 0.360300; classification loss: 0.009503;  cosine similarity loss: 1.763492\n",
      "[ 5600/ 5482] total-loss: 0.361726; classification loss: 0.010822;  cosine similarity loss: 1.765345\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.677     0.600     0.708    106\n",
      " disgust     0.677     0.656     0.811    106\n",
      "    fear     0.677     0.656     0.575    106\n",
      "   happy     0.677     0.565     0.613    106\n",
      " neutral     0.677     0.804     0.811    106\n",
      "     sad     0.677     0.707     0.660    106\n",
      "surprise     0.677     0.819     0.557    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.677     0.687     0.677    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 2.182804 \n",
      "\n",
      "classification loss: 2.319479;  cosine similarity loss: 1.863896 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359829; classification loss: 0.009037;  cosine similarity loss: 1.762995\n",
      "[ 1400/ 5482] total-loss: 0.360187; classification loss: 0.008610;  cosine similarity loss: 1.766492\n",
      "[ 2800/ 5482] total-loss: 0.362290; classification loss: 0.010038;  cosine similarity loss: 1.771297\n",
      "[ 4200/ 5482] total-loss: 0.359930; classification loss: 0.009059;  cosine similarity loss: 1.763416\n",
      "[ 5600/ 5482] total-loss: 0.381798; classification loss: 0.030770;  cosine similarity loss: 1.785911\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.685     0.717    106\n",
      " disgust     0.710     0.719     0.821    106\n",
      "    fear     0.710     0.683     0.651    106\n",
      "   happy     0.710     0.644     0.613    106\n",
      " neutral     0.710     0.761     0.840    106\n",
      "     sad     0.710     0.737     0.689    106\n",
      "surprise     0.710     0.739     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.710     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.143215 \n",
      "\n",
      "classification loss: 2.263302;  cosine similarity loss: 1.863012 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361576; classification loss: 0.009285;  cosine similarity loss: 1.770737\n",
      "[ 1400/ 5482] total-loss: 0.360227; classification loss: 0.009175;  cosine similarity loss: 1.764436\n",
      "[ 2800/ 5482] total-loss: 0.359936; classification loss: 0.009118;  cosine similarity loss: 1.763208\n",
      "[ 4200/ 5482] total-loss: 0.359807; classification loss: 0.008954;  cosine similarity loss: 1.763217\n",
      "[ 5600/ 5482] total-loss: 0.359905; classification loss: 0.009130;  cosine similarity loss: 1.763006\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.708     0.667     0.717    106\n",
      " disgust     0.708     0.755     0.755    106\n",
      "    fear     0.708     0.698     0.632    106\n",
      "   happy     0.708     0.624     0.642    106\n",
      " neutral     0.708     0.731     0.821    106\n",
      "     sad     0.708     0.723     0.689    106\n",
      "surprise     0.708     0.763     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.708     0.709     0.708    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.106209 \n",
      "\n",
      "classification loss: 2.209202;  cosine similarity loss: 1.865893 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.363028; classification loss: 0.012447;  cosine similarity loss: 1.765350\n",
      "[ 1400/ 5482] total-loss: 0.365819; classification loss: 0.012323;  cosine similarity loss: 1.779805\n",
      "[ 2800/ 5482] total-loss: 0.359935; classification loss: 0.008935;  cosine similarity loss: 1.763934\n",
      "[ 4200/ 5482] total-loss: 0.360781; classification loss: 0.009787;  cosine similarity loss: 1.764754\n",
      "[ 5600/ 5482] total-loss: 0.361171; classification loss: 0.009916;  cosine similarity loss: 1.766192\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.685     0.717    106\n",
      " disgust     0.713     0.732     0.774    106\n",
      "    fear     0.713     0.684     0.632    106\n",
      "   happy     0.713     0.639     0.651    106\n",
      " neutral     0.713     0.752     0.830    106\n",
      "     sad     0.713     0.745     0.689    106\n",
      "surprise     0.713     0.755     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.713     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 2.080376 \n",
      "\n",
      "classification loss: 2.171972;  cosine similarity loss: 1.866653 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360193; classification loss: 0.009336;  cosine similarity loss: 1.763623\n",
      "[ 1400/ 5482] total-loss: 0.359828; classification loss: 0.009143;  cosine similarity loss: 1.762566\n",
      "[ 2800/ 5482] total-loss: 0.359738; classification loss: 0.008778;  cosine similarity loss: 1.763579\n",
      "[ 4200/ 5482] total-loss: 0.359697; classification loss: 0.008746;  cosine similarity loss: 1.763501\n",
      "[ 5600/ 5482] total-loss: 0.360525; classification loss: 0.009561;  cosine similarity loss: 1.764378\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.714     0.691     0.717    106\n",
      " disgust     0.714     0.730     0.792    106\n",
      "    fear     0.714     0.698     0.632    106\n",
      "   happy     0.714     0.654     0.642    106\n",
      " neutral     0.714     0.739     0.830    106\n",
      "     sad     0.714     0.753     0.689    106\n",
      "surprise     0.714     0.733     0.698    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.714     0.714     0.714    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 2.090122 \n",
      "\n",
      "classification loss: 2.188689;  cosine similarity loss: 1.860134 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359678; classification loss: 0.008816;  cosine similarity loss: 1.763124\n",
      "[ 1400/ 5482] total-loss: 0.360135; classification loss: 0.008782;  cosine similarity loss: 1.765543\n",
      "[ 2800/ 5482] total-loss: 0.361323; classification loss: 0.010099;  cosine similarity loss: 1.766216\n",
      "[ 4200/ 5482] total-loss: 0.359765; classification loss: 0.008762;  cosine similarity loss: 1.763777\n",
      "[ 5600/ 5482] total-loss: 0.359738; classification loss: 0.008918;  cosine similarity loss: 1.763018\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.703     0.736    106\n",
      " disgust     0.709     0.706     0.792    106\n",
      "    fear     0.709     0.657     0.632    106\n",
      "   happy     0.709     0.629     0.623    106\n",
      " neutral     0.709     0.780     0.802    106\n",
      "     sad     0.709     0.716     0.689    106\n",
      "surprise     0.709     0.777     0.689    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.709     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.075046 \n",
      "\n",
      "classification loss: 2.167770;  cosine similarity loss: 1.858691 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360238; classification loss: 0.008618;  cosine similarity loss: 1.766718\n",
      "[ 1400/ 5482] total-loss: 0.359646; classification loss: 0.008784;  cosine similarity loss: 1.763096\n",
      "[ 2800/ 5482] total-loss: 0.359606; classification loss: 0.008525;  cosine similarity loss: 1.763934\n",
      "[ 4200/ 5482] total-loss: 0.462237; classification loss: 0.131618;  cosine similarity loss: 1.784713\n",
      "[ 5600/ 5482] total-loss: 0.359665; classification loss: 0.008509;  cosine similarity loss: 1.764293\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.681     0.726    106\n",
      " disgust     0.710     0.759     0.802    106\n",
      "    fear     0.710     0.660     0.623    106\n",
      "   happy     0.710     0.633     0.651    106\n",
      " neutral     0.710     0.761     0.811    106\n",
      "     sad     0.710     0.720     0.679    106\n",
      "surprise     0.710     0.758     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.710     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.081434 \n",
      "\n",
      "classification loss: 2.174309;  cosine similarity loss: 1.864724 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360824; classification loss: 0.009083;  cosine similarity loss: 1.767787\n",
      "[ 1400/ 5482] total-loss: 0.359814; classification loss: 0.008690;  cosine similarity loss: 1.764308\n",
      "[ 2800/ 5482] total-loss: 0.360193; classification loss: 0.009005;  cosine similarity loss: 1.764946\n",
      "[ 4200/ 5482] total-loss: 0.359936; classification loss: 0.008966;  cosine similarity loss: 1.763817\n",
      "[ 5600/ 5482] total-loss: 0.359969; classification loss: 0.008490;  cosine similarity loss: 1.765885\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.690     0.710     0.670    106\n",
      " disgust     0.690     0.691     0.802    106\n",
      "    fear     0.690     0.740     0.538    106\n",
      "   happy     0.690     0.506     0.736    106\n",
      " neutral     0.690     0.817     0.802    106\n",
      "     sad     0.690     0.684     0.736    106\n",
      "surprise     0.690     0.829     0.547    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.690     0.711     0.690    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.151120 \n",
      "\n",
      "classification loss: 2.271935;  cosine similarity loss: 1.869219 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360012; classification loss: 0.008375;  cosine similarity loss: 1.766557\n",
      "[ 1400/ 5482] total-loss: 0.360163; classification loss: 0.009074;  cosine similarity loss: 1.764517\n",
      "[ 2800/ 5482] total-loss: 0.359791; classification loss: 0.008596;  cosine similarity loss: 1.764568\n",
      "[ 4200/ 5482] total-loss: 0.359629; classification loss: 0.008805;  cosine similarity loss: 1.762924\n",
      "[ 5600/ 5482] total-loss: 0.359633; classification loss: 0.008782;  cosine similarity loss: 1.763037\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.741     0.755    106\n",
      " disgust     0.717     0.693     0.830    106\n",
      "    fear     0.717     0.677     0.632    106\n",
      "   happy     0.717     0.657     0.613    106\n",
      " neutral     0.717     0.774     0.840    106\n",
      "     sad     0.717     0.679     0.698    106\n",
      "surprise     0.717     0.812     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.719     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.013573 \n",
      "\n",
      "classification loss: 2.078509;  cosine similarity loss: 1.862055 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359592; classification loss: 0.008641;  cosine similarity loss: 1.763394\n",
      "[ 1400/ 5482] total-loss: 0.359864; classification loss: 0.008740;  cosine similarity loss: 1.764358\n",
      "[ 2800/ 5482] total-loss: 0.360020; classification loss: 0.009143;  cosine similarity loss: 1.763525\n",
      "[ 4200/ 5482] total-loss: 0.359506; classification loss: 0.008733;  cosine similarity loss: 1.762599\n",
      "[ 5600/ 5482] total-loss: 0.359722; classification loss: 0.008779;  cosine similarity loss: 1.763497\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.686     0.764    106\n",
      " disgust     0.709     0.744     0.821    106\n",
      "    fear     0.709     0.652     0.566    106\n",
      "   happy     0.709     0.657     0.632    106\n",
      " neutral     0.709     0.750     0.821    106\n",
      "     sad     0.709     0.688     0.708    106\n",
      "surprise     0.709     0.784     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.709     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.994179 \n",
      "\n",
      "classification loss: 2.050621;  cosine similarity loss: 1.862481 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359829; classification loss: 0.008847;  cosine similarity loss: 1.763755\n",
      "[ 1400/ 5482] total-loss: 0.359465; classification loss: 0.008640;  cosine similarity loss: 1.762764\n",
      "[ 2800/ 5482] total-loss: 0.359847; classification loss: 0.009034;  cosine similarity loss: 1.763101\n",
      "[ 4200/ 5482] total-loss: 0.472801; classification loss: 0.148418;  cosine similarity loss: 1.770334\n",
      "[ 5600/ 5482] total-loss: 0.359818; classification loss: 0.008906;  cosine similarity loss: 1.763467\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.786     0.764    106\n",
      " disgust     0.717     0.794     0.802    106\n",
      "    fear     0.717     0.593     0.632    106\n",
      "   happy     0.717     0.645     0.651    106\n",
      " neutral     0.717     0.718     0.840    106\n",
      "     sad     0.717     0.675     0.726    106\n",
      "surprise     0.717     0.865     0.604    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.725     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.027332 \n",
      "\n",
      "classification loss: 2.096627;  cosine similarity loss: 1.865644 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359699; classification loss: 0.008578;  cosine similarity loss: 1.764184\n",
      "[ 1400/ 5482] total-loss: 0.359506; classification loss: 0.008591;  cosine similarity loss: 1.763164\n",
      "[ 2800/ 5482] total-loss: 0.359517; classification loss: 0.008606;  cosine similarity loss: 1.763163\n",
      "[ 4200/ 5482] total-loss: 0.361707; classification loss: 0.010134;  cosine similarity loss: 1.767997\n",
      "[ 5600/ 5482] total-loss: 0.359823; classification loss: 0.008166;  cosine similarity loss: 1.766452\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.648     0.783    106\n",
      " disgust     0.705     0.796     0.774    106\n",
      "    fear     0.705     0.613     0.613    106\n",
      "   happy     0.705     0.667     0.642    106\n",
      " neutral     0.705     0.743     0.792    106\n",
      "     sad     0.705     0.689     0.670    106\n",
      "surprise     0.705     0.805     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.709     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.002268 \n",
      "\n",
      "classification loss: 2.062851;  cosine similarity loss: 1.860907 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359617; classification loss: 0.008387;  cosine similarity loss: 1.764536\n",
      "[ 1400/ 5482] total-loss: 0.359742; classification loss: 0.008604;  cosine similarity loss: 1.764293\n",
      "[ 2800/ 5482] total-loss: 0.360454; classification loss: 0.008300;  cosine similarity loss: 1.769069\n",
      "[ 4200/ 5482] total-loss: 0.360609; classification loss: 0.009338;  cosine similarity loss: 1.765694\n",
      "[ 5600/ 5482] total-loss: 0.360220; classification loss: 0.009031;  cosine similarity loss: 1.764975\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.678     0.755    106\n",
      " disgust     0.717     0.718     0.792    106\n",
      "    fear     0.717     0.667     0.679    106\n",
      "   happy     0.717     0.640     0.670    106\n",
      " neutral     0.717     0.804     0.774    106\n",
      "     sad     0.717     0.728     0.708    106\n",
      "surprise     0.717     0.819     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.722     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.037068 \n",
      "\n",
      "classification loss: 2.110723;  cosine similarity loss: 1.865208 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360173; classification loss: 0.008740;  cosine similarity loss: 1.765909\n",
      "[ 1400/ 5482] total-loss: 0.560953; classification loss: 0.255892;  cosine similarity loss: 1.781197\n",
      "[ 2800/ 5482] total-loss: 0.362122; classification loss: 0.011427;  cosine similarity loss: 1.764904\n",
      "[ 4200/ 5482] total-loss: 0.359424; classification loss: 0.008382;  cosine similarity loss: 1.763592\n",
      "[ 5600/ 5482] total-loss: 0.752083; classification loss: 0.490821;  cosine similarity loss: 1.797134\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.725     0.781     0.708    106\n",
      " disgust     0.725     0.711     0.811    106\n",
      "    fear     0.725     0.638     0.698    106\n",
      "   happy     0.725     0.702     0.623    106\n",
      " neutral     0.725     0.812     0.896    106\n",
      "     sad     0.725     0.655     0.679    106\n",
      "surprise     0.725     0.795     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.725     0.728     0.725    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.942859 \n",
      "\n",
      "classification loss: 1.976364;  cosine similarity loss: 1.864682 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359522; classification loss: 0.008674;  cosine similarity loss: 1.762911\n",
      "[ 1400/ 5482] total-loss: 0.359547; classification loss: 0.008438;  cosine similarity loss: 1.763982\n",
      "[ 2800/ 5482] total-loss: 0.360791; classification loss: 0.008875;  cosine similarity loss: 1.768457\n",
      "[ 4200/ 5482] total-loss: 0.359860; classification loss: 0.008968;  cosine similarity loss: 1.763425\n",
      "[ 5600/ 5482] total-loss: 0.514167; classification loss: 0.190851;  cosine similarity loss: 1.807432\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.719     0.774    106\n",
      " disgust     0.717     0.736     0.764    106\n",
      "    fear     0.717     0.704     0.651    106\n",
      "   happy     0.717     0.664     0.670    106\n",
      " neutral     0.717     0.796     0.811    106\n",
      "     sad     0.717     0.615     0.679    106\n",
      "surprise     0.717     0.807     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.720     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 1.916162 \n",
      "\n",
      "classification loss: 1.938167;  cosine similarity loss: 1.864817 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.361334; classification loss: 0.010319;  cosine similarity loss: 1.765392\n",
      "[ 1400/ 5482] total-loss: 0.359507; classification loss: 0.008450;  cosine similarity loss: 1.763737\n",
      "[ 2800/ 5482] total-loss: 0.359896; classification loss: 0.009100;  cosine similarity loss: 1.763081\n",
      "[ 4200/ 5482] total-loss: 0.361391; classification loss: 0.008744;  cosine similarity loss: 1.771978\n",
      "[ 5600/ 5482] total-loss: 0.360978; classification loss: 0.009247;  cosine similarity loss: 1.767903\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.669     0.802    106\n",
      " disgust     0.713     0.745     0.774    106\n",
      "    fear     0.713     0.660     0.623    106\n",
      "   happy     0.713     0.667     0.623    106\n",
      " neutral     0.713     0.782     0.811    106\n",
      "     sad     0.713     0.713     0.679    106\n",
      "surprise     0.713     0.758     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.713     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.983523 \n",
      "\n",
      "classification loss: 2.035268;  cosine similarity loss: 1.862785 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360341; classification loss: 0.008866;  cosine similarity loss: 1.766241\n",
      "[ 1400/ 5482] total-loss: 0.359482; classification loss: 0.008370;  cosine similarity loss: 1.763928\n",
      "[ 2800/ 5482] total-loss: 0.359297; classification loss: 0.008454;  cosine similarity loss: 1.762668\n",
      "[ 4200/ 5482] total-loss: 0.360497; classification loss: 0.009326;  cosine similarity loss: 1.765178\n",
      "[ 5600/ 5482] total-loss: 0.359803; classification loss: 0.008827;  cosine similarity loss: 1.763704\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.765     0.736    106\n",
      " disgust     0.721     0.685     0.802    106\n",
      "    fear     0.721     0.667     0.660    106\n",
      "   happy     0.721     0.699     0.613    106\n",
      " neutral     0.721     0.791     0.821    106\n",
      "     sad     0.721     0.785     0.689    106\n",
      "surprise     0.721     0.670     0.726    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.723     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 2.038913 \n",
      "\n",
      "classification loss: 2.115952;  cosine similarity loss: 1.859155 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359476; classification loss: 0.008546;  cosine similarity loss: 1.763195\n",
      "[ 1400/ 5482] total-loss: 0.359734; classification loss: 0.008751;  cosine similarity loss: 1.763663\n",
      "[ 2800/ 5482] total-loss: 0.359715; classification loss: 0.008855;  cosine similarity loss: 1.763155\n",
      "[ 4200/ 5482] total-loss: 0.370113; classification loss: 0.020070;  cosine similarity loss: 1.770288\n",
      "[ 5600/ 5482] total-loss: 0.359355; classification loss: 0.008308;  cosine similarity loss: 1.763545\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.714     0.755    106\n",
      " disgust     0.713     0.730     0.840    106\n",
      "    fear     0.713     0.623     0.623    106\n",
      "   happy     0.713     0.708     0.642    106\n",
      " neutral     0.713     0.820     0.774    106\n",
      "     sad     0.713     0.730     0.689    106\n",
      "surprise     0.713     0.670     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.714     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 1.941581 \n",
      "\n",
      "classification loss: 1.976061;  cosine similarity loss: 1.861127 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359738; classification loss: 0.008708;  cosine similarity loss: 1.763859\n",
      "[ 1400/ 5482] total-loss: 0.361229; classification loss: 0.008237;  cosine similarity loss: 1.773198\n",
      "[ 2800/ 5482] total-loss: 0.359400; classification loss: 0.008444;  cosine similarity loss: 1.763227\n",
      "[ 4200/ 5482] total-loss: 0.368508; classification loss: 0.018743;  cosine similarity loss: 1.767567\n",
      "[ 5600/ 5482] total-loss: 0.360416; classification loss: 0.008608;  cosine similarity loss: 1.767649\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.750     0.764    106\n",
      " disgust     0.722     0.697     0.802    106\n",
      "    fear     0.722     0.630     0.708    106\n",
      "   happy     0.722     0.698     0.632    106\n",
      " neutral     0.722     0.827     0.811    106\n",
      "     sad     0.722     0.696     0.670    106\n",
      "surprise     0.722     0.780     0.670    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.725     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 2.054374 \n",
      "\n",
      "classification loss: 2.132027;  cosine similarity loss: 1.873181 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.725906; classification loss: 0.458568;  cosine similarity loss: 1.795255\n",
      "[ 1400/ 5482] total-loss: 0.359330; classification loss: 0.008394;  cosine similarity loss: 1.763072\n",
      "[ 2800/ 5482] total-loss: 0.360187; classification loss: 0.008434;  cosine similarity loss: 1.767198\n",
      "[ 4200/ 5482] total-loss: 0.365695; classification loss: 0.013774;  cosine similarity loss: 1.773381\n",
      "[ 5600/ 5482] total-loss: 0.360015; classification loss: 0.008365;  cosine similarity loss: 1.766614\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.721     0.736     0.736    106\n",
      " disgust     0.721     0.724     0.792    106\n",
      "    fear     0.721     0.640     0.670    106\n",
      "   happy     0.721     0.685     0.594    106\n",
      " neutral     0.721     0.796     0.849    106\n",
      "     sad     0.721     0.661     0.755    106\n",
      "surprise     0.721     0.831     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.721     0.725     0.721    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 1.926021 \n",
      "\n",
      "classification loss: 1.952494;  cosine similarity loss: 1.864252 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360343; classification loss: 0.008994;  cosine similarity loss: 1.765736\n",
      "[ 1400/ 5482] total-loss: 0.362332; classification loss: 0.011082;  cosine similarity loss: 1.767334\n",
      "[ 2800/ 5482] total-loss: 0.359762; classification loss: 0.008075;  cosine similarity loss: 1.766508\n",
      "[ 4200/ 5482] total-loss: 0.359257; classification loss: 0.008429;  cosine similarity loss: 1.762572\n",
      "[ 5600/ 5482] total-loss: 0.359261; classification loss: 0.008360;  cosine similarity loss: 1.762862\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.802     0.689    106\n",
      " disgust     0.709     0.719     0.774    106\n",
      "    fear     0.709     0.640     0.689    106\n",
      "   happy     0.709     0.604     0.632    106\n",
      " neutral     0.709     0.729     0.887    106\n",
      "     sad     0.709     0.679     0.679    106\n",
      "surprise     0.709     0.844     0.613    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.717     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.151329 \n",
      "\n",
      "classification loss: 2.274404;  cosine similarity loss: 1.864154 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359980; classification loss: 0.008921;  cosine similarity loss: 1.764216\n",
      "[ 1400/ 5482] total-loss: 0.360071; classification loss: 0.008735;  cosine similarity loss: 1.765413\n",
      "[ 2800/ 5482] total-loss: 0.360192; classification loss: 0.008577;  cosine similarity loss: 1.766650\n",
      "[ 4200/ 5482] total-loss: 0.359292; classification loss: 0.008372;  cosine similarity loss: 1.762971\n",
      "[ 5600/ 5482] total-loss: 0.362201; classification loss: 0.010672;  cosine similarity loss: 1.768317\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.706     0.722     0.736    106\n",
      " disgust     0.706     0.764     0.764    106\n",
      "    fear     0.706     0.657     0.651    106\n",
      "   happy     0.706     0.621     0.604    106\n",
      " neutral     0.706     0.730     0.840    106\n",
      "     sad     0.706     0.730     0.689    106\n",
      "surprise     0.706     0.714     0.660    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.706     0.706     0.706    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.090912 \n",
      "\n",
      "classification loss: 2.185490;  cosine similarity loss: 1.870231 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360779; classification loss: 0.008981;  cosine similarity loss: 1.767968\n",
      "[ 1400/ 5482] total-loss: 0.360060; classification loss: 0.008440;  cosine similarity loss: 1.766539\n",
      "[ 2800/ 5482] total-loss: 0.360164; classification loss: 0.009028;  cosine similarity loss: 1.764706\n",
      "[ 4200/ 5482] total-loss: 0.359849; classification loss: 0.008514;  cosine similarity loss: 1.765190\n",
      "[ 5600/ 5482] total-loss: 0.359458; classification loss: 0.008245;  cosine similarity loss: 1.764313\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.705     0.738     0.745    106\n",
      " disgust     0.705     0.711     0.811    106\n",
      "    fear     0.705     0.571     0.679    106\n",
      "   happy     0.705     0.650     0.613    106\n",
      " neutral     0.705     0.741     0.811    106\n",
      "     sad     0.705     0.773     0.642    106\n",
      "surprise     0.705     0.798     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.705     0.712     0.705    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.082430 \n",
      "\n",
      "classification loss: 2.175749;  cosine similarity loss: 1.864686 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359892; classification loss: 0.008197;  cosine similarity loss: 1.766669\n",
      "[ 1400/ 5482] total-loss: 0.361077; classification loss: 0.009494;  cosine similarity loss: 1.767408\n",
      "[ 2800/ 5482] total-loss: 0.359896; classification loss: 0.008133;  cosine similarity loss: 1.766946\n",
      "[ 4200/ 5482] total-loss: 0.364884; classification loss: 0.013221;  cosine similarity loss: 1.771536\n",
      "[ 5600/ 5482] total-loss: 0.359271; classification loss: 0.008202;  cosine similarity loss: 1.763549\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.770     0.726    106\n",
      " disgust     0.717     0.730     0.792    106\n",
      "    fear     0.717     0.617     0.698    106\n",
      "   happy     0.717     0.613     0.642    106\n",
      " neutral     0.717     0.722     0.858    106\n",
      "     sad     0.717     0.774     0.679    106\n",
      "surprise     0.717     0.857     0.623    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.726     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.056825 \n",
      "\n",
      "classification loss: 2.138799;  cosine similarity loss: 1.865551 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359559; classification loss: 0.007821;  cosine similarity loss: 1.766509\n",
      "[ 1400/ 5482] total-loss: 0.359287; classification loss: 0.008303;  cosine similarity loss: 1.763223\n",
      "[ 2800/ 5482] total-loss: 0.359762; classification loss: 0.007846;  cosine similarity loss: 1.767429\n",
      "[ 4200/ 5482] total-loss: 0.362303; classification loss: 0.010265;  cosine similarity loss: 1.770455\n",
      "[ 5600/ 5482] total-loss: 0.409995; classification loss: 0.063218;  cosine similarity loss: 1.797099\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.717     0.696     0.821    106\n",
      " disgust     0.717     0.700     0.792    106\n",
      "    fear     0.717     0.674     0.604    106\n",
      "   happy     0.717     0.650     0.613    106\n",
      " neutral     0.717     0.789     0.811    106\n",
      "     sad     0.717     0.787     0.698    106\n",
      "surprise     0.717     0.727     0.679    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.717     0.718     0.717    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.031751 \n",
      "\n",
      "classification loss: 2.104425;  cosine similarity loss: 1.862180 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359775; classification loss: 0.007926;  cosine similarity loss: 1.767172\n",
      "[ 1400/ 5482] total-loss: 0.359776; classification loss: 0.008642;  cosine similarity loss: 1.764310\n",
      "[ 2800/ 5482] total-loss: 0.359402; classification loss: 0.008313;  cosine similarity loss: 1.763760\n",
      "[ 4200/ 5482] total-loss: 0.359065; classification loss: 0.008024;  cosine similarity loss: 1.763230\n",
      "[ 5600/ 5482] total-loss: 0.359083; classification loss: 0.008209;  cosine similarity loss: 1.762578\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.722     0.686     0.783    106\n",
      " disgust     0.722     0.711     0.811    106\n",
      "    fear     0.722     0.670     0.613    106\n",
      "   happy     0.722     0.698     0.632    106\n",
      " neutral     0.722     0.765     0.830    106\n",
      "     sad     0.722     0.703     0.736    106\n",
      "surprise     0.722     0.852     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.722     0.726     0.722    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.963533 \n",
      "\n",
      "classification loss: 2.006953;  cosine similarity loss: 1.862218 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.360849; classification loss: 0.008301;  cosine similarity loss: 1.771042\n",
      "[ 1400/ 5482] total-loss: 0.359907; classification loss: 0.008479;  cosine similarity loss: 1.765616\n",
      "[ 2800/ 5482] total-loss: 0.538815; classification loss: 0.229813;  cosine similarity loss: 1.774823\n",
      "[ 4200/ 5482] total-loss: 0.359294; classification loss: 0.008226;  cosine similarity loss: 1.763567\n",
      "[ 5600/ 5482] total-loss: 0.359325; classification loss: 0.008194;  cosine similarity loss: 1.763851\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.710     0.758     0.708    106\n",
      " disgust     0.710     0.735     0.783    106\n",
      "    fear     0.710     0.581     0.679    106\n",
      "   happy     0.710     0.680     0.623    106\n",
      " neutral     0.710     0.690     0.840    106\n",
      "     sad     0.710     0.745     0.689    106\n",
      "surprise     0.710     0.841     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.710     0.718     0.710    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 2.024456 \n",
      "\n",
      "classification loss: 2.094886;  cosine similarity loss: 1.860121 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359615; classification loss: 0.007813;  cosine similarity loss: 1.766822\n",
      "[ 1400/ 5482] total-loss: 0.360125; classification loss: 0.008877;  cosine similarity loss: 1.765118\n",
      "[ 2800/ 5482] total-loss: 0.362445; classification loss: 0.008124;  cosine similarity loss: 1.779731\n",
      "[ 4200/ 5482] total-loss: 0.359931; classification loss: 0.008395;  cosine similarity loss: 1.766073\n",
      "[ 5600/ 5482] total-loss: 0.359855; classification loss: 0.008860;  cosine similarity loss: 1.763835\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.716     0.689     0.774    106\n",
      " disgust     0.716     0.720     0.802    106\n",
      "    fear     0.716     0.698     0.632    106\n",
      "   happy     0.716     0.585     0.585    106\n",
      " neutral     0.716     0.811     0.811    106\n",
      "     sad     0.716     0.717     0.764    106\n",
      "surprise     0.716     0.810     0.642    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.716     0.719     0.716    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.974449 \n",
      "\n",
      "classification loss: 2.021113;  cosine similarity loss: 1.865565 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.371077; classification loss: 0.021777;  cosine similarity loss: 1.768276\n",
      "[ 1400/ 5482] total-loss: 0.359347; classification loss: 0.008354;  cosine similarity loss: 1.763320\n",
      "[ 2800/ 5482] total-loss: 0.360298; classification loss: 0.009156;  cosine similarity loss: 1.764866\n",
      "[ 4200/ 5482] total-loss: 0.359492; classification loss: 0.008068;  cosine similarity loss: 1.765189\n",
      "[ 5600/ 5482] total-loss: 0.359693; classification loss: 0.008882;  cosine similarity loss: 1.762937\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.709     0.686     0.764    106\n",
      " disgust     0.709     0.748     0.783    106\n",
      "    fear     0.709     0.656     0.575    106\n",
      "   happy     0.709     0.602     0.613    106\n",
      " neutral     0.709     0.736     0.868    106\n",
      "     sad     0.709     0.762     0.726    106\n",
      "surprise     0.709     0.779     0.632    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.709     0.710     0.709    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.035395 \n",
      "\n",
      "classification loss: 2.109419;  cosine similarity loss: 1.862670 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.359399; classification loss: 0.008132;  cosine similarity loss: 1.764469\n",
      "[ 1400/ 5482] total-loss: 0.359679; classification loss: 0.008631;  cosine similarity loss: 1.763871\n",
      "[ 2800/ 5482] total-loss: 0.362092; classification loss: 0.009221;  cosine similarity loss: 1.773573\n",
      "[ 4200/ 5482] total-loss: 0.359399; classification loss: 0.008543;  cosine similarity loss: 1.762825\n",
      "[ 5600/ 5482] total-loss: 0.359261; classification loss: 0.008028;  cosine similarity loss: 1.764194\n",
      "           accuracy  precision  recall   support\n",
      "   angry     0.713     0.670     0.726    106\n",
      " disgust     0.713     0.723     0.811    106\n",
      "    fear     0.713     0.711     0.557    106\n",
      "   happy     0.713     0.595     0.623    106\n",
      " neutral     0.713     0.771     0.858    106\n",
      "     sad     0.713     0.736     0.764    106\n",
      "surprise     0.713     0.802     0.651    106\n",
      "                                          742\n",
      "\n",
      " \n",
      "     avg     0.713     0.715     0.713    \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 2.114788 \n",
      "\n",
      "classification loss: 2.221884;  cosine similarity loss: 1.864897 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "[    0/ 5482] total-loss: 0.358943; classification loss: 0.007856;  cosine similarity loss: 1.763294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mexp_trainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_em\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_wrapper_trainer_experiments.py:37\u001B[0m, in \u001B[0;36mExperimentsTrainer.train_em\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m trail \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrials_per_model_type):\n\u001B[1;32m     36\u001B[0m     lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_lr \u001B[38;5;241m/\u001B[39m  (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_quotient \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m trail)\n\u001B[0;32m---> 37\u001B[0m     highest_acc_c, higest_epoch_c, higest_true_c, higest_pred_c \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_conv_model_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs_per_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrail\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;66;03m# generate Report\u001B[39;00m\n\u001B[1;32m     39\u001B[0m     SSGenModelTrainer\u001B[38;5;241m.\u001B[39mgenAndSaveEvaluation(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/Run_Nr_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrail\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/conv\u001B[39m\u001B[38;5;124m\"\u001B[39m, higest_true_c, higest_pred_c, highest_acc_c, higest_epoch_c, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvolutional\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mencoded_dataset\u001B[38;5;241m.\u001B[39mlabel_list)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_wrapper_trainer_experiments.py:57\u001B[0m, in \u001B[0;36mExperimentsTrainer.run_conv_model_test\u001B[0;34m(self, lr, epochs, current_run)\u001B[0m\n\u001B[1;32m     55\u001B[0m model \u001B[38;5;241m=\u001B[39m SSConvModel3Sec(num_emotions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_list), xSize\u001B[38;5;241m=\u001B[39mx_size, ySize\u001B[38;5;241m=\u001B[39my_size)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     56\u001B[0m save_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Run_Nr_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_run\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/conv/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 57\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_model_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_wrapper_trainer_experiments.py:84\u001B[0m, in \u001B[0;36mExperimentsTrainer.run_model_test\u001B[0;34m(self, lr, epochs, model, save_dir, bs)\u001B[0m\n\u001B[1;32m     76\u001B[0m trainDS, testDs \u001B[38;5;241m=\u001B[39m train_val_dataset(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, val_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m     77\u001B[0m trainer \u001B[38;5;241m=\u001B[39m SSGenModelTrainer(lr\u001B[38;5;241m=\u001B[39mlr, num_epochs\u001B[38;5;241m=\u001B[39mepochs, model\u001B[38;5;241m=\u001B[39mmodel, train_dataset\u001B[38;5;241m=\u001B[39mtrainDS,\n\u001B[1;32m     78\u001B[0m                             eval_dataset\u001B[38;5;241m=\u001B[39mtestDs,\n\u001B[1;32m     79\u001B[0m                             device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, labelList\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_list,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     82\u001B[0m                             save_highest_acc_min_acc\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_highest_acc_min_acc,\n\u001B[1;32m     83\u001B[0m                             model_path \u001B[38;5;241m=\u001B[39m save_dir, regularize_dims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularize_dims)\n\u001B[0;32m---> 84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:76\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m-------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# this is the trainloop\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# --------------------- testloop and evaluation- ---------------\u001B[39;00m\n\u001B[1;32m     79\u001B[0m acc, true, preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loop(test_dataloader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/network_models/soundsream_models_and_utils/ss_trainer_gen_models.py:102\u001B[0m, in \u001B[0;36mSSGenModelTrainer.train_loop\u001B[0;34m(self, dataloader, model, loss_fn, optimizer, epoch)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(X) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m--> 102\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m# Compute prediction and loss\u001B[39;00m\n\u001B[1;32m    104\u001B[0m z \u001B[38;5;241m=\u001B[39m z\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "exp_trainer.train_em()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 10:00:38.227854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 10:00:38.701976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 10:00:38.702028: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 10:00:38.702032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with dataset of 267178 samples and validating with randomly splitted 14063 samples\n",
      "0: soundstream total loss: 545563.781, soundstream recon loss: 0.603 | discr (scale 1) loss: 2.001 | discr (scale 0.5) loss: 2.002 | discr (scale 0.25) loss: 2.000\n",
      "0: saving to ../content/soundstream/verision0.12.1/RQ12_CBS_2048_attnD_3/00_10000_1e-4_bs6_gae8_dml320-32\n",
      "0: saving model to ../content/soundstream/verision0.12.1/RQ12_CBS_2048_attnD_3/00_10000_1e-4_bs6_gae8_dml320-32\n",
      "1: soundstream total loss: 660274.273, soundstream recon loss: 0.702 | discr (scale 1) loss: 1.989 | discr (scale 0.5) loss: 1.994 | discr (scale 0.25) loss: 1.997\n",
      "2: soundstream total loss: 526542.078, soundstream recon loss: 0.547 | discr (scale 1) loss: 1.966 | discr (scale 0.5) loss: 1.990 | discr (scale 0.25) loss: 2.001\n",
      "3: soundstream total loss: 158701.781, soundstream recon loss: 0.173 | discr (scale 1) loss: 1.958 | discr (scale 0.5) loss: 1.994 | discr (scale 0.25) loss: 2.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 37\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m#soundstream.load(\"../content/soundstream/verision0.12.1/00_10000_1e-4_bs6_gae8_dml320-32/soundstream.42500.pt\")\u001B[39;00m\n\u001B[1;32m     20\u001B[0m trainer \u001B[38;5;241m=\u001B[39m SoundStreamTrainer(\n\u001B[1;32m     21\u001B[0m     soundstream,\n\u001B[1;32m     22\u001B[0m     folder \u001B[38;5;241m=\u001B[39m  \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/home/ckwdani/Music/libri\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;66;03m#standard lr 3e-4,\u001B[39;00m\n\u001B[1;32m     35\u001B[0m )\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[0;32m---> 37\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/audiolm_pytorch/trainer.py:455\u001B[0m, in \u001B[0;36mSoundStreamTrainer.train\u001B[0;34m(self, log_fn)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(\u001B[38;5;28mself\u001B[39m, log_fn \u001B[38;5;241m=\u001B[39m noop):\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_train_steps:\n\u001B[0;32m--> 455\u001B[0m         logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    456\u001B[0m         log_fn(logs)\n\u001B[1;32m    458\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining complete\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/audiolm_pytorch/trainer.py:357\u001B[0m, in \u001B[0;36mSoundStreamTrainer.train_step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    354\u001B[0m     multiscale_discr_optim\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrad_accum_every):\n\u001B[0;32m--> 357\u001B[0m     wave, \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdl_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    358\u001B[0m     wave \u001B[38;5;241m=\u001B[39m wave\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    360\u001B[0m     discr_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msoundstream(\n\u001B[1;32m    361\u001B[0m         wave,\n\u001B[1;32m    362\u001B[0m         apply_grad_penalty \u001B[38;5;241m=\u001B[39m apply_grad_penalty,\n\u001B[1;32m    363\u001B[0m         return_discr_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    364\u001B[0m         return_discr_losses_separately \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    365\u001B[0m     )\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/audiolm_pytorch/trainer.py:72\u001B[0m, in \u001B[0;36mcycle\u001B[0;34m(dl)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcycle\u001B[39m(dl):\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m---> 72\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m dl:\n\u001B[1;32m     73\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/accelerate/data_loader.py:383\u001B[0m, in \u001B[0;36mDataLoaderShard.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    382\u001B[0m     current_batch \u001B[38;5;241m=\u001B[39m send_to_device(current_batch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 383\u001B[0m next_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m current_batch\n\u001B[1;32m    385\u001B[0m current_batch \u001B[38;5;241m=\u001B[39m next_batch\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:295\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[0;32m--> 295\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/audiolm_pytorch/data.py:67\u001B[0m, in \u001B[0;36mSoundDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m     65\u001B[0m     file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfiles[idx]\n\u001B[0;32m---> 67\u001B[0m     data, sample_hz \u001B[38;5;241m=\u001B[39m \u001B[43mtorchaudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m data\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mone of your audio file (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) is empty. please remove it from your folder\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     72\u001B[0m         \u001B[38;5;66;03m# the audio has more than 1 channel, convert to mono\u001B[39;00m\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torchaudio/backend/sox_io_backend.py:222\u001B[0m, in \u001B[0;36mload\u001B[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _fallback_load_fileobj(filepath, frame_offset, num_frames, normalize, channels_first, \u001B[38;5;28mformat\u001B[39m)\n\u001B[1;32m    221\u001B[0m     filepath \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(filepath)\n\u001B[0;32m--> 222\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtorchaudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msox_io_load_audio_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_frames\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels_first\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\n\u001B[1;32m    224\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    226\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[0;32m~/Programming/Projects/masterarbeit/Jupyter/mainProject/venv/lib/python3.10/site-packages/torch/_ops.py:442\u001B[0m, in \u001B[0;36mOpOverloadPacket.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001B[39;00m\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;66;03m# is still callable from JIT\u001B[39;00m\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;66;03m# We save the function ptr as the `op` attribute on\u001B[39;00m\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;66;03m# OpOverloadPacket to access it here.\u001B[39;00m\n\u001B[0;32m--> 442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "#\n",
    "# import numpy as np\n",
    "# from audiolm_pytorch import SoundStream, SoundStreamTrainer\n",
    "#\n",
    "# soundstream = SoundStream(\n",
    "#\n",
    "#     codebook_size = 2048,\n",
    "#     rq_num_quantizers = 12,\n",
    "#     attn_window_size = 128,       # local attention receptive field at bottleneck\n",
    "#     attn_depth = 3\n",
    "#     #target_sample_hz=16000\n",
    "# )\n",
    "#\n",
    "# #soundstream.load(\"../content/soundstream/verision0.12.1/00_10000_1e-4_bs6_gae8_dml320-32/soundstream.42500.pt\")\n",
    "#\n",
    "# trainer = SoundStreamTrainer(\n",
    "#     soundstream,\n",
    "#     folder =  '/home/ckwdani/Music/libri',\n",
    "#     #'/home/ckwdani/Music/train-clean-100',\n",
    "#     batch_size = 6,\n",
    "#     grad_accum_every = 8,         # effective batch size of 32\n",
    "#     data_max_length = 320 * 32,\n",
    "#     save_results_every=1000,\n",
    "#     num_train_steps = 60001,\n",
    "#     save_model_every= 500,\n",
    "#     results_folder = '../content/soundstream/verision0.12.1/RQ12_CBS_2048_attnD_3/00_10000_1e-4_bs6_gae8_dml320-32',\n",
    "#     #lr=1e-4\n",
    "# #    lr = 5e-5,\n",
    "#     #lr = 5e-5\n",
    "#     #standard lr 3e-4,\n",
    "# ).cuda()\n",
    "#\n",
    "# trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
